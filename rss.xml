<?xml version="1.0"?>
<rss version="2.0">
    <channel>
        <title>LinuxSre云原生</title>
        <link>http://xuyong.cn</link>
        <description>专注于 Linux 运维、云计算、云原⽣等技术</description>
        <language>zh-CN</language>
        <pubDate>Wed, 09 Apr 2025 18:28:34 +0800</pubDate>
        <lastBuildDate>Wed, 09 Apr 2025 18:28:34 +0800</lastBuildDate>
        <category>Harbor</category>
        <category>Kubernetes</category>
        <category>rsync</category>
        <item>
            <guid isPermalink="true">http://xuyong.cn/posts/3166738000.html</guid>
            <title>Kubeadm高可用安装K8s集群</title>
            <link>http://xuyong.cn/posts/3166738000.html</link>
            <category>Kubernetes</category>
            <pubDate>Wed, 09 Apr 2025 18:28:34 +0800</pubDate>
            <description><![CDATA[ &lt;h2 id=&#34;kubeadm高可用安装k8s集群&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#kubeadm高可用安装k8s集群&#34;&gt;#&lt;/a&gt; Kubeadm 高可用安装 K8s 集群&lt;/h2&gt;
&lt;h4 id=&#34;1-基本配置&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-基本配置&#34;&gt;#&lt;/a&gt; 1. 基本配置&lt;/h4&gt;
&lt;h5 id=&#34;11-基本环境配置&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#11-基本环境配置&#34;&gt;#&lt;/a&gt; 1.1 基本环境配置&lt;/h5&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;IP 地址&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;k8s-master01 ~ 03&lt;/td&gt;
&lt;td&gt;192.168.1.71 ~ 73&lt;/td&gt;
&lt;td&gt;master 节点 * 3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;/&lt;/td&gt;
&lt;td&gt;192.168.1.70&lt;/td&gt;
&lt;td&gt;keepalived 虚拟 IP（不占用机器）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;k8s-node01 ~ 02&lt;/td&gt;
&lt;td&gt;192.168.1.74/75&lt;/td&gt;
&lt;td&gt;worker 节点 * 2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;em&gt;请统一替换这些网段，Pod 网段和 service 和宿主机网段不要重复！！！&lt;/em&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;em&gt;&lt;strong&gt;* 配置信息 *&lt;/strong&gt;&lt;/em&gt;&lt;/th&gt;
&lt;th&gt;备注&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;系统版本&lt;/td&gt;
&lt;td&gt;Rocky Linux 8/9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Containerd&lt;/td&gt;
&lt;td&gt;latest&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Pod 网段&lt;/td&gt;
&lt;td&gt;172.16.0.0/16&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Service 网段&lt;/td&gt;
&lt;td&gt;10.96.0.0/16&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;更改主机名（其它节点按需修改）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;hostnamectl set-hostname k8s-master01 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;配置 hosts，修改 /etc/hosts 如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# cat /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
192.168.1.71 k8s-master01
192.168.1.72 k8s-master02
192.168.1.73 k8s-master03
192.168.1.74 k8s-node01
192.168.1.75 k8s-node02
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;配置 yum 源：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 配置基础源
sed -e &#39;s|^mirrorlist=|#mirrorlist=|g&#39; \
    -e &#39;s|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g&#39; \
    -i.bak \
    /etc/yum.repos.d/*.repo

yum makecache
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;必备工具安装：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yum install wget jq psmisc vim net-tools telnet yum-utils device-mapper-persistent-data lvm2 git rsyslog -y
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;关闭防火墙、selinux、dnsmasq、swap、开启 rsyslog。服务器配置如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;systemctl disable --now firewalld 
systemctl disable --now dnsmasq
setenforce 0
sed -i &#39;s#SELINUX=enforcing#SELINUX=disabled#g&#39; /etc/sysconfig/selinux
sed -i &#39;s#SELINUX=enforcing#SELINUX=disabled#g&#39; /etc/selinux/config
systemctl enable --now rsyslog
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;关闭 swap 分区：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;swapoff -a &amp;amp;&amp;amp; sysctl -w vm.swappiness=0
sed -ri &#39;/^[^#]*swap/s@^@#@&#39; /etc/fstab
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;安装 ntpdate：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo dnf install epel-release -y
sudo dnf config-manager --set-enabled epel
sudo dnf install ntpsec
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;同步时间并配置上海时区：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
echo &#39;Asia/Shanghai&#39; &amp;gt;/etc/timezone
ntpdate time2.aliyun.com
# 加入到crontab
crontab -e
*/5 * * * * /usr/sbin/ntpdate time2.aliyun.com
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;配置 limit：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ulimit -SHn 65535
vim /etc/security/limits.conf
# 末尾添加如下内容
* soft nofile 65536
* hard nofile 131072
* soft nproc 65535
* hard nproc 655350
* soft memlock unlimited
* hard memlock unlimited
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;升级系统：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yum update -y
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;Master01 节点&lt;/mark&gt;免密钥登录其他节点，安装过程中生成配置文件和证书均在 Master01 上操作，集群管理也在 Master01 上操作：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ssh-keygen -t rsa
for i in k8s-master01 k8s-master02 k8s-master03 k8s-node01 k8s-node02;do ssh-copy-id -i .ssh/id_rsa.pub $i;done
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;注意：公有云环境，可能需要把 kubectl 放在一个非 Master 节点上&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;mark&gt;Master01 节点&lt;/mark&gt;下载安装所有的源码文件：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd /root/ ; git clone https://gitee.com/chinagei/k8s-ha-install
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;12-内核配置&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#12-内核配置&#34;&gt;#&lt;/a&gt; 1.2 内核配置&lt;/h5&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;安装 ipvsadm：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yum install ipvsadm ipset sysstat conntrack libseccomp -y
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;配置 ipvs 模块：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;modprobe -- ip_vs
modprobe -- ip_vs_rr
modprobe -- ip_vs_wrr
modprobe -- ip_vs_sh
modprobe -- nf_conntrack
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;创建 ipvs.conf，并配置开机自动加载：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vim /etc/modules-load.d/ipvs.conf 
# 加入以下内容
ip_vs
ip_vs_lc
ip_vs_wlc
ip_vs_rr
ip_vs_wrr
ip_vs_lblc
ip_vs_lblcr
ip_vs_dh
ip_vs_sh
ip_vs_fo
ip_vs_nq
ip_vs_sed
ip_vs_ftp
ip_vs_sh
nf_conntrack
ip_tables
ip_set
xt_set
ipt_set
ipt_rpfilter
ipt_REJECT
ipip
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;然后执行 systemctl enable --now systemd-modules-load.service 即可（报错不用管）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;systemctl enable --now systemd-modules-load.service
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;内核优化配置：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt;EOF &amp;gt; /etc/sysctl.d/k8s.conf
net.ipv4.ip_forward = 1
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-ip6tables = 1
fs.may_detach_mounts = 1
net.ipv4.conf.all.route_localnet = 1
vm.overcommit_memory=1
vm.panic_on_oom=0
fs.inotify.max_user_watches=89100
fs.file-max=52706963
fs.nr_open=52706963
net.netfilter.nf_conntrack_max=2310720

net.ipv4.tcp_keepalive_time = 600
net.ipv4.tcp_keepalive_probes = 3
net.ipv4.tcp_keepalive_intvl =15
net.ipv4.tcp_max_tw_buckets = 36000
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_max_orphans = 327680
net.ipv4.tcp_orphan_retries = 3
net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_max_syn_backlog = 16384
net.ipv4.ip_conntrack_max = 65536
net.ipv4.tcp_max_syn_backlog = 16384
net.ipv4.tcp_timestamps = 0
net.core.somaxconn = 16384
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;应用配置：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sysctl --system
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;配置完内核后，重启机器，之后查看内核模块是否已自动加载：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;reboot
lsmod | grep --color=auto -e ip_vs -e nf_conntrack
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2-高可用组件安装&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-高可用组件安装&#34;&gt;#&lt;/a&gt; 2. 高可用组件安装&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;注意：如果安装的不是高可用集群，haproxy 和 keepalived 无需安装&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;注意：公有云要用公有云自带的负载均衡，比如阿里云的 SLB、NLB，腾讯云的 ELB，用来替代 haproxy 和 keepalived，因为公有云大部分都是不支持 keepalived 的。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;mark&gt;所有 Master 节点&lt;/mark&gt;通过 yum 安装 HAProxy 和 KeepAlived：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yum install keepalived haproxy -y
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有 Master 节点&lt;/mark&gt;配置 HAProxy，需要注意黄色部分的 IP：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 etc]# mkdir /etc/haproxy
[root@k8s-master01 etc]# vim /etc/haproxy/haproxy.cfg 
global
  maxconn  2000
  ulimit-n  16384
  log  127.0.0.1 local0 err
  stats timeout 30s

defaults
  log global
  mode  http
  option  httplog
  timeout connect 5000
  timeout client  50000
  timeout server  50000
  timeout http-request 15s
  timeout http-keep-alive 15s

frontend monitor-in
  bind *:33305
  mode http
  option httplog
  monitor-uri /monitor

frontend k8s-master
  bind 0.0.0.0:16443       #HAProxy监听端口
  bind 127.0.0.1:16443     #HAProxy监听端口
  mode tcp
  option tcplog
  tcp-request inspect-delay 5s
  default_backend k8s-master

backend k8s-master
  mode tcp
  option tcplog
  option tcp-check
  balance roundrobin
  default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100
  server k8s-master01	192.168.1.71:6443  check       #API Server IP地址
  server k8s-master02	192.168.1.72:6443  check       #API Server IP地址
  server k8s-master03	192.168.1.73:6443  check       #API Server IP地址
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有 Master 节点&lt;/mark&gt;配置 KeepAlived，需要注意黄色部分的配置。&lt;/p&gt;
&lt;p&gt;&lt;mark&gt;Master01 节点&lt;/mark&gt;的配置：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 etc]# mkdir /etc/keepalived

[root@k8s-master01 ~]# vim /etc/keepalived/keepalived.conf 
! Configuration File for keepalived
global_defs &amp;#123;
    router_id LVS_DEVEL
script_user root
    enable_script_security
&amp;#125;
vrrp_script chk_apiserver &amp;#123;
    script &amp;quot;/etc/keepalived/check_apiserver.sh&amp;quot;
    interval 5
    weight -5
    fall 2  
rise 1
&amp;#125;
vrrp_instance VI_1 &amp;#123;
    state MASTER
    interface ens160               #网卡名称
    mcast_src_ip 192.168.1.71      #K8s-master01 IP地址
    virtual_router_id 51
    priority 101
    advert_int 2
    authentication &amp;#123;
        auth_type PASS
        auth_pass K8SHA_KA_AUTH
    &amp;#125;
    virtual_ipaddress &amp;#123;
        192.168.1.70        #VIP地址
    &amp;#125;
    track_script &amp;#123;
       chk_apiserver
    &amp;#125;
&amp;#125;	
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;Master02 节点&lt;/mark&gt;的配置：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# vim /etc/keepalived/keepalived.conf 

! Configuration File for keepalived
global_defs &amp;#123;
    router_id LVS_DEVEL
script_user root
    enable_script_security
&amp;#125;
vrrp_script chk_apiserver &amp;#123;
    script &amp;quot;/etc/keepalived/check_apiserver.sh&amp;quot;
   interval 5
    weight -5
    fall 2  
rise 1
&amp;#125;
vrrp_instance VI_1 &amp;#123;
    state BACKUP
    interface ens160                #网卡名称
    mcast_src_ip 192.168.1.72       #K8s-master02 IP地址
    virtual_router_id 51
    priority 100
    advert_int 2
    authentication &amp;#123;
        auth_type PASS
        auth_pass K8SHA_KA_AUTH
    &amp;#125;
    virtual_ipaddress &amp;#123;
        192.168.1.70              #VIP地址
    &amp;#125;
    track_script &amp;#123;
       chk_apiserver
    &amp;#125;
&amp;#125;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;Master03 节点&lt;/mark&gt;的配置：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# vim /etc/keepalived/keepalived.conf 

! Configuration File for keepalived
global_defs &amp;#123;
    router_id LVS_DEVEL
script_user root
    enable_script_security
&amp;#125;
vrrp_script chk_apiserver &amp;#123;
    script &amp;quot;/etc/keepalived/check_apiserver.sh&amp;quot;
 interval 5
    weight -5
    fall 2  
rise 1
&amp;#125;
vrrp_instance VI_1 &amp;#123;
    state BACKUP
    interface ens160                 #网卡名称
    mcast_src_ip 192.168.1.73        #K8s-master03 IP地址
    virtual_router_id 51
    priority 100
    advert_int 2
    authentication &amp;#123;
        auth_type PASS
        auth_pass K8SHA_KA_AUTH
    &amp;#125;
    virtual_ipaddress &amp;#123;
        192.168.1.70          #VIP地址
    &amp;#125;
    track_script &amp;#123;
       chk_apiserver
    &amp;#125;
&amp;#125;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有 master 节点&lt;/mark&gt;配置 KeepAlived 健康检查文件：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 keepalived]# vim /etc/keepalived/check_apiserver.sh 
#!/bin/bash

err=0
for k in $(seq 1 3)
do
    check_code=$(pgrep haproxy)
    if [[ $check_code == &amp;quot;&amp;quot; ]]; then
        err=$(expr $err + 1)
        sleep 1
        continue
    else
        err=0
        break
    fi
done

if [[ $err != &amp;quot;0&amp;quot; ]]; then
    echo &amp;quot;systemctl stop keepalived&amp;quot;
    /usr/bin/systemctl stop keepalived
    exit 1
else
    exit 0
fi
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有 master 节点&lt;/mark&gt;配置健康检查文件添加执行权限：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;chmod +x /etc/keepalived/check_apiserver.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有 master 节点&lt;/mark&gt;启动 haproxy 和 keepalived：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 keepalived]# systemctl daemon-reload
[root@k8s-master01 keepalived]# systemctl enable --now haproxy
[root@k8s-master01 keepalived]# systemctl enable --now keepalived
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;重要：如果安装了 keepalived 和 haproxy，需要测试 keepalived 是否是正常的&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;所有节点测试VIP
[root@k8s-master01 ~]# ping 192.168.1.70 -c 4
PING 192.168.1.70 (192.168.1.70) 56(84) bytes of data.
64 bytes from 192.168.1.70: icmp_seq=1 ttl=64 time=0.464 ms
64 bytes from 192.168.1.70: icmp_seq=2 ttl=64 time=0.063 ms
64 bytes from 192.168.1.70: icmp_seq=3 ttl=64 time=0.062 ms
64 bytes from 192.168.1.70: icmp_seq=4 ttl=64 time=0.063 ms

[root@k8s-master01 ~]# telnet 192.168.1.70 16443
Trying 192.168.1.70...
Connected to 192.168.1.70.
Escape character is &#39;^]&#39;.
Connection closed by foreign host.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果 ping 不通且 telnet 没有出现 ] ，则认为 VIP 不可以，不可在继续往下执行，需要排查 keepalived 的问题，比如防火墙和 selinux，haproxy 和 keepalived 的状态，监听端口等&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;所有节点查看防火墙状态必须为 disable 和 inactive：systemctl status firewalld&lt;/li&gt;
&lt;li&gt;所有节点查看 selinux 状态，必须为 disable：getenforce&lt;/li&gt;
&lt;li&gt;master 节点查看 haproxy 和 keepalived 状态：systemctl status keepalived haproxy&lt;/li&gt;
&lt;li&gt;master 节点查看监听端口：netstat -lntp&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果以上都没有问题，需要确认：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;是否是公有云机器&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;是否是私有云机器（类似 OpenStack）&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;上述公有云一般都是不支持 keepalived，私有云可能也有限制，需要和自己的私有云管理员咨询&lt;/p&gt;
&lt;h4 id=&#34;3-runtime安装&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3-runtime安装&#34;&gt;#&lt;/a&gt; 3. Runtime 安装&lt;/h4&gt;
&lt;p&gt;如果安装的版本低于 1.24，选择 Docker 和 Containerd 均可，高于 1.24 建议选择 Containerd 作为 Runtime，不再推荐使用 Docker 作为 Runtime。&lt;/p&gt;
&lt;h5 id=&#34;31-安装containerd&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#31-安装containerd&#34;&gt;#&lt;/a&gt; 3.1 安装 Containerd&lt;/h5&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;配置安装源：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yum install wget jq psmisc vim net-tools telnet yum-utils device-mapper-persistent-data lvm2 git -y
yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;安装 docker-ce（如果在以前已经安装过，需要重新安装更新一下）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# yum install docker-ce containerd -y
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;可以无需启动 Docker，只需要配置和启动 Containerd 即可。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;首先配置 Containerd 所需的模块（&lt;mark&gt;所有节点&lt;/mark&gt;）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cat &amp;lt;&amp;lt;EOF | sudo tee /etc/modules-load.d/containerd.conf
overlay
br_netfilter
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;加载模块：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# modprobe -- overlay
# modprobe -- br_netfilter
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;，配置 Containerd 所需的内核：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cat &amp;lt;&amp;lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
net.bridge.bridge-nf-call-iptables  = 1
net.ipv4.ip_forward                 = 1
net.bridge.bridge-nf-call-ip6tables = 1
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;加载内核：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# sysctl --system
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;生成 Containerd 的配置文件：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# mkdir -p /etc/containerd
# containerd config default | tee /etc/containerd/config.toml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;更改 Containerd 的 Cgroup 和 Pause 镜像配置：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sed -i &#39;s#SystemdCgroup = false#SystemdCgroup = true#g&#39; /etc/containerd/config.toml
sed -i &#39;s#k8s.gcr.io/pause#registry.cn-hangzhou.aliyuncs.com/google_containers/pause#g&#39;  /etc/containerd/config.toml
sed -i &#39;s#registry.gcr.io/pause#registry.cn-hangzhou.aliyuncs.com/google_containers/pause#g&#39;  /etc/containerd/config.toml
sed -i &#39;s#registry.k8s.io/pause#registry.cn-hangzhou.aliyuncs.com/google_containers/pause#g&#39;  /etc/containerd/config.toml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;启动 Containerd，并配置开机自启动：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# systemctl daemon-reload
# systemctl enable --now containerd
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;配置 crictl 客户端连接的运行时位置（可选）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cat &amp;gt; /etc/crictl.yaml &amp;lt;&amp;lt;EOF
runtime-endpoint: unix:///run/containerd/containerd.sock
image-endpoint: unix:///run/containerd/containerd.sock
timeout: 10
debug: false
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;4-安装kubernetes组件&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4-安装kubernetes组件&#34;&gt;#&lt;/a&gt; 4 . 安装 Kubernetes 组件&lt;/h4&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;配置源（注意更改版本号）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt;EOF | tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/rpm/
enabled=1
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/rpm/repodata/repomd.xml.key
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;首先在&lt;mark&gt; Master01 节点&lt;/mark&gt;查看最新的 Kubernetes 版本是多少：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# yum list kubeadm.x86_64 --showduplicates | sort -r
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;安装 1.32 最新版本 kubeadm、kubelet 和 kubectl：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# yum install kubeadm-1.32* kubelet-1.32* kubectl-1.32* -y
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;设置 Kubelet 开机自启动（由于还未初始化，没有 kubelet 的配置文件，此时 kubelet 无法启动，无需关心）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# systemctl daemon-reload
# systemctl enable --now kubelet
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;此时 kubelet 是起不来的，日志会有报错不影响！&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&#34;5-集群初始化&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#5-集群初始化&#34;&gt;#&lt;/a&gt; 5 . 集群初始化&lt;/h4&gt;
&lt;p&gt;以下操作在&lt;mark&gt; master01&lt;/mark&gt;（注意黄色部分）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vim kubeadm-config.yaml
apiVersion: kubeadm.k8s.io/v1beta3
bootstrapTokens:
- groups:
  - system:bootstrappers:kubeadm:default-node-token
  token: 7t2weq.bjbawausm0jaxury
  ttl: 24h0m0s
  usages:
  - signing
  - authentication
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.1.71
  bindPort: 6443
nodeRegistration:
  criSocket: unix:///var/run/containerd/containerd.sock
  name: k8s-master01
  taints:
  - effect: NoSchedule
    key: node-role.kubernetes.io/control-plane
---
apiServer:
  certSANs:
  - 192.168.1.70               # 如果搭建的不是高可用集群，把此处改为master的IP
  timeoutForControlPlane: 4m0s
apiVersion: kubeadm.k8s.io/v1beta3
certificatesDir: /etc/kubernetes/pki
clusterName: kubernetes
controlPlaneEndpoint: 192.168.1.70:16443 # 如果搭建的不是高可用集群，把此处IP改为master的IP，端口改成6443
controllerManager: &amp;#123;&amp;#125;
etcd:
  local:
    dataDir: /var/lib/etcd
imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers
kind: ClusterConfiguration
kubernetesVersion: v1.32.3    # 更改此处的版本号和kubeadm version一致
networking:
  dnsDomain: cluster.local
  podSubnet: 172.16.0.0/16    # 注意此处的网段，不要与service和节点网段冲突
  serviceSubnet: 10.96.0.0/16 # 注意此处的网段，不要与pod和节点网段冲突
scheduler: &amp;#123;&amp;#125;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;master01 节点&lt;/mark&gt;更新 kubeadm 文件：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubeadm config migrate --old-config kubeadm-config.yaml --new-config new.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;将 new.yaml 文件复制到&lt;mark&gt;其他 master 节点&lt;/mark&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;for i in k8s-master02 k8s-master03; do scp new.yaml $i:/root/; done
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;之后&lt;mark&gt;所有 Master 节点&lt;/mark&gt;提前下载镜像，可以节省初始化时间（其他节点不需要更改任何配置，包括 IP 地址也不需要更改）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubeadm config images pull --config /root/new.yaml 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;正确的反馈信息如下（&lt;em&gt;&lt;strong&gt;* 版本可能不一样 *&lt;/strong&gt;&lt;/em&gt;）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master02 ~]# kubeadm config images pull --config /root/new.yaml 
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.32.0
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.32.0
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.32.0
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.32.0
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.11.3
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.10
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.5.16-0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;Master01 节点&lt;/mark&gt;初始化，初始化以后会在 /etc/kubernetes 目录下生成对应的证书和配置文件，之后其他 Master 节点加入 Master01 即可：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubeadm init --config /root/new.yaml  --upload-certs
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;初始化成功以后，会产生 Token 值，用于其他节点加入时使用，因此要记录下初始化成功生成的 token 值（令牌值）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run &amp;quot;kubectl apply -f [podnetwork].yaml&amp;quot; with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of the control-plane node running the following command on each as root:

# 不要复制文档当中的，要去使用节点生成的
  kubeadm join 192.168.1.70:16443 --token 7t2weq.bjbawausm0jaxury \
	--discovery-token-ca-cert-hash sha256:df72788de04bbc2e8fca70becb8a9e8503a962b5d7cd9b1842a0c39930d08c94 \
	--control-plane --certificate-key c595f7f4a7a3beb0d5bdb75d9e4eff0a60b977447e76c1d6885e82c3aa43c94c

Please note that the certificate-key gives access to cluster sensitive data, keep it secret!
As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use
&amp;quot;kubeadm init phase upload-certs --upload-certs&amp;quot; to reload certs afterward.

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 192.168.1.70:16443 --token 7t2weq.bjbawausm0jaxury \
	--discovery-token-ca-cert-hash sha256:df72788de04bbc2e8fca70becb8a9e8503a962b5d7cd9b1842a0c39930d08c94
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;Master01 节点&lt;/mark&gt;配置环境变量，用于访问 Kubernetes 集群：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt;EOF &amp;gt;&amp;gt; /root/.bashrc
export KUBECONFIG=/etc/kubernetes/admin.conf
EOF
source /root/.bashrc
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;Master01 节点&lt;/mark&gt;查看节点状态：（显示 NotReady 不影响）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# kubectl get node
NAME           STATUS     ROLES           AGE   VERSION
k8s-master01   NotReady   control-plane   24s   v1.32.3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;采用初始化安装方式，所有的系统组件均以容器的方式运行并且在 kube-system 命名空间内，此时可以查看 Pod 状态（显示 pending 不影响）：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-\&#34;&gt;# kubectl get pods -n kube-system
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;51-初始化失败排查&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#51-初始化失败排查&#34;&gt;#&lt;/a&gt; 5.1 初始化失败排查&lt;/h5&gt;
&lt;p&gt;如果初始化失败，重置后再次初始化，命令如下（没有失败不要执行）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubeadm reset -f ; ipvsadm --clear  ; rm -rf ~/.kube
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果多次尝试都是初始化失败，需要看系统日志，CentOS/RockyLinux 日志路径:/var/log/messages，Ubuntu 系列日志路径:/var/log/syslog：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tail -f /var/log/messages | grep -v &amp;quot;not found&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;经常出错的原因：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Containerd 的配置文件修改的不对，自行参考《安装 containerd》小节核对&lt;/li&gt;
&lt;li&gt;new.yaml 配置问题，比如非高可用集群忘记修改 16443 端口为 6443&lt;/li&gt;
&lt;li&gt;new.yaml 配置问题，三个网段有交叉，出现 IP 地址冲突&lt;/li&gt;
&lt;li&gt;VIP 不通导致无法初始化成功，此时 messages 日志会有 VIP 超时的报错&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;52-高可用master&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#52-高可用master&#34;&gt;#&lt;/a&gt; 5.2 高可用 Master&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;其他 master&lt;/strong&gt; 加入集群，master02 和 master03 分别执行 (千万不要在 master01 再次执行，不能直接复制文档当中的命令，而是你自己刚才 master01 初始化之后产生的命令)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubeadm join 192.168.1.70:16443 --token 7t2weq.bjbawausm0jaxury \
	--discovery-token-ca-cert-hash sha256:df72788de04bbc2e8fca70becb8a9e8503a962b5d7cd9b1842a0c39930d08c94 \
	--control-plane --certificate-key c595f7f4a7a3beb0d5bdb75d9e4eff0a60b977447e76c1d6885e82c3aa43c94c
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;查看当前状态：（如果显示 NotReady 不影响）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# kubectl get node
NAME           STATUS     ROLES           AGE     VERSION
k8s-master01   NotReady   control-plane   4m23s   v1.32.3
k8s-master02   NotReady   control-plane   66s     v1.32.3
k8s-master03   NotReady   control-plane   14s     v1.32.3
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;53-token过期处理&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#53-token过期处理&#34;&gt;#&lt;/a&gt; 5.3 Token 过期处理&lt;/h5&gt;
&lt;p&gt;注意：以下步骤是上述 init 命令产生的 Token 过期了才需要执行以下步骤，如果没有过期不需要执行，直接 join 即可。&lt;/p&gt;
&lt;p&gt;Token 过期后生成新的 token：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubeadm token create --print-join-command
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Master 需要生成 --certificate-key：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubeadm init phase upload-certs  --upload-certs
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;6-node节点的配置&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#6-node节点的配置&#34;&gt;#&lt;/a&gt; 6. Node 节点的配置&lt;/h4&gt;
&lt;p&gt;Node 节点上主要部署公司的一些业务应用，生产环境中不建议 Master 节点部署系统组件之外的其他 Pod，测试环境可以允许 Master 节点部署 Pod 以节省系统资源。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubeadm join 192.168.1.70:16443 --token 7t2weq.bjbawausm0jaxury \
	--discovery-token-ca-cert-hash sha256:377702f508fe70b9d8ab68beccaa9af1b4609b754e4cc2fcc6185974e1d620b5
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;所有节点初始化完成后，查看集群状态（NotReady 不影响）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# kubectl get node
NAME           STATUS     ROLES           AGE     VERSION
k8s-master01   NotReady   control-plane   4m23s   v1.32.3
k8s-master02   NotReady   control-plane   66s     v1.32.3
k8s-master03   NotReady   control-plane   14s     v1.32.3
k8s-node01     NotReady   &amp;lt;none&amp;gt;          13s     v1.32.3
k8s-node02     NotReady   &amp;lt;none&amp;gt;          10s     v1.32.3
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;7-calico组件的安装&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#7-calico组件的安装&#34;&gt;#&lt;/a&gt; 7. Calico 组件的安装&lt;/h4&gt;
&lt;p&gt;&lt;mark&gt;所有节点&lt;/mark&gt;禁止 NetworkManager 管理 Calico 的网络接口，防止有冲突或干扰：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;gt;&amp;gt;/etc/NetworkManager/conf.d/calico.conf&amp;lt;&amp;lt;EOF
[keyfile]
unmanaged-devices=interface-name:cali*;interface-name:tunl*;interface-name:vxlan.calico;interface-name:vxlan-v6.calico;interface-name:wireguard.cali;interface-name:wg-v6.cali
EOF
systemctl daemon-reload
systemctl restart NetworkManager
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;以下步骤只在&lt;mark&gt; master01&lt;/mark&gt; 执行（.x 不需要更改）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd /root/k8s-ha-install &amp;amp;&amp;amp; git checkout manual-installation-v1.32.x &amp;amp;&amp;amp; cd calico/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;修改 Pod 网段：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;POD_SUBNET=`cat /etc/kubernetes/manifests/kube-controller-manager.yaml | grep cluster-cidr= | awk -F= &#39;&amp;#123;print $NF&amp;#125;&#39;`

sed -i &amp;quot;s#POD_CIDR#$&amp;#123;POD_SUBNET&amp;#125;#g&amp;quot; calico.yaml
kubectl apply -f calico.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;查看容器和节点状态：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# kubectl get pods -n kube-system
NAME                                       READY   STATUS    RESTARTS   AGE
calico-kube-controllers-6f497d8478-v2q8c   1/1     Running   0          24h
calico-node-7mzmb                          1/1     Running   0          24h
calico-node-ljqnl                          1/1     Running   0          24h
calico-node-njqlb                          1/1     Running   0          24h
calico-node-ph4m4                          1/1     Running   0          24h
calico-node-rx8rl                          1/1     Running   0          24h
coredns-76fccbbb6b-76559                   1/1     Running   0          24h
coredns-76fccbbb6b-hkvn7                   1/1     Running   0          24h
etcd-k8s-master01                          1/1     Running   0          24h
etcd-k8s-master02                          1/1     Running   0          24h
etcd-k8s-master03                          1/1     Running   0          24h
kube-apiserver-k8s-master01                1/1     Running   0          24h
kube-apiserver-k8s-master02                1/1     Running   0          24h
kube-apiserver-k8s-master03                1/1     Running   0          24h
kube-controller-manager-k8s-master01       1/1     Running   0          24h
kube-controller-manager-k8s-master02       1/1     Running   0          24h
kube-controller-manager-k8s-master03       1/1     Running   0          24h
kube-proxy-9dtz4                           1/1     Running   0          24h
kube-proxy-jh7rl                           1/1     Running   0          24h
kube-proxy-jvvwt                           1/1     Running   0          24h
kube-proxy-sh89l                           1/1     Running   0          24h
kube-proxy-t2j49                           1/1     Running   0          24h
kube-scheduler-k8s-master01                1/1     Running   0          24h
kube-scheduler-k8s-master02                1/1     Running   0          24h
kube-scheduler-k8s-master03                1/1     Running   0          24h
metrics-server-7d9d8df576-jgnp2            1/1     Running   0          24h
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;此时节点全部变为 Ready 状态：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# kubectl get nodes
NAME           STATUS   ROLES           AGE   VERSION
k8s-master01   Ready    control-plane   24h   v1.32.3
k8s-master02   Ready    control-plane   24h   v1.32.3
k8s-master03   Ready    control-plane   24h   v1.32.3
k8s-node01     Ready    &amp;lt;none&amp;gt;          24h   v1.32.3
k8s-node02     Ready    &amp;lt;none&amp;gt;          24h   v1.32.3
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;8-metrics部署&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#8-metrics部署&#34;&gt;#&lt;/a&gt; 8. Metrics 部署&lt;/h4&gt;
&lt;p&gt;在新版的 Kubernetes 中系统资源的采集均使用 Metrics-server，可以通过 Metrics 采集节点和 Pod 的内存、磁盘、CPU 和网络的使用率。&lt;/p&gt;
&lt;p&gt;将&lt;mark&gt; Master01 节点&lt;/mark&gt;的 front-proxy-ca.crt 复制到所有 Node 节点&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;scp /etc/kubernetes/pki/front-proxy-ca.crt k8s-node01:/etc/kubernetes/pki/front-proxy-ca.crt

scp /etc/kubernetes/pki/front-proxy-ca.crt k8s-node(其他节点自行拷贝):/etc/kubernetes/pki/front-proxy-ca.crt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;以下操作均在&lt;mark&gt; master01 节点&lt;/mark&gt;执行:&lt;/p&gt;
&lt;p&gt;安装 metrics server&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd /root/k8s-ha-install/kubeadm-metrics-server

# kubectl  create -f comp.yaml 
serviceaccount/metrics-server created
clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created
clusterrole.rbac.authorization.k8s.io/system:metrics-server created
rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created
clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created
clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created
service/metrics-server created
deployment.apps/metrics-server created
apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;查看状态：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# kubectl get po -n kube-system -l k8s-app=metrics-server
NAME                              READY   STATUS    RESTARTS   AGE
metrics-server-7d9d8df576-jgnp2   1/1     Running   0          24h
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;等 Pod 变成 1/1   Running 后，查看节点和 Pod 资源使用率：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]#  kubectl top node
NAME           CPU(cores)   CPU(%)   MEMORY(bytes)   MEMORY(%)   
k8s-master01   132m         3%       932Mi           5%          
k8s-master02   131m         3%       845Mi           5%          
k8s-master03   148m         3%       912Mi           5%          
k8s-node01     54m          1%       600Mi           3%          
k8s-node02     49m          1%       602Mi           3%          
[root@k8s-master01 ~]#  kubectl top po -A
NAMESPACE              NAME                                         CPU(cores)   MEMORY(bytes)   
ingress-nginx          ingress-nginx-controller-5v9gl               2m           98Mi            
ingress-nginx          ingress-nginx-controller-r978m               1m           104Mi           
krm                    krm-backend-d7ff675d8-vmt9z                  1m           21Mi            
krm                    krm-frontend-588ffd677b-c2pgj                1m           4Mi             
krm                    nginx-574cf48959-vcfjs                       0m           2Mi             
kube-system            calico-kube-controllers-6f497d8478-v2q8c     6m           17Mi            
kube-system            calico-node-7mzmb                            16m          176Mi           
kube-system            calico-node-ljqnl                            15m          182Mi           
kube-system            calico-node-njqlb                            19m          180Mi           
kube-system            calico-node-ph4m4                            15m          178Mi           
kube-system            calico-node-rx8rl                            17m          180Mi           
kube-system            coredns-76fccbbb6b-76559                     2m           16Mi            
kube-system            coredns-76fccbbb6b-hkvn7                     2m           16Mi            
kube-system            etcd-k8s-master01                            22m          86Mi            
kube-system            etcd-k8s-master02                            27m          84Mi            
kube-system            etcd-k8s-master03                            22m          84Mi            
kube-system            kube-apiserver-k8s-master01                  22m          267Mi           
kube-system            kube-apiserver-k8s-master02                  20m          242Mi           
kube-system            kube-apiserver-k8s-master03                  18m          241Mi           
kube-system            kube-controller-manager-k8s-master01         6m           69Mi            
kube-system            kube-controller-manager-k8s-master02         2m           21Mi            
kube-system            kube-controller-manager-k8s-master03         1m           19Mi            
kube-system            kube-proxy-9dtz4                             11m          30Mi            
kube-system            kube-proxy-jh7rl                             1m           27Mi            
kube-system            kube-proxy-jvvwt                             17m          29Mi            
kube-system            kube-proxy-sh89l                             1m           29Mi            
kube-system            kube-proxy-t2j49                             16m          29Mi            
kube-system            kube-scheduler-k8s-master01                  6m           25Mi            
kube-system            kube-scheduler-k8s-master02                  6m           25Mi            
kube-system            kube-scheduler-k8s-master03                  6m           25Mi            
kube-system            metrics-server-7d9d8df576-jgnp2              2m           26Mi            
kubernetes-dashboard   dashboard-metrics-scraper-69b4796d9b-klnwr   1m           19Mi            
kubernetes-dashboard   kubernetes-dashboard-778584b9dd-pd5ln        1m           31Mi  
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;9-dashboard部署&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#9-dashboard部署&#34;&gt;#&lt;/a&gt; 9. Dashboard 部署&lt;/h4&gt;
&lt;h5 id=&#34;91-安装dashboard&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#91-安装dashboard&#34;&gt;#&lt;/a&gt; 9.1 安装 Dashboard&lt;/h5&gt;
&lt;p&gt;Dashboard 用于展示集群中的各类资源，同时也可以通过 Dashboard 实时查看 Pod 的日志和在容器中执行一些命令等。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd /root/k8s-ha-install/dashboard/

[root@k8s-master01 dashboard]# kubectl  create -f .
serviceaccount/admin-user created
clusterrolebinding.rbac.authorization.k8s.io/admin-user created
namespace/kubernetes-dashboard created
serviceaccount/kubernetes-dashboard created
service/kubernetes-dashboard created
secret/kubernetes-dashboard-certs created
secret/kubernetes-dashboard-csrf created
secret/kubernetes-dashboard-key-holder created
configmap/kubernetes-dashboard-settings created
role.rbac.authorization.k8s.io/kubernetes-dashboard created
clusterrole.rbac.authorization.k8s.io/kubernetes-dashboard created
rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created
clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created
deployment.apps/kubernetes-dashboard created
service/dashboard-metrics-scraper created
deployment.apps/dashboard-metrics-scraper created
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;92-登录dashboard&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#92-登录dashboard&#34;&gt;#&lt;/a&gt; 9.2 登录 dashboard&lt;/h5&gt;
&lt;p&gt;在谷歌浏览器（Chrome）启动文件中加入启动参数，用于解决无法访问 Dashboard 的问题，参考下图：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--test-type --ignore-certificate-errors
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://imgse.com/i/pEgWfHJ&#34;&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://s21.ax1x.com/2025/04/09/pEgWfHJ.png&#34; alt=&#34;pEgWfHJ.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;更改 dashboard 的 svc 为 NodePort:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl edit svc kubernetes-dashboard -n kubernetes-dashboard
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://imgse.com/i/pEgW5NR&#34;&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://s21.ax1x.com/2025/04/09/pEgW5NR.png&#34; alt=&#34;pEgW5NR.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;将 ClusterIP 更改为 NodePort（如果已经为 NodePort 忽略此步骤）&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;查看端口号：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# kubectl get svc kubernetes-dashboard -n kubernetes-dashboard
NAME                   TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)         AGE
kubernetes-dashboard   NodePort   10.96.139.11   &amp;lt;none&amp;gt;        443:32409/TCP   24h
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;根据自己的实例端口号，通过任意安装了 kube-proxy 的宿主机的 IP + 端口即可访问到 dashboard：&lt;/p&gt;
&lt;p&gt;访问 Dashboard：&lt;a href=&#34;https://192.168.181.129:31106&#34;&gt;https://192.168.1.71:32409&lt;/a&gt; （把 IP 地址和端口改成你自己的）选择登录方式为令牌（即 token 方式），参考下图：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://imgse.com/i/pEgW736&#34;&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://s21.ax1x.com/2025/04/09/pEgW736.png&#34; alt=&#34;pEgW736.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;创建登录 Token：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl create token admin-user -n kube-system
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;将 token 值输入到令牌后，单击登录即可访问 Dashboard，参考下图：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://imgse.com/i/pEgfPv8&#34;&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://s21.ax1x.com/2025/04/09/pEgfPv8.png&#34; alt=&#34;pEgfPv8.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;10必看一些必须的配置更改&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#10必看一些必须的配置更改&#34;&gt;#&lt;/a&gt; 10.【必看】一些必须的配置更改&lt;/h4&gt;
&lt;p&gt;将 Kube-proxy 改为 ipvs 模式，因为在初始化集群的时候注释了 ipvs 配置，所以需要自行修改一下：&lt;/p&gt;
&lt;p&gt;在 master01 节点执行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl edit cm kube-proxy -n kube-system
mode: ipvs
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;更新 Kube-Proxy 的 Pod：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl patch daemonset kube-proxy -p &amp;quot;&amp;#123;\&amp;quot;spec\&amp;quot;:&amp;#123;\&amp;quot;template\&amp;quot;:&amp;#123;\&amp;quot;metadata\&amp;quot;:&amp;#123;\&amp;quot;annotations\&amp;quot;:&amp;#123;\&amp;quot;date\&amp;quot;:\&amp;quot;`date +&#39;%s&#39;`\&amp;quot;&amp;#125;&amp;#125;&amp;#125;&amp;#125;&amp;#125;&amp;quot; -n kube-system
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;验证 Kube-Proxy 模式:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01]# curl 127.0.0.1:10249/proxyMode
ipvs
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;11必看注意事项&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#11必看注意事项&#34;&gt;#&lt;/a&gt; 11.【必看】注意事项&lt;/h4&gt;
&lt;p&gt;注意：kubeadm 安装的集群，证书有效期默认是一年。master 节点的 kube-apiserver、kube-scheduler、kube-controller-manager、etcd 都是以容器运行的。可以通过 kubectl get po -n kube-system 查看。&lt;/p&gt;
&lt;p&gt;启动和二进制不同的是，kubelet 的配置文件在 /etc/sysconfig/kubelet 和 /var/lib/kubelet/config.yaml，修改后需要重启 kubelet 进程。&lt;/p&gt;
&lt;p&gt;其他组件的配置文件在 /etc/kubernetes/manifests 目录下，比如 kube-apiserver.yaml，该 yaml 文件更改后，kubelet 会自动刷新配置，也就是会重启 pod。不能再次创建该文件。&lt;/p&gt;
&lt;p&gt;kube-proxy 的配置在 kube-system 命名空间下的 configmap 中，可以通过&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl edit cm kube-proxy -n kube-system
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;进行更改，更改完成后，可以通过 patch 重启 kube-proxy&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl patch daemonset kube-proxy -p &amp;quot;&amp;#123;\&amp;quot;spec\&amp;quot;:&amp;#123;\&amp;quot;template\&amp;quot;:&amp;#123;\&amp;quot;metadata\&amp;quot;:&amp;#123;\&amp;quot;annotations\&amp;quot;:&amp;#123;\&amp;quot;date\&amp;quot;:\&amp;quot;`date +&#39;%s&#39;`\&amp;quot;&amp;#125;&amp;#125;&amp;#125;&amp;#125;&amp;#125;&amp;quot; -n kube-system
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Kubeadm 安装后，master 节点默认不允许部署 pod，可以通过以下方式删除 Taint，即可部署 Pod：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# kubectl  taint node  -l node-role.kubernetes.io/control-plane node-role.kubernetes.io/control-plane:NoSchedule-
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;12-containerd配置镜像加速&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#12-containerd配置镜像加速&#34;&gt;#&lt;/a&gt; 12. Containerd 配置镜像加速&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;# vim /etc/containerd/config.toml
#添加以下配置镜像加速服务
       [plugins.&amp;quot;io.containerd.grpc.v1.cri&amp;quot;.registry.mirrors.&amp;quot;docker.io&amp;quot;]
        endpoint=[&amp;quot;https://dockerproxy.com&amp;quot;, &amp;quot;https://mirror.baidubce.com&amp;quot;,&amp;quot;https://ccr.ccs.tencentyun.com&amp;quot;,&amp;quot;https://docker.m.daocloud.io&amp;quot;,&amp;quot;https://docker.nju.edu.cn&amp;quot;,&amp;quot;https://docker.mirrors.ustc.edu.cn&amp;quot;,&amp;quot;https://registry-1.docker.io&amp;quot;, &amp;quot;https://hbv0b596.mirror.aliyuncs.com&amp;quot;]
       [plugins.&amp;quot;io.containerd.grpc.v1.cri&amp;quot;.registry.mirrors.&amp;quot;registry.k8s.io&amp;quot;]
        endpoint=[&amp;quot;https://dockerproxy.com&amp;quot;, &amp;quot;https://mirror.baidubce.com&amp;quot;,&amp;quot;https://ccr.ccs.tencentyun.com&amp;quot;,&amp;quot;https://docker.m.daocloud.io&amp;quot;,&amp;quot;https://docker.nju.edu.cn&amp;quot;,&amp;quot;https://docker.mirrors.ustc.edu.cn&amp;quot;,&amp;quot;https://hbv0b596.mirror.aliyuncs.com&amp;quot;, &amp;quot;https://k8s.m.daocloud.io&amp;quot;, &amp;quot;https://docker.mirrors.ustc.edu.cn&amp;quot;,&amp;quot;https://hub-mirror.c.163.com&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;所有节点重新启动 Containerd：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# systemctl daemon-reload
# systemctl restart containerd
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;13-docker配置镜像加速&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#13-docker配置镜像加速&#34;&gt;#&lt;/a&gt; 13. Docker 配置镜像加速&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;# sudo mkdir -p /etc/docker
# sudo tee /etc/docker/daemon.json &amp;lt;&amp;lt;-&#39;EOF&#39;
&amp;#123;
  &amp;quot;registry-mirrors&amp;quot;: [
	  &amp;quot;https://docker.credclouds.com&amp;quot;,
	  &amp;quot;https://k8s.credclouds.com&amp;quot;,
	  &amp;quot;https://quay.credclouds.com&amp;quot;,
	  &amp;quot;https://gcr.credclouds.com&amp;quot;,
	  &amp;quot;https://k8s-gcr.credclouds.com&amp;quot;,
	  &amp;quot;https://ghcr.credclouds.com&amp;quot;,
	  &amp;quot;https://do.nark.eu.org&amp;quot;,
	  &amp;quot;https://docker.m.daocloud.io&amp;quot;,
	  &amp;quot;https://docker.nju.edu.cn&amp;quot;,
	  &amp;quot;https://docker.mirrors.sjtug.sjtu.edu.cn&amp;quot;,
	  &amp;quot;https://docker.1panel.live&amp;quot;,
	  &amp;quot;https://docker.rainbond.cc&amp;quot;
  ], 
  &amp;quot;exec-opts&amp;quot;: [&amp;quot;native.cgroupdriver=systemd&amp;quot;] 
&amp;#125;
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;所有节点重新启动 Docker：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# systemctl daemon-reload
# systemctl enable --now docker
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;本文出自于：&lt;a href=&#34;https://edu.51cto.com/course/23845.html&#34;&gt;https://edu.51cto.com/course/23845.html&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">http://xuyong.cn/posts/1922841233.html</guid>
            <title>Rsync服务实践</title>
            <link>http://xuyong.cn/posts/1922841233.html</link>
            <category>rsync</category>
            <pubDate>Sun, 30 Mar 2025 20:45:48 +0800</pubDate>
            <description><![CDATA[ &lt;h3 id=&#34;ursync服务实践u&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#ursync服务实践u&#34;&gt;#&lt;/a&gt; &lt;u&gt;Rsync 服务实践&lt;/u&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;环境准备&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;主机名&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;strong&gt;IP&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;角色&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;server&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;192.168.40.101&lt;/td&gt;
&lt;td&gt;rsync 服务端&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;client&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;192.168.40.102&lt;/td&gt;
&lt;td&gt;rsync 客户&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;1rsync服务端&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1rsync服务端&#34;&gt;#&lt;/a&gt; 1.rsync 服务端&lt;/h4&gt;
&lt;h5 id=&#34;11-关闭防火墙-selinux&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#11-关闭防火墙-selinux&#34;&gt;#&lt;/a&gt; 1.1 关闭防火墙、selinux&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@localhost ~]# hostnamectl set-hostname backup
[root@localhost ~]# bash
[root@backup ~]# hostnamectl set-hostname aizj_lb01
[root@backup ~]# systemctl stop firewalld
[root@backup ~]# systemctl disable firewalld
[root@backup ~]# sed -i &#39;s/^SELINUX=enforcing/SELINUX=disabled/g&#39; /etc/sysconfig/selinux
[root@backup ~]# sed -i &#39;s/^SELINUX=enforcing/SELINUX=disabled/g&#39; /etc/selinux/config
[root@backup ~]# yum install net-tools vim tree lrzsz wget unzip dos2unix bash-completion  lsof ntp ntpdate git -y
[root@backup ~]# yum update -y --exclude=kernel* &amp;amp;&amp;amp; reboot
[root@backup ~]# echo &#39;Asia/Shanghai&#39; &amp;gt;/etc/timezone
[root@backup ~]# ntpdate time2.aliyun.com
[root@backup ~]# crontab -e
*/5 * * * * /usr/sbin/ntpdate time2.aliyun.com &amp;amp;&amp;gt; /dev/nul
[root@backup ~]# mkdir /soft /data /scripts /backup
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;12-安装rsync&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#12-安装rsync&#34;&gt;#&lt;/a&gt; 1.2 安装 rsync&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@backup ~]# yum install -y rsync
[root@server ~]# systemctl start rsyncd
[root@server ~]# systemctl enable rsyncd
[root@backup ~]# useradd -M -s /sbin/nologin rsync
[root@backup ~]# mkdir -p /backup/mysql  /backup/file
[root@backup ~]# chown -R rsync.rsync /backup/mysql /backup/file 
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;13-修改配置文件&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#13-修改配置文件&#34;&gt;#&lt;/a&gt; 1.3 修改配置文件&lt;/h5&gt;
&lt;p&gt;&lt;em&gt;&lt;mark&gt;#生产环境中取消注释，导致备份数据报错&lt;/mark&gt;&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#带注释配置文件
[root@backup ~]# vim /etc/rsyncd.conf
uid = rsync             #运行服务的用户
gid = rsync             #运行服务的组
port = 873              #服务监听端口
fake super = yes        #服务无需使用root用户身份，即可接收文件的完整属性
use chroot = no         #禁锢目录,不允许获取root权限
max connections = 200   #最大连接数,最多能有多少个客户端跟服务端的873端口建立连接
timeout = 600           #超时时间
ignore errors          #忽略错误
read only = false      #客户是否只读
list = false           #不允许查看模块信息
auth users = rsync_backup         #定义虚拟用户，用户数据传输
secrets file = /etc/rsync.passwd  #定义虚拟用户密码认证文件
log file = /var/log/rsyncd.log    #日志文件存放的位置
[backup_mysql]         #模块名
comment = welcome to rsync_backup
path = /backup/mysql   #数据存放目录
[backup_file]          #模块名
comment = welcome to rsync_backup
path = /backup/file    #数据存放目录 

#不带注释配置文件
[root@backup ~]# cat /etc/rsyncd.conf
uid = rsync        
gid = rsync         
port = 873     
fake super = yes     
use chroot = no        
max connections = 200  
timeout = 600         
ignore errors       
read only = false    
list = false          
auth users = rsync_backup        
secrets file = /etc/rsync.passwd
log file = /var/log/rsyncd.log    
[backup_mysql]       
comment = welcome to rsync_backup
path = /backup/mysql  
[backup_file]         
comment = welcome to rsync_backup
path = /backup/file 
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;4-创建虚拟用户密码文件并设置权限&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4-创建虚拟用户密码文件并设置权限&#34;&gt;#&lt;/a&gt; 4. 创建虚拟用户密码文件并设置权限&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@backup ~]# cat /etc/rsync.passwd
rsync_backup:your passwd
[root@backup ~]# chmod 600 /etc/rsync.passwd
[root@backup ~]# systemctl restart rsyncd &amp;amp;&amp;amp; systemctl status rsyncd
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;5-检查服务端口是否开启&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#5-检查服务端口是否开启&#34;&gt;#&lt;/a&gt; 5. 检查服务端口是否开启&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@backup ~]# netstat -lntp | grep &amp;quot;rsync&amp;quot;
tcp        0      0 0.0.0.0:873             0.0.0.0:*               LISTEN      20357/rsync         
tcp6       0      0 :::873                  :::*                    LISTEN      20357/rsync 
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2-rsync客户端&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-rsync客户端&#34;&gt;#&lt;/a&gt; 2. rsync 客户端&lt;/h4&gt;
&lt;h5 id=&#34;21-安装rsync&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#21-安装rsync&#34;&gt;#&lt;/a&gt; 2.1 安装 rsync&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@db01 ~]# yum install nfs-utils -y
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;22-配置传输密码&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#22-配置传输密码&#34;&gt;#&lt;/a&gt; 2.2 配置传输密码&lt;/h5&gt;
&lt;p&gt;方法 1：将密码写入文件&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@db01 ~]#  echo &#39;your passwd&#39; &amp;gt; /etc/rsync.pass
[root@db01 ~]# cat /etc/rsync.pass 
your passwd
[root@db01 ~]# chmod 600 /etc/rsync.pass
--测试收发数据：
[root@db01 ~]# rsync -avz --password-file=/etc/rsync.pass /root/test rsync_backup@192.168.40.101::backup_file
sending incremental file list

sent 47 bytes  received 20 bytes  134.00 bytes/sec
total size is 0  speedup is 0.00
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;方法 2：使用密码环境变量 RSYNC_PASSWORD&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@db01 ~]# export RSYNC_PASSWORD=&#39;your passwd&#39;
--测试收发数据：
[root@db01 ~]# rsync -avz /root/test rsync_backup@192.168.40.101::backup_file
sending incremental file list

sent 47 bytes  received 20 bytes  134.00 bytes/sec
total size is 0  speedup is 0.00
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;ursync企业级备份案例u&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#ursync企业级备份案例u&#34;&gt;#&lt;/a&gt; &lt;u&gt;Rsync 企业级备份案例&lt;/u&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;环境准备&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;主机名&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;strong&gt;IP&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;角色&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;server&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;192.168.40.101&lt;/td&gt;
&lt;td&gt;rsync 服务端&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;client&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;192.168.40.102&lt;/td&gt;
&lt;td&gt;rsync 客户&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;客户端需求&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;客户端每天凌晨 3 点备份 MySQL 至 /backup 下以 &amp;quot;主机名_IP 地址_当前时间命名&amp;quot; 的目录中&lt;/li&gt;
&lt;li&gt;客户端推送 /backup 目录下数据备份目录至 Rsync 备份服务器&lt;/li&gt;
&lt;li&gt;客户端只保留最近七天的备份数据，避免浪费磁盘空间&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;服务端需求&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;服务端部署 rsync 服务，用于接收用户的备份数据&lt;/li&gt;
&lt;li&gt;服务端每天校验客户端推送过来的数据是否完整，并将结果以邮件的方式发送给管理员&lt;/li&gt;
&lt;li&gt;服务端仅保留 6 个月的备份数据&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：所有服务器的备份目录均为 /backup，所有脚本存放目录均为 /scripts。&lt;/p&gt;
&lt;h4 id=&#34;1-服务端部署rsync服务&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-服务端部署rsync服务&#34;&gt;#&lt;/a&gt; &lt;strong&gt;1. 服务端部署 rsync 服务&lt;/strong&gt;&lt;/h4&gt;
&lt;h5 id=&#34;11-关闭防火墙-selinux-2&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#11-关闭防火墙-selinux-2&#34;&gt;#&lt;/a&gt; 1.1 关闭防火墙、selinux&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@localhost ~]# hostnamectl set-hostname backup
[root@localhost ~]# bash
[root@backup ~]# hostnamectl set-hostname aizj_lb01
[root@backup ~]# systemctl stop firewalld
[root@backup ~]# systemctl disable firewalld
[root@backup ~]# sed -i &#39;s/^SELINUX=enforcing/SELINUX=disabled/g&#39; /etc/sysconfig/selinux
[root@backup ~]# sed -i &#39;s/^SELINUX=enforcing/SELINUX=disabled/g&#39; /etc/selinux/config
[root@backup ~]# yum install net-tools vim tree lrzsz wget unzip dos2unix bash-completion  lsof ntp ntpdate git -y
[root@backup ~]# yum update -y --exclude=kernel* &amp;amp;&amp;amp; reboot
[root@backup ~]# echo &#39;Asia/Shanghai&#39; &amp;gt;/etc/timezone
[root@backup ~]# ntpdate time2.aliyun.com
[root@backup ~]# crontab -e
*/5 * * * * /usr/sbin/ntpdate time2.aliyun.com &amp;amp;&amp;gt; /dev/nul
[root@backup ~]# mkdir /soft /data /scripts /backup
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;12-安装rsync-2&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#12-安装rsync-2&#34;&gt;#&lt;/a&gt; 1.2 安装 rsync&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@backup ~]# yum install -y rsync
[root@server ~]# systemctl start rsyncd
[root@server ~]# systemctl enable rsyncd
[root@backup ~]# useradd -M -s /sbin/nologin rsync
[root@backup ~]# mkdir -p /backup/mysql  /backup/file
[root@backup ~]# chown -R rsync.rsync /backup/mysql /backup/file 
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;13-修改配置文件-2&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#13-修改配置文件-2&#34;&gt;#&lt;/a&gt; 1.3 修改配置文件&lt;/h5&gt;
&lt;p&gt;&lt;em&gt;&lt;mark&gt;#生产环境中取消注释，导致备份数据报错&lt;/mark&gt;&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#带注释配置文件
[root@backup ~]# vim /etc/rsyncd.conf
uid = rsync             #运行服务的用户
gid = rsync             #运行服务的组
port = 873              #服务监听端口
fake super = yes        #服务无需使用root用户身份，即可接收文件的完整属性
use chroot = no         #禁锢目录,不允许获取root权限
max connections = 200   #最大连接数,最多能有多少个客户端跟服务端的873端口建立连接
timeout = 600           #超时时间
ignore errors          #忽略错误
read only = false      #客户是否只读
list = false           #不允许查看模块信息
auth users = rsync_backup         #定义虚拟用户，用户数据传输
secrets file = /etc/rsync.passwd  #定义虚拟用户密码认证文件
log file = /var/log/rsyncd.log    #日志文件存放的位置
[backup_mysql]         #模块名
comment = welcome to rsync_backup
path = /backup/mysql   #数据存放目录
[backup_file]          #模块名
comment = welcome to rsync_backup
path = /backup/file    #数据存放目录 

#不带注释配置文件
[root@backup ~]# cat /etc/rsyncd.conf
uid = rsync        
gid = rsync         
port = 873     
fake super = yes     
use chroot = no        
max connections = 200  
timeout = 600         
ignore errors       
read only = false    
list = false          
auth users = rsync_backup        
secrets file = /etc/rsync.passwd
log file = /var/log/rsyncd.log    
[backup_mysql]       
comment = welcome to rsync_backup
path = /backup/mysql  
[backup_file]         
comment = welcome to rsync_backup
path = /backup/file 
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;4-创建虚拟用户密码文件并设置权限-2&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4-创建虚拟用户密码文件并设置权限-2&#34;&gt;#&lt;/a&gt; 4. 创建虚拟用户密码文件并设置权限&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@backup ~]# cat /etc/rsync.passwd
rsync_backup:your passwd
[root@backup ~]# chmod 600 /etc/rsync.passwd
[root@backup ~]# systemctl restart rsyncd &amp;amp;&amp;amp; systemctl status rsyncd
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;5-检查服务端口是否开启-2&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#5-检查服务端口是否开启-2&#34;&gt;#&lt;/a&gt; 5. 检查服务端口是否开启&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@backup ~]# netstat -lntp | grep &amp;quot;rsync&amp;quot;
tcp        0      0 0.0.0.0:873             0.0.0.0:*               LISTEN      20357/rsync         
tcp6       0      0 :::873                  :::*                    LISTEN      20357/rsync 
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2-rsync客户端-2&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-rsync客户端-2&#34;&gt;#&lt;/a&gt; 2. rsync 客户端&lt;/h4&gt;
&lt;h5 id=&#34;21-安装rsync-2&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#21-安装rsync-2&#34;&gt;#&lt;/a&gt; 2.1 安装 rsync&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@db01 ~]# yum install nfs-utils -y
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;22-测试客户端备份数据并推送至rsync服务器&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#22-测试客户端备份数据并推送至rsync服务器&#34;&gt;#&lt;/a&gt; 2.2 测试客户端备份数据并推送至 rsync 服务器&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@db01 ~]# export RSYNC_PASSWORD=&#39;your passwd&#39;
[root@db01 ~]# rsync -avz /root/test rsync_backup@192.168.40.101::backup_file
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;23-客户端备份数据并推送至rsync服务器&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#23-客户端备份数据并推送至rsync服务器&#34;&gt;#&lt;/a&gt; &lt;strong&gt;2.3 客户端备份数据并推送至 rsync 服务器&lt;/strong&gt;&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@db01 ~]# mkdir /scripts
[root@db01 ~]# cat /scripts/mysql_backup.sh 
#!/bin/bash
export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin

#1、定义变量
Host=$(hostname)
Ip=$(ifconfig ens192 | awk &#39;NR==2&amp;#123;print $2&amp;#125;&#39;)
Date=$(date +%F)
BackupDir=/backup/mysql
Dest=$&amp;#123;BackupDir&amp;#125;/$&amp;#123;Host&amp;#125;_$&amp;#123;Ip&amp;#125;_$&amp;#123;Date&amp;#125;
FILE_NAME=mysql_backup_`date &#39;+%Y%m%d%H%M%S&#39;`;
OLDBINLOG=/var/lib/mysql/oldbinlog

#2、创建备份目录
if [ ! -d $Dest ];then
  mkdir -p $Dest
fi

#3、备份目录
/usr/bin/mysqldump -u&#39;root&#39; -p&#39;your passwd&#39; nf_flms &amp;gt; $Dest/nf-flms_$&amp;#123;FILE_NAME&amp;#125;.sql
tar -czvf $Dest/$&amp;#123;FILE_NAME&amp;#125;.tar.gz $Dest/nf-flms_$&amp;#123;FILE_NAME&amp;#125;.sql
rm -rf $Dest/*$&amp;#123;FILE_NAME&amp;#125;.sql
echo &amp;quot;Your database backup successfully&amp;quot;

#4、校验
md5sum $Dest/* &amp;gt;$Dest/backup_check_$Date

#5、将备份目录推动到rsync服务端
Rsync_Ip=192.168.1.145
Rsync_user=rsync_backup
Rsync_Module=backup_mysql
export RSYNC_PASSWORD=your passwd
rsync -avz $Dest $Rsync_user@$Rsync_Ip::$Rsync_Module

#6、删除15天备份目录
find $Dest -type d -mtime +15 | xargs rm -rf
echo &amp;quot;remove file  successfully&amp;quot;

[root@db01 ~]# chmod +x /scripts/etc_backup.sh
[root@db01 ~]# crontab -e
00 03 * * * /bin/bash /scripts/mysql_backup.sh &amp;amp;&amp;gt; /dev/null
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;24-服务端校验数据并将结果以邮件发送给管理员&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#24-服务端校验数据并将结果以邮件发送给管理员&#34;&gt;#&lt;/a&gt; &lt;strong&gt;2.4 服务端校验数据并将结果以邮件发送给管理员&lt;/strong&gt;&lt;/h5&gt;
&lt;h6 id=&#34;241-配置邮件服务&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#241-配置邮件服务&#34;&gt;#&lt;/a&gt; 2.4.1 配置邮件服务&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;[root@backup ~]# yum -y install mailx
[root@backup ~]# cat /etc/mail.rc      #最后一行插入
set from=373370405@qq.com
set smtp=smtps://smtp.qq.com:465
set smtp-auth-user=373370405@qq.com
set smtp-auth-password=**********   # 发件邮箱的授权码
set smtp-auth=login
set ssl-verify=ignore
set nss-config-dir=/etc/pki/nssdb
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;242-发送邮件测试&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#242-发送邮件测试&#34;&gt;#&lt;/a&gt; 2.4.2 发送邮件测试&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;[root@backup ~]#  echo Hello World | mail -s test 373370405@qq.com &amp;amp;&amp;gt; /dev/null
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;243-配置脚本校验数据并将结果发送给管理员&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#243-配置脚本校验数据并将结果发送给管理员&#34;&gt;#&lt;/a&gt; 2.4.3 配置脚本校验数据并将结果发送给管理员&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;[root@backup mysql]# cat /scripts/check_backup.sh 
#!/bin/bash
export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin

#1、定义变量
Path=/backup/mysql
Date=$(date +%F)

#2、查看flag文件，并对对文件进行校验,然后将校验的结果保存至result_时间
find $Path -type f -name &amp;quot;backup_check_$&amp;#123;Date&amp;#125;*&amp;quot;|xargs md5sum -c &amp;gt;$Path/result_$&amp;#123;Date&amp;#125;

#3、将校验结果发送邮件给管理员
mail -s &amp;quot;Mysql Backup&amp;quot; 373370405@qq.com &amp;lt;$Path/result_$&amp;#123;Date&amp;#125; &amp;amp;&amp;gt; /dev/null

#4、删除超过7天的校验结果文件，删除超过180天的备份数据文件
find $Path -type f -name &amp;quot;result*&amp;quot; -mtime +7 | xargs rm -rf
find $Path -type f -mtime +180 | xargs rm -rf
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;244-写计划任务&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#244-写计划任务&#34;&gt;#&lt;/a&gt; &lt;strong&gt;2.4.4 写计划任务&lt;/strong&gt;&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;[root@backup ~]# chmod +x /scripts/check_backup.sh 
[root@db01 ~]# crontab -e
00 06 * * * /bin/bash /scripts/mysql_backup.sh &amp;amp;&amp;gt; /dev/null
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;rsyncsersync实现数据实时同步&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#rsyncsersync实现数据实时同步&#34;&gt;#&lt;/a&gt; Rsync+sersync 实现数据实时同步&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;环境准备&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;主机名&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;strong&gt;IP&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;角色&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;server&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;192.168.40.101&lt;/td&gt;
&lt;td&gt;rsync 服务端&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;client&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;192.168.40.102&lt;/td&gt;
&lt;td&gt;rsync 客户&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;1rsync服务端-2&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1rsync服务端-2&#34;&gt;#&lt;/a&gt; 1.rsync 服务端&lt;/h4&gt;
&lt;h5 id=&#34;11-关闭防火墙-selinux-3&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#11-关闭防火墙-selinux-3&#34;&gt;#&lt;/a&gt; 1.1 关闭防火墙、selinux&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@localhost ~]# hostnamectl set-hostname backup
[root@localhost ~]# bash
[root@backup ~]# hostnamectl set-hostname aizj_lb01
[root@backup ~]# systemctl stop firewalld
[root@backup ~]# systemctl disable firewalld
[root@backup ~]# sed -i &#39;s/^SELINUX=enforcing/SELINUX=disabled/g&#39; /etc/sysconfig/selinux
[root@backup ~]# sed -i &#39;s/^SELINUX=enforcing/SELINUX=disabled/g&#39; /etc/selinux/config
[root@backup ~]# yum install net-tools vim tree lrzsz wget unzip dos2unix bash-completion  lsof ntp ntpdate git -y
[root@backup ~]# yum update -y --exclude=kernel* &amp;amp;&amp;amp; reboot
[root@backup ~]# echo &#39;Asia/Shanghai&#39; &amp;gt;/etc/timezone
[root@backup ~]# ntpdate time2.aliyun.com
[root@backup ~]# crontab -e
*/5 * * * * /usr/sbin/ntpdate time2.aliyun.com &amp;amp;&amp;gt; /dev/nul
[root@backup ~]# mkdir /soft /data /scripts /backup
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;12-安装rsync-3&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#12-安装rsync-3&#34;&gt;#&lt;/a&gt; 1.2 安装 rsync&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@backup ~]# yum install -y rsync
[root@server ~]# systemctl start rsyncd
[root@server ~]# systemctl enable rsyncd
[root@backup ~]# useradd -M -s /sbin/nologin rsync
[root@backup ~]# mkdir -p /backup/mysql  /backup/file
[root@backup ~]# chown -R rsync.rsync /backup/mysql /backup/file 
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;13-修改配置文件-3&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#13-修改配置文件-3&#34;&gt;#&lt;/a&gt; 1.3 修改配置文件&lt;/h5&gt;
&lt;p&gt;&lt;em&gt;&lt;mark&gt;#生产环境中取消注释，导致备份数据报错&lt;/mark&gt;&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#带注释配置文件
[root@backup ~]# vim /etc/rsyncd.conf
uid = rsync             #运行服务的用户
gid = rsync             #运行服务的组
port = 873              #服务监听端口
fake super = yes        #服务无需使用root用户身份，即可接收文件的完整属性
use chroot = no         #禁锢目录,不允许获取root权限
max connections = 200   #最大连接数,最多能有多少个客户端跟服务端的873端口建立连接
timeout = 600           #超时时间
ignore errors          #忽略错误
read only = false      #客户是否只读
list = false           #不允许查看模块信息
auth users = rsync_backup         #定义虚拟用户，用户数据传输
secrets file = /etc/rsync.passwd  #定义虚拟用户密码认证文件
log file = /var/log/rsyncd.log    #日志文件存放的位置
[backup_mysql]         #模块名
comment = welcome to rsync_backup
path = /backup/mysql   #数据存放目录
[backup_file]          #模块名
comment = welcome to rsync_backup
path = /backup/file    #数据存放目录 

#不带注释配置文件
[root@backup ~]# cat /etc/rsyncd.conf
uid = rsync        
gid = rsync         
port = 873     
fake super = yes     
use chroot = no        
max connections = 200  
timeout = 600         
ignore errors       
read only = false    
list = false          
auth users = rsync_backup        
secrets file = /etc/rsync.passwd
log file = /var/log/rsyncd.log    
[backup_mysql]       
comment = welcome to rsync_backup
path = /backup/mysql  
[backup_file]         
comment = welcome to rsync_backup
path = /backup/file 
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;4-创建虚拟用户密码文件并设置权限-3&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4-创建虚拟用户密码文件并设置权限-3&#34;&gt;#&lt;/a&gt; 4. 创建虚拟用户密码文件并设置权限&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@backup ~]# cat /etc/rsync.passwd
rsync_backup:your passwd
[root@backup ~]# chmod 600 /etc/rsync.passwd
[root@backup ~]# systemctl restart rsyncd &amp;amp;&amp;amp; systemctl status rsyncd
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;5-检查服务端口是否开启-3&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#5-检查服务端口是否开启-3&#34;&gt;#&lt;/a&gt; 5. 检查服务端口是否开启&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@backup ~]# netstat -lntp | grep &amp;quot;rsync&amp;quot;
tcp        0      0 0.0.0.0:873             0.0.0.0:*               LISTEN      20357/rsync         
tcp6       0      0 :::873                  :::*                    LISTEN      20357/rsync 
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2-客户端安装sersync&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-客户端安装sersync&#34;&gt;#&lt;/a&gt; 2. 客户端安装 sersync&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;2.1 安装 sercync 依赖&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@nfs ~]# yum install -y inotify-tools rsync
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;2.2 安装 sercync&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@nfs ~]# mkdir -p /soft
[root@nfs ~]# cd /soft/
[root@nfs ~]# wget https://down.whsir.com/downloads/sersync2.5.4_64bit_binary_stable_final.tar.gz
[root@nfs soft]# tar -xf sersync2.5.4_64bit_binary_stable_final.tar.gz
[root@nfs soft]# mv GNU-Linux-x86 /usr/local/sersync
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;23-修改配置文件&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#23-修改配置文件&#34;&gt;#&lt;/a&gt; 2.3 &lt;strong&gt;修改配置文件&lt;/strong&gt;&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@nfs soft]# cd /usr/local/sersync/
[root@nfs sersync]# cp confxml.xml confxml.xml.bak
[root@nfs sersync]# vim confxml.xml
...
5    &amp;lt;fileSystem xfs=&amp;quot;true&amp;quot;/&amp;gt;    #第5行 false改为true
13          &amp;lt;delete start=&amp;quot;true&amp;quot;/&amp;gt; #第13-20行 false改为true,#说明：监控以上变化推送
14        &amp;lt;createFolder start=&amp;quot;true&amp;quot;/&amp;gt;
15        &amp;lt;createFile start=&amp;quot;false&amp;quot;/&amp;gt;
16        &amp;lt;closeWrite start=&amp;quot;true&amp;quot;/&amp;gt;
17        &amp;lt;moveFrom start=&amp;quot;true&amp;quot;/&amp;gt;
18        &amp;lt;moveTo start=&amp;quot;true&amp;quot;/&amp;gt;
19        &amp;lt;attrib start=&amp;quot;true&amp;quot;/&amp;gt;
20        &amp;lt;modify start=&amp;quot;true&amp;quot;/&amp;gt;
24        &amp;lt;localpath watch=&amp;quot;/data&amp;quot;&amp;gt;      #监控的本地目录
25             &amp;lt;remote ip=&amp;quot;192.168.1.145&amp;quot; name=&amp;quot;backup_file&amp;quot;/&amp;gt;  #rsync服务端IP和模块名backup_file
30      &amp;lt;commonParams params=&amp;quot;-avz&amp;quot;/&amp;gt;  #rsync命令选项
31      &amp;lt;auth start=&amp;quot;true&amp;quot; users=&amp;quot;rsync_backup&amp;quot; passwordfile=&amp;quot;/etc/rsync.passwd&amp;quot;/&amp;gt; #rsync认证信息
...
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;24-生成密码文件&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#24-生成密码文件&#34;&gt;#&lt;/a&gt; 2.4 生成密码文件&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@nfs sersync]# echo &#39;your passwd&#39; &amp;gt; /etc/rsync.passwd
[root@nfs sersync]# chmod 600 /etc/rsync.passwd
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;25-启动sersync&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#25-启动sersync&#34;&gt;#&lt;/a&gt; 2.5 启动 sersync&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@nfs sersync]# ln -s /usr/local/sersync/sersync2 /usr/bin/
[root@nfs sersync]# sersync2 -dro /usr/local/sersync/confxml.xml     #针对配置文件confxml.xml启动sersync
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;2.5 设置 sersync 开机自启&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@qzj_nfs sersync]# vim /etc/rc.d/rc.local   
/usr/local/sersync/sersync2 -d -r -o  /usr/local/sersync/confxml.xml  #在最后添加一行
[root@qzj_nfs sersync]# chmod +x /etc/rc.d/rc.local
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;2.6 测试&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;在客户端 /data 目录增删改目录文件，rsync 服务端数据存放目录变化&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@backup backup]# watch ls
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;2.7 添加脚本监控 sersync 是否正常运行&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@nfs sersync]# cat /scripts/check_sersync.sh 
#!/bin/sh
sersync=&amp;quot;/usr/local/sersync/sersync2&amp;quot;
confxml=&amp;quot;/usr/local/sersync/confxml.xml&amp;quot;
status=$(ps aux |grep &#39;sersync2&#39;|grep -v &#39;grep&#39;|wc -l)
if [ $status -eq 0 ];
then
$sersync -d -r -o $confxml &amp;amp;
else
exit 0;
fi

[root@nfs sersync]# chmod +x /scripts/check_sersync.sh
[root@nfs sersync]# crontab -l
*/5 * * * * /usr/bin/sh /scripts/check_sersync.sh &amp;amp;&amp;gt; /dev/null
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;补充： 多实例情况&lt;/strong&gt;&lt;/em&gt;&lt;br /&gt;
 1、配置多个 confxml.xml 文件（比如：www、bbs、blog.... 等等）&lt;br /&gt;
2、修改端口、同步路径、模块名称&lt;br /&gt;
 3、根据不同的需求同步对应的实例文件&lt;br /&gt;
 /usr/local/sersync/sersync2 -dro /usr/local/sersync/www_confxml.xml&lt;br /&gt;
/usr/local/sersync/sersync2 -dro /usr/local/sersync/bbs_confxml.xml&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">http://xuyong.cn/posts/3071070978.html</guid>
            <title>企业级私有仓库Harbor搭建</title>
            <link>http://xuyong.cn/posts/3071070978.html</link>
            <category>Harbor</category>
            <pubDate>Sun, 30 Mar 2025 16:17:00 +0800</pubDate>
            <description><![CDATA[ &lt;h3 id=&#34;企业级私有仓库harbor&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#企业级私有仓库harbor&#34;&gt;#&lt;/a&gt; 企业级私有仓库 Harbor&lt;/h3&gt;
&lt;p&gt;企业部署 Kuberetes 集群环境之后，我们就可以将原来在传统虚拟机上运行的业务，迁移到 kubernetes 上，让 Kubernetes 通过容器的方式来管理。而一旦我们需要将传统业务使用容器的方式运行起来，就需要构建很多镜像，那么这些镜像就需要有一个专门的位置存储起来，为我们提供镜像上传和镜像下载等功能。但我们不能使用阿里云或者 Dockerhub 等仓库，首先拉取速度比较慢，其次镜像的安全性无法保证，所以就需要部署一个私有的镜像仓库来管理这些容器镜像。同时该仓库还需要提供高可用功能，确保随时都能上传和下载可用的容器镜像。&lt;/p&gt;
&lt;h4 id=&#34;1-关闭防火墙-selinux-环境配置&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-关闭防火墙-selinux-环境配置&#34;&gt;#&lt;/a&gt; 1、关闭防火墙、Selinux、环境配置&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@harbor ~]# sudo mkdir -p /etc/docker
[root@harbor ~]# hostnamectl set-hostname harbor
[root@harbor ~]# systemctl stop firewalld
[root@harbor ~]# systemctl disable firewalld
[root@harbor ~]# sed -i &#39;s/^SELINUX=enforcing/SELINUX=disabled/g&#39; /etc/sysconfig/selinux
[root@harbor ~]# yum install net-tools vim tree lrzsz wget unzip dos2unix bash-completion  lsof ntp ntpdate -y
[root@harbor ~]# yum update -y
[root@harbor ~]# mkdir /soft /data /scripts /backup
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2-docker安装&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-docker安装&#34;&gt;#&lt;/a&gt; 2、Docker 安装&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@harbor ~]# yum install -y yum-utils device-mapper-persistent-data lvm2
[root@harbor ~]# curl -o /etc/yum.repos.d/docker-ce.repo  https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
[root@harbor ~]# yum list docker-ce --showduplicates |sort -r 
[root@harbor ~]# yum install docker-ce docker-compose -y
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;3-配置docker加速&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3-配置docker加速&#34;&gt;#&lt;/a&gt; 3、配置 Docker 加速&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@harbor ~]# sudo mkdir -p /etc/docker
[root@harbor ~]# sudo tee /etc/docker/daemon.json &amp;lt;&amp;lt;-&#39;EOF&#39;
&amp;#123;
  &amp;quot;registry-mirrors&amp;quot;: [
	  &amp;quot;https://docker.credclouds.com&amp;quot;,
	  &amp;quot;https://k8s.credclouds.com&amp;quot;,
	  &amp;quot;https://quay.credclouds.com&amp;quot;,
	  &amp;quot;https://gcr.credclouds.com&amp;quot;,
	  &amp;quot;https://k8s-gcr.credclouds.com&amp;quot;,
	  &amp;quot;https://ghcr.credclouds.com&amp;quot;,
	  &amp;quot;https://do.nark.eu.org&amp;quot;,
	  &amp;quot;https://docker.m.daocloud.io&amp;quot;,
	  &amp;quot;https://docker.nju.edu.cn&amp;quot;,
	  &amp;quot;https://docker.mirrors.sjtug.sjtu.edu.cn&amp;quot;,
	  &amp;quot;https://docker.1panel.live&amp;quot;,
	  &amp;quot;https://docker.rainbond.cc&amp;quot;
  ], 
  &amp;quot;exec-opts&amp;quot;: [&amp;quot;native.cgroupdriver=systemd&amp;quot;] 
&amp;#125;
EOF
[root@harbor ~]# systemctl enable docker --now
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;4-安装harbor&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4-安装harbor&#34;&gt;#&lt;/a&gt; 4、安装 Harbor&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@harbor ~]# cd /soft/
[root@harbor ~]# wget https://github.com/goharbor/harbor/releases/download/v2.6.1/harbor-offline-installer-v2.6.1.tgz
[root@harbor soft]# tar xf harbor-offline-installer-v2.6.1.tgz
[root@harbor soft]# cd harbor
[root@harbor harbor]# vim harbor.yml
hostname: 192.168.1.134
...
#https:
#  # https port for harbor, default is 443
#  port: 443
#  # The path of cert and key files for nginx
#  certificate: /your/certificate/path
#  private_key: /your/private/key/path
...
harbor_admin_password: Harbor12345
[root@harbor harbor]#  ./install.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;5-配置nginx负载均衡调度&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#5-配置nginx负载均衡调度&#34;&gt;#&lt;/a&gt; 5、配置 Nginx 负载均衡调度&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@lb ~]# vim s.hmallleasing.com.conf
server &amp;#123;
    listen 443 ssl;
    server_name harbor.hmallleasing.com;
    client_max_body_size 1G; 
    ssl_prefer_server_ciphers on;
    ssl_certificate  /etc/nginx/sslkey/_.hmallleasing.com_chain.crt;
    ssl_certificate_key  /etc/nginx/sslkey/_.hmallleasing.com_key.key;
    location / &amp;#123;
        proxy_pass http://192.168.1.134;
#      include proxy_params;
#        proxy_set_header Host $http_host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        
        proxy_connect_timeout 30;
        proxy_send_timeout 60;
        proxy_read_timeout 60;
        
        proxy_buffering on;
        proxy_buffer_size 32k;
        proxy_buffers 4 128k;
        proxy_temp_file_write_size 10240k;		
        proxy_max_temp_file_size 10240k;
    &amp;#125;
&amp;#125;

server &amp;#123;
    listen 80;
    server_name s.hmallleasing.com;
    return 302 https://$server_name$request_uri;
&amp;#125;
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;6-推送镜像至harbor&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#6-推送镜像至harbor&#34;&gt;#&lt;/a&gt; 6、推送镜像至 Harbor&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@harbor harbor]# docker tag beae173ccac6 harbor.hmallleasing.com/ops/busybox.v1
[root@harbor harbor]# docker push harbor.hmallleasing.com/ops/busybox.v1
[root@harbor harbor]# docker login harbor.hmallleasing.com
[root@harbor harbor]# docker push harbor.hmallleasing.com/ops/busybox.v1
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;7-harbor停止与启动&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#7-harbor停止与启动&#34;&gt;#&lt;/a&gt; 7、Harbor 停止与启动&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;#停用Harbor
[root@harbor harbor]# pwd
/soft/harbor
[root@harbor harbor]# docker-compose stop
 #启动Harbor
[root@harbor harbor]# docker-compose up -d
[root@harbor harbor]# docker-compose start
&lt;/code&gt;&lt;/pre&gt;
 ]]></description>
        </item>
    </channel>
</rss>
