<!-- build time:Mon Jun 30 2025 20:54:24 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta http-equiv="X-UA-COMPATIBLE" content="IE=edge,chrome=1"><meta name="renderer" content="webkit"><link rel="icon" type="image/ico" sizes="32x32" href="/assets/favicon.ico"><link rel="apple-touch-icon" sizes="180x180" href="/assets/favicon.ico"><link rel="alternate" href="/rss.xml" title="LinuxSre云原生" type="application/rss+xml"><link rel="alternate" href="/atom.xml" title="LinuxSre云原生" type="application/atom+xml"><link rel="alternate" type="application/json" title="LinuxSre云原生" href="http://ixuyong.cn/feed.json"><link rel="preconnect" href="https://s4.zstatic.net"><link rel="preconnect" href="https://at.alicdn.com"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Mulish:400,400italic,700,700italic%7CFredericka%20the%20Great:400,400italic,700,700italic%7CNoto%20Serif%20JP:400,400italic,700,700italic%7CNoto%20Serif%20SC:400,400italic,700,700italic%7CInconsolata:400,400italic,700,700italic&display=swap&subset=latin,latin-ext" media="none" onload="this.media&#x3D;&#39;all&#39;"><link rel="stylesheet" href="/css/app.css?v=0.4.17"><link rel="modulepreload" href="/js/chunk-GV364XSK.js"><link rel="modulepreload" href="/js/chunk-NYSE5UKM.js"><link rel="modulepreload" href="/js/chunk-RONCYO2S.js"><link rel="modulepreload" href="/js/chunk-THHXCRSX.js"><link rel="modulepreload" href="/js/chunk-WIQECBEN.js"><link rel="modulepreload" href="/js/comments-DL2IYMPZ.js"><link rel="modulepreload" href="/js/copy-tex-NADCTXPG.js"><link rel="modulepreload" href="/js/post-DA635IH6.js"><link rel="modulepreload" href="/js/quicklink-WEDHL4BA.js"><link rel="modulepreload" href="/js/search-VCZRKTM5.js"><link rel="modulepreload" href="/js/siteInit.js"><link rel="modulepreload" href="/js/waline-NNBYRQEE.js"><link rel="stylesheet" href="/css/comments-F4ZGS7LD.css" media="none" onload="this.media&#x3D;&#39;all&#39;"><link rel="stylesheet" href="/css/siteInit.css" media="none" onload="this.media&#x3D;&#39;all&#39;"><link rel="stylesheet" href="/css/waline-IDNZKML2.css" media="none" onload="this.media&#x3D;&#39;all&#39;"><link rel="preload" href="https://s21.ax1x.com/2025/03/29/pEsS0hD.png" as="image" fetchpriority="high"><meta name="keywords" content="Prometheus"><meta name="description" content="专注于 Linux 运维、云计算、云原⽣等技术"><link rel="canonical" href="http://ixuyong.cn/posts/2041568856.html"><title>Prometheus监控Kubernetes</title><meta name="generator" content="Hexo 7.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">Prometheus监控Kubernetes</h1><div class="meta"><span class="item" title="创建时间：2025-06-30 10:33:49"><span class="icon"><i class="ic i-calendar"></i></span><span class="text">发表于</span><time itemprop="dateCreated datePublished" datetime="2025-06-30T10:33:49+08:00">2025-06-30</time></span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i></span><span class="text">本文字数</span><span>274k</span><span class="text">字</span></span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i></span><span class="text">阅读时长</span><span>4:09</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span><span class="line"></span><span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">LinuxSre云原生</a></li></ul><ul class="right" id="rightNav"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div class="pjax" id="imgs"><img src="https://s21.ax1x.com/2025/03/29/pEsS0hD.png" loading="eager" decoding="async" fetchpriority="high" alt="LinuxSre云原生"></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"></path></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"></use><use xlink:href="#gentle-wave" x="48" y="3"></use><use xlink:href="#gentle-wave" x="48" y="5"></use><use xlink:href="#gentle-wave" x="48" y="7"></use></g></svg></div><main><div class="inner"><div class="pjax" id="main"><div class="article wrap"><div class="breadcrumb" itemlistelement itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i><span><a href="/">首页</a></span><i class="ic i-angle-right"></i><span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/Prometheus/" itemprop="item" rel="index" title="分类于Prometheus"><span itemprop="name">Prometheus<meta itemprop="position" content="0"></span></a></span></div><article class="post block" itemscope itemtype="http://schema.org/Article" lang="zh-CN"><link itemprop="mainEntityOfPage" href="http://ixuyong.cn/posts/2041568856.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/assets/avatar.png"><meta itemprop="name" content="Xu Yong"><meta itemprop="description" content="致力于技术布道、普及前沿技术、打造云原生系列标杆博客, 专注于 Linux 运维、云计算、云原⽣等技术"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="LinuxSre云原生"></span><div class="body md" itemprop="articleBody"><h3 id="prometheus监控kubernetes"><a class="anchor" href="#prometheus监控kubernetes">#</a> Prometheus 监控 Kubernetes</h3><h4 id="1-监控kubernetes环境准备"><a class="anchor" href="#1-监控kubernetes环境准备">#</a> 1、监控 Kubernetes 环境准备</h4><pre><code>[root@k8s-master01 ~]# kubectl get nodes
NAME           STATUS   ROLES    AGE   VERSION
k8s-master01   Ready    &lt;none&gt;   46d   v1.27.10
k8s-master02   Ready    &lt;none&gt;   46d   v1.27.10
k8s-master03   Ready    &lt;none&gt;   46d   v1.27.10
k8s-node01     Ready    &lt;none&gt;   46d   v1.27.10
k8s-node02     Ready    &lt;none&gt;   46d   v1.27.10
</code></pre><h4 id="2-部署alertmanager至kubernetes"><a class="anchor" href="#2-部署alertmanager至kubernetes">#</a> 2、部署 AlertManager ⾄ Kubernetes</h4><ul><li>①先交付 webhook_wechat、webhook_dingding；</li><li>②创建 ConfigMap，准备邮件的告警 template 模板；</li><li>③创建 ConfigMap，准备告警路由相关的配置；</li><li>④创建 HeadlessService；</li><li>⑤创建 statefulSet，运⾏ 3 个节点 AlertManager；</li><li>⑥创建 Ingress 对外提供；</li></ul><pre><code>#创建namespace
[root@k8s-master01 ~]# kubectl create ns monitoring
[root@k8s-master01 01-alert-webhook-wechat]# sed -i &quot;s#kube-prom#monitoring#g&quot; *.yaml
</code></pre><h5 id="21-部署webhook_wechat"><a class="anchor" href="#21-部署webhook_wechat">#</a> 2.1 部署 webhook_wechat</h5><p>1、编写 deployment，运⾏ webhook-wechat</p><pre><code>[root@k8s-master01 01-alert-webhook-wechat]# cat 01-webhook-wechat-deploy.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webhook-wechat
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: wechat
  template:
    metadata:
      labels:
        app: wechat
    spec:
      containers:
      - name: webchat
        image: oldxu3957/webhook_wechat_oldxu:v1.0
        args: [&quot;--port&quot;,&quot;5001&quot;]		# 默认就是5001端口
        ports:
        - containerPort: 5001

[root@k8s-master01 01-alert-webhook-wechat]# kubectl apply -f 01-webhook-wechat-deploy.yaml
[root@k8s-master01 01-alert-webhook-wechat]# kubectl get pods -n monitoring
NAME                              READY   STATUS    RESTARTS   AGE
webhook-wechat-54b5bbf677-rmr26   1/1     Running   0          16s
</code></pre><p>2、编写 Service</p><pre><code>[root@k8s-master01 01-alert-webhook-wechat]# cat 02-webhook-wechat-service.yaml 
apiVersion: v1
kind: Service
metadata:
  name: webhook-wechat-svc
  namespace: monitoring
spec:
  selector:
    app: wechat
  ports:
   - port: 5001
     targetPort: 5001
     
[root@k8s-master01 01-alert-webhook-wechat]# kubectl apply -f 02-webhook-wechat-service.yaml 
[root@k8s-master01 01-alert-webhook-wechat]# kubectl get svc -n monitoring
NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE
webhook-wechat-svc   ClusterIP   10.96.82.7   &lt;none&gt;        5001/TCP   13s
</code></pre><p>3、测试 webhook-wechat 是否能正常发送消息 (8e24a24d-3f48-4ea8-bbde-36ca84d857e4)</p><pre><code>[root@prom-node01 ~]# curl -X POST http://10.96.82.7:5001/alert?token=8e24a24d-3f48-4ea8-bbde-36ca84d857e4 \
-H &quot;Content-Type: application/json&quot; \
-d '&#123;
  &quot;alerts&quot;: [
    &#123;
      &quot;status&quot;: &quot;firing&quot;,
      &quot;labels&quot;: &#123;
        &quot;severity&quot;: &quot;critical&quot;,
        &quot;alertname&quot;: &quot;InstanceDown&quot;,
        &quot;instance&quot;: &quot;example1&quot;
      &#125;,
      &quot;annotations&quot;: &#123;
        &quot;summary&quot;: &quot;Instance example1 down&quot;,
        &quot;description&quot;: &quot;The instance example1 is down.&quot;
      &#125;,
      &quot;startsAt&quot;: &quot;2024-12-20T15:04:05Z&quot;,
      &quot;endsAt&quot;: &quot;0001-01-01T00:00:00Z&quot;
    &#125;,
   &#123;
      &quot;status&quot;: &quot;resolved&quot;,
      &quot;labels&quot;: &#123;
        &quot;severity&quot;: &quot;critical&quot;,
        &quot;alertname&quot;: &quot;InstanceDown&quot;,
        &quot;instance&quot;: &quot;example1&quot;
      &#125;,
      &quot;annotations&quot;: &#123;
        &quot;summary&quot;: &quot;Instance example1 is back up&quot;,
        &quot;description&quot;: &quot;The instance example1 has recovered.&quot;
      &#125;,
      &quot;startsAt&quot;: &quot;2024-12-20T15:04:05Z&quot;,
      &quot;endsAt&quot;: &quot;2024-12-20T16:04:05Z&quot;
    &#125;
  ]
&#125;'
</code></pre><h5 id="22-部署webhook_dingding"><a class="anchor" href="#22-部署webhook_dingding">#</a> 2.2 部署 webhook_dingding</h5><p>1、编写 deployment，运⾏ webhook-dingding</p><pre><code>[root@k8s-master01 02-alert-webhook-dingding]# cat 01-webhook-dingding-deploy.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webhook-dingding
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: dingding
  template:
    metadata:
      labels:
        app: dingding
    spec:
      containers:
      - name: dingding
        image: oldxu3957/webhook_dingding_oldxu:v1.0
        args: [&quot;--port&quot;,&quot;5002&quot;]
        ports:
        - containerPort: 5002

[root@k8s-master01 02-alert-webhook-dingding]# kubectl apply -f 01-webhook-dingding-deploy.yaml
[root@k8s-master01 02-alert-webhook-dingding]# kubectl get pods -n monitoring
NAME                                READY   STATUS    RESTARTS   AGE
webhook-dingding-6d68854649-r6smd   1/1     Running   0          14s
webhook-wechat-54b5bbf677-rmr26     1/1     Running   0          13m
</code></pre><p>2、编写 Service</p><pre><code>[root@k8s-master01 02-alert-webhook-dingding]# cat 02-webhook-dingding-service.yaml 
apiVersion: v1
kind: Service
metadata:
  name: webhook-dingding-svc
  namespace: monitoring
spec:
  selector:
    app: dingding
  ports:
  - port: 5002
    targetPort: 5002

[root@k8s-master01 02-alert-webhook-dingding]# kubectl apply -f 02-webhook-dingding-service.yaml 
[root@k8s-master01 02-alert-webhook-dingding]# kubectl get svc -n monitoring
NAME                   TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE
webhook-dingding-svc   ClusterIP   10.96.241.84   &lt;none&gt;        5002/TCP   0s
webhook-wechat-svc     ClusterIP   10.96.82.7     &lt;none&gt;        5001/TCP   12m
</code></pre><p>3、测试 webhook-wechat 是否能正常发送消息，49989606592d7ff06ee4b83120bf5a81ed1e4c3860696dcd7e663be1c66ef43f</p><pre><code>[root@k8s-master01 ~]# curl -X POST http://10.96.241.84:5002/alert?token=49989606592d7ff06ee4b83120bf5a81ed1e4c3860696dcd7e663be1c66ef43f \
-H &quot;Content-Type: application/json&quot; \
-d '&#123;
  &quot;alerts&quot;: [
    &#123;
      &quot;status&quot;: &quot;firing&quot;,
      &quot;labels&quot;: &#123;
        &quot;severity&quot;: &quot;critical&quot;,
        &quot;alertname&quot;: &quot;InstanceDown&quot;,
        &quot;instance&quot;: &quot;example1&quot;
      &#125;,
      &quot;annotations&quot;: &#123;
        &quot;summary&quot;: &quot;Instance example1 down&quot;,
        &quot;description&quot;: &quot;The instance example1 is down.&quot;
      &#125;,
      &quot;startsAt&quot;: &quot;2024-12-20T15:04:05Z&quot;,
      &quot;endsAt&quot;: &quot;0001-01-01T00:00:00Z&quot;
    &#125;,
   &#123;
      &quot;status&quot;: &quot;resolved&quot;,
      &quot;labels&quot;: &#123;
        &quot;severity&quot;: &quot;critical&quot;,
        &quot;alertname&quot;: &quot;InstanceDown&quot;,
        &quot;instance&quot;: &quot;example1&quot;
      &#125;,
      &quot;annotations&quot;: &#123;
        &quot;summary&quot;: &quot;Instance example1 is back up&quot;,
        &quot;description&quot;: &quot;The instance example1 has recovered.&quot;
      &#125;,
      &quot;startsAt&quot;: &quot;2024-12-20T15:04:05Z&quot;,
      &quot;endsAt&quot;: &quot;2024-12-20T16:04:05Z&quot;
    &#125;
  ]
&#125;'
</code></pre><h5 id="23-创建alertmanager配置"><a class="anchor" href="#23-创建alertmanager配置">#</a> 2.3 创建 AlertManager 配置</h5><p>1、使⽤ ConfigMap 创建 AlertManager 所需的配置⽂件，名称为： alert-configs</p><pre><code>[root@k8s-master01 03-alertmanager]# cat 01-alert-configs-configmap.yaml 
apiVersion: v1
kind: ConfigMap
metadata:
  name: alert-configs
  namespace: monitoring
data:
  alertmanager.yml: |-
    # 全局配置
    global:
      smtp_smarthost: 'smtp.qq.com:25'
      smtp_from: '373370405@qq.com'  	
      smtp_auth_username: '373370405@qq.com'
      smtp_auth_password: 'jmtpwlkuijaybhic'
      smtp_hello: 'qq.com'
      smtp_require_tls: false
    
    # 加载模板的路径
    templates:
      - '/etc/alertmanager/template/*.tmpl'
    
    # 路由规则
    route:
      group_by: ['alertname']
      group_wait: 30s
      group_interval: 30s
      repeat_interval: 5m
      receiver: webhook-dingding-ops		# 默认发送给钉钉
    
      # 子路由
      routes:
      - match_re:
          job: 'kube.*'
        receiver: 'webhook-wechat'			# 如果匹配到job=kube.*的都发送给微信
        continue: true
    
      - match_re:
          job: 'redis_exporter'
        receiver: 'email'		        	# 如果job=domain_exporter则都发送给email
        continue: true
    
    receivers:
    - name: 'email'
      email_configs:
      - to: '373370405@qq.com'
        send_resolved: true
        html: '&#123;&#123; template "email.html" . &#125;&#125;'   # 发送邮件内容，调用该模板进行渲染

    - name: 'webhook-wechat'
      webhook_configs:
      - url: 'http://webhook-wechat-svc:5001/alert?token=8e24a24d-3f48-4ea8-bbde-36ca84d857e4'
      
    - name: 'webhook-dingding-ops'
      webhook_configs:
      - url: 'http://webhook-dingding-svc:5002/alert?token=49989606592d7ff06ee4b83120bf5a81ed1e4c3860696dcd7e663be1c66ef43f'
      
[root@k8s-master01 03-alertmanager]# kubectl apply -f 01-alert-configs-configmap.yaml
[root@k8s-master01 03-alertmanager]# kubectl get cm -n monitoring
NAME               DATA   AGE
alert-configs      1      25s
alert-template     1      19s
kube-root-ca.crt   1      27m
</code></pre><p>2、使⽤ configmap 创建 AlertManager 邮件所依赖的模板⽂件，名称为： alert-template</p><pre><code>[root@k8s-master01 03-alertmanager]# cat 02-alert-template-configmap.yaml 
apiVersion: v1
kind: ConfigMap
metadata:
  name: alert-template
  namespace: monitoring
data:
  email.tmpl: |-
    &#123;&#123; define "email.html" &#125;&#125;
    &#123;&#123;- if gt (len .Alerts.Firing) 0 -&#125;&#125;
    &#123;&#123; range .Alerts &#125;&#125;
    &lt;h2 style=&quot;color: red;&quot;&gt;@告警通知&lt;/h2&gt;
    告警程序: AlertManager &lt;br&gt;
    告警级别: &#123;&#123; .Labels.severity &#125;&#125; &lt;br&gt;
    告警类型: &#123;&#123; .Labels.alertname &#125;&#125; &lt;br&gt;
    故障主机: &#123;&#123; .Labels.instance &#125;&#125; &lt;br&gt;
    告警主题: &#123;&#123; .Annotations.summary &#125;&#125; &lt;br&gt;
    告警详情: &#123;&#123; .Annotations.description &#125;&#125; &lt;br&gt;
    触发时间: &#123;&#123; (.StartsAt.Add 28800e9).Format "2006-01-02 15:04:05" &#125;&#125; &lt;br&gt;
    &#123;&#123; end &#125;&#125;&#123;&#123; end -&#125;&#125;
    
    &#123;&#123;- if gt (len .Alerts.Resolved) 0 -&#125;&#125;
    &#123;&#123; range .Alerts &#125;&#125;
    &lt;h2 style=&quot;color: green;&quot;&gt;@告警恢复&lt;/h2&gt;
    告警程序: AlertManager &lt;br&gt;
    告警级别: &#123;&#123; .Labels.severity &#125;&#125; &lt;br&gt;
    告警类型: &#123;&#123; .Labels.alertname &#125;&#125; &lt;br&gt;
    告警主机: &#123;&#123; .Labels.instance &#125;&#125; &lt;br&gt;
    告警主题: &#123;&#123; .Annotations.summary &#125;&#125; &lt;br&gt;
    告警详情: &#123;&#123; .Annotations.description &#125;&#125; &lt;br&gt;
    触发时间: &#123;&#123; (.StartsAt.Add 28800e9).Format "2006-01-02 15:04:05" &#125;&#125; &lt;br&gt;
    恢复时间: &#123;&#123; (.EndsAt.Add 28800e9).Format "2006-01-02 15:04:05" &#125;&#125; &lt;br&gt;
    &#123;&#123; end &#125;&#125;&#123;&#123; end -&#125;&#125;
    &#123;&#123; end &#125;&#125;
    
[root@k8s-master01 03-alertmanager]# kubectl apply -f 02-alert-template-configmap.yaml 
[root@k8s-master01 03-alertmanager]# kubectl get cm -n monitoring
NAME               DATA   AGE
alert-configs      1      25s
alert-template     1      19s
kube-root-ca.crt   1      27m
</code></pre><h5 id="24-创建headlessservice"><a class="anchor" href="#24-创建headlessservice">#</a> 2.4 创建 HeadLessService</h5><pre><code>[root@k8s-master01 03-alertmanager]# cat 03-alertmanager-headlessService.yaml 
apiVersion: v1
kind: Service
metadata:
  name: alertmanager-svc
  namespace: monitoring
spec:
  clusterIP: &quot;None&quot;
  selector:
    app: alert
  ports:
  - name: web
    port: 9093
    targetPort: 9093
  - name: cluster
    port: 9094
    targetPort: 9094
[root@k8s-master01 03-alertmanager]# kubectl apply -f 03-alertmanager-headlessService.yaml 
[root@k8s-master01 03-alertmanager]# kubectl get svc -n monitoring
NAME                   TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)             AGE
alertmanager-svc       ClusterIP   None           &lt;none&gt;        9093/TCP,9094/TCP   6s
webhook-dingding-svc   ClusterIP   10.96.241.84   &lt;none&gt;        5002/TCP            12m
webhook-wechat-svc     ClusterIP   10.96.82.7     &lt;none&gt;        5001/TCP            24m
</code></pre><h5 id="25-部署alertmanager服务"><a class="anchor" href="#25-部署alertmanager服务">#</a> 2.5 部署 AlertManager 服务</h5><p>使⽤ statefulSet 编写 AlertManager 的⾼可⽤清单⽂件</p><ul><li>1、定义 Alertmanager 实例的启动命令，包含了对应的 “配置⽂件路径 “、“数据存储路径” 以及 “Gossip 集群通信” 相关的参数。</li><li>2、定义 AlertManager 实例挂载 “邮件模板” 的 ConfigMap 资源，以及 AlertManager 主配置⽂件的 ConfigMap 资源。</li><li>3、Alertmanager 的每个实例，都需要使⽤ PVC 模板来提供数据持久化；</li><li>4、AlertManager 在启动时可以采⽤并⾏的⽅式，因为集群之间没有先后依赖关系；</li></ul><pre><code>[root@k8s-master01 03-alertmanager]# cat 04-alertmanager-statefulset.yaml 
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: alertmanager
  namespace: monitoring
spec:
  serviceName: &quot;alertmanager-svc&quot;
  podManagementPolicy: &quot;Parallel&quot;  #采用并行方式
  replicas: 3
  selector:
    matchLabels:
      app: alert
  template:
    metadata:
      labels:
        app: alert
    spec:
      volumes:
      - name: alert-cfg
        configMap:
          name: alert-configs
      - name: alert-temp-cfg
        configMap:
          name: alert-template
      containers:
      - name: alertmanager
        image: prom/alertmanager:v0.26.0
        args:
        - &quot;--web.listen-address=:9093&quot;
        - &quot;--cluster.listen-address=0.0.0.0:9094&quot;
        - &quot;--cluster.peer=alertmanager-0.alertmanager-svc:9094&quot;
        - &quot;--cluster.peer=alertmanager-1.alertmanager-svc:9094&quot;
        - &quot;--cluster.peer=alertmanager-2.alertmanager-svc:9094&quot;
        - &quot;--cluster.peer-timeout=60s&quot;
        - &quot;--config.file=/etc/alertmanager/alertmanager.yml&quot;
        - &quot;--storage.path=/etc/alertmanager/data&quot;
        - &quot;--data.retention=120h&quot;
        volumeMounts:
        - name: alert-cfg
          mountPath: /etc/alertmanager/
        - name: alert-temp-cfg
          mountPath: /etc/alertmanager/template
        - name: alert-data
          mountPath: /etc/alertmanager/data
        ports:
        - name: web
          containerPort: 9093
        - name: cluster
          containerPort: 9094
        resources:
          requests:
            cpu: 200m
            memory: 200Mi
          limits:
            cpu: 300m
            memory: 300Mi

  volumeClaimTemplates:
    - metadata:
        name: alert-data
      spec:
        accessModes: [&quot;ReadWriteMany&quot;]
        storageClassName: &quot;nfs-storage&quot;
        resources:
          requests:
            storage: 3Gi

[root@k8s-master01 03-alertmanager]# kubectl apply -f 04-alertmanager-statefulset.yaml
[root@k8s-master01 03-alertmanager]# kubectl get pods -n monitoring
NAME                                READY   STATUS    RESTARTS   AGE
alertmanager-0                      1/1     Running   0          97s
alertmanager-1                      1/1     Running   0          97s
alertmanager-2                      1/1     Running   0          97s
webhook-dingding-6d68854649-r6smd   1/1     Running   0          19m
webhook-wechat-54b5bbf677-rmr26     1/1     Running   0          32m
</code></pre><h5 id="26-发布alertmanager服务"><a class="anchor" href="#26-发布alertmanager服务">#</a> 2.6 发布 AlertManager 服务</h5><p>1、编写 Ingress 资源清单</p><pre><code>[root@k8s-master01 03-alertmanager]# cat 05-alertmanager-ingress.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: alert-ingress
  namespace: monitoring
spec:
  ingressClassName: &quot;nginx&quot;
  rules:
  - host: &quot;k8s-alert.hmallleasing.com&quot;
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: alertmanager-svc
            port:
              number: 9093

[root@k8s-master01 03-alertmanager]# kubectl apply -f 05-alertmanager-ingress.yaml 
[root@k8s-master01 03-alertmanager]# kubectl get ingress -n monitoring
NAME            CLASS   HOSTS                        ADDRESS                                        PORTS   AGE
alert-ingress   nginx   k8s-alert.hmallleasing.com   192.168.40.103,192.168.40.104,192.168.40.105   80      21s
</code></pre><p>2、访问 AlertManager 的⻚⾯</p><p><img loading="lazy" data-src="C:%5CUsers%5CAdministrator%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240310213846950.png" alt="image-20240310213846950"></p><h5 id="27-测试alertmanager告警"><a class="anchor" href="#27-测试alertmanager告警">#</a> 2.7 测试 AlertManager 告警</h5><p>1、模拟故障测试 AlertManager 告警是否能正常发送</p><pre><code>[root@k8s-master01 ~]# kubectl run tools --image=uhub.service.ucloud.cn/oldxu/tools:v1.0
[root@k8s-master01 ~]# kubectl exec -it tools -- /bin/bash

# 路由给钉钉
/alert_test_oldxu --alertURL=&quot;http://alertmanager-svc.monitoring.svc.cluster.local:9093/api/v1/alerts&quot; --label=&quot;alertname=CPU故障,instance=dingding,severity=critical,job=node_exporter&quot;

# 路由给微信
/alert_test_oldxu --alertURL=&quot;http://alertmanager-svc.monitoring.svc.cluster.local:9093/api/v1/alerts&quot; --label=&quot;alertname=节点故障,instance=wechat,severity=critical,job=kube-nodes&quot;

# 路由给邮件
/alert_test_oldxu --alertURL=&quot;http://alertmanager-svc.monitoring.svc.cluster.local:9093/api/v1/alerts&quot; --label=&quot;alertname=redis故障,instance=email,severity=critical,job=redis_exporter&quot;
</code></pre><h4 id="3-部署prometheus至kubernetes"><a class="anchor" href="#3-部署prometheus至kubernetes">#</a> 3、部署 Prometheus ⾄ Kubernetes</h4><ul><li>1、创建 ConfigMap，准备 Prometheus 配置⽂件，定义 AlertManager 的地址、以及 Rules 规则⽂件的路径等</li><li>2、创建 ConfigMap，准备 Prometheus 告警相关的规则⽂件；</li><li>3、创建 RBAC 权限，我们需要使⽤ Prometheus 访问 APIServer 来抓取各种资源的指标，这意味着 Prometheus 的 Pod 需要相应的权限来访问 Kubernetes API</li><li>4、创建 HeadlessService；</li><li>5、创建 statefulSet，运⾏单节点的 Prometheus（⽣产环境不建议使⽤ NFS 作为后端存储）；</li><li>6、创建 Ingress，对外提供 Prometheus</li></ul><h5 id="31-创建prometheus配置文件"><a class="anchor" href="#31-创建prometheus配置文件">#</a> 3.1 创建 Prometheus 配置⽂件</h5><p>1、编辑 Prometheus 配置⽂件，先使⽤最⼩化配置。（后期监控其他组件在进⾏修改或增加。） configMap 资源名称： prom-configs</p><pre><code>[root@k8s-master01 04-prometheus]# cat 01-prom-configs-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prom-configs
  namespace: monitoring
data:
  prometheus.yml: |-
    global:
      scrape_interval: 15s
      scrape_timeout:  15s
    
    # 告警地址(填写AlertManager的负载均衡地址即可)
    alerting:
      alertmanagers:
      - static_configs:
        - targets: [&quot;alertmanager-svc:9093&quot;]
    
    # 告警规则文件
    rule_files:
      - &quot;/etc/prometheus/rules/*.yml&quot;

    scrape_configs:
      - job_name: &quot;prometheus&quot;
        metrics_path: &quot;/metrics&quot;
        static_configs:
        - targets: [&quot;localhost:9090&quot;]
[root@k8s-master01 04-prometheus]# kubectl apply -f 01-prom-configs-configmap.yaml
[root@k8s-master01 04-prometheus]# kubectl get cm -n monitoring
NAME               DATA   AGE
alert-configs      1      25m
alert-template     1      25m
kube-root-ca.crt   1      52m
prom-configs       1      16s
</code></pre><h5 id="32-创建prometheus告警规则"><a class="anchor" href="#32-创建prometheus告警规则">#</a> 3.2 创建 Prometheus 告警规则</h5><p>1、编辑 PrometheusRules 告警规则⽂件 以 node、pods、jvm、redis、blackbox 等告警规则⽂件为例，后续根据情况在添加， configMap 资源名称： prom-rules</p><p><em>注意：这些 rules 是基于此前节点监控的规则，然后结合 K8S 的标签进⾏了重新修订。</em></p><pre><code>[root@k8s-master01 04-prometheus]# cat 02-prom-rules-configmap.yaml 
apiVersion: v1
kind: ConfigMap
metadata:
  name: prom-rules
  namespace: monitoring
data:
  node_rules.yml: |-
    groups:
    - name: CPU告警规则
      rules:
      - alert: 节点CPU使用率超过80%
        expr: ( 1 - avg(irate(node_cpu_seconds_total&#123;mode=&quot;idle&quot;&#125;[1m])) by (instance,job) ) * 100 &gt; 80
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: &quot;主机CPU利用率过高，实例：&#123;&#123; $labels.instance &#125;&#125; , &#123;&#123; $labels.job &#125;&#125;&quot;
          description: &quot;该实例的CPU利用率低于20%，当前利用率：&#123;&#123; $value &#125;&#125;%。可能存在CPU资源浪费情况。&quot;
      - alert: CPU饱和度过高
        expr: sum(node_load1) by (instance,job) / (count(node_cpu_seconds_total&#123;mode=&quot;idle&quot;&#125;) by (instance,job) * 2) * 100 &gt; 80
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: &quot;CPU饱和度过高，实例：&#123;&#123; $labels.instance &#125;&#125; , &#123;&#123; $labels.job &#125;&#125;&quot;
          description: &quot;该实例的1分钟平均CPU负载超过了核心数的两倍，已经持续2分钟，当前CPU饱和度：&#123;&#123; $value &#125;&#125;%。需要立即检查系统负载情况。&quot;
    
      - alert: 主机内存不足
        expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes)  / node_memory_MemTotal_bytes * 100 &gt; 80
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: &quot;主机内存使用率较高, 实例:&#123;&#123; $labels.instance &#125;&#125;, 任务:&#123;&#123; $labels.job &#125;&#125;&quot;
          description: &quot;该实例的内存使用率持续2分钟高于80%，当前利用率：&#123;&#123; $value &#125;&#125;%&quot;
    
    
      - alert: 内存饱和度高
        expr: ( 1 - node_memory_SwapFree_bytes / node_memory_SwapTotal_bytes ) * 100 &gt; 30
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: &quot;主机内存内存饱和度高, 实例:&#123;&#123; $labels.instance &#125;&#125;, 任务:&#123;&#123; $labels.job &#125;&#125;&quot;
          description: &quot;SWAP内存使用率已连续2分钟超过30%，表明内存饱和度过高，当前SWAP使用率为：&#123;&#123; $value &#125;&#125;%。&quot;
    

      - alert: 磁盘空间告急
        expr: ( node_filesystem_size_bytes&#123;device!=&quot;tmpfs&quot;&#125; - node_filesystem_avail_bytes&#123;device!=&quot;tmpfs&quot;&#125; ) / node_filesystem_size_bytes&#123;device!=&quot;tmpfs&quot;&#125; * 100 &gt; 70
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: &quot;实例 &#123;&#123; $labels.instance &#125;&#125; 磁盘&#123;&#123; $labels.mountpoint &#125;&#125; 分区空间不足&quot;
          description: &quot;实例 &#123;&#123; $labels.instance &#125;&#125; 的磁盘空间使用率已超过 70%，当前使用率为 &#123;&#123; $value &#125;&#125;%，请及时处理。&quot;
    
    
      - alert: 磁盘Inode空间告急
        expr: (node_filesystem_files&#123;device!=&quot;tmpfs&quot;&#125; - node_filesystem_files_free&#123;device!=&quot;tmpfs&quot;&#125; ) / node_filesystem_files&#123;device!=&quot;tmpfs&quot;&#125; * 100 &gt; 70
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: &quot;实例 &#123;&#123; $labels.instance &#125;&#125; 磁盘空间不足&quot;
          description: &quot;实例 &#123;&#123; $labels.instance &#125;&#125; 的磁盘Inode空间使用率已超过 70%，当前使用率为 &#123;&#123; $value &#125;&#125;%，请及时处理。&quot;
    
      - alert: 磁盘IOPS写入较高
        #expr: sum(rate(node_disk_writes_completed_total[1m])) by (instance,job) / 120 * 100 &gt;60
        #round函数可以对值进行四舍五入
        expr: round(max(irate(node_disk_writes_completed_total[1m])) by (instance,job) / 120 * 100) &gt; 60
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: &quot;实例 &#123;&#123; $labels.instance &#125;&#125; IOPS每秒写入次数超过120次/s&quot;
          description: 
            目前磁盘IOPS写入饱和度是 &#123;&#123; $value &#125;&#125;%
            目前磁盘IOPS每秒写入最大 &#123;&#123; printf `max(rate(node_disk_writes_completed_total&#123;instance="%s",job="%s"&#125;[1m]))` $labels.instance $labels.job | query | first | value | printf "%.2f" &#125;&#125; 次/s
    
      - alert: 磁盘IOPS读取较高
        expr: round(max(irate(node_disk_reads_completed_total[1m])) by (instance,job) / 120 * 100) &gt; 60
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: &quot;实例 &#123;&#123; $labels.instance &#125;&#125; IOPS每秒读取次数超过120次/s&quot;
          description: 
            目前磁盘IOPS读取饱和度是 &#123;&#123; $value &#125;&#125;%
            目前磁盘IOPS每秒读取最大 &#123;&#123; printf `max(rate(node_disk_reads_completed_total&#123;instance="%s",job="%s"&#125;[1m]))` $labels.instance $labels.job | query | first | value | printf "%.2f" &#125;&#125; 次/s
    
    
      - alert: 磁盘IO写入吞吐较高
        expr: round(max(rate(node_disk_written_bytes_total[1m])) by (instance,job) / 1024 /1024 / 30 * 100) &gt; 60
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: &quot;实例 &#123;&#123; $labels.instance &#125;&#125; 磁盘IO写入每秒超过最大30MB/s&quot;
          description: 
            目前磁盘IO写入吞吐量的饱和度是 &#123;&#123; $value &#125;&#125;%。
            目前磁盘IO写入吞吐量每秒最大是 &#123;&#123; printf `max(rate(node_disk_written_bytes_total&#123;instance="%s",job="%s"&#125;[1m])) /1024/1024` $labels.instance $labels.job | query | first | value | printf "%.2f" &#125;&#125;MB/s
    
      - alert: 磁盘IO读取吞吐较高
        expr: round(max(rate(node_disk_read_bytes_total[1m])) by (instance,job) / 1024 /1024 /30 * 100 ) &gt; 60
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: &quot;实例 &#123;&#123; $labels.instance &#125;&#125; 磁盘IO读取每秒超过最大30MB/s&quot;
          description:
            目前磁盘IO读取吞吐量的饱和度是 &#123;&#123; $value &#125;&#125;%。
            目前磁盘IO读取吞吐量每秒最大是 &#123;&#123; printf `max(rate(node_disk_read_bytes_total&#123;instance="%s",job="%s"&#125;[1m])) /1024/1024` $labels.instance $labels.job | query | first | value | printf "%.2f" &#125;&#125;MB/s
    
    
      - alert: 网络下载带宽异常
        expr: max(irate(node_network_receive_bytes_total[1m]) * 8 / 1024 / 1024) by (instance,job,device) / 50 * 100  &gt;= 80
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: &quot;实例 &#123;&#123; $labels.instance &#125;&#125; 的 &#123;&#123; $labels.device &#125;&#125;接口下载流量已经超过公司实际50Mbps&quot;
          description: 
            目前下载带宽已经达到 &#123;&#123; printf `(irate(node_network_receive_bytes_total&#123;instance="%s",job="%s",device="%s"&#125;[1m]) * 8 / 1024 / 1024)` $labels.instance $labels.job $labels.device | query | first | value | printf "%.2f" &#125;&#125; Mbps/s
            目前下载带宽使用率在 &#123;&#123; $value &#125;&#125;%
    
      - alert: 网络上传带宽异常
        expr: max(irate(node_network_transmit_bytes_total[1m]) * 8 / 1024 / 1024) by (instance,job,device) / 50 * 100 &gt;= 80
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: &quot;实例 &#123;&#123; $labels.instance &#125;&#125; 的 &#123;&#123; $labels.device &#125;&#125;接口上传流量已经超过公司实际50Mbps&quot;
          description: 
            目前上传带宽已经达到 &#123;&#123; printf `(irate(node_network_transmit_bytes_total&#123;instance="%s",job="%s",device="%s"&#125;[1m]) * 8 / 1024 / 1024)` $labels.instance $labels.job $labels.device | query | first | value | printf "%.2f" &#125;&#125; Mbps/s
            目前上传带宽使用率在 &#123;&#123; $value &#125;&#125;%
    
    
      - alert: 网络TCP连接数异常
        expr: node_nf_conntrack_entries / node_nf_conntrack_entries_limit * 100 &gt; 80
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: &quot;实例 &#123;&#123; $labels.instance &#125;&#125; 的 tcp连接数超过80%&quot;
          description: 
            目前TCP连接数是 &#123;&#123; printf `node_nf_conntrack_entries&#123;instance="%s",job="%s"&#125;` $labels.instance $labels.job | query | first | value | printf "%.2f" &#125;&#125;
            目前TCP连接使用率是 &#123;&#123; $value &#125;&#125;%
    
      - alert: 节点处于Down状态
        expr: up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: &quot;实例:&#123;&#123; $labels.instance &#125;&#125; 处于Down状态&quot;
          description: &quot;&#123;&#123; $labels.instance &#125;&#125; 节点已连接超时&quot;

  kube_pods_rules.yml: |-
    groups:
    - name: Pods的告警规则文件
      rules:
      - alert: Pod中容器的CPU利用率高
        expr: sum (rate(container_cpu_usage_seconds_total&#123;image!=&quot;&quot;&#125;[5m])) by (instance,job,pod,namespace) * 100 &gt; 80
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: &quot;在 '&#123;&#123; $labels.instance &#125;&#125;' 节点上运行的 '&#123;&#123; $labels.pod &#125;&#125;' Pod CPU利用率高&quot;
          description: &quot;在 '&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod &#125;&#125;' Pod的CPU利用率当前为 &#123;&#123; $value &#125;&#125;%，超过了80%的阈值。&quot;
    
      - alert: Pod中容器内存利用率高
        expr: |
          sum(container_memory_working_set_bytes&#123;name!=&quot;&quot;&#125;) by (instance,job,pod,namespace)
          /
          sum(container_spec_memory_limit_bytes&#123;name!=&quot;&quot;&#125; &gt; 0) by (instance,job,pod,namespace) * 100 &gt; 80
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: &quot;在 '&#123;&#123; $labels.instance &#125;&#125;' 节点上运行的 '&#123;&#123; $labels.pod &#125;&#125;' Pod内存利用率高&quot;
          description: 在 '&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod &#125;&#125;' Pod的内存最大限制是 &#123;&#123; printf `sum (container_spec_memory_limit_bytes&#123;namespace="%s",pod="%s"&#125; > 0 ) /1024 /1024` $labels.namespace $labels.pod | query | first | value &#125;&#125;MB , 目前利用率已达&#123;&#123; $value &#125;&#125;%，超过限制的80%。

      - alert: Pod容器网络发送速率过高
        expr: sum(rate(container_network_transmit_bytes_total&#123;image!=&quot;&quot;&#125;[1m])) by (instance,job,pod,namespace) * 8 /1024 /1024 &gt; 50
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: &quot;在 '&#123;&#123; $labels.instance &#125;&#125;' 节点上运行的 '&#123;&#123; $labels.pod &#125;&#125;' Pod网络发送速率过高&quot;
          description: &quot;在 '&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod &#125;&#125;' Pod的网络发送速率达到&#123;&#123; $value &#125;&#125;Mbps，超过了50Mbps的阈值。&quot;
    
      - alert: Pod容器网络接收速率过高
        expr: sum(rate(container_network_receive_bytes_total&#123;image!=&quot;&quot;&#125;[1m])) by (instance,job,pod,namespace) * 8 /1024 /1024 &gt; 50
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: &quot;在 '&#123;&#123; $labels.instance &#125;&#125;' 节点上运行的 '&#123;&#123; $labels.pod &#125;&#125;' Pod网络发送速率过高&quot;
          description: &quot;在 '&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod &#125;&#125;' Pod的网络接收速率达到&#123;&#123; $value &#125;&#125;Mbps，超过了50Mbps的阈值。&quot;
    
      - alert: Pod容器磁盘写入吞吐量过大
        expr: sum (rate(container_fs_writes_bytes_total&#123;name!=&quot;&quot;&#125;[1m])) by (instance,job,pod,namespace) /1024 /1024 &gt; 20
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: &quot;在 '&#123;&#123; $labels.instance &#125;&#125;' 节点上运行的 '&#123;&#123; $labels.pod &#125;&#125;' Pod磁盘写入吞吐量过大&quot;
          description: &quot;在 '&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod &#125;&#125;' Pod的磁盘写入吞吐量达到&#123;&#123; $value &#125;&#125;MB/s，超过了20MB/s的阈值。&quot;
    
      - alert: Pod容器磁盘读取吞吐量过大
        expr: sum (rate(container_fs_reads_bytes_total&#123;name!=&quot;&quot;&#125;[1m])) by (instance,job,pod,namespace) /1024 /1024 &gt; 20
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: &quot;在 '&#123;&#123; $labels.instance &#125;&#125;' 节点上运行的 '&#123;&#123; $labels.pod &#125;&#125;' Pod磁盘读取吞吐量过大&quot;
          description: &quot;在 '&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod &#125;&#125;' Pod的磁盘读取吞吐量达到&#123;&#123; $value &#125;&#125;MB/s，超过了20MB/s的阈值。&quot;


  jvm_rules.yml: |-
    groups:
    - name: &quot;JVM告警规则&quot;
      rules:
      - alert: JVM堆内存使用率过高
        expr: jvm_memory_bytes_used&#123;area=&quot;heap&quot;,&#125; / jvm_memory_bytes_max&#123;area=&quot;heap&quot;,&#125; * 100 &gt; 90
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' 实例的JVM 堆内存使用率超过80%&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间下的 '&#123;&#123; $labels.pod_name &#125;&#125;' PodJVM堆内存使用率超过80%, 当前使用率是 &#123;&#123; $value &#125;&#125;%&quot;

      - alert: JVMGC时间过长
        expr: sum (rate(jvm_gc_collection_seconds_sum[5m]) / rate(jvm_gc_collection_seconds_count[5m])) by (instance,job,gc,namespace,pod_name) &gt; 1
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' 实例的JVM  GC时间超过了1秒。&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间下的 '&#123;&#123; $labels.pod_name &#125;&#125;' Pod使用 &#123;&#123; $labels.gc &#125;&#125; GC垃圾回收算法时间超过1s，当前值 &#123;&#123; $value &#125;&#125;秒&quot;

      - alert: JVM死锁线程过多
        expr: min_over_time(jvm_threads_deadlocked[5m]) &gt; 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: &quot;JVM检测到'&#123;&#123; $labels.instance &#125;&#125;' 实例有死锁线程&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间下的 '&#123;&#123; $labels.pod_name &#125;&#125;' Pod，在过去5分钟检测到死锁线程, 当前死锁线程数是 &#123;&#123; $value &#125;&#125;。&quot;


  redis_rules.yml: |-
    groups:
    - name: redis告警规则
      rules:
      - alert: Redis实例宕机
        expr: redis_up == 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' Redis实例宕机&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod_name &#125;&#125;' Pod在过去5分钟内无法连接。&quot;

      - alert: Redis连接数过高
        expr: redis_connected_clients / redis_config_maxclients * 100 &gt; 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' Redis实例连接数超过80%&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod_name &#125;&#125;' Pod当前连接数占最大连接数的比率超过80%。当前比率: &#123;&#123; $value &#125;&#125;%。&quot;

      - alert: Redis连接被拒绝
        expr: increase(redis_rejected_connections_total[1h]) &gt; 0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' Redis实例有连接被拒绝&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod_name &#125;&#125;' Pod在过去1小时内有连接被拒绝。当前被拒绝的连接数: &#123;&#123; $value &#125;&#125;。&quot;

      - alert: Redis内存使用率过高
        expr: redis_memory_used_bytes / redis_memory_max_bytes * 100 &gt; 80
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' Redis实例内存使用率超过80%&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod_name &#125;&#125;' Pod的内存使用率超过配置的最大内存值的80%。当前内存使用率: &#123;&#123; $value &#125;&#125;%。&quot;

      - alert: Redis缓存命中率低
        expr: |
          irate(redis_keyspace_hits_total[5m])
          / 
          (irate(redis_keyspace_hits_total[5m]) + irate(redis_keyspace_misses_total[5m])) * 100 &lt; 90
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' Redis实例缓存命中率低于90%&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod_name &#125;&#125;' Pod最近5分钟内的缓存命中率低于90%。当前命中率: &#123;&#123; $value &#125;&#125;%。&quot;

      - alert: Redis即将过期的Key数量过多
        expr: |
          sum(redis_db_keys_expiring) by (instance, job, namespace,pod_name,db)
          / 
          sum(redis_db_keys) by (instance, job, namespace,pod_name,db) * 100 &gt; 50
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' Redis实例中的 '&#123;&#123; $labels.db &#125;&#125;' 数据库有大量即将过期的Key&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod_name &#125;&#125;' Pod中的 '&#123;&#123; $labels.db &#125;&#125;' 数据库有超过50%的Key即将过期。当前过期比率: &#123;&#123; $value &#125;&#125;%。&quot;

      - alert: RedisRDB备份失败
        expr: redis_rdb_last_bgsave_status == 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' Redis实例 RDB备份失败&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod_name &#125;&#125;' Pod最近的RDB备份失败。&quot;

      - alert: RedisRDB备份时间过长
        expr: redis_rdb_last_bgsave_duration_sec &gt; 3 and redis_rdb_last_bgsave_status == 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' Redis实例 RDB备份成功但耗时超过3秒&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod_name &#125;&#125;' Pod, RDB备份成功但耗时超过了3秒。持续时间: &#123;&#123; $value &#125;&#125;秒。&quot;

      - alert: RedisRDB备份过期
        expr: (time() - redis_rdb_last_save_timestamp_seconds) &gt; 36000
        for: 24h
        labels:
          severity: critical
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' Redis实例超过10小时未进行RDB备份&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod_name &#125;&#125;' Pod已超过10小时没有生成新的RDB备份文件。&quot;

      - alert: Redis命令拒绝率过高
        expr: |
          sum(irate(redis_commands_rejected_calls_total[5m])) by (instance,job,namespace,pod_name)
          / 
          sum(irate(redis_commands_total[5m])) by (instance,job,namespace,pod_name) * 100 &gt; 25
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' Redis实例命令拒绝率超过25%&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod_name &#125;&#125;' Pod的命令拒绝率超过了25%。当前拒绝率: &#123;&#123; $value &#125;&#125;%。&quot;

      - alert: Redis命令平均响应时间过长
        expr: |
          sum(rate(redis_commands_duration_seconds_total[5m])) by (instance,job,namespace,pod_name)
          / 
          sum(rate(redis_commands_processed_total[5m])) by (instance,job,namespace,pod_name) &gt; 0.250
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' Redis实例命令平均响应时间超过250ms&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod_name &#125;&#125;' Pod的执行命令平均响应时间超过了250毫秒。当前平均响应时间: &#123;&#123; $value &#125;&#125;秒。&quot;


  blackbox_tcp_rules.yml: |-
    groups:
    - name: Blackbox_tcp告警规则文件
      rules:
      - alert: Service TCP探测失败
        expr: sum(probe_success&#123;job=~&quot;.*tcp&quot;&#125;) by (instance,job,namespace,service_name) == 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;探测 '&#123;&#123; $labels.instance &#125;&#125;' Service 的TCP接口探测失败。&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中的 '&#123;&#123; $labels.service_name &#125;&#125;' Service资源 '&#123;&#123; $labels.instance &#125;&#125;' 地址探测失败。&quot;
    
      - alert: Service TCP请求的响应时间过长
        expr: probe_duration_seconds&#123;job=~&quot;.*tcp&quot;&#125; &gt; 0.500
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;探测 '&#123;&#123; $labels.instance &#125;&#125;' Service 的TCP响应时间超过了500毫秒。&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中的 '&#123;&#123; $labels.service_name &#125;&#125;' Service资源 '&#123;&#123; $labels.instance &#125;&#125;' 当前响应时长为 &#123;&#123; $value &#125;&#125; 秒。&quot;

      - alert: Service的DNS解析响应时间过长
        expr: probe_dns_lookup_time_seconds&#123;job=~&quot;.*tcp&quot;&#125; &gt; 0.500
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;探测 '&#123;&#123; $labels.instance &#125;&#125;' Service 的DNS解析响应时间超过了500毫秒。&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中的 '&#123;&#123; $labels.service_name &#125;&#125;' Service资源 '&#123;&#123; $labels.instance &#125;&#125;' 当前响应时长为 &#123;&#123; $value &#125;&#125; 秒。&quot;	

  blackbox_http_rules.yml: |-
    groups:
    - name: Blackbox_http告警规则文件
      rules:
      - alert: 站点平均请求过长
        expr: sum (avg_over_time(probe_http_duration_seconds[1m])) by (instance,job,namespace,ingress_name) &gt; 3
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' 域名整体请求时间超过了3秒。&quot;
          description: &quot;&#123;&#123; $labels.namespace &#125;&#125; 名称空间 '&#123;&#123; $labels.instance &#125;&#125;' 域名最近1分钟的平均请求时间超过3秒。当前平均请求时间：&#123;&#123; $value &#125;&#125;秒。&quot;

      - alert: 站点阶段耗时过长
        expr: |
          (
            probe_http_duration_seconds&#123;phase=&quot;connect&quot;&#125; &gt; 1 or
            probe_http_duration_seconds&#123;phase=&quot;processing&quot;&#125; &gt; 1 or
            probe_http_duration_seconds&#123;phase=&quot;resolve&quot;&#125; &gt; 1 or
            probe_http_duration_seconds&#123;phase=&quot;tls&quot;&#125; &gt; 1 or
            probe_http_duration_seconds&#123;phase=&quot;transfer&quot;&#125; &gt; 1
          )
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' 域名在 '&#123;&#123; $labels.phase &#125;&#125;' 阶段耗时过长&quot;
          description: &quot;&#123;&#123; $labels.namespace &#125;&#125; 名称空间 '&#123;&#123; $labels.instance &#125;&#125;' 域名在阶段 '&#123;&#123; $labels.phase &#125;&#125;' 的耗时超过0.5秒。当前耗时：&#123;&#123; $value &#125;&#125;秒。&quot;

      - alert: 站点响应状态码异常
        expr: probe_http_status_code &lt;= 199 or probe_http_status_code &gt;= 400
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' 域名返回异常状态码&quot;
          description: &quot;&#123;&#123; $labels.namespace &#125;&#125; 名称空间 '&#123;&#123; $labels.instance &#125;&#125;' 域名返回的状态码为 &#123;&#123; $value &#125;&#125;，表明请求可能存在问题。&quot;
    
      - alert: 重定向次数过多
        expr: probe_http_redirects &gt; 5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' 域名重定向次数过多&quot;
          description: &quot;&#123;&#123; $labels.namespace &#125;&#125; 名称空间 '&#123;&#123; $labels.instance &#125;&#125;' 域名在最近的探测中重定向次数超过5次。当前次数：&#123;&#123; $value &#125;&#125;次。&quot;

      - alert: 证书即将过期&lt;30
        expr: (probe_ssl_earliest_cert_expiry - time()) /86400 &lt; 30
        for: 24h
        labels:
          severity: critical
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' 域名的 SSL 证书即将过期&quot;
          description: &quot;&#123;&#123; $labels.namespace &#125;&#125; 名称空间 '&#123;&#123; $labels.instance &#125;&#125;' 域名的 SSL 证书将在 &#123;&#123; $value &#125;&#125; 天内过期。&quot;
    
      - alert: 证书即将过期&lt;7
        expr: (probe_ssl_earliest_cert_expiry - time()) /86400 &lt; 7
        for: 24h
        labels:
          severity: critical
        annotations:
          summary: &quot;&#123;&#123; $labels.instance &#125;&#125;' 域名的 SSL 证书即将过期&quot;
          description: &quot;&#123;&#123; $labels.namespace &#125;&#125; 名称空间 &#123;&#123; $labels.instance &#125;&#125;' 域名的 SSL 证书将在 &#123;&#123; $value &#125;&#125; 天内过期。&quot;
</code></pre><p>2、创建 ConfigMap</p><pre><code>[root@k8s-master01 04-prometheus]# kubectl apply -f 02-prom-rules-configmap.yaml 
[root@k8s-master01 04-prometheus]# kubectl get cm -n monitoring
NAME               DATA   AGE
alert-configs      1      34m
alert-template     1      34m
kube-root-ca.crt   1      61m
prom-configs       1      9m2s
prom-rules         6      13s
</code></pre><h5 id="33-创建prometheusrbac权限"><a class="anchor" href="#33-创建prometheusrbac权限">#</a> 3.3 创建 PrometheusRBAC 权限</h5><p>1、创建⼀个 ServiceAccount ⽤户，名称为 prometheus-sa</p><p>2、创建 ClusterRole，设定对应的权限规则，名称为 Prometheus-role 。</p><p>3、创建 ClusterRoleBinding，名称为 prometheus-rolebinding ，将 Prometheus-role ⻆⾊的权限关联⾄ kube-prom</p><p>名称空间 prometheus-sa ⽤户。</p><pre><code>[root@k8s-master01 04-prometheus]# cat 03-prometheus-rbac.yaml 
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus-sa
  namespace: monitoring

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus-role
rules:
  - apiGroups:
      - &quot;&quot;
    resources:
      - nodes
      - services
      - endpoints
      - pods
      - nodes/proxy
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - &quot;networking.k8s.io&quot;
    resources:
      - ingresses
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - &quot;&quot;
    resources:
      - configmaps
      - nodes/metrics
    verbs:
      - get
  - nonResourceURLs:
      - /metrics
    verbs:
      - get

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus-rolebinding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus-role
subjects:
  - kind: ServiceAccount
    name: prometheus-sa
    namespace: monitoring
    
[root@k8s-master01 04-prometheus]# kubectl apply -f 03-prometheus-rbac.yaml 
serviceaccount/prometheus-sa created
clusterrole.rbac.authorization.k8s.io/prometheus-role created
clusterrolebinding.rbac.authorization.k8s.io/prometheus-rolebinding created
</code></pre><h5 id="34-创建headlesssevice"><a class="anchor" href="#34-创建headlesssevice">#</a> 3.4 创建 headlessSevice</h5><pre><code>[root@k8s-master01 04-prometheus]# cat 04-prometheus-headlessService.yaml 
apiVersion: v1
kind: Service
metadata:
  name: prometheus-svc
  namespace: monitoring
spec:
  clusterIP: &quot;None&quot;
  selector:
    app: prometheus
  ports:
  - name: http
    port: 9090
    targetPort: 9090
    
[root@k8s-master01 04-prometheus]# kubectl apply -f 04-prometheus-headlessService.yaml 
[root@k8s-master01 04-prometheus]# kubectl get svc -n monitoring
NAME                   TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)             AGE
alertmanager-svc       ClusterIP   None           &lt;none&gt;        9093/TCP,9094/TCP   37m
prometheus-svc         ClusterIP   None           &lt;none&gt;        9090/TCP            16s
webhook-dingding-svc   ClusterIP   10.96.241.84   &lt;none&gt;        5002/TCP            49m
webhook-wechat-svc     ClusterIP   10.96.82.7     &lt;none&gt;        5001/TCP            62m
</code></pre><h5 id="35-部署prometheus服务"><a class="anchor" href="#35-部署prometheus服务">#</a> 3.5 部署 Prometheus 服务</h5><p>使⽤ statefulSet 编写 Prometheus 清单⽂件</p><ul><li>1、定义 Prometheus 所关联的 ServiceAccount 账户，确保有权限能访问 APIServer</li><li>1、定义 Prometheus 实例的启动命令，包含了对应的 “配置⽂件路径 “、“数据存储路径” 相关的参数。</li><li>2、定义 Prometheus 实例挂载 “配置⽂件” 的 ConfigMap 资源，以及 rules 告警规则⽂件的 ConfigMap 资源。</li><li>3、Prometheus 使⽤ PVC 模板来提供数据持久化；</li></ul><pre><code>[root@k8s-master01 04-prometheus]# cat 05-prometheus-statefulset.yaml 
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: prometheus
  namespace: monitoring
spec:
  serviceName: &quot;prometheus-svc&quot;
  replicas: 2
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      serviceAccountName: &quot;prometheus-sa&quot;		# sa账号
      volumes:
      - name: prom-cfg
        configMap:
          name: prom-configs
      - name: prom-rules-cfg
        configMap:
          name: prom-rules
      containers:
      - name: prom
        image: prom/prometheus:v2.49.1
        args:
        - &quot;--config.file=/etc/prometheus/prometheus.yml&quot;
        - &quot;--storage.tsdb.path=/etc/prometheus/data&quot;
        - &quot;--storage.tsdb.retention.time=10d&quot;
        - &quot;--web.enable-lifecycle&quot;
        volumeMounts:
        - name: prom-cfg
          mountPath: /etc/prometheus
        - name: prom-rules-cfg
          mountPath: /etc/prometheus/rules
        - name: prom-data
          mountPath: /etc/prometheus/data
        ports:
        - containerPort: 9090
        resources:
          requests:
            cpu: 1000m
            memory: 1024Mi
          limits:
            cpu: 1000m
            memory: 1024Mi
  volumeClaimTemplates:
    - metadata:
        name: prom-data
      spec:
        accessModes: [&quot;ReadWriteMany&quot;]
        storageClassName: &quot;nfs-storage&quot;
        resources:
          requests:
            storage: 3Gi
            
[root@k8s-master01 04-prometheus]# kubectl apply -f 05-prometheus-statefulset.yaml
[root@k8s-master01 04-prometheus]# kubectl get pods -n monitoring
NAME                                READY   STATUS    RESTARTS   AGE
alertmanager-0                      1/1     Running   0          38m
alertmanager-1                      1/1     Running   0          38m
alertmanager-2                      1/1     Running   0          38m
prometheus-0                        1/1     Running   0          2m35s
prometheus-1                        1/1     Running   0          92s
webhook-dingding-6d68854649-r6smd   1/1     Running   0          56m
webhook-wechat-54b5bbf677-rmr26     1/1     Running   0          69m

</code></pre><h5 id="36-发布prometheus服务"><a class="anchor" href="#36-发布prometheus服务">#</a> 3.6 发布 Prometheus 服务</h5><p>1、编写 Ingress 资源清单</p><pre><code>[root@k8s-master01 04-prometheus]# cat 06-prometheus-ingress.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: prom-ingress
  namespace: monitoring
spec:
  ingressClassName: &quot;nginx&quot;
  rules:
  - host: &quot;k8s-prom.hmallleasing.com&quot;
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: prometheus-svc
            port:
              number: 9090

[root@k8s-master01 04-prometheus]# kubectl apply -f 06-prometheus-ingress.yaml 
[root@k8s-master01 04-prometheus]# kubectl get ingress -n monitoring
NAME            CLASS   HOSTS                        ADDRESS                                        PORTS   AGE
alert-ingress   nginx   k8s-alert.hmallleasing.com   192.168.40.103,192.168.40.104,192.168.40.105   80      38m
prom-ingress    nginx   k8s-prom.hmallleasing.com    192.168.40.103,192.168.40.104,192.168.40.105   80      78s
</code></pre><h4 id="4-部署grafana至kubernetes"><a class="anchor" href="#4-部署grafana至kubernetes">#</a> 4、部署 Grafana ⾄ Kubernetes</h4><ul><li>1、创建 HeadlessService；</li><li>2、部署 Grafana，使⽤ statefulSet；</li><li>3、创建 Ingress，对外提供 Grafana；</li></ul><h5 id="41-创建headlessservice"><a class="anchor" href="#41-创建headlessservice">#</a> 4.1 创建 HeadlessService</h5><p>1、编写 Grafana 的 headlessService</p><pre><code>[root@k8s-master01 05-grafana]# cat 01-grafana-headlessService.yaml 
apiVersion: v1
kind: Service
metadata:
  name: grafana-svc
  namespace: monitoring
spec:
  clusterIP: &quot;None&quot;
  selector:
    app: grafana
  ports:
  - name: http
    port: 3000
    targetPort: 3000
</code></pre><p>2、检查 service</p><pre><code>[root@k8s-master01 05-grafana]# kubectl apply -f 01-grafana-headlessService.yaml 
[root@k8s-master01 05-grafana]# kubectl get svc -n monitoring
NAME                   TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)             AGE
alertmanager-svc       ClusterIP   None           &lt;none&gt;        9093/TCP,9094/TCP   23h
grafana-svc            ClusterIP   None           &lt;none&gt;        3000/TCP            5s
prometheus-svc         ClusterIP   None           &lt;none&gt;        9090/TCP            22h
webhook-dingding-svc   ClusterIP   10.96.241.84   &lt;none&gt;        5002/TCP            23h
webhook-wechat-svc     ClusterIP   10.96.82.7     &lt;none&gt;        5001/TCP            23h
</code></pre><h5 id="42-部署grafana服务"><a class="anchor" href="#42-部署grafana服务">#</a> 4.2 部署 Grafana 服务</h5><p>使⽤ statefulSet 编写 Grafana 清单⽂件</p><ul><li>1、Grafana 需要通过 GF_SECURITY_ADMIN_USER 传递⽤户名， GF_SECURITY_ADMIN_PASSWORD 传递密码。</li><li>2、Grafana 的实例，需要使⽤ PVC 模板来提供数据持久化；</li><li>3、Grafana 的持久存储需要考虑权限， fsGroup: 472</li></ul><pre><code>[root@k8s-master01 05-grafana]# cat 02-grafana-statefulset.yaml 
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: grafana
  namespace: monitoring
spec:
  serviceName: &quot;grafana-svc&quot;
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      securityContext:
        fsGroup: 472    # 当Pod启动时，Kubernetes会自动将此组ID应用到Pod级别共享的存储上（比如持久卷）。
      containers:
      - name: grafana
        image: grafana/grafana:10.2.2
        env:
        - name: GF_SECURITY_ADMIN_USER
          value: &quot;admin&quot;
        - name: GF_SECURITY_ADMIN_PASSWORD
          value: &quot;talent&quot;
        volumeMounts:
        - name: grafana-data
          mountPath: /var/lib/grafana
        ports:
        - containerPort: 3000
        readinessProbe:
          httpGet:
            path: /api/health
            port: 3000
            scheme: HTTP
          initialDelaySeconds: 60
          failureThreshold: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 30
        livenessProbe:
          httpGet:
            path: /api/health
            port: 3000
            scheme: HTTP
          initialDelaySeconds: 60
          failureThreshold: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 30
        resources:
          requests:
            cpu: 500m
            memory: 2048Mi
          limits:
            cpu: 500m
            memory: 2048Mi
  volumeClaimTemplates:
    - metadata:
        name: grafana-data
      spec:
        accessModes: [&quot;ReadWriteMany&quot;]
        storageClassName: &quot;nfs-storage&quot;
        resources:
          requests:
            storage: 3Gi

[root@k8s-master01 05-grafana]# kubectl apply -f 02-grafana-statefulset.yaml 
[root@k8s-master01 ~]# kubectl get pods -n monitoring
NAME                                READY   STATUS    RESTARTS            AGE
alertmanager-0                      1/1     Running   1 (6m18s ago)       23h
alertmanager-1                      1/1     Running   1 (&lt;invalid&gt; ago)   23h
alertmanager-2                      1/1     Running   1 (11m ago)         23h
grafana-0                           1/1     Running   0                   2m22s
prometheus-0                        1/1     Running   1 (4m34s ago)       23h
prometheus-1                        1/1     Running   1 (6m18s ago)       23h
webhook-dingding-6d68854649-r6smd   1/1     Running   1 (4m34s ago)       23h
webhook-wechat-54b5bbf677-rmr26     1/1     Running   1 (6m18s ago)       24h
</code></pre><h5 id="43-发布grafana服务"><a class="anchor" href="#43-发布grafana服务">#</a> 4.3 发布 Grafana 服务</h5><p>1、编辑 Grafana 的 Ingress</p><pre><code>[root@k8s-master01 05-grafana]# cat 03-grafana-ingress.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: grafana-ingress
  namespace: monitoring
spec:
  ingressClassName: &quot;nginx&quot;
  rules:
  - host: &quot;k8s-grafana.hmallleasing.com&quot;
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: grafana-svc
            port:
              number: 3000
       
[root@k8s-master01 05-grafana]# kubectl apply -f 03-grafana-ingress.yaml 
[root@k8s-master01 05-grafana]# kubectl get ingress -n monitoring
NAME              CLASS   HOSTS                          ADDRESS                         PORTS   AGE
alert-ingress     nginx   k8s-alert.hmallleasing.com     192.168.40.103,192.168.40.105   80      23h
grafana-ingress   nginx   k8s-grafana.hmallleasing.com   192.168.40.103,192.168.40.105   80      21s
prom-ingress      nginx   k8s-prom.hmallleasing.com      192.168.40.103,192.168.40.105   80      23h
</code></pre><p>2、访问 Grafana 的 web 界⾯</p><p><img loading="lazy" data-src="C:%5CUsers%5CAdministrator%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240311211754517.png" alt="image-20240311211754517"></p><h5 id="44-配置grafana连接prometheus"><a class="anchor" href="#44-配置grafana连接prometheus">#</a> 4.4 配置 Grafana 连接 Prometheus</h5><p>1、点击 Connections--&gt;Add newConnection，搜索 Prometheus，点击添加 DataSource</p><p><img loading="lazy" data-src="C:%5CUsers%5CAdministrator%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240311212003641.png" alt="image-20240311212003641"></p><p>2、点击测试并保存</p><p><img loading="lazy" data-src="C:%5CUsers%5CAdministrator%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240311212027200.png" alt="image-20240311212027200"></p><h4 id="5-部署blackbox至kubernetes"><a class="anchor" href="#5-部署blackbox至kubernetes">#</a> 5、部署 blackbox ⾄ Kubernetes</h4><ul><li>1、创建 ConfigMap，定义 blackbox.yml 中的检测模块；</li><li>2、部署 Blackbox，使⽤ Deployment；</li><li>3、创建 Service、ingress，对外发布 Blackbox；</li></ul><h5 id="51-创建blackbox的配置文件"><a class="anchor" href="#51-创建blackbox的配置文件">#</a> 5.1 创建 Blackbox 的配置⽂件</h5><p>1、创建 ConfigMap 配置，定义 Blackbox 的检测⽅法，名称为 blackbox-configs</p><pre><code>[root@k8s-master01 06-blackbox]# cat 01-blackbox-configs-configmap.yaml 
apiVersion: v1
kind: ConfigMap
metadata:
  name: blackbox-configs
  namespace: monitoring
data:
  blackbox.yml: |-
    modules:
      # http检查模块
      http_2xx:
        prober: http
        http:
          preferred_ip_protocol: &quot;ip4&quot;
          valid_http_versions: [ &quot;HTTP/1.1&quot;, &quot;HTTP/2.0&quot; ]
      # Http Post检查模块
      http_post_2xx:
        prober: http
        http:
          method: POST
          preferred_ip_protocol: &quot;ip4&quot;
          valid_http_versions: [ &quot;HTTP/1.1&quot;, &quot;HTTP/2.0&quot; ]
    
      # TCP检查模块
      tcp_connect:
        prober: tcp
        timeout: 5s
    
      # ICMP检查模块
      icmp:
        prober: icmp
        timeout: 5s
        icmp:
          preferred_ip_protocol: &quot;ip4&quot;
    
      # DNS检查模块
      dns_tcp:  
        prober: dns
        dns:
          transport_protocol: &quot;tcp&quot;
          preferred_ip_protocol: &quot;ip4&quot;
          query_name: &quot;kubernetes.default.svc.cluster.local&quot;

      # SSH检查模块
      ssh_banner:
        prober: tcp
        tcp:
          query_response:
          - expect: &quot;^SSH-2.0-&quot;
          - send: &quot;SSH-2.0-blackbox-ssh-check&quot;
</code></pre><p>2、创建 configmap</p><pre><code>[root@k8s-master01 06-blackbox]# kubectl apply -f 01-blackbox-configs-configmap.yaml 
configmap/blackbox-configs created
[root@k8s-master01 06-blackbox]# kubectl get cm -n monitoring
NAME               DATA   AGE
alert-configs      1      23h
alert-template     1      23h
blackbox-configs   1      1s
kube-root-ca.crt   1      24h
prom-configs       1      23h
prom-rules         6      23h
</code></pre><h5 id="52-部署blackbox服务"><a class="anchor" href="#52-部署blackbox服务">#</a> 5.2 部署 Blackbox 服务</h5><p>编写 Blackbox 的部署清单⽂件</p><pre><code>[root@k8s-master01 06-blackbox]# cat 02-blackbox-deployment.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: blackbox
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: blackbox
  template:
    metadata:
      labels:
        app: blackbox
    spec:
      volumes:
      - name: blackbox-cfg
        configMap:
          name: blackbox-configs
      containers:
      - name: blackbox
        image: prom/blackbox-exporter:v0.24.0
        args:
        - &quot;--web.listen-address=:9115&quot;
        - &quot;--config.file=/etc/blackbox_exporter/blackbox.yml&quot;
        volumeMounts:
        - name: blackbox-cfg
          mountPath: /etc/blackbox_exporter
        ports:
        - containerPort: 9115

[root@k8s-master01 06-blackbox]# kubectl apply -f 02-blackbox-deployment.yaml
[root@k8s-master01 06-blackbox]# kubectl get pods -n monitoring
NAME                                READY   STATUS    RESTARTS            AGE
alertmanager-0                      1/1     Running   1 (20m ago)         23h
alertmanager-1                      1/1     Running   1 (&lt;invalid&gt; ago)   23h
alertmanager-2                      1/1     Running   1 (25m ago)         23h
blackbox-7c7c8db4f7-hqs4c           1/1     Running   0                   112s
grafana-0                           1/1     Running   0                   16m
prometheus-0                        1/1     Running   1 (19m ago)         23h
prometheus-1                        1/1     Running   1 (20m ago)         23h
webhook-dingding-6d68854649-r6smd   1/1     Running   1 (19m ago)         24h
webhook-wechat-54b5bbf677-rmr26     1/1     Running   1 (20m ago)         24h
</code></pre><h5 id="53-发布blackbox服务"><a class="anchor" href="#53-发布blackbox服务">#</a> 5.3 发布 blackbox 服务</h5><p>1、创建 Service</p><pre><code>[root@k8s-master01 06-blackbox]# cat 03-blackbox-service.yaml 
apiVersion: v1
kind: Service
metadata:
  name: blackbox-svc
  namespace: monitoring
spec:
  selector:
    app: blackbox
  ports:
  - name: http
    port: 9115
    targetPort: 9115

[root@k8s-master01 06-blackbox]# kubectl apply -f 03-blackbox-service.yaml 
</code></pre><p>2、创建 Ingress</p><pre><code>[root@k8s-master01 06-blackbox]# cat 04-blackbox-ingress.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: blackbox-ingress
  namespace: monitoring
spec:
  ingressClassName: &quot;nginx&quot;
  rules:
  - host: &quot;k8s-blackbox.hmallleasing.com&quot;
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: blackbox-svc
            port:
              number: 9115

[root@k8s-master01 06-blackbox]# kubectl apply -f 04-blackbox-ingress.yaml 
</code></pre><p>3、访问 blackbox ⻚⾯</p><h4 id="image-202403112132301406-监控kubernetes集群节点"><a class="anchor" href="#image-202403112132301406-监控kubernetes集群节点">#</a> <img loading="lazy" data-src="C:%5CUsers%5CAdministrator%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240311213230140.png" alt="image-20240311213230140">6、监控 Kubernetes 集群节点</h4><p>使⽤ Prometheus 监控 Kubernetes 集群中的 节点，⼤体需要如下⼏步：</p><ul><li>1、使⽤ DaemonSet 部署 Node_exporter</li><li>2、使⽤ Prometheus 的 Kubernetes 服务发现功能，⾃动识别集群中的 Node 节点</li><li>3、使⽤ relabeling 功能调整⽬标地址和端⼝：</li><li>4、使⽤ relabel 功能，为节点增加⼀些必要的标签维度；</li></ul><h5 id="61-部署node-exporter"><a class="anchor" href="#61-部署node-exporter">#</a> 6.1 部署 Node-Exporter</h5><p>使⽤ DaemonSet 部署 Node_exporter</p><ul><li>1、使⽤ DaemonSet 部署 Node Exporter，确保设置 hostPID、hostIPC 和 hostNetwork 为 true，让 Node Exporter 容器能够访问宿主机的⽹络、进程和 IPC 空间。</li><li>2、需要确保 Node Exporter 可以在所有节点上运⾏，包括 Master 节点，因此需要在 DaemonSet 的 Pod 规范中添加容忍度，允许调度到有污点的节点上运⾏。</li><li>3、通过 volumeMounts，将宿主机的 /proc、/sys 和根⽬录 / 挂载到 Node Exporter 容器的相应位置。确保 Node Exporter 能够直接访问宿主机的系统信息。</li><li>4、最后在 Node Exporter 的启动参数中，指定 /proc、/sys 等挂载后的路径，以便正确读取宿主机的数据。</li></ul><pre><code>[root@k8s-master01 07-node_exporter]# cat 01-node-exporter-daemonset.yaml 
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: node-exporter
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app: node-exporter
  template:
    metadata:
      labels:
        app: node-exporter
    spec:
      hostPID: true
      hostIPC: true
      hostNetwork: true
      # 容忍度
      tolerations:
      - key: node-role.kubernetes.io/control-plane
        operator: &quot;Exists&quot;
      volumes:
      - name: proc
        hostPath:
          path: /proc
      - name: sys
        hostPath:
          path: /sys
      - name: root
        hostPath:
          path: /root
      containers:
      - name: node
        image: prom/node-exporter:v1.7.0
        args:
        - &quot;--web.listen-address=:9100&quot;
        - &quot;--web.max-requests=40&quot;
        - &quot;--collector.mountstats&quot;
        - &quot;--collector.systemd&quot;
        - &quot;--collector.ethtool&quot;
        - &quot;--collector.tcpstat&quot;
        - &quot;--path.procfs=/host/proc&quot;
        - &quot;--path.sysfs=/host/sys&quot;
        - &quot;--path.rootfs=/host/root&quot;
        volumeMounts:
        - name: proc
          mountPath: /host/proc
        - name: sys
          mountPath: /host/sys
        - name: root
          mountPath: /host/root
        ports:
        - containerPort: 9100
        resources:
          requests:
            cpu: 200m
            memory: 200Mi
          limits:
            cpu: 200m
            memory: 200Mi
</code></pre><p>2、检查 Node_exporter 的部署情况</p><pre><code>[root@k8s-master01 07-node_exporter]# kubectl apply -f 01-node-exporter-daemonset.yaml 
[root@k8s-master01 07-node_exporter]# kubectl get pods -n monitoring -o wide|grep node-exporter
node-exporter-55bsf                 1/1     Running   0                   2m48s   192.168.40.103   k8s-master03   &lt;none&gt;           &lt;none&gt;
node-exporter-5ldbs                 1/1     Running   0                   2m48s   192.168.40.104   k8s-node01     &lt;none&gt;           &lt;none&gt;
node-exporter-dj269                 1/1     Running   0                   2m48s   192.168.40.101   k8s-master01   &lt;none&gt;           &lt;none&gt;
node-exporter-kqdmg                 1/1     Running   0                   2m48s   192.168.40.102   k8s-master02   &lt;none&gt;           &lt;none&gt;
node-exporter-ml2sk                 1/1     Running   0                   2m48s   192.168.40.105   k8s-node02     &lt;none&gt;           &lt;none&gt;
</code></pre><h5 id="62-配置prometheus监控node"><a class="anchor" href="#62-配置prometheus监控node">#</a> 6.2 配置 Prometheus 监控 Node</h5><p>1、修改 Prometheus 的配置⽂件中，使⽤ kubernetes_sd_configs 配置项指定服务发现的⻆⾊为 node。这样 Prometheus 将会⾃动发现 Kubernetes 集群中的所有 Node，并获取它们的元数据。</p><pre><code>[root@k8s-master01 04-prometheus]# cat  01-prom-configs-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prom-configs
  namespace: monitoring
data:
  prometheus.yml: |-
    global:
      scrape_interval: 15s
      scrape_timeout:  15s
    
    # 告警地址(填写AlertManager的负载均衡地址即可)
    alerting:
      alertmanagers:
      - static_configs:
        - targets: [&quot;alertmanager-svc:9093&quot;]
    
    # 告警规则文件
    rule_files:
      - &quot;/etc/prometheus/rules/*.yml&quot;

    scrape_configs:
      - job_name: &quot;prometheus&quot;
        metrics_path: &quot;/metrics&quot;
        static_configs:
        - targets: [&quot;localhost:9090&quot;]
      # 监控Kubernetes的节点
      - job_name: &quot;kube-nodes&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: node

[root@k8s-master01 04-prometheus]# kubectl apply -f 01-prom-configs-configmap.yaml
</code></pre><p>2、检查配置是否更新</p><pre><code>[root@k8s-master01 04-prometheus]# kubectl exec -it prometheus-0 -n monitoring -- cat /etc/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  scrape_timeout:  15s

# 告警地址(填写AlertManager的负载均衡地址即可)
alerting:
  alertmanagers:
  - static_configs:
    - targets: [&quot;alertmanager-svc:9093&quot;]

# 告警规则文件
rule_files:
  - &quot;/etc/prometheus/rules/*.yml&quot;

scrape_configs:
  - job_name: &quot;prometheus&quot;
    metrics_path: &quot;/metrics&quot;
    static_configs:
    - targets: [&quot;localhost:9090&quot;]
  # 监控Kubernetes的节点
  - job_name: &quot;kube-nodes&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: node
</code></pre><p>3、重启 Prometheus，⽽后检查 Prometheus 的 Target</p><pre><code>#确保k8s-prom.hmallleasing.com可以解析
[root@k8s-master01 04-prometheus]# cat /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
192.168.40.101 k8s-master01
192.168.40.102 k8s-master02
192.168.40.103 k8s-master03 k8s-prom.hmallleasing.com
192.168.40.100 k8s-master-lb # 如果不是高可用集群，该IP为Master01的IP
192.168.40.104 k8s-node01
192.168.40.105 k8s-node02
[root@k8s-master01 04-prometheus]# curl -X POST http://k8s-prom.hmallleasing.com/-/reload
</code></pre><p><img loading="lazy" data-src="C:%5CUsers%5CAdministrator%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240311222953117.png" alt="image-20240311222953117"></p><h5 id="63-relabel修改抓取的节点端口"><a class="anchor" href="#63-relabel修改抓取的节点端口">#</a> 6.3 relabel 修改抓取的节点端⼝</h5><p>1、重新修改配置，通过 relabel ⽅式将 10250 端⼝，修改为 9100 端⼝</p><pre><code>[root@k8s-master01 04-prometheus]# cat 01-prom-configs-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prom-configs
  namespace: monitoring
data:
  prometheus.yml: |-
    global:
      scrape_interval: 15s
      scrape_timeout:  15s
    
    # 告警地址(填写AlertManager的负载均衡地址即可)
    alerting:
      alertmanagers:
      - static_configs:
        - targets: [&quot;alertmanager-svc:9093&quot;]
    
    # 告警规则文件
    rule_files:
      - &quot;/etc/prometheus/rules/*.yml&quot;

    scrape_configs:
      - job_name: &quot;prometheus&quot;
        metrics_path: &quot;/metrics&quot;
        static_configs:
        - targets: [&quot;localhost:9090&quot;]
      # 监控Kubernetes的节点
      - job_name: &quot;kube-nodes&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - source_labels: [&quot;__address__&quot;]
          regex: &quot;(.*):10250&quot;
          replacement: &quot;$1:9100&quot;
          target_label: __address__
          action: replace
          
[root@k8s-master01 04-prometheus]# kubectl apply -f 01-prom-configs-configmap.yaml
</code></pre><p>2、检查配置是否更新</p><pre><code>[root@k8s-master01 04-prometheus]# kubectl exec -it prometheus-0 -n monitoring -- cat /etc/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  scrape_timeout:  15s

# 告警地址(填写AlertManager的负载均衡地址即可)
alerting:
  alertmanagers:
  - static_configs:
    - targets: [&quot;alertmanager-svc:9093&quot;]

# 告警规则文件
rule_files:
  - &quot;/etc/prometheus/rules/*.yml&quot;

scrape_configs:
  - job_name: &quot;prometheus&quot;
    metrics_path: &quot;/metrics&quot;
    static_configs:
    - targets: [&quot;localhost:9090&quot;]
  # 监控Kubernetes的节点
  - job_name: &quot;kube-nodes&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: node
    relabel_configs:
    - source_labels: [&quot;__address__&quot;]
      regex: &quot;(.*):10250&quot;
      replacement: &quot;$1:9100&quot;
      target_label: __address__
      action: replace
</code></pre><p>3、重新加载 Prometheus，然后检查节点的 targets，发现端⼝变成了 9100，能正常监控 Kubernets 的节点</p><pre><code>[root@k8s-master01 04-prometheus]# curl -X POST http://k8s-prom.hmallleasing.com/-/reload
</code></pre><p><img loading="lazy" data-src="C:%5CUsers%5CAdministrator%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240311223411745.png" alt="image-20240311223411745"></p><h5 id="64-relabel为节点添加新标签"><a class="anchor" href="#64-relabel为节点添加新标签">#</a> 6.4 relabel 为节点添加新标签</h5><p>查询节点的元数据标签，发现如下的⼀些 labels，希望保留下来，以便在监控中提供更多的维度和上下⽂。</p><p><img loading="lazy" data-src="C:%5CUsers%5CAdministrator%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240311223515199.png" alt="image-20240311223515199"></p><p>1、修改 Prometheus 的配置⽂件，使⽤ labelmap 将标签映射到每个节点上。</p><pre><code>[root@k8s-master01 04-prometheus]# cat 01-prom-configs-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prom-configs
  namespace: monitoring
data:
  prometheus.yml: |-
    global:
      scrape_interval: 15s
      scrape_timeout:  15s
    
    # 告警地址(填写AlertManager的负载均衡地址即可)
    alerting:
      alertmanagers:
      - static_configs:
        - targets: [&quot;alertmanager-svc:9093&quot;]
    
    # 告警规则文件
    rule_files:
      - &quot;/etc/prometheus/rules/*.yml&quot;

    scrape_configs:
      - job_name: &quot;prometheus&quot;
        metrics_path: &quot;/metrics&quot;
        static_configs:
        - targets: [&quot;localhost:9090&quot;]
      # 监控Kubernetes的节点
      - job_name: &quot;kube-nodes&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - source_labels: [&quot;__address__&quot;]
          regex: &quot;(.*):10250&quot;
          replacement: &quot;$1:9100&quot;
          target_label: __address__
          action: replace
        - regex: __meta_kubernetes_node_label_(.*)
          replacement: $1
          action: labelmap
          
[root@k8s-master01 04-prometheus]# kubectl apply -f 01-prom-configs-configmap.yaml
</code></pre><p>2、检查配置是否更新</p><pre><code>[root@k8s-master01 04-prometheus]# kubectl exec -it prometheus-0 -n monitoring -- cat /etc/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  scrape_timeout:  15s

# 告警地址(填写AlertManager的负载均衡地址即可)
alerting:
  alertmanagers:
  - static_configs:
    - targets: [&quot;alertmanager-svc:9093&quot;]

# 告警规则文件
rule_files:
  - &quot;/etc/prometheus/rules/*.yml&quot;

scrape_configs:
  - job_name: &quot;prometheus&quot;
    metrics_path: &quot;/metrics&quot;
    static_configs:
    - targets: [&quot;localhost:9090&quot;]
  # 监控Kubernetes的节点
  - job_name: &quot;kube-nodes&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: node
    relabel_configs:
    - source_labels: [&quot;__address__&quot;]
      regex: &quot;(.*):10250&quot;
      replacement: &quot;$1:9100&quot;
      target_label: __address__
      action: replace
    - regex: __meta_kubernetes_node_label_(.*)
      replacement: $1
      action: labelmap
</code></pre><p>3、重新加载 Prometheus，⽽后这些元数据是否附加到节点的 Labels 上了。</p><pre><code>[root@k8s-master01 04-prometheus]# curl -X POST http://k8s-prom.hmallleasing.com/-/reload
</code></pre><p><img loading="lazy" data-src="C:%5CUsers%5CAdministrator%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240311223925408.png" alt="image-20240311223925408"></p><h5 id="65-导入节点可视化图形"><a class="anchor" href="#65-导入节点可视化图形">#</a> 6.5 导⼊节点可视化图形</h5><p>ID：16098</p><h4 id="7-监控k8s控制组件"><a class="anchor" href="#7-监控k8s控制组件">#</a> 7、监控 K8S 控制组件</h4><h5 id="71-监控控制平面组件"><a class="anchor" href="#71-监控控制平面组件">#</a> 7.1 监控控制平⾯组件</h5><p>监控 Kubernetes 集群的控制平⾯，⾸先需要知道要监控哪些组件，然后了解它们是如何提供 Metrics 指标的，最后确定这些指标的监控⽅法，是通过⼿动配置还是⾃动发现。</p><ul><li>关键组件包括：APIServer、ControllerManager、Scheduler、etcd、CoreDNS、kubelet、kube-proxy</li><li>Metrics 指标获取：这些控制平⾯组件都内建 Metrics 端点。但是某些组件可能默认只在本地接⼝（127.0.0.1）上暴露 Metrics，因此需要修改对应组件的配置，以确保这些 Metrics 可通过远程的⽅式进⾏访问。</li></ul><h5 id="72-监控控制平面组件策略"><a class="anchor" href="#72-监控控制平面组件策略">#</a> 7.2 监控控制平⾯组件策略</h5><p><strong>监控这些组件有两种主要⽅法：</strong></p><ul><li>1、⼿动配置监控，在 Prometheus 配置⽂件中，⼿动指定每个控制器组件服务的地址和端⼝，来完成监控。很明显这种⽅式⾮常繁琐，且维护成本太⾼。</li><li>2、⾃动化监控，利⽤ Kubernetes 的服务发现机制，来动态发现服务实例。有如下两种常⽤的⽅法</li></ul><p><strong>⾃动化监控⽅式：</strong></p><ul><li>1、基于 endpoints 的服务发现，⾃动发现所有的 endpints 端点，然后使⽤ relabel 匹配，来保留符合条件的端点实例。</li><li>2、基于 Pod 的服务发现，⾃动发现所有 Pod，然后使⽤ relabel 匹配，只保留符合标签条件的 Pod 实例。</li></ul><p><em>注意事项：</em></p><p><em>1、使⽤ endpoints 作为服务发现的⽅式，它要求被监控的⽬标必须有对应的 Service 才可以实现，否则⽆法获取端点。但基于 Pod 的发现⽅式不依赖是否有 Service。</em></p><p><em>2、不论采⽤哪种服务的发现⽅式，最终都必须通过 relabel 来基于标签筛选所需要的端点，因此获取所需要监控的⽬标标签，⾄关重要。</em></p><h5 id="73-监控apiserver"><a class="anchor" href="#73-监控apiserver">#</a> 7.3 监控 APIServer</h5><h6 id="731-获取apiserver的metrics"><a class="anchor" href="#731-获取apiserver的metrics">#</a> 7.3.1 获取 APIServer 的 Metrics</h6><p>1、API-Server 在 https 协议的， 6443/metrics 接⼝上提供了指标数据。</p><pre><code>[root@k8s-master01 ~]# netstat -lntp|grep 6443
tcp        0      0 127.0.0.1:16443         0.0.0.0:*               LISTEN      1126/haproxy        
tcp        0      0 0.0.0.0:16443           0.0.0.0:*               LISTEN      1126/haproxy        
tcp6       0      0 :::6443                 :::*                    LISTEN      2301/kube-apiserver 
</code></pre><p>2、APIServer 有对应的 Service，所以采⽤ Endpints ⽅式发现服务，因此我们需要获取 APIServer 的 Service 标签（labels），以便 Prometheus 只抓取 APIServer 服务的 Pod 实例</p><pre><code>[root@k8s-master01 ~]#  kubectl describe service -n default kubernet
Name:              kubernetes
Namespace:         default
Labels:            component=apiserver
                   provider=kubernetes
Annotations:       &lt;none&gt;
Selector:          &lt;none&gt;
Type:              ClusterIP
IP Family Policy:  SingleStack
IP Families:       IPv4
IP:                10.96.0.1
IPs:               10.96.0.1
Port:              https  443/TCP
TargetPort:        6443/TCP
Endpoints:         192.168.40.101:6443,192.168.40.102:6443,192.168.40.103:6443
Session Affinity:  None
Events:            &lt;none&gt;
</code></pre><h6 id="732-配置prometheus监控apiserver"><a class="anchor" href="#732-配置prometheus监控apiserver">#</a> 7.3.2 配置 Prometheus 监控 APIServer</h6><ul><li>1、添加⼀个新的 Job，名为： kube-apiserver ，metrics 路径是 /metrics ，协议是 https</li><li>2、基于 Kubernetes 的 Endpoints 来实现⾃动发现，由于 APIServer 采⽤的是 HTTPS，因此还需要指定 TLS 相关的配置；</li><li>3、使⽤ relabel_configs，仅保留标签名为 __meta_kubernetes_service_label_component ，标签值为 apiserver 。（会查询所有名称空间，意味着范围查询会更⼴）</li><li>4、使⽤ relabel_configs，仅保留 __meta_kubernetes_namespace=default 、 __meta_kubernetes_service_name=kubernetes 并且 __meta_kubernetes_endpoint_port_name=https 的实例（明确名称空间和 service 名称，以及对应的端⼝，这种⽅式会更精准⼀些）</li></ul><p>1、修改 Prometheus 配置</p><pre><code>[root@k8s-master01 04-prometheus]# cat 01-prom-configs-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prom-configs
  namespace: monitoring
data:
  prometheus.yml: |-
    global:
      scrape_interval: 15s
      scrape_timeout:  15s
    
    # 告警地址(填写AlertManager的负载均衡地址即可)
    alerting:
      alertmanagers:
      - static_configs:
        - targets: [&quot;alertmanager-svc:9093&quot;]
    
    # 告警规则文件
    rule_files:
      - &quot;/etc/prometheus/rules/*.yml&quot;

    scrape_configs:
      - job_name: &quot;prometheus&quot;
        metrics_path: &quot;/metrics&quot;
        static_configs:
        - targets: [&quot;localhost:9090&quot;]

      # 监控Kubernetes的节点
      - job_name: &quot;kube-nodes&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - source_labels: [&quot;__address__&quot;]
          regex: &quot;(.*):10250&quot;
          replacement: &quot;$1:9100&quot;
          target_label: __address__
          action: replace
        - regex: __meta_kubernetes_node_label_(.*)
          replacement: $1
          action: labelmap

      # 监控APIServer
      - job_name: &quot;kube-apiserver&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
        tls_config:
          insecure_skip_verify: true   # 跳过证书验证
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        # 标签重写
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
          regex: &quot;apiserver&quot;
          action: &quot;keep&quot;
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: service_name
        - regex: __meta_kubernetes_service_label_(.*)        #通过值映射获取标签
          replacement: $1
          action: labelmap
          
[root@k8s-master01 04-prometheus]# kubectl apply -f 01-prom-configs-configmap.yaml
</code></pre><p>2、检查配置是否更新</p><pre><code>[root@k8s-master01 04-prometheus]# kubectl exec -it prometheus-0 -n monitoring -- cat /etc/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  scrape_timeout:  15s

# 告警地址(填写AlertManager的负载均衡地址即可)
alerting:
  alertmanagers:
  - static_configs:
    - targets: [&quot;alertmanager-svc:9093&quot;]

# 告警规则文件
rule_files:
  - &quot;/etc/prometheus/rules/*.yml&quot;

scrape_configs:
  - job_name: &quot;prometheus&quot;
    metrics_path: &quot;/metrics&quot;
    static_configs:
    - targets: [&quot;localhost:9090&quot;]

  # 监控Kubernetes的节点
  - job_name: &quot;kube-nodes&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: node
    relabel_configs:
    - source_labels: [&quot;__address__&quot;]
      regex: &quot;(.*):10250&quot;
      replacement: &quot;$1:9100&quot;
      target_label: __address__
      action: replace
    - regex: __meta_kubernetes_node_label_(.*)
      replacement: $1
      action: labelmap

  # 监控APIServer
  - job_name: &quot;kube-apiserver&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: endpoints
    scheme: https
    tls_config:
      insecure_skip_verify: true   # 跳过证书验证
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    # 标签重写
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
      regex: &quot;apiserver&quot;
      action: &quot;keep&quot;
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: service_name
    - regex: __meta_kubernetes_service_label_(.*)        #通过值映射获取标签
      replacement: $1
      action: labelmap[root@k8s-master01 04-prometheus]# kubectl exec -it prometheus-0 -n monitoring -- cat /etc/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  scrape_timeout:  15s

# 告警地址(填写AlertManager的负载均衡地址即可)
alerting:
  alertmanagers:
  - static_configs:
    - targets: [&quot;alertmanager-svc:9093&quot;]

# 告警规则文件
rule_files:
  - &quot;/etc/prometheus/rules/*.yml&quot;

scrape_configs:
  - job_name: &quot;prometheus&quot;
    metrics_path: &quot;/metrics&quot;
    static_configs:
    - targets: [&quot;localhost:9090&quot;]

  # 监控Kubernetes的节点
  - job_name: &quot;kube-nodes&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: node
    relabel_configs:
    - source_labels: [&quot;__address__&quot;]
      regex: &quot;(.*):10250&quot;
      replacement: &quot;$1:9100&quot;
      target_label: __address__
      action: replace
    - regex: __meta_kubernetes_node_label_(.*)
      replacement: $1
      action: labelmap

  # 监控APIServer
  - job_name: &quot;kube-apiserver&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: endpoints
    scheme: https
    tls_config:
      insecure_skip_verify: true   # 跳过证书验证
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    # 标签重写
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
      regex: &quot;apiserver&quot;
      action: &quot;keep&quot;
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: service_name
    - regex: __meta_kubernetes_service_label_(.*)        #通过标签映射获取标签
      replacement: $1
      action: labelmap
</code></pre><p>3、重新加载 Prometheus，然后检查节点的 targets，能正常监控 Kubernets 的节点</p><pre><code>[root@k8s-master01 04-prometheus]# curl -X POST http://k8s-prom.hmallleasing.com/-/reload
</code></pre><p>4、检查最终结果</p><p><img loading="lazy" data-src="C:%5CUsers%5CAdministrator%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240313214452728.png" alt="image-20240313214452728"></p><h6 id="733-apiserver告警规则文件"><a class="anchor" href="#733-apiserver告警规则文件">#</a> 7.3.3 APIServer 告警规则⽂件</h6><p>1、编辑 Prometheus 的 Alert 规则⽂件</p><pre><code>  kube_apiserver_rules.yml: |-
    groups:
    - name: APIServer告警规则
      rules:
      - alert: APIServer请求错误率过高
        expr: |
          sum by (instance, namespace, job, group, code, resource, verb,subresource) (rate(apiserver_request_total&#123;code=~&quot;5..|4..&quot;&#125;[5m])) 
          /
          sum by (instance, namespace, job, group, code, resource, verb,subresource) (rate(apiserver_request_total[5m])) * 100  &gt; 10
        for: 5m 
        labels:
          severity: critical
        annotations:
          summary: &quot;APIServer请求错误率超过10%&quot;
          description: &quot;APIServer实例 &#123;&#123; $labels.instance &#125;&#125; 在命名空间 &#123;&#123; $labels.namespace &#125;&#125; 中的 &#123;&#123; $labels.group &#125;&#125; 组中 &#123;&#123; $labels.resource &#125;&#125; 类型请求错误率超过10%。当前错误率: &#123;&#123; $value &#125;&#125;%，请求类型: &#123;&#123; $labels.verb &#125;&#125;，状态码: &#123;&#123; $labels.code &#125;&#125;。&quot;
    
      - alert: APIServer Mutating请求负载过高
        expr: avg_over_time(apiserver_current_inflight_requests&#123;request_kind=&quot;mutating&quot;&#125;[5m]) &gt; (400 * 0.8)
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;APIServer Mutating请求负载过高&quot;
          description: &quot;APIServer处理变更性请求的平均负载超过了最大限制的80%。当前负载: &#123;&#123; $value &#125;&#125;。&quot;
    
      - alert: APIServer ReadOnly请求负载过高
        expr: avg_over_time(apiserver_current_inflight_requests&#123;request_kind=&quot;readOnly&quot;&#125;[5m]) &gt; (800 * 0.8)
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;APIServer ReadOnly请求负载过高&quot;
          description: &quot;APIServer处理只读请求的平均负载超过了最大限制的80%。当前负载: &#123;&#123; $value &#125;&#125;，实例: &#123;&#123; $labels.instance &#125;&#125;，命名空间: &#123;&#123; $labels.namespace &#125;&#125;。&quot;
      
      - alert: APIServer平均延迟过高
        expr: |
          rate(apiserver_request_duration_seconds_sum&#123;verb!=&quot;WATCH&quot;&#125;[5m])
          /
          rate(apiserver_request_duration_seconds_count&#123;verb!=&quot;WATCH&quot;&#125;[5m]) &gt; 5
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;APIServer平均延迟过高&quot;
          description: &quot;APIServer实例 &#123;&#123; $labels.instance &#125;&#125; 对资源 &#123;&#123; $labels.resource &#125;&#125; 的 &#123;&#123; $labels.verb &#125;&#125; 请求的平均延迟超过5秒。当前平均延迟: &#123;&#123; $value &#125;&#125;秒。&quot;
          
[root@k8s-master01 04-prometheus]# kubectl apply -f 02-prom-rules-configmap.yaml 
</code></pre><p>2、检查配置是否更新</p><pre><code>[root@k8s-master01 04-prometheus]#  kubectl exec -it prometheus-0 -n monitoring -- ls /etc/prometheus/rules/
[root@k8s-master01 04-prometheus]#  kubectl exec -it prometheus-0 -n monitoring -- cat /etc/prometheus/rules/kube_apiserver_rules.yml
</code></pre><p>3、重新加载 Prometheus</p><pre><code>[root@k8s-master01 04-prometheus]# curl -X POST http://k8s-prom.hmallleasing.com/-/reload
</code></pre><p>4、检查告警规则</p><p><img loading="lazy" data-src="C:%5CUsers%5CAdministrator%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240313222355735.png" alt="image-20240313222355735"></p><h5 id="74-监控k8s核心组件-controller"><a class="anchor" href="#74-监控k8s核心组件-controller">#</a> 7.4 监控 K8S 核⼼组件 - Controller</h5><h6 id="741-获取controller的metrics"><a class="anchor" href="#741-获取controller的metrics">#</a> 7.4.1 获取 Controller 的 Metrics</h6><p>Controller Manager 默认在 10257/metrics 接⼝上提供了指标数据，默认情况下，ControllerManager 的 Metrics 接⼝仅在本地（127.0.0.1）地址监听，因此我们需要修改其监听地址的参数，将 --bind-address=127.0.0.1 修改为 --bind-address=0.0.0.0</p><p>1、修改 ControllerManager Pod 的配置清单，所有的 master 节点都需修改，生产环境需分开修改，防止业务不可用。</p><pre><code>[root@k8s-master01 ~]#  cat /etc/kubernetes/manifests/kube-controller-manager.yaml
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    component: kube-controller-manager
    tier: control-plane
  name: kube-controller-manager
  namespace: kube-system
spec:
  containers:
  - command:
    - kube-controller-manager
    - --allocate-node-cidrs=true
    - --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf
    - --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf
    - --bind-address=0.0.0.0
    - --client-ca-file=/etc/kubernetes/pki/ca.crt
...
</code></pre><p>2、在 Kubernetes 1.28 版本中，默认配置不再允许通过 HTTP 访问 ControllerManager 的 metrics 端点，因此必须使⽤ HTTPS。在本地测试访问 Controller Manager 的 Metrics ，我们可以使⽤已存在的 prometheus-sa 服务账户来创建⼀个令牌 (token)，然后在来访问 controllerManager 的 Metrics。</p><pre><code>[root@k8s-master01 ~]# TOKEN=$(kubectl create token -n monitoring prometheus-sa)
[root@k8s-master01 ~]# curl -s -k -H &quot;Authorization: Bearer $TOKEN&quot; https://192.168.40.101:10257/metrics |grep kube-controller
leader_election_master_status&#123;name=&quot;kube-controller-manager&quot;&#125; 1
running_managed_controllers&#123;manager=&quot;kube-controller-manager&quot;,name=&quot;nodeipam&quot;&#125; 1
</code></pre><p>3、Controller Manager 没有 Service，因此我们直接获取对应 Pod 的标签（labels），以便 Prometheus 只抓取提供 Controller Manager 服务的 Pod 实例。</p><pre><code># 查看kube-controllerManager的标签
[root@k8s-master01 ~]# kubectl describe pod -n kube-system kube-controller-manager-k8s-master01|grep -i label
Labels:               component=kube-controller-manager
</code></pre><h6 id="742-配置prometheus监控controller"><a class="anchor" href="#742-配置prometheus监控controller">#</a> 7.4.2 配置 Prometheus 监控 Controller</h6><ul><li>1、添加⼀个新的 Job，名为： kube-controller ，metrics 路径是 /metrics ，协议是 https</li><li>2、基于 Kubernetes 的 Pod ⽅式实现⾃动发现，由于 ControllerManager 采⽤的是 HTTPS，因此还需要指定 TLS 相关的配置；</li><li>3、使⽤ relabel_configs，仅保留标签名为 __meta_kubernetes_pod_label_component ，标签值为 kube-controller-manager</li></ul><p>1、修改 Prometheus 配置</p><pre><code>[root@k8s-master01 04-prometheus]# cat 01-prom-configs-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prom-configs
  namespace: monitoring
data:
  prometheus.yml: |-
    global:
      scrape_interval: 15s
      scrape_timeout:  15s
    
    # 告警地址(填写AlertManager的负载均衡地址即可)
    alerting:
      alertmanagers:
      - static_configs:
        - targets: [&quot;alertmanager-svc:9093&quot;]
    
    # 告警规则文件
    rule_files:
      - &quot;/etc/prometheus/rules/*.yml&quot;

    scrape_configs:
      - job_name: &quot;prometheus&quot;
        metrics_path: &quot;/metrics&quot;
        static_configs:
        - targets: [&quot;localhost:9090&quot;]

      # 监控Kubernetes的节点
      - job_name: &quot;kube-nodes&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - source_labels: [&quot;__address__&quot;]
          regex: &quot;(.*):10250&quot;
          replacement: &quot;$1:9100&quot;
          target_label: __address__
          action: replace
        - regex: __meta_kubernetes_node_label_(.*)
          replacement: $1
          action: labelmap

      # 监控APIServer
      - job_name: &quot;kube-apiserver&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
        tls_config:
          insecure_skip_verify: true   # 跳过证书验证
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        # 标签重写
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
          regex: &quot;apiserver&quot;
          action: &quot;keep&quot;
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: service_name
        - regex: __meta_kubernetes_service_label_(.*)        #通过标签映射获取标签
          replacement: $1
          action: labelmap

      # 监控controllerManager
      - job_name: &quot;kube-controller&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: pod
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        # 仅保留标签名是component 值为kube-controller-manager
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;kube-controller-manager&quot;
          action: keep
       
[root@k8s-master01 04-prometheus]# kubectl apply -f 01-prom-configs-configmap.yaml
</code></pre><p>2、检查配置是否更新</p><pre><code>[root@k8s-master01 04-prometheus]# kubectl exec -it prometheus-0 -n monitoring -- cat /etc/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  scrape_timeout:  15s

# 告警地址(填写AlertManager的负载均衡地址即可)
alerting:
  alertmanagers:
  - static_configs:
    - targets: [&quot;alertmanager-svc:9093&quot;]

# 告警规则文件
rule_files:
  - &quot;/etc/prometheus/rules/*.yml&quot;

scrape_configs:
  - job_name: &quot;prometheus&quot;
    metrics_path: &quot;/metrics&quot;
    static_configs:
    - targets: [&quot;localhost:9090&quot;]

  # 监控Kubernetes的节点
  - job_name: &quot;kube-nodes&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: node
    relabel_configs:
    - source_labels: [&quot;__address__&quot;]
      regex: &quot;(.*):10250&quot;
      replacement: &quot;$1:9100&quot;
      target_label: __address__
      action: replace
    - regex: __meta_kubernetes_node_label_(.*)
      replacement: $1
      action: labelmap

  # 监控APIServer
  - job_name: &quot;kube-apiserver&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: endpoints
    scheme: https
    tls_config:
      insecure_skip_verify: true   # 跳过证书验证
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    # 标签重写
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
      regex: &quot;apiserver&quot;
      action: &quot;keep&quot;
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: service_name
    - regex: __meta_kubernetes_service_label_(.*)        #通过标签映射获取标签
      replacement: $1
      action: labelmap


  # 监控controllerManager
  - job_name: &quot;kube-controller&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: https
    kubernetes_sd_configs:
    - role: pod
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    # 仅保留标签名是component 值为kube-controller-manager
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;kube-controller-manager&quot;
      action: keep
</code></pre><p>3、重新加载 Prometheus，然后检查节点的 targets，能正常监控 Kubernets 的节点</p><pre><code>[root@k8s-master01 04-prometheus]# curl -X POST http://k8s-prom.hmallleasing.com/-/reload
</code></pre><p>4、检查最终结果</p><p>抓取的 ControllerManager 的地址没错，但是端口不是 10257，而是 https 默认的 443，因此我们需要重新</p><p><img loading="lazy" data-src="C:%5CUsers%5CAdministrator%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240314215117208.png" alt="image-20240314215117208"></p><h6 id="743-relabel修改抓取的pod端口"><a class="anchor" href="#743-relabel修改抓取的pod端口">#</a> 7.4.3 relabel 修改抓取的 Pod 端⼝</h6><p>1、修改 Prometheus 配置</p><pre><code>[root@k8s-master01 04-prometheus]# cat 01-prom-configs-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prom-configs
  namespace: monitoring
data:
  prometheus.yml: |-
    global:
      scrape_interval: 15s
      scrape_timeout:  15s
    
    # 告警地址(填写AlertManager的负载均衡地址即可)
    alerting:
      alertmanagers:
      - static_configs:
        - targets: [&quot;alertmanager-svc:9093&quot;]
    
    # 告警规则文件
    rule_files:
      - &quot;/etc/prometheus/rules/*.yml&quot;

    scrape_configs:
      - job_name: &quot;prometheus&quot;
        metrics_path: &quot;/metrics&quot;
        static_configs:
        - targets: [&quot;localhost:9090&quot;]

      # 监控Kubernetes的节点
      - job_name: &quot;kube-nodes&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - source_labels: [&quot;__address__&quot;]
          regex: &quot;(.*):10250&quot;
          replacement: &quot;$1:9100&quot;
          target_label: __address__
          action: replace
        - regex: __meta_kubernetes_node_label_(.*)
          replacement: $1
          action: labelmap

      # 监控APIServer
      - job_name: &quot;kube-apiserver&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
        tls_config:
          insecure_skip_verify: true   # 跳过证书验证
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        # 标签重写
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
          regex: &quot;apiserver&quot;
          action: &quot;keep&quot;
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: service_name
        - regex: __meta_kubernetes_service_label_(.*)        #通过标签映射获取标签
          replacement: $1
          action: labelmap


      # 监控controllerManager
      - job_name: &quot;kube-controller&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: pod
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        # 仅保留标签名是component 值为kube-controller-manager
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;kube-controller-manager&quot;
          action: keep
        # 替换抓取的实例端口为10257
        - source_labels: [__address__]
          regex: (.*)
          replacement: $1:10257
          target_label: __address__
          
[root@k8s-master01 04-prometheus]# kubectl apply -f 01-prom-configs-configmap.yaml     
</code></pre><p>2、检查配置是否更新</p><pre><code>[root@k8s-master01 04-prometheus]# kubectl exec -it prometheus-0 -n monitoring -- cat /etc/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  scrape_timeout:  15s

# 告警地址(填写AlertManager的负载均衡地址即可)
alerting:
  alertmanagers:
  - static_configs:
    - targets: [&quot;alertmanager-svc:9093&quot;]

# 告警规则文件
rule_files:
  - &quot;/etc/prometheus/rules/*.yml&quot;

scrape_configs:
  - job_name: &quot;prometheus&quot;
    metrics_path: &quot;/metrics&quot;
    static_configs:
    - targets: [&quot;localhost:9090&quot;]

  # 监控Kubernetes的节点
  - job_name: &quot;kube-nodes&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: node
    relabel_configs:
    - source_labels: [&quot;__address__&quot;]
      regex: &quot;(.*):10250&quot;
      replacement: &quot;$1:9100&quot;
      target_label: __address__
      action: replace
    - regex: __meta_kubernetes_node_label_(.*)
      replacement: $1
      action: labelmap

  # 监控APIServer
  - job_name: &quot;kube-apiserver&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: endpoints
    scheme: https
    tls_config:
      insecure_skip_verify: true   # 跳过证书验证
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    # 标签重写
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
      regex: &quot;apiserver&quot;
      action: &quot;keep&quot;
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: service_name
    - regex: __meta_kubernetes_service_label_(.*)        #通过标签映射获取标签
      replacement: $1
      action: labelmap


  # 监控controllerManager
  - job_name: &quot;kube-controller&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: https
    kubernetes_sd_configs:
    - role: pod
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    # 仅保留标签名是component 值为kube-controller-manager
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;kube-controller-manager&quot;
      action: keep
    # 替换抓取的实例端口为10257
    - source_labels: [__address__]
      regex: (.*)
      replacement: $1:10257
      target_label: __address__
</code></pre><p>3、重新加载 Prometheus，然后检查节点的 targets，能正常监控 Kubernets 的节点</p><pre><code>[root@k8s-master01 04-prometheus]# curl -X POST http://k8s-prom.hmallleasing.com/-/reload
</code></pre><p>4、检查最终结果</p><p><img loading="lazy" data-src="C:%5CUsers%5CAdministrator%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240314215543314.png" alt="image-20240314215543314"></p><h6 id="744-relabel为pod添加新标签"><a class="anchor" href="#744-relabel为pod添加新标签">#</a> 7.4.4 relabel 为 Pod 添加新标签</h6><p>Pod 的元数据标签，我们希望保留 __meta_kubernetes_namespace、__meta_kubernetes_pod_name ，这两个维度的标签。</p><p>1、修改 Prometheus 配置</p><pre><code>[root@k8s-master01 04-prometheus]# cat 01-prom-configs-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prom-configs
  namespace: monitoring
data:
  prometheus.yml: |-
    global:
      scrape_interval: 15s
      scrape_timeout:  15s
    
    # 告警地址(填写AlertManager的负载均衡地址即可)
    alerting:
      alertmanagers:
      - static_configs:
        - targets: [&quot;alertmanager-svc:9093&quot;]
    
    # 告警规则文件
    rule_files:
      - &quot;/etc/prometheus/rules/*.yml&quot;

    scrape_configs:
      - job_name: &quot;prometheus&quot;
        metrics_path: &quot;/metrics&quot;
        static_configs:
        - targets: [&quot;localhost:9090&quot;]

      # 监控Kubernetes的节点
      - job_name: &quot;kube-nodes&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - source_labels: [&quot;__address__&quot;]
          regex: &quot;(.*):10250&quot;
          replacement: &quot;$1:9100&quot;
          target_label: __address__
          action: replace
        - regex: __meta_kubernetes_node_label_(.*)
          replacement: $1
          action: labelmap

      # 监控APIServer
      - job_name: &quot;kube-apiserver&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
        tls_config:
          insecure_skip_verify: true   # 跳过证书验证
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        # 标签重写
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
          regex: &quot;apiserver&quot;
          action: &quot;keep&quot;
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: service_name
        - regex: __meta_kubernetes_service_label_(.*)        #通过标签映射获取标签
          replacement: $1
          action: labelmap


      # 监控controllerManager
      - job_name: &quot;kube-controller&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: pod
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        # 仅保留标签名是component 值为kube-controller-manager
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;kube-controller-manager&quot;
          action: keep
        # 替换抓取的实例端口为10257
        - source_labels: [__address__]
          regex: (.*)
          replacement: $1:10257
          target_label: __address__
        # 保留特定标签
        - source_labels: [__meta_kubernetes_namespace]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [__meta_kubernetes_pod_name]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name


[root@k8s-master01 04-prometheus]# kubectl apply -f 01-prom-configs-configmap.yaml
</code></pre><p>2、检查配置是否更新</p><pre><code>[root@k8s-master01 04-prometheus]# kubectl exec -it prometheus-0 -n monitoring -- cat /etc/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  scrape_timeout:  15s

# 告警地址(填写AlertManager的负载均衡地址即可)
alerting:
  alertmanagers:
  - static_configs:
    - targets: [&quot;alertmanager-svc:9093&quot;]

# 告警规则文件
rule_files:
  - &quot;/etc/prometheus/rules/*.yml&quot;

scrape_configs:
  - job_name: &quot;prometheus&quot;
    metrics_path: &quot;/metrics&quot;
    static_configs:
    - targets: [&quot;localhost:9090&quot;]

  # 监控Kubernetes的节点
  - job_name: &quot;kube-nodes&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: node
    relabel_configs:
    - source_labels: [&quot;__address__&quot;]
      regex: &quot;(.*):10250&quot;
      replacement: &quot;$1:9100&quot;
      target_label: __address__
      action: replace
    - regex: __meta_kubernetes_node_label_(.*)
      replacement: $1
      action: labelmap

  # 监控APIServer
  - job_name: &quot;kube-apiserver&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: endpoints
    scheme: https
    tls_config:
      insecure_skip_verify: true   # 跳过证书验证
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    # 标签重写
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
      regex: &quot;apiserver&quot;
      action: &quot;keep&quot;
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: service_name
    - regex: __meta_kubernetes_service_label_(.*)        #通过标签映射获取标签
      replacement: $1
      action: labelmap


  # 监控controllerManager
  - job_name: &quot;kube-controller&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: https
    kubernetes_sd_configs:
    - role: pod
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    # 仅保留标签名是component 值为kube-controller-manager
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;kube-controller-manager&quot;
      action: keep
    # 替换抓取的实例端口为10257
    - source_labels: [__address__]
      regex: (.*)
      replacement: $1:10257
      target_label: __address__
    # 保留特定标签
    - source_labels: [__meta_kubernetes_namespace]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [__meta_kubernetes_pod_name]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name
</code></pre><p>3、重新加载 Prometheus，然后检查节点的 targets，能正常监控 Kubernets 的节点</p><pre><code>[root@k8s-master01 04-prometheus]# curl -X POST http://k8s-prom.hmallleasing.com/-/reload
</code></pre><p>4、检查最终结果</p><p><img loading="lazy" data-src="C:%5CUsers%5CAdministrator%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240314220057566.png" alt="image-20240314220057566"></p><h5 id="75-监控k8s核心组件-scheduler"><a class="anchor" href="#75-监控k8s核心组件-scheduler">#</a> 7.5 监控 K8S 核⼼组件 - Scheduler</h5><h6 id="751-获取scheduler的metrics"><a class="anchor" href="#751-获取scheduler的metrics">#</a> 7.5.1 获取 Scheduler 的 Metrics</h6><p>Scheduler 默认在 10259/metrics 接⼝上提供了指标数据，默认情况下，Scheduler 的 Metrics 接⼝仅在本地（127.0.0.1）地址监听，因此我们需要修改其监听地址的参数，将 --bind-address=127.0.0.1 修改为 --bind-address=0.0.0.0。</p><pre><code>[root@k8s-master01 ~]# netstat -lntp|grep 10259
tcp        0      0 127.0.0.1:10259         0.0.0.0:*               LISTEN      1762/kube-scheduler 
</code></pre><p>1、修改 Scheduler Pod 的配置清单，3 台 master 都需修改，生产环境需不要同时修改，避免业务不可用。</p><pre><code>[root@k8s-master01 ~]# cat /etc/kubernetes/manifests/kube-scheduler.yaml 
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    component: kube-scheduler
    tier: control-plane
  name: kube-scheduler
  namespace: kube-system
spec:
  containers:
  - command:
    - kube-scheduler
    - --authentication-kubeconfig=/etc/kubernetes/scheduler.conf
    - --authorization-kubeconfig=/etc/kubernetes/scheduler.conf
    - --bind-address=0.0.0.0
    - --kubeconfig=/etc/kubernetes/scheduler.conf
...
</code></pre><p>2、本地测试访问 Scheduler 的 Metrics ，我们可以使⽤已存在的 prometheussa 服务账户来创建⼀个令牌 (token)，然后在来访问 Scheduler 的 Metrics。</p><pre><code>[root@k8s-master01 ~]# TOKEN=$(kubectl create token -n monitoring prometheus-sa)
[root@k8s-master01 ~]# curl -s -k -H &quot;Authorization: Bearer $TOKEN&quot; https://192.168.40.101:10259/metrics |grep kube-scheduler
leader_election_master_status&#123;name=&quot;kube-scheduler&quot;&#125; 1
</code></pre><p>3、Scheduler 没有 Service，因此我们直接获取对应 Pod 的标签（labels），以便 Prometheus 只抓取提供 Scheduler 服务的 Pod 实例。</p><pre><code>[root@k8s-master01 ~]# kubectl describe pod kube-scheduler-k8s-master01  -n kube-system
Name:                 kube-scheduler-k8s-master01
Namespace:            kube-system
Priority:             2000001000
Priority Class Name:  system-node-critical
Node:                 k8s-master01/192.168.40.101
Start Time:           Sun, 17 Mar 2024 13:59:17 +0800
Labels:               component=kube-scheduler
                      tier=control-plane
...
</code></pre><h6 id="752-配置prometheus监控scheduler"><a class="anchor" href="#752-配置prometheus监控scheduler">#</a> 7.5.2 配置 Prometheus 监控 Scheduler</h6><ul><li>1、添加⼀个新的 Job，名为： kube-scheduler ，metrics 路径是 /metrics ，协议是 https</li><li>2、基于 Kubernetes 的 Pod 来实现⾃动发现，由于 scheduler 采⽤的是 HTTPS，因此还需要指定 TLS 相关的配置；</li><li>3、使⽤ relabel_configs，仅保留标签名为 __meta_kubernetes_pod_label_component ，标签值为 kube-scheduler</li><li>4、使⽤ relabel_configs，修改抓取 Pod 的端⼝为 10259，默认 pod ⾃动抓取的实例，使⽤ http80 端⼝和 https443 端⼝；</li><li>5、使⽤ relabel_configs，保留 __meta_kubernetes_namespace、___meta_kubernetes_pod_name ，这两个维度的标签。</li></ul><p>1、修改 Prometheus 配置</p><pre><code>[root@k8s-master01 04-prometheus]# cat 01-prom-configs-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prom-configs
  namespace: monitoring
data:
  prometheus.yml: |-
    global:
      scrape_interval: 15s
      scrape_timeout:  15s
    
    # 告警地址(填写AlertManager的负载均衡地址即可)
    alerting:
      alertmanagers:
      - static_configs:
        - targets: [&quot;alertmanager-svc:9093&quot;]
    
    # 告警规则文件
    rule_files:
      - &quot;/etc/prometheus/rules/*.yml&quot;

    scrape_configs:
      - job_name: &quot;prometheus&quot;
        metrics_path: &quot;/metrics&quot;
        static_configs:
        - targets: [&quot;localhost:9090&quot;]

      # 监控Kubernetes的节点
      - job_name: &quot;kube-nodes&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - source_labels: [&quot;__address__&quot;]
          regex: &quot;(.*):10250&quot;
          replacement: &quot;$1:9100&quot;
          target_label: __address__
          action: replace
        - regex: __meta_kubernetes_node_label_(.*)
          replacement: $1
          action: labelmap

      # 监控APIServer
      - job_name: &quot;kube-apiserver&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
        tls_config:
          insecure_skip_verify: true   # 跳过证书验证
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        # 标签重写
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
          regex: &quot;apiserver&quot;
          action: &quot;keep&quot;
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: service_name
        - regex: __meta_kubernetes_service_label_(.*)        #通过标签映射获取标签
          replacement: $1
          action: labelmap


      # 监控controllerManager
      - job_name: &quot;kube-controller&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: pod
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        # 仅保留标签名是component 值为kube-controller-manager
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;kube-controller-manager&quot;
          action: keep
        # 替换抓取的实例端口为10257
        - source_labels: [__address__]
          regex: (.*)
          replacement: $1:10257
          target_label: __address__
        # 保留特定标签
        - source_labels: [__meta_kubernetes_namespace]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [__meta_kubernetes_pod_name]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控Scheduler
      - job_name: &quot;kube-schduler&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: pod
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        # 基于标签进行过滤
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;kube-scheduler&quot;
          action: keep

        # 修订抓取的端口
        - source_labels: [&quot;__address__&quot;]
          regex: (.*)
          replacement: $1:10259
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

[root@k8s-master01 04-prometheus]# kubectl apply -f 01-prom-configs-configmap.yaml
</code></pre><p>2、检查配置是否更新</p><pre><code>[root@k8s-master01 04-prometheus]# kubectl exec -it prometheus-0 -n monitoring -- cat /etc/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  scrape_timeout:  15s

# 告警地址(填写AlertManager的负载均衡地址即可)
alerting:
  alertmanagers:
  - static_configs:
    - targets: [&quot;alertmanager-svc:9093&quot;]

# 告警规则文件
rule_files:
  - &quot;/etc/prometheus/rules/*.yml&quot;

scrape_configs:
  - job_name: &quot;prometheus&quot;
    metrics_path: &quot;/metrics&quot;
    static_configs:
    - targets: [&quot;localhost:9090&quot;]

  # 监控Kubernetes的节点
  - job_name: &quot;kube-nodes&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: node
    relabel_configs:
    - source_labels: [&quot;__address__&quot;]
      regex: &quot;(.*):10250&quot;
      replacement: &quot;$1:9100&quot;
      target_label: __address__
      action: replace
    - regex: __meta_kubernetes_node_label_(.*)
      replacement: $1
      action: labelmap

  # 监控APIServer
  - job_name: &quot;kube-apiserver&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: endpoints
    scheme: https
    tls_config:
      insecure_skip_verify: true   # 跳过证书验证
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    # 标签重写
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
      regex: &quot;apiserver&quot;
      action: &quot;keep&quot;
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: service_name
    - regex: __meta_kubernetes_service_label_(.*)        #通过标签映射获取标签
      replacement: $1
      action: labelmap


  # 监控controllerManager
  - job_name: &quot;kube-controller&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: https
    kubernetes_sd_configs:
    - role: pod
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    # 仅保留标签名是component 值为kube-controller-manager
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;kube-controller-manager&quot;
      action: keep
    # 替换抓取的实例端口为10257
    - source_labels: [__address__]
      regex: (.*)
      replacement: $1:10257
      target_label: __address__
    # 保留特定标签
    - source_labels: [__meta_kubernetes_namespace]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [__meta_kubernetes_pod_name]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控Scheduler
  - job_name: &quot;kube-schduler&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: https
    kubernetes_sd_configs:
    - role: pod
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

    # 基于标签进行过滤
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;kube-scheduler&quot;
      action: keep

    # 修订抓取的端口
    - source_labels: [&quot;__address__&quot;]
      regex: (.*)
      replacement: $1:10259
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name
</code></pre><p>3、重新加载 Prometheus，然后检查节点的 targets，能正常监控 Kubernets 的节点</p><pre><code>[root@k8s-master01 04-prometheus]# curl -X POST http://k8s-prom.hmallleasing.com/-/reload
</code></pre><p>4、检查 Prometheus 抓取的结果</p><p><img loading="lazy" data-src="C:%5CUsers%5CAdministrator%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240317141321154.png" alt="image-20240317141321154"></p><h6 id="753-schedule告警规则文件"><a class="anchor" href="#753-schedule告警规则文件">#</a> 7.5.3 Schedule 告警规则⽂件</h6><p>1、编写告警规则⽂件</p><pre><code>  kube_scheduler_rules.yml: |-
    groups:
    - name: scheduler告警规则文件
      rules:
      - alert: 调度器每秒调度Pod次数过高
        expr: rate(scheduler_pod_scheduling_attempts_sum[1m]) &gt; 20
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: &quot;调度器每秒调度Pod次数过高 (当前值: &#123;&#123; $value &#125;&#125;次)&quot;
          description: &quot;调度器实例 &#123;&#123; $labels.instance &#125;&#125; 在过去的一分钟内每秒调度的Pod次数超过了20次，当前值为 &#123;&#123; $value &#125;&#125;次。&quot;
    
    
      - alert: Pending状态的Pod数量过多
        expr: avg_over_time(scheduler_pending_pods&#123;queue!=&quot;active&quot;&#125;[5m]) &gt; 10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;Pending状态的Pod数量过多 (当前值: &#123;&#123; $value &#125;&#125;个)&quot;
          description: &quot;调度器实例 &#123;&#123; $labels.instance &#125;&#125; 在过去五分钟内处于Pending状态的Pod数量平均超过了10个，当前值为 &#123;&#123; $value &#125;&#125;个。&quot;
    
    
      - alert: 'Pod平均调度尝试次数过多'
        expr: avg(rate(scheduler_pod_scheduling_attempts_sum[5m])) by (instance, job, pod_name) &gt; 5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;Pod平均调度尝试次数过多 (当前值: &#123;&#123; $value &#125;&#125;次)&quot;
          description: &quot;调度器实例 `&#123;&#123; $labels.instance &#125;&#125;` 的Pod在过去五分钟内平均尝试调度次数超过5次，当前值为 &#123;&#123; $value &#125;&#125;次。&quot;
    
      - alert: '调度器扩展点平均延迟过高'
        expr: | 
          rate(scheduler_framework_extension_point_duration_seconds_sum[5m])
          /
          rate(scheduler_framework_extension_point_duration_seconds_count[5m]) &gt; 1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;调度器扩展点平均延迟过高 (当前值: &#123;&#123; $value &#125;&#125;秒)&quot;
          description: &quot;调度器实例 `&#123;&#123; $labels.instance &#125;&#125;` 的扩展点 `&#123;&#123; $labels.extension_point &#125;&#125;` 在过去五分钟内平均延迟超过了1秒，当前值为 &#123;&#123; $value &#125;&#125;秒。
</code></pre><h5 id="76-监控k8s核心组件-etcd"><a class="anchor" href="#76-监控k8s核心组件-etcd">#</a> 7.6 监控 K8S 核⼼组件 - Etcd</h5><h6 id="761-获取etcd的metrics"><a class="anchor" href="#761-获取etcd的metrics">#</a> 7.6.1 获取 Etcd 的 Metrics</h6><p>etcd 默认在 2381/metrics 接⼝上提供了指标数据，默认情况下，etcd 的 Metrics 接⼝仅在本地（127.0.0.1）地址监听，因此我们需要修改其监听地址的参数，将 --listen-metrics-urls=http://127.0.0.1:2381 修改为 ---listen-metrics-urls=http://0.0.0.0:2381</p><pre><code>[root@k8s-master01 04-prometheus]# netstat -lntp|grep 2381
tcp        0      0 127.0.0.1:2381          0.0.0.0:*               LISTEN      1808/etcd 
</code></pre><p>1、修改 etcd Pod 的配置清单，3 台 master 都需修改，生产环境需不要同时修改，避免业务不可用。</p><pre><code>[root@k8s-master01 04-prometheus]# cat /etc/kubernetes/manifests/etcd.yaml 
apiVersion: v1
kind: Pod
metadata:
  annotations:
    kubeadm.kubernetes.io/etcd.advertise-client-urls: https://192.168.40.101:2379
  creationTimestamp: null
  labels:
    component: etcd
    tier: control-plane
  name: etcd
  namespace: kube-system
spec:
  containers:
  - command:
    - etcd
    - --advertise-client-urls=https://192.168.40.101:2379
    - --cert-file=/etc/kubernetes/pki/etcd/server.crt
    - --client-cert-auth=true
    - --data-dir=/var/lib/etcd
    - --experimental-initial-corrupt-check=true
    - --experimental-watch-progress-notify-interval=5s
    - --initial-advertise-peer-urls=https://192.168.40.101:2380
    - --initial-cluster=k8s-master01=https://192.168.40.101:2380
    - --key-file=/etc/kubernetes/pki/etcd/server.key
    - --listen-client-urls=https://127.0.0.1:2379,https://192.168.40.101:2379
    - --listen-metrics-urls=http://0.0.0.0:2381
    - --listen-peer-urls=https://192.168.40.101:2380
...
</code></pre><p>2、本地访问 etcd 的 Metrics</p><pre><code>[root@k8s-master01 04-prometheus]#  curl -s http://192.168.40.101:2381/metrics |grep etcd|head -n 10
# HELP etcd_cluster_version Which version is running. 1 for 'cluster_version' label with current cluster version
# TYPE etcd_cluster_version gauge
etcd_cluster_version&#123;cluster_version=&quot;3.5&quot;&#125; 1
# HELP etcd_debugging_auth_revision The current revision of auth store.
# TYPE etcd_debugging_auth_revision gauge
etcd_debugging_auth_revision 1
# HELP etcd_debugging_disk_backend_commit_rebalance_duration_seconds The latency distributions of commit.rebalance called by bboltdb backend.
# TYPE etcd_debugging_disk_backend_commit_rebalance_duration_seconds histogram
etcd_debugging_disk_backend_commit_rebalance_duration_seconds_bucket&#123;le=&quot;0.001&quot;&#125; 933
etcd_debugging_disk_backend_commit_rebalance_duration_seconds_bucket&#123;le=&quot;0.002&quot;&#125; 933
</code></pre><p>3、etcd 没有 Service，因此我们直接获取对应 Pod 的标签（labels），以便 Prometheus 只抓取提供 etcd 服务的 Pod 实例。</p><pre><code>[root@k8s-master01 04-prometheus]# kubectl describe pods etcd-k8s-master01 -n kube-system
Name:                 etcd-k8s-master01
Namespace:            kube-system
Priority:             2000001000
Priority Class Name:  system-node-critical
Node:                 k8s-master01/192.168.40.101
Start Time:           Sun, 17 Mar 2024 13:48:58 +0800
Labels:               component=etcd
                      tier=control-plane
...
</code></pre><h6 id="762-配置prometheus监控etcd"><a class="anchor" href="#762-配置prometheus监控etcd">#</a> 7.6.2 配置 Prometheus 监控 Etcd</h6><ul><li>1、添加⼀个新的 Job，名为： kube-etcd ，metrics 路径是 /metrics，协议是 http</li><li>2、基于 Kubernetes 的 Pod 来实现⾃动发现；</li><li>3、使⽤ relabel_configs，仅保留标签名为 __meta_kubernetes_pod_label_component ，标签值为 etcd</li><li>4、使⽤ relabel_configs，修改抓取 Pod 的端⼝为 2381，默认 pod ⾃动抓取的实例，使⽤ http80 端⼝和 https443 端⼝；</li><li>5、使⽤ relabel_configs，保留 ____meta_kubernetes_namespace、__meta_kubernetes_pod_name ，这两个维度的标签。</li></ul><p>1、修改 Prometheus 配置</p><pre><code>[root@k8s-master01 04-prometheus]# cat 01-prom-configs-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prom-configs
  namespace: monitoring
data:
  prometheus.yml: |-
    global:
      scrape_interval: 15s
      scrape_timeout:  15s
    
    # 告警地址(填写AlertManager的负载均衡地址即可)
    alerting:
      alertmanagers:
      - static_configs:
        - targets: [&quot;alertmanager-svc:9093&quot;]
    
    # 告警规则文件
    rule_files:
      - &quot;/etc/prometheus/rules/*.yml&quot;

    scrape_configs:
      - job_name: &quot;prometheus&quot;
        metrics_path: &quot;/metrics&quot;
        static_configs:
        - targets: [&quot;localhost:9090&quot;]

      # 监控Kubernetes的节点
      - job_name: &quot;kube-nodes&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - source_labels: [&quot;__address__&quot;]
          regex: &quot;(.*):10250&quot;
          replacement: &quot;$1:9100&quot;
          target_label: __address__
          action: replace
        - regex: __meta_kubernetes_node_label_(.*)
          replacement: $1
          action: labelmap

      # 监控APIServer
      - job_name: &quot;kube-apiserver&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
        tls_config:
          insecure_skip_verify: true   # 跳过证书验证
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        # 标签重写
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
          regex: &quot;apiserver&quot;
          action: &quot;keep&quot;
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: service_name
        - regex: __meta_kubernetes_service_label_(.*)        #通过标签映射获取标签
          replacement: $1
          action: labelmap


      # 监控controllerManager
      - job_name: &quot;kube-controller&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: pod
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        # 仅保留标签名是component 值为kube-controller-manager
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;kube-controller-manager&quot;
          action: keep
        # 替换抓取的实例端口为10257
        - source_labels: [__address__]
          regex: (.*)
          replacement: $1:10257
          target_label: __address__
        # 保留特定标签
        - source_labels: [__meta_kubernetes_namespace]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [__meta_kubernetes_pod_name]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控Scheduler
      - job_name: &quot;kube-schduler&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: pod
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        # 基于标签进行过滤
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;kube-scheduler&quot;
          action: keep

        # 修订抓取的端口
        - source_labels: [&quot;__address__&quot;]
          regex: (.*)
          replacement: $1:10259
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控etcd
      - job_name: &quot;kube-etcd&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: pod

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;etcd&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__address__&quot;]
          regex: (.*)
          replacement: $1:2381
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

[root@k8s-master01 04-prometheus]# kubectl apply -f 01-prom-configs-configmap.yaml
</code></pre><p>2、检查配置是否更新</p><pre><code>[root@k8s-master01 04-prometheus]# kubectl exec -it prometheus-0 -n monitoring -- cat /etc/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  scrape_timeout:  15s

# 告警地址(填写AlertManager的负载均衡地址即可)
alerting:
  alertmanagers:
  - static_configs:
    - targets: [&quot;alertmanager-svc:9093&quot;]

# 告警规则文件
rule_files:
  - &quot;/etc/prometheus/rules/*.yml&quot;

scrape_configs:
  - job_name: &quot;prometheus&quot;
    metrics_path: &quot;/metrics&quot;
    static_configs:
    - targets: [&quot;localhost:9090&quot;]

  # 监控Kubernetes的节点
  - job_name: &quot;kube-nodes&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: node
    relabel_configs:
    - source_labels: [&quot;__address__&quot;]
      regex: &quot;(.*):10250&quot;
      replacement: &quot;$1:9100&quot;
      target_label: __address__
      action: replace
    - regex: __meta_kubernetes_node_label_(.*)
      replacement: $1
      action: labelmap

  # 监控APIServer
  - job_name: &quot;kube-apiserver&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: endpoints
    scheme: https
    tls_config:
      insecure_skip_verify: true   # 跳过证书验证
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    # 标签重写
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
      regex: &quot;apiserver&quot;
      action: &quot;keep&quot;
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: service_name
    - regex: __meta_kubernetes_service_label_(.*)        #通过标签映射获取标签
      replacement: $1
      action: labelmap


  # 监控controllerManager
  - job_name: &quot;kube-controller&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: https
    kubernetes_sd_configs:
    - role: pod
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    # 仅保留标签名是component 值为kube-controller-manager
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;kube-controller-manager&quot;
      action: keep
    # 替换抓取的实例端口为10257
    - source_labels: [__address__]
      regex: (.*)
      replacement: $1:10257
      target_label: __address__
    # 保留特定标签
    - source_labels: [__meta_kubernetes_namespace]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [__meta_kubernetes_pod_name]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控Scheduler
  - job_name: &quot;kube-schduler&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: https
    kubernetes_sd_configs:
    - role: pod
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

    # 基于标签进行过滤
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;kube-scheduler&quot;
      action: keep

    # 修订抓取的端口
    - source_labels: [&quot;__address__&quot;]
      regex: (.*)
      replacement: $1:10259
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控etcd
  - job_name: &quot;kube-etcd&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: http
    kubernetes_sd_configs:
    - role: pod

    # 保留对应标签的Pod
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;etcd&quot;
      action: keep

    # 修订端口
    - source_labels: [&quot;__address__&quot;]
      regex: (.*)
      replacement: $1:2381
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name
</code></pre><p>3、重新加载 Prometheus，然后检查节点的 targets，能正常监控 Kubernets 的节点</p><pre><code>[root@k8s-master01 04-prometheus]# curl -X POST http://k8s-prom.hmallleasing.com/-/reload
</code></pre><p>4、检查 Prometheus 抓取的结果</p><p><img loading="lazy" data-src="C:%5CUsers%5CAdministrator%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240317144233242.png" alt="image-20240317144233242"></p><h6 id="763-etcd告警规则文件"><a class="anchor" href="#763-etcd告警规则文件">#</a> 7.6.3 Etcd 告警规则⽂件</h6><pre><code>  kube_etcd_rules.yml: |-
    groups:
    - name: etcd告警规则文件
      rules:
      - alert: Etcd成员异常下线
        expr: count(etcd_server_id) by (job) % 2 == 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;Etcd成员异常下线&quot;
          description: &quot;Etcd集群成员数量为偶数，可能有成员下线导致集群无法正常提供服务。&quot;
    
      - alert: Etcd通信异常
        expr: etcd_server_has_leader == 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;Etcd通信异常 (实例: &#123;&#123; $labels.instance &#125;&#125;)&quot;
          description: &quot;实例 &#123;&#123; $labels.instance &#125;&#125; 的Etcd节点无法与集群中的其它节点通信。&quot;
    
    
      - alert: Etcd领导者变更频繁
        expr: rate(etcd_server_leader_changes_seen_total[5m]) &gt; 5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;Etcd领导者变更频繁 (实例: &#123;&#123; $labels.instance &#125;&#125;)&quot;
          description: &quot;在过去的5分钟内，实例 &#123;&#123; $labels.instance &#125;&#125; 的Etcd领导者变更次数超过了5次，这可能会影响集群稳定性。&quot;
    
      - alert: Etcd后端提交到磁盘耗时异常
        expr: |
          sum by (instance, job, pod_name) (rate(etcd_disk_backend_commit_duration_seconds_sum[5m])) 
          / 
          sum by (instance, job, pod_name) (rate(etcd_disk_backend_commit_duration_seconds_count[5m])) &gt; 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;Etcd后端提交耗时异常 (实例: &#123;&#123; $labels.instance &#125;&#125;)&quot;
          description: &quot;实例 &#123;&#123; $labels.instance &#125;&#125; 的Etcd后端在过去5分钟内提交到磁盘的操作平均耗时超过了2秒。&quot;
    
    
      - alert: Etcd wal日志fsync耗时异常
        expr: |
          sum by (instance, job, pod_name) (rate(etcd_disk_wal_fsync_duration_seconds_sum[5m]))
          /
          sum by (instance, job, pod_name) (rate(etcd_disk_wal_fsync_duration_seconds_count[5m])) &gt; 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;Etcd wal日志fsync耗时异常 (实例: &#123;&#123; $labels.instance &#125;&#125;)&quot;
          description: &quot;实例 &#123;&#123; $labels.instance &#125;&#125; 的Etcd节点在过去5分钟内日志文件的fsync调用平均耗时超过了2秒。&quot;
</code></pre><h6 id="764-导入etcd图形"><a class="anchor" href="#764-导入etcd图形">#</a> 7.6.4 导⼊ Etcd 图形</h6><p>导⼊ ID：9733</p><h5 id="77-监控k8s核心组件-coredns"><a class="anchor" href="#77-监控k8s核心组件-coredns">#</a> 7.7 监控 K8S 核⼼组件 - CoreDNS</h5><h6 id="771-获取coredns的metrics"><a class="anchor" href="#771-获取coredns的metrics">#</a> 7.7.1 获取 CoreDNS 的 Metrics</h6><p>1、CoreDNS 通过 9153 端⼝的 /metrics 路径提供指标数据。</p><pre><code>[root@k8s-master01 04-prometheus]# kubectl get svc -n kube-system
NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)                  AGE
calico-typha     ClusterIP   10.96.237.85   &lt;none&gt;        5473/TCP                 198d
kube-dns         ClusterIP   10.96.0.10     &lt;none&gt;        53/UDP,53/TCP,9153/TCP   198d
metrics-server   ClusterIP   10.96.23.183   &lt;none&gt;        443/TCP                  198d

[root@k8s-master01 04-prometheus]# curl -s http://10.96.0.10:9153/metrics|head -n 10
# HELP coredns_build_info A metric with a constant '1' value labeled by version, revision, and goversion from which CoreDNS was built.
# TYPE coredns_build_info gauge
coredns_build_info&#123;goversion=&quot;go1.20&quot;,revision=&quot;055b2c3&quot;,version=&quot;1.10.1&quot;&#125; 1
# HELP coredns_cache_entries The number of elements in the cache.
# TYPE coredns_cache_entries gauge
coredns_cache_entries&#123;server=&quot;dns://:53&quot;,type=&quot;denial&quot;,view=&quot;&quot;,zones=&quot;.&quot;&#125; 39
coredns_cache_entries&#123;server=&quot;dns://:53&quot;,type=&quot;success&quot;,view=&quot;&quot;,zones=&quot;.&quot;&#125; 12
# HELP coredns_cache_hits_total The count of cache hits.
# TYPE coredns_cache_hits_total counter
coredns_cache_hits_total&#123;server=&quot;dns://:53&quot;,type=&quot;denial&quot;,view=&quot;&quot;,zones=&quot;.&quot;&#125; 878
</code></pre><p>2、CoreDNS 有对应的 Service，因此我们需要获取 DNS 对应的 Service 的标签（labels），以便 Prometheus 只抓取提供 DNS 服务的 Pod 实例。</p><pre><code>[root@k8s-master01 04-prometheus]# kubectl describe svc kube-dns -n kube-system
Name:              kube-dns
Namespace:         kube-system
Labels:            k8s-app=kube-dns
                   kubernetes.io/cluster-service=true
                   kubernetes.io/name=CoreDNS
...
</code></pre><h6 id="772-配置prometheus监控dns"><a class="anchor" href="#772-配置prometheus监控dns">#</a> 7.7.2 配置 Prometheus 监控 DNS</h6><ul><li>1、添加⼀个新的 Job，名为： kube-dns ，metrics 路径是 /metrics ，协议是 http</li><li>2、基于 Kubernetes 的 endpoints 来实现⾃动发现；</li><li>3、使⽤ relabel_configs，仅保留标签名为 __meta_kubernetes_service_label_k8s_app ，标签值为 kube-dns</li><li>4、使⽤ relabel_configs，重新调整 Pod 的端⼝，将标签 __meta_kubernetes_pod_ip 修改为 IP:9153 端⼝。默认将匹配到的 53、9153 端⼝ ，都视作⼀独⽴的实例。</li><li>5、使⽤ relabel_configs，保留 ___meta_kubernetes_namespace、____meta_kubernetes_pod_name、__meta_kubernetes_service_name ，这三个维度的标签。</li></ul><p>1、修改 Prometheus 配置</p><pre><code>[root@k8s-master01 04-prometheus]# cat 01-prom-configs-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prom-configs
  namespace: monitoring
data:
  prometheus.yml: |-
    global:
      scrape_interval: 15s
      scrape_timeout:  15s
    
    # 告警地址(填写AlertManager的负载均衡地址即可)
    alerting:
      alertmanagers:
      - static_configs:
        - targets: [&quot;alertmanager-svc:9093&quot;]
    
    # 告警规则文件
    rule_files:
      - &quot;/etc/prometheus/rules/*.yml&quot;

    scrape_configs:
      - job_name: &quot;prometheus&quot;
        metrics_path: &quot;/metrics&quot;
        static_configs:
        - targets: [&quot;localhost:9090&quot;]

      # 监控Kubernetes的节点
      - job_name: &quot;kube-nodes&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - source_labels: [&quot;__address__&quot;]
          regex: &quot;(.*):10250&quot;
          replacement: &quot;$1:9100&quot;
          target_label: __address__
          action: replace
        - regex: __meta_kubernetes_node_label_(.*)
          replacement: $1
          action: labelmap

      # 监控APIServer
      - job_name: &quot;kube-apiserver&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
        tls_config:
          insecure_skip_verify: true   # 跳过证书验证
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        # 标签重写
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
          regex: &quot;apiserver&quot;
          action: &quot;keep&quot;
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: service_name
        - regex: __meta_kubernetes_service_label_(.*)        #通过标签映射获取标签
          replacement: $1
          action: labelmap


      # 监控controllerManager
      - job_name: &quot;kube-controller&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: pod
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        # 仅保留标签名是component 值为kube-controller-manager
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;kube-controller-manager&quot;
          action: keep
        # 替换抓取的实例端口为10257
        - source_labels: [__address__]
          regex: (.*)
          replacement: $1:10257
          target_label: __address__
        # 保留特定标签
        - source_labels: [__meta_kubernetes_namespace]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [__meta_kubernetes_pod_name]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控Scheduler
      - job_name: &quot;kube-schduler&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: pod
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        # 基于标签进行过滤
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;kube-scheduler&quot;
          action: keep

        # 修订抓取的端口
        - source_labels: [&quot;__address__&quot;]
          regex: (.*)
          replacement: $1:10259
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控etcd
      - job_name: &quot;kube-etcd&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: pod

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;etcd&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__address__&quot;]
          regex: (.*)
          replacement: $1:2381
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控CoreDNS
      - job_name: &quot;kube-dns&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: endpoints

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_k8s_app&quot;]
          regex: &quot;kube-dns&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
          regex: (.*)
          replacement: $1:9153
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name
        - source_labels: [&quot;__meta_kubernetes_service_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: service_name

[root@k8s-master01 04-prometheus]# kubectl apply -f 01-prom-configs-configmap.yaml
</code></pre><p>2、检查配置是否更新</p><pre><code>[root@k8s-master01 04-prometheus]# kubectl exec -it prometheus-0 -n monitoring -- cat /etc/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  scrape_timeout:  15s

# 告警地址(填写AlertManager的负载均衡地址即可)
alerting:
  alertmanagers:
  - static_configs:
    - targets: [&quot;alertmanager-svc:9093&quot;]

# 告警规则文件
rule_files:
  - &quot;/etc/prometheus/rules/*.yml&quot;

scrape_configs:
  - job_name: &quot;prometheus&quot;
    metrics_path: &quot;/metrics&quot;
    static_configs:
    - targets: [&quot;localhost:9090&quot;]

  # 监控Kubernetes的节点
  - job_name: &quot;kube-nodes&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: node
    relabel_configs:
    - source_labels: [&quot;__address__&quot;]
      regex: &quot;(.*):10250&quot;
      replacement: &quot;$1:9100&quot;
      target_label: __address__
      action: replace
    - regex: __meta_kubernetes_node_label_(.*)
      replacement: $1
      action: labelmap

  # 监控APIServer
  - job_name: &quot;kube-apiserver&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: endpoints
    scheme: https
    tls_config:
      insecure_skip_verify: true   # 跳过证书验证
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    # 标签重写
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
      regex: &quot;apiserver&quot;
      action: &quot;keep&quot;
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: service_name
    - regex: __meta_kubernetes_service_label_(.*)        #通过标签映射获取标签
      replacement: $1
      action: labelmap


  # 监控controllerManager
  - job_name: &quot;kube-controller&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: https
    kubernetes_sd_configs:
    - role: pod
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    # 仅保留标签名是component 值为kube-controller-manager
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;kube-controller-manager&quot;
      action: keep
    # 替换抓取的实例端口为10257
    - source_labels: [__address__]
      regex: (.*)
      replacement: $1:10257
      target_label: __address__
    # 保留特定标签
    - source_labels: [__meta_kubernetes_namespace]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [__meta_kubernetes_pod_name]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控Scheduler
  - job_name: &quot;kube-schduler&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: https
    kubernetes_sd_configs:
    - role: pod
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

    # 基于标签进行过滤
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;kube-scheduler&quot;
      action: keep

    # 修订抓取的端口
    - source_labels: [&quot;__address__&quot;]
      regex: (.*)
      replacement: $1:10259
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控etcd
  - job_name: &quot;kube-etcd&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: http
    kubernetes_sd_configs:
    - role: pod

    # 保留对应标签的Pod
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;etcd&quot;
      action: keep

    # 修订端口
    - source_labels: [&quot;__address__&quot;]
      regex: (.*)
      replacement: $1:2381
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控CoreDNS
  - job_name: &quot;kube-dns&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: http
    kubernetes_sd_configs:
    - role: endpoints

    # 保留对应标签的Pod
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_service_label_k8s_app&quot;]
      regex: &quot;kube-dns&quot;
      action: keep

    # 修订端口
    - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
      regex: (.*)
      replacement: $1:9153
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name
    - source_labels: [&quot;__meta_kubernetes_service_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: service_name
</code></pre><p>3、重新加载 Prometheus，然后检查节点的 targets，能正常监控 Kubernets 的节点</p><pre><code>[root@k8s-master01 04-prometheus]# curl -X POST http://k8s-prom.hmallleasing.com/-/reload
</code></pre><p>4、检查 Prometheus 抓取的结果</p><p><img loading="lazy" data-src="C:%5CUsers%5CAdministrator%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240317151422648.png" alt="image-20240317151422648"></p><h6 id="773-coredns告警规则文件"><a class="anchor" href="#773-coredns告警规则文件">#</a> 7.7.3 CoreDNS 告警规则⽂件</h6><p>1、编写告警规则⽂件</p><pre><code>  kube_coredns_rules.yml: |-
    groups:
    - name: CoreDNS告警规则文件
      rules:
      - alert: CoreDNS SERVFAIL响应率过高
        expr: |
          sum(rate(coredns_dns_responses_total&#123;rcode=&quot;SERVFAIL&quot;&#125;[5m])) by (instance, job, server, pod_name, zone) &gt; 10
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;实例 &#123;&#123; $labels.instance &#125;&#125; 的 CoreDNS SERVFAIL 响应率过高&quot;
          description: &quot;在过去5分钟内，实例 &#123;&#123; $labels.instance &#125;&#125;，CoreDNS Pod名称 &#123;&#123; $labels.pod_name &#125;&#125;，服务端点 &#123;&#123; $labels.server &#125;&#125;，区域 &#123;&#123; $labels.zone &#125;&#125; 的SERVFAIL响应率超过了10次，当前值：&#123;&#123; $value &#125;&#125;次/秒。请检查CoreDNS服务状态。&quot;
  
      - alert: CoreDNS域名解析时延过高
        expr: |
          sum(rate(coredns_dns_request_duration_seconds_sum[5m])) by (instance, job, server, pod_name, zone)
          /
          sum(rate(coredns_dns_request_duration_seconds_count[5m])) by (instance, job, server, pod_name, zone) &gt; 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;实例 &#123;&#123; $labels.instance &#125;&#125; 的 CoreDNS 解析时延超过1秒&quot;
          description: &quot;在过去5分钟内，实例 &#123;&#123; $labels.instance &#125;&#125;，CoreDNS Pod名称 &#123;&#123; $labels.pod_name &#125;&#125;，服务端点 &#123;&#123; $labels.server &#125;&#125;，区域 &#123;&#123; $labels.zone &#125;&#125; 的平均域名解析时延超过了1秒，当前平均时延：&#123;&#123; $value &#125;&#125;秒。
</code></pre><h6 id="774-导入coredns图形"><a class="anchor" href="#774-导入coredns图形">#</a> 7.7.4 导⼊ CoreDNS 图形</h6><p>导⼊ ID：15762</p><h5 id="78-监控k8s核心组件-kubeproxy"><a class="anchor" href="#78-监控k8s核心组件-kubeproxy">#</a> 7.8 监控 K8S 核⼼组件 - Kubeproxy</h5><h6 id="781-获取kube-proxy的metrics"><a class="anchor" href="#781-获取kube-proxy的metrics">#</a> 7.8.1 获取 kube-proxy 的 Metrics</h6><p>1、Kube-Proxy 在 10249/metrics 接⼝上提供指标数据，默认情况下 kube-proxy 的 Metrics 接⼝仅在本地（127.0.0.1）地址监听，因此我们需要修改其监听地址的参数，将 metricsBindAddress: &quot;&quot;修改 metricsBindAddress:&quot;0.0.0.0&quot; ，然后重启 kube-proxy</p><pre><code>[root@k8s-master01 04-prometheus]#  kubectl edit configmap -n kube-system kube-proxy
...
    kind: KubeProxyConfiguration
    metricsBindAddress: &quot;0.0.0.0&quot;
    mode: &quot;ipvs&quot;
    nodePortAddresses: null
    oomScoreAdj: null
    portRange: &quot;&quot;
    showHiddenMetricsForVersion: &quot;&quot;
    winkernel:
...

# 重启kube-proxy的pod
[root@k8s-master01 04-prometheus]#  kubectl rollout restart daemonset -n kube-system kube-proxy
</code></pre><p>2、检查 kube-proxy 的监听地址</p><pre><code>[root@k8s-master01 04-prometheus]#  netstat -lntp |grep kube-proxy
tcp6       0      0 :::10256                :::*                    LISTEN      60042/kube-proxy    
tcp6       0      0 :::10249                :::*                    LISTEN      60042/kube-proxy 
</code></pre><p>3、kube-proxy 没有 Service，因此我们直接获取对应 Pod 的标签（labels），以便 Prometheus 只抓取提供 kube-proxy 服务的 Pod 实例。</p><pre><code>[root@k8s-master01 04-prometheus]#  kubectl describe daemonsets.apps -n kube-system kube-proxy
Name:           kube-proxy
Selector:       k8s-app=kube-proxy
Node-Selector:  kubernetes.io/os=linux
Labels:         k8s-app=kube-proxy
Annotations:    deprecated.daemonset.template.generation: 3
...
</code></pre><h6 id="782-配置prometheus监控kube-proxy"><a class="anchor" href="#782-配置prometheus监控kube-proxy">#</a> 7.8.2 配置 Prometheus 监控 kube-proxy</h6><ul><li>1、添加⼀个新的 Job，名为： kube-proxy ，metrics 路径是 /metrics ，协议是 http</li><li>2、基于 Kubernetes 的 pod 来实现⾃动发现；</li><li>3、使⽤ relabel_configs，仅保留标签名为 __meta_kubernetes_pod_label_k8s_app ，标签值为 kube-proxy</li><li>4、使⽤ relabel_configs，重新调整 Pod 的端⼝，将标签 __meta_kubernetes_pod_ip 修改为 IP:10249 端⼝，默认 Pod 的⾃动发现端⼝ http 是 80，https 是 443。</li><li>5、使⽤ relabel_configs，保留 __meta_kubernetes_namespace、__meta_kubernetes_pod_name ，这两个维度的标签。</li></ul><p>1、修改 Prometheus 配置</p><pre><code>[root@k8s-master01 04-prometheus]# cat 01-prom-configs-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prom-configs
  namespace: monitoring
data:
  prometheus.yml: |-
    global:
      scrape_interval: 15s
      scrape_timeout:  15s
    
    # 告警地址(填写AlertManager的负载均衡地址即可)
    alerting:
      alertmanagers:
      - static_configs:
        - targets: [&quot;alertmanager-svc:9093&quot;]
    
    # 告警规则文件
    rule_files:
      - &quot;/etc/prometheus/rules/*.yml&quot;

    scrape_configs:
      - job_name: &quot;prometheus&quot;
        metrics_path: &quot;/metrics&quot;
        static_configs:
        - targets: [&quot;localhost:9090&quot;]

      # 监控Kubernetes的节点
      - job_name: &quot;kube-nodes&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - source_labels: [&quot;__address__&quot;]
          regex: &quot;(.*):10250&quot;
          replacement: &quot;$1:9100&quot;
          target_label: __address__
          action: replace
        - regex: __meta_kubernetes_node_label_(.*)
          replacement: $1
          action: labelmap

      # 监控APIServer
      - job_name: &quot;kube-apiserver&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
        tls_config:
          insecure_skip_verify: true   # 跳过证书验证
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        # 标签重写
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
          regex: &quot;apiserver&quot;
          action: &quot;keep&quot;
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: service_name
        - regex: __meta_kubernetes_service_label_(.*)        #通过标签映射获取标签
          replacement: $1
          action: labelmap


      # 监控controllerManager
      - job_name: &quot;kube-controller&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: pod
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        # 仅保留标签名是component 值为kube-controller-manager
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;kube-controller-manager&quot;
          action: keep
        # 替换抓取的实例端口为10257
        - source_labels: [__address__]
          regex: (.*)
          replacement: $1:10257
          target_label: __address__
        # 保留特定标签
        - source_labels: [__meta_kubernetes_namespace]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [__meta_kubernetes_pod_name]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控Scheduler
      - job_name: &quot;kube-schduler&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: pod
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        # 基于标签进行过滤
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;kube-scheduler&quot;
          action: keep

        # 修订抓取的端口
        - source_labels: [&quot;__address__&quot;]
          regex: (.*)
          replacement: $1:10259
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控etcd
      - job_name: &quot;kube-etcd&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: pod

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;etcd&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__address__&quot;]
          regex: (.*)
          replacement: $1:2381
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控CoreDNS
      - job_name: &quot;kube-dns&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: endpoints

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_k8s_app&quot;]
          regex: &quot;kube-dns&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
          regex: (.*)
          replacement: $1:9153
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name
        - source_labels: [&quot;__meta_kubernetes_service_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: service_name

      # 监控kube-proxy
      - job_name: &quot;kube-proxy&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: pod

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_k8s_app&quot;]
          regex: &quot;kube-proxy&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
          regex: (.*)
          replacement: $1:10249
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

[root@k8s-master01 04-prometheus]# kubectl apply -f 01-prom-configs-configmap.yaml
</code></pre><p>2、检查配置是否更新</p><pre><code>[root@k8s-master01 04-prometheus]# kubectl exec -it prometheus-0 -n monitoring -- cat /etc/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  scrape_timeout:  15s

# 告警地址(填写AlertManager的负载均衡地址即可)
alerting:
  alertmanagers:
  - static_configs:
    - targets: [&quot;alertmanager-svc:9093&quot;]

# 告警规则文件
rule_files:
  - &quot;/etc/prometheus/rules/*.yml&quot;

scrape_configs:
  - job_name: &quot;prometheus&quot;
    metrics_path: &quot;/metrics&quot;
    static_configs:
    - targets: [&quot;localhost:9090&quot;]

  # 监控Kubernetes的节点
  - job_name: &quot;kube-nodes&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: node
    relabel_configs:
    - source_labels: [&quot;__address__&quot;]
      regex: &quot;(.*):10250&quot;
      replacement: &quot;$1:9100&quot;
      target_label: __address__
      action: replace
    - regex: __meta_kubernetes_node_label_(.*)
      replacement: $1
      action: labelmap

  # 监控APIServer
  - job_name: &quot;kube-apiserver&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: endpoints
    scheme: https
    tls_config:
      insecure_skip_verify: true   # 跳过证书验证
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    # 标签重写
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
      regex: &quot;apiserver&quot;
      action: &quot;keep&quot;
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: service_name
    - regex: __meta_kubernetes_service_label_(.*)        #通过标签映射获取标签
      replacement: $1
      action: labelmap


  # 监控controllerManager
  - job_name: &quot;kube-controller&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: https
    kubernetes_sd_configs:
    - role: pod
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    # 仅保留标签名是component 值为kube-controller-manager
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;kube-controller-manager&quot;
      action: keep
    # 替换抓取的实例端口为10257
    - source_labels: [__address__]
      regex: (.*)
      replacement: $1:10257
      target_label: __address__
    # 保留特定标签
    - source_labels: [__meta_kubernetes_namespace]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [__meta_kubernetes_pod_name]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控Scheduler
  - job_name: &quot;kube-schduler&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: https
    kubernetes_sd_configs:
    - role: pod
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

    # 基于标签进行过滤
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;kube-scheduler&quot;
      action: keep

    # 修订抓取的端口
    - source_labels: [&quot;__address__&quot;]
      regex: (.*)
      replacement: $1:10259
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控etcd
  - job_name: &quot;kube-etcd&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: http
    kubernetes_sd_configs:
    - role: pod

    # 保留对应标签的Pod
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;etcd&quot;
      action: keep

    # 修订端口
    - source_labels: [&quot;__address__&quot;]
      regex: (.*)
      replacement: $1:2381
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控CoreDNS
  - job_name: &quot;kube-dns&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: http
    kubernetes_sd_configs:
    - role: endpoints

    # 保留对应标签的Pod
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_service_label_k8s_app&quot;]
      regex: &quot;kube-dns&quot;
      action: keep

    # 修订端口
    - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
      regex: (.*)
      replacement: $1:9153
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name
    - source_labels: [&quot;__meta_kubernetes_service_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: service_name

  # 监控kube-proxy
  - job_name: &quot;kube-proxy&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: http
    kubernetes_sd_configs:
    - role: pod

    # 保留对应标签的Pod
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_k8s_app&quot;]
      regex: &quot;kube-proxy&quot;
      action: keep

    # 修订端口
    - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
      regex: (.*)
      replacement: $1:10249
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name
</code></pre><p>3、重新加载 Prometheus，然后检查节点的 targets，能正常监控 Kubernets 的节点</p><pre><code>[root@k8s-master01 04-prometheus]# curl -X POST http://k8s-prom.hmallleasing.com/-/reload
</code></pre><p>4、检查 Prometheus 抓取的结果</p><p><img loading="lazy" data-src="C:%5CUsers%5CAdministrator%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240317153148617.png" alt="image-20240317153148617"></p><h6 id="783-kube-proxy告警规则文件"><a class="anchor" href="#783-kube-proxy告警规则文件">#</a> 7.8.3 Kube-Proxy 告警规则⽂件</h6><p>1、编写告警规则⽂件</p><pre><code>  kube_proxy_rules.yml: |-
    groups:
    - name: kube-proxy告警规则文件
      rules:
      - alert: KubeProxy同步时间过长
        expr: |
          rate (kubeproxy_sync_proxy_rules_duration_seconds_sum[5m]) /
          rate (kubeproxy_sync_proxy_rules_duration_seconds_count[5m]) &gt; 3
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;kube-proxy同步时间过长 (实例: &#123;&#123; $labels.instance &#125;&#125;)&quot;
          description: &quot;实例 &#123;&#123; $labels.instance &#125;&#125;, kube-proxy同步操作的平均时间超过了3秒。该Pod &#123;&#123; $labels.pod_name &#125;&#125; 当前同步延迟：&#123;&#123; $value &#125;&#125;/s&quot;
      
      - alert: Iptables规则同步失败次数过多
        expr: rate(kubeproxy_sync_proxy_rules_iptables_restore_failures_total[5m]) &gt; 10
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;Iptables同步失败告警 (实例: &#123;&#123; $labels.instance &#125;&#125;)&quot;
          description: &quot;实例 &#123;&#123; $labels.instance &#125;&#125;, iptables规则同步失败次数超过10次。该Pod &#123;&#123; $labels.pod_name &#125;&#125; 当前失败次数：&#123;&#123; $value &#125;&#125;&quot;
</code></pre><h5 id="79-监控kubernetes集群资源状态"><a class="anchor" href="#79-监控kubernetes集群资源状态">#</a> 7.9 监控 Kubernetes 集群资源状态</h5><h6 id="791-什么是集群资源状态"><a class="anchor" href="#791-什么是集群资源状态">#</a> 7.9.1 什么是集群资源状态</h6><p>集群资源状态是指， Kubernetes 集群中所有资源对象、以及这些资源对象的当前状态信息。这些资源对象，包括 Pod、Deployment、DaemonSet、StatefulSet、Job、CronJob 等 。⽽这些资源状态，则提供了这些资源的详细信息，例如：</p><ul><li>1、当前集群中资源的数量；</li><li>2、当前集群中总共有多少个 Pod，分别处于什么状态（如 Running、Stopped、Terminated）。</li><li>3、有多少个 Deployment 正在运⾏，以及它们正在运⾏的 Pod 副本数量与实际期望运⾏的 Pod 副本数是否⼀致。</li><li>3、DaemonSet 控制的 Pod 是否已经在所有（或指定的）节点上运⾏。</li><li>4、Job 和 CronJob 是否按预定计划运⾏，以及执⾏成功与否。</li><li>...</li></ul><p>但是在 Kubernetes 中的组件，并不提供关于资源状态的指标。因此我们需要使⽤ kube-state-metrics ，因为 kube-state-metrics 它会主动收集关于 Kubernetes 集群中的各种资源的状态信息。如 Pod、Deployment、Job 以及它们的数量、运⾏状况等，⽽后将些信息转换成 Prometheus 所兼容的指标格式，进⽽让 Prometheus 能抓取这些指标，并进⾏分析与展示。</p><h6 id="792-安装kube-state-metrics"><a class="anchor" href="#792-安装kube-state-metrics">#</a> 7.9.2 安装 Kube-State-Metrics</h6><p>kube-state-metrics 版本与 kubernetes 的版本对应关系（注意版本要兼容）</p><table><thead><tr><th style="text-align:center">kube-state-metrics</th><th style="text-align:center">Kubernetes client-go Version</th></tr></thead><tbody><tr><td style="text-align:center">v2.6.0</td><td style="text-align:center">v1.24</td></tr><tr><td style="text-align:center">v2.7.0</td><td style="text-align:center">v1.25</td></tr><tr><td style="text-align:center">v2.8.2</td><td style="text-align:center">v1.26</td></tr><tr><td style="text-align:center">v2.9.2</td><td style="text-align:center">v1.26</td></tr><tr><td style="text-align:center">v2.10.0</td><td style="text-align:center">v1.27</td></tr><tr><td style="text-align:center">main</td><td style="text-align:center">v1.28</td></tr></tbody></table><p>1、安装 kube-state-metrics，⾸先克隆最新分⽀的源代码</p><pre><code>[root@k8s-master01 ~]# yum install git -y
[root@k8s-master01 ~]#  git clone https://github.com/kubernetes/kube-state-metrics.git
# 加速地址
[root@k8s-master01 ~]# git clone https://mirror.ghproxy.com/https://github.com/kubernetes/kube-state-metrics.git
</code></pre><p>2、修改 kube-state-metrics/examples/standard/deployment.yaml 镜像为国内的镜像</p><pre><code>[root@k8s-master01 ~]# cat kube-state-metrics/examples/standard/deployment.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: exporter
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/version: 2.11.0
  name: kube-state-metrics
  namespace: kube-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: kube-state-metrics
  template:
    metadata:
      labels:
        app.kubernetes.io/component: exporter
        app.kubernetes.io/name: kube-state-metrics
        app.kubernetes.io/version: 2.11.0
    spec:
      automountServiceAccountToken: true
      containers:
#      - image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.11.0
      - image: uhub.service.ucloud.cn/oldxu/kube-state-metrics:v2.10.0
...
</code></pre><p>3、应⽤资源清单⽂件</p><pre><code>[root@k8s-master01 ~]#  kubectl apply -f kube-state-metrics/examples/standard/
clusterrolebinding.rbac.authorization.k8s.io/kube-state-metrics created
clusterrole.rbac.authorization.k8s.io/kube-state-metrics created
deployment.apps/kube-state-metrics created
serviceaccount/kube-state-metrics created
service/kube-state-metrics created
</code></pre><p>4、 Kube-state-metrics 的 Pod 运⾏在 kube-system 名称空间</p><pre><code>[root@k8s-master01 standard]# kubectl get pods,svc -n kube-system -l app.kubernetes.io/name=kube-state-metrics
NAME                                      READY   STATUS    RESTARTS   AGE
pod/kube-state-metrics-5864c7d699-mwbp4   1/1     Running   0          2m15s

NAME                         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)             AGE
service/kube-state-metrics   ClusterIP   None         &lt;none&gt;        8080/TCP,8081/TCP   2m15s
</code></pre><p>5、 Kube-state-metrics 有提供 Service ，因此我们需要获取 Service 的标签（labels），以便 Prometheus 只抓取提供 Kube-state-metrics 服务的实例。</p><pre><code>[root@k8s-master01 standard]# curl -s http://172.16.85.199:8080/metrics | head -n 10
# HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles.
# TYPE go_gc_duration_seconds summary
go_gc_duration_seconds&#123;quantile=&quot;0&quot;&#125; 2.1866e-05
go_gc_duration_seconds&#123;quantile=&quot;0.25&quot;&#125; 8.7894e-05
go_gc_duration_seconds&#123;quantile=&quot;0.5&quot;&#125; 0.000165906
go_gc_duration_seconds&#123;quantile=&quot;0.75&quot;&#125; 0.000179164
go_gc_duration_seconds&#123;quantile=&quot;1&quot;&#125; 0.000420888
go_gc_duration_seconds_sum 0.001599982
go_gc_duration_seconds_count 10
# HELP go_goroutines Number of goroutines that currently exist.

[root@k8s-master01 standard]#  kubectl describe service -n kube-system kube-state-metrics
Name:              kube-state-metrics
Namespace:         kube-system
Labels:            app.kubernetes.io/component=exporter
                   app.kubernetes.io/name=kube-state-metrics
                   app.kubernetes.io/version=2.11.0
...
</code></pre><h6 id="793-配置prometheus监控ksm"><a class="anchor" href="#793-配置prometheus监控ksm">#</a> 7.9.3 配置 Prometheus 监控 KSM</h6><ul><li>1、添加⼀个新的 Job，名为： kube-state-metrics ，metrics 路径是 /metrics ，协议是 http</li><li>2、基于 Kubernetes 的 endpoints 来⾃动发现所有的 endpoints 端点；</li><li>3、使⽤ relabel_configs，仅保留标签名 __meta_kubernetes_service_label_app_kubernetes_io_name ，标签值是 kube-state-metrics 的实例。</li><li>4、使⽤ relabel_configs，重新调整 Pod 的端⼝，将标签 __meta_kubernetes_pod_ip 修改为 IP:8080 端⼝。</li><li>5、使⽤ relabel_configs，映射 _<em>meta_kubernetes_service_label</em> (.*) ，所有的标签以及标签值。</li></ul><p>1、配置 Prometheus</p><pre><code>[root@k8s-master01 04-prometheus]# cat 01-prom-configs-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prom-configs
  namespace: monitoring
data:
  prometheus.yml: |-
    global:
      scrape_interval: 15s
      scrape_timeout:  15s
    
    # 告警地址(填写AlertManager的负载均衡地址即可)
    alerting:
      alertmanagers:
      - static_configs:
        - targets: [&quot;alertmanager-svc:9093&quot;]
    
    # 告警规则文件
    rule_files:
      - &quot;/etc/prometheus/rules/*.yml&quot;

    scrape_configs:
      - job_name: &quot;prometheus&quot;
        metrics_path: &quot;/metrics&quot;
        static_configs:
        - targets: [&quot;localhost:9090&quot;]

      # 监控Kubernetes的节点
      - job_name: &quot;kube-nodes&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - source_labels: [&quot;__address__&quot;]
          regex: &quot;(.*):10250&quot;
          replacement: &quot;$1:9100&quot;
          target_label: __address__
          action: replace
        - regex: __meta_kubernetes_node_label_(.*)
          replacement: $1
          action: labelmap

      # 监控APIServer
      - job_name: &quot;kube-apiserver&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
        tls_config:
          insecure_skip_verify: true   # 跳过证书验证
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        # 标签重写
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
          regex: &quot;apiserver&quot;
          action: &quot;keep&quot;
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: service_name
        - regex: __meta_kubernetes_service_label_(.*)        #通过标签映射获取标签
          replacement: $1
          action: labelmap


      # 监控controllerManager
      - job_name: &quot;kube-controller&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: pod
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        # 仅保留标签名是component 值为kube-controller-manager
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;kube-controller-manager&quot;
          action: keep
        # 替换抓取的实例端口为10257
        - source_labels: [__address__]
          regex: (.*)
          replacement: $1:10257
          target_label: __address__
        # 保留特定标签
        - source_labels: [__meta_kubernetes_namespace]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [__meta_kubernetes_pod_name]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控Scheduler
      - job_name: &quot;kube-schduler&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: pod
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        # 基于标签进行过滤
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;kube-scheduler&quot;
          action: keep

        # 修订抓取的端口
        - source_labels: [&quot;__address__&quot;]
          regex: (.*)
          replacement: $1:10259
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控etcd
      - job_name: &quot;kube-etcd&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: pod

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;etcd&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__address__&quot;]
          regex: (.*)
          replacement: $1:2381
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控CoreDNS
      - job_name: &quot;kube-dns&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: endpoints

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_k8s_app&quot;]
          regex: &quot;kube-dns&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
          regex: (.*)
          replacement: $1:9153
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name
        - source_labels: [&quot;__meta_kubernetes_service_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: service_name

      # 监控kube-proxy
      - job_name: &quot;kube-proxy&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: pod

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_k8s_app&quot;]
          regex: &quot;kube-proxy&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
          regex: (.*)
          replacement: $1:10249
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控kube-state-metrics
      - job_name: &quot;kube-state-metrics&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: endpoints

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_app_kubernetes_io_name&quot;]
          regex: &quot;kube-state-metrics&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
          regex: (.*)
          replacement: $1:8080
          target_label: __address__

        # 添加维度标签
        - regex: __meta_kubernetes_service_label_(.*)
          action: labelmap

[root@k8s-master01 04-prometheus]# kubectl apply -f 01-prom-configs-configmap.yaml
</code></pre><p>2、检查配置是否更新</p><pre><code>[root@k8s-master01 04-prometheus]#  kubectl exec -it prometheus-0 -n monitoring -- cat /etc/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  scrape_timeout:  15s

# 告警地址(填写AlertManager的负载均衡地址即可)
alerting:
  alertmanagers:
  - static_configs:
    - targets: [&quot;alertmanager-svc:9093&quot;]

# 告警规则文件
rule_files:
  - &quot;/etc/prometheus/rules/*.yml&quot;

scrape_configs:
  - job_name: &quot;prometheus&quot;
    metrics_path: &quot;/metrics&quot;
    static_configs:
    - targets: [&quot;localhost:9090&quot;]

  # 监控Kubernetes的节点
  - job_name: &quot;kube-nodes&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: node
    relabel_configs:
    - source_labels: [&quot;__address__&quot;]
      regex: &quot;(.*):10250&quot;
      replacement: &quot;$1:9100&quot;
      target_label: __address__
      action: replace
    - regex: __meta_kubernetes_node_label_(.*)
      replacement: $1
      action: labelmap

  # 监控APIServer
  - job_name: &quot;kube-apiserver&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: endpoints
    scheme: https
    tls_config:
      insecure_skip_verify: true   # 跳过证书验证
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    # 标签重写
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
      regex: &quot;apiserver&quot;
      action: &quot;keep&quot;
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: service_name
    - regex: __meta_kubernetes_service_label_(.*)        #通过标签映射获取标签
      replacement: $1
      action: labelmap


  # 监控controllerManager
  - job_name: &quot;kube-controller&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: https
    kubernetes_sd_configs:
    - role: pod
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    # 仅保留标签名是component 值为kube-controller-manager
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;kube-controller-manager&quot;
      action: keep
    # 替换抓取的实例端口为10257
    - source_labels: [__address__]
      regex: (.*)
      replacement: $1:10257
      target_label: __address__
    # 保留特定标签
    - source_labels: [__meta_kubernetes_namespace]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [__meta_kubernetes_pod_name]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控Scheduler
  - job_name: &quot;kube-schduler&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: https
    kubernetes_sd_configs:
    - role: pod
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

    # 基于标签进行过滤
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;kube-scheduler&quot;
      action: keep

    # 修订抓取的端口
    - source_labels: [&quot;__address__&quot;]
      regex: (.*)
      replacement: $1:10259
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控etcd
  - job_name: &quot;kube-etcd&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: http
    kubernetes_sd_configs:
    - role: pod

    # 保留对应标签的Pod
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;etcd&quot;
      action: keep

    # 修订端口
    - source_labels: [&quot;__address__&quot;]
      regex: (.*)
      replacement: $1:2381
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控CoreDNS
  - job_name: &quot;kube-dns&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: http
    kubernetes_sd_configs:
    - role: endpoints

    # 保留对应标签的Pod
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_service_label_k8s_app&quot;]
      regex: &quot;kube-dns&quot;
      action: keep

    # 修订端口
    - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
      regex: (.*)
      replacement: $1:9153
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name
    - source_labels: [&quot;__meta_kubernetes_service_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: service_name

  # 监控kube-proxy
  - job_name: &quot;kube-proxy&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: http
    kubernetes_sd_configs:
    - role: pod

    # 保留对应标签的Pod
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_k8s_app&quot;]
      regex: &quot;kube-proxy&quot;
      action: keep

    # 修订端口
    - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
      regex: (.*)
      replacement: $1:10249
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控kube-state-metrics
  - job_name: &quot;kube-state-metrics&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: http
    kubernetes_sd_configs:
    - role: endpoints

    # 保留对应标签的Pod
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_service_label_app_kubernetes_io_name&quot;]
      regex: &quot;kube-state-metrics&quot;
      action: keep

    # 修订端口
    - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
      regex: (.*)
      replacement: $1:8080
      target_label: __address__

    # 添加维度标签
    - regex: __meta_kubernetes_service_label_(.*)
      action: labelmap
</code></pre><p>3、重新加载 Prometheus，然后检查节点的 targets，能正常监控 Kubernets 的节点</p><pre><code>[root@k8s-master01 04-prometheus]# curl -X POST http://k8s-prom.hmallleasing.com/-/reload
</code></pre><p>4、检查 Prometheus 抓取的结果</p><p><img loading="lazy" data-src="C:%5CUsers%5CAdministrator%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240317205755162.png" alt="image-20240317205755162"></p><h6 id="794-资源状态告警规则文件"><a class="anchor" href="#794-资源状态告警规则文件">#</a> 7.9.4 资源状态告警规则⽂件</h6><p>1、编写告警规则⽂件</p><pre><code>  kube_state_metrics_rules.yml: |-
    groups:
    - name: KSM告警规则文件
      rules:
      - alert: 节点kubelet未就绪
        expr: kube_node_status_condition&#123;condition=&quot;Ready&quot;, status=&quot;true&quot;&#125; == 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;节点 &#123;&#123; $labels.node &#125;&#125; kubelet未就绪&quot;
          description: &quot;节点 &#123;&#123; $labels.node &#125;&#125; kubelet已经超过5分钟未处于就绪状态，需要立即检查。&quot;

      - alert: 节点内存压力大
        expr: kube_node_status_condition&#123;condition=&quot;MemoryPressure&quot;, status=&quot;true&quot;&#125; == 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;节点 &#123;&#123; $labels.node &#125;&#125; 内存压力过高&quot;
          description: &quot;节点 &#123;&#123; $labels.node &#125;&#125; 正在经历内存压力，可能需要增加内存资源或减少工作负载。&quot;

      - alert: 节点网络压力大
        expr: kube_node_status_condition&#123;condition=&quot;NetworkUnavailable&quot;,status=&quot;true&quot;&#125; == 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;节点 &#123;&#123; $labels.node &#125;&#125; 网络压力过高&quot;
          description: &quot;节点 &#123;&#123; $labels.node &#125;&#125; 的网络接压力过大，可能存在网络瓶颈。&quot;

      - alert: 节点磁盘压力大
        expr: kube_node_status_condition&#123;condition=&quot;DiskPressure&quot;, status=&quot;true&quot;&#125; == 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;节点 &#123;&#123; $labels.node &#125;&#125;磁盘压力过高&quot;
          description: &quot;节点 &#123;&#123; $labels.node &#125;&#125; 正在经历磁盘压力，磁盘空间或inode可能不足。&quot;

      - alert: 节点PID压力大
        expr: kube_node_status_condition&#123;condition=&quot;PIDPressure&quot;, status=&quot;true&quot;&#125; == 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;节点 &#123;&#123; $labels.node &#125;&#125; PID压力过高&quot;
          description: &quot;节点 &#123;&#123; $labels.node &#125;&#125; 上的进程数可能已经达到上限。&quot;

      - alert: 启动失败的Pod
        expr: sum (kube_pod_status_phase&#123;phase=~&quot;Pending|Unknown|Failed&quot;&#125;) by (job,namespace, pod) &gt; 0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;Pod启动失败&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中的Pod '&#123;&#123; $labels.pod &#125;&#125;'启动失败。&quot;
      
      - alert: 因为OOM重启的Pod
        expr: |
          (kube_pod_container_status_restarts_total - kube_pod_container_status_restarts_total offset 10m &gt;= 1)
          and ignoring (reason)
          min_over_time(kube_pod_container_status_last_terminated_reason&#123;reason=&quot;OOMKilled&quot;&#125;[10m]) &gt;= 1
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: &quot;&#123;&#123; $labels.pod &#125;&#125; Pod因OOM重启&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中的Pod '&#123;&#123; $labels.pod &#125;&#125;' 触发了OOM造成Pod重启,触发OOM的容器是 '&#123;&#123; $labels.container &#125;&#125;'。&quot;

      - alert: Deployment副本数不一致
        expr: kube_deployment_spec_replicas - kube_deployment_status_replicas_available &gt; 0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;Deployment副本数不一致&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 &#123;&#123; $labels.deployment &#125;&#125; 部署副本数与期望副本数不一致，当前偏差了&#123;&#123; $value &#125;&#125;个副本。&quot;
      
      - alert: DaemonSet副本数不一致
        expr: |
          kube_daemonset_status_number_ready / kube_daemonset_status_desired_number_scheduled * 100 &lt; 100
          or
          kube_daemonset_status_desired_number_scheduled - kube_daemonset_status_current_number_scheduled &gt; 0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;DaemonSet副本数不一致&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 &#123;&#123; $labels.daemonset &#125;&#125; 期望副本数与实际运行副本数不一致。&quot;

      - alert: DaemonSet调度出现错误
        expr: kube_daemonset_status_number_misscheduled &gt; 0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;DaemonSet调度错误&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 &#123;&#123; $labels.daemonset &#125;&#125; 调度了错误的Pod。&quot;

      - alert: StatefulSet副本数异常
        expr: |
          kube_statefulset_status_replicas_ready  / kube_statefulset_replicas  * 100 &lt; 100
          or
          kube_statefulset_replicas - kube_statefulset_status_replicas_current &gt; 0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;StatefulSet副本数异常&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 &#123;&#123; $labels.statefulset &#125;&#125; 期望副本数与实际运行副本数不一致。&quot;

      - alert: PV异常
        expr: kube_persistentvolume_status_phase&#123;phase=&quot;Failed&quot;&#125; &gt; 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;PV异常&quot;
          description: &quot;持久卷'&#123;&#123; $labels.persistentvolume &#125;&#125;'处于Failed状态。&quot;

      - alert: PVC异常
        expr: kube_persistentvolumeclaim_status_phase&#123;phase=~&quot;Lost|Pending&quot;&#125; &gt; 0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;PVC异常&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 &#123;&#123; $labels.persistentvolumeclaim &#125;&#125; 持久卷(PVC)处于 &#123;&#123; $labels.phase &#125;&#125;状态。&quot;

      - alert: Job完成度低
        expr: kube_job_status_succeeded / kube_job_spec_completions * 100 &lt; 75
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;Job完成度低于75%&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 &#123;&#123; $labels.job_name &#125;&#125; Job任务完成度低于预期的75%。&quot;

      - alert: Job失败次数高
        expr: kube_job_status_failed &gt; 5
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;Job失败次数过高&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 &#123;&#123; $labels.job_name &#125;&#125; Job任务执行失败次数超过5次以上，当前失败 &#123;&#123; $value &#125;&#125; 次。&quot;
</code></pre><h6 id="795-导入资源状态图形"><a class="anchor" href="#795-导入资源状态图形">#</a> 7.9.5 导⼊资源状态图形</h6><p>ID：13332 或 15757</p><h5 id="710-监控kubernetes集群pod资源"><a class="anchor" href="#710-监控kubernetes集群pod资源">#</a> 7.10 监控 Kubernetes 集群 Pod 资源</h5><h6 id="7101-pod资源是什么"><a class="anchor" href="#7101-pod资源是什么">#</a> 7.10.1 Pod 资源是什么</h6><p>所谓 Pod 资源，指的是，运⾏在 Pod 中的 &quot;容器&quot; 所使⽤的计算资源。这些计算资源指的是 CPU、内存、⽹络以及磁盘 IO 等相关指标。之前我们监控容器的资源时，使⽤的是 cAdvisor ⼯具来监控。不过在 Kubernetes 中，Cadvisor ⼯具已经被内置到了 kubelet 的组件中。因此，我们可以直接监控节点的 kubelet，来收集相关 Pod 的指标数据。</p><p>kubelet 的指标可以通过以下⽅式访问：</p><ul><li>端⼝：10250，kubelet ⽤于指标数据。</li><li>协议：HTTPS，确保数据传输的安全性（因此需要进⾏认证才可以抓取数据）。</li><li>路径： /metrics/cadvisor ，特定的 URL 路径，我们需要从这个路径获取 cAdvisor 提供的指标数据。</li></ul><h6 id="7102-配置prometheus监控pod"><a class="anchor" href="#7102-配置prometheus监控pod">#</a> 7.10.2 配置 Prometheus 监控 Pod</h6><ul><li>1、添加⼀个新的 Job，名为： kube-kubelet ，metrics 路径是 /metrics/cadvisor ，协议是 https</li><li>2、基于 Kubernetes 的 node ⽅式来发现所有的主机实例，由于 kubelet 采⽤的是 HTTPS，因此还需要指定 TLS 相关的配置；</li><li>3、使⽤ relabel_configs，映射 _<em>meta_kubernetes_node_label</em> (.*) ，所有的标签以及标签值。</li></ul><pre><code>[root@k8s-master01 04-prometheus]# TOKEN=$(kubectl create token -n monitoring prometheus-sa)
[root@k8s-master01 04-prometheus]# curl -s -k -H &quot;Authorization: Bearer $TOKEN&quot; https://192.168.40.101:10250/metrics|head -n 10
# HELP aggregator_discovery_aggregation_count_total [ALPHA] Counter of number of times discovery was aggregated
# TYPE aggregator_discovery_aggregation_count_total counter
aggregator_discovery_aggregation_count_total 0
# HELP apiserver_audit_event_total [ALPHA] Counter of audit events generated and sent to the audit backend.
# TYPE apiserver_audit_event_total counter
apiserver_audit_event_total 0
# HELP apiserver_audit_requests_rejected_total [ALPHA] Counter of apiserver requests rejected due to an error in audit logging backend.
# TYPE apiserver_audit_requests_rejected_total counter
apiserver_audit_requests_rejected_total 0
# HELP apiserver_client_certificate_expiration_seconds [ALPHA] Distribution of the remaining lifetime on the certificate used to authenticate a request.
</code></pre><p>1、配置 Prometheus</p><pre><code>[root@k8s-master01 04-prometheus]# cat 01-prom-configs-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prom-configs
  namespace: monitoring
data:
  prometheus.yml: |-
    global:
      scrape_interval: 15s
      scrape_timeout:  15s
    
    # 告警地址(填写AlertManager的负载均衡地址即可)
    alerting:
      alertmanagers:
      - static_configs:
        - targets: [&quot;alertmanager-svc:9093&quot;]
    
    # 告警规则文件
    rule_files:
      - &quot;/etc/prometheus/rules/*.yml&quot;

    scrape_configs:
      - job_name: &quot;prometheus&quot;
        metrics_path: &quot;/metrics&quot;
        static_configs:
        - targets: [&quot;localhost:9090&quot;]

      # 监控Kubernetes的节点
      - job_name: &quot;kube-nodes&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - source_labels: [&quot;__address__&quot;]
          regex: &quot;(.*):10250&quot;
          replacement: &quot;$1:9100&quot;
          target_label: __address__
          action: replace
        - regex: __meta_kubernetes_node_label_(.*)
          replacement: $1
          action: labelmap

      # 监控APIServer
      - job_name: &quot;kube-apiserver&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
        tls_config:
          insecure_skip_verify: true   # 跳过证书验证
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        # 标签重写
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
          regex: &quot;apiserver&quot;
          action: &quot;keep&quot;
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: service_name
        - regex: __meta_kubernetes_service_label_(.*)        #通过标签映射获取标签
          replacement: $1
          action: labelmap


      # 监控controllerManager
      - job_name: &quot;kube-controller&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: pod
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        # 仅保留标签名是component 值为kube-controller-manager
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;kube-controller-manager&quot;
          action: keep
        # 替换抓取的实例端口为10257
        - source_labels: [__address__]
          regex: (.*)
          replacement: $1:10257
          target_label: __address__
        # 保留特定标签
        - source_labels: [__meta_kubernetes_namespace]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [__meta_kubernetes_pod_name]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控Scheduler
      - job_name: &quot;kube-schduler&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: pod
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        # 基于标签进行过滤
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;kube-scheduler&quot;
          action: keep

        # 修订抓取的端口
        - source_labels: [&quot;__address__&quot;]
          regex: (.*)
          replacement: $1:10259
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控etcd
      - job_name: &quot;kube-etcd&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: pod

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;etcd&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__address__&quot;]
          regex: (.*)
          replacement: $1:2381
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控CoreDNS
      - job_name: &quot;kube-dns&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: endpoints

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_k8s_app&quot;]
          regex: &quot;kube-dns&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
          regex: (.*)
          replacement: $1:9153
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name
        - source_labels: [&quot;__meta_kubernetes_service_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: service_name

      # 监控kube-proxy
      - job_name: &quot;kube-proxy&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: pod

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_k8s_app&quot;]
          regex: &quot;kube-proxy&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
          regex: (.*)
          replacement: $1:10249
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控kube-state-metrics
      - job_name: &quot;kube-state-metrics&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: endpoints

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_app_kubernetes_io_name&quot;]
          regex: &quot;kube-state-metrics&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
          regex: (.*)
          replacement: $1:8080
          target_label: __address__

        # 添加维度标签
        - regex: __meta_kubernetes_service_label_(.*)
          action: labelmap

      # 监控kubelet(Pod)
      - job_name: &quot;kube-kubelet&quot;
        metrics_path: &quot;/metrics/cadvisor&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: node
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        # 添加标签的映射
        relabel_configs:
        - regex: __meta_kubernetes_node_label_(.*)
          action: labelmap

[root@k8s-master01 04-prometheus]# kubectl apply -f 01-prom-configs-configmap.yaml
</code></pre><p>2、检查配置是否更新</p><pre><code>[root@k8s-master01 04-prometheus]# kubectl exec -it prometheus-0 -n monitoring -- cat /etc/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  scrape_timeout:  15s

# 告警地址(填写AlertManager的负载均衡地址即可)
alerting:
  alertmanagers:
  - static_configs:
    - targets: [&quot;alertmanager-svc:9093&quot;]

# 告警规则文件
rule_files:
  - &quot;/etc/prometheus/rules/*.yml&quot;

scrape_configs:
  - job_name: &quot;prometheus&quot;
    metrics_path: &quot;/metrics&quot;
    static_configs:
    - targets: [&quot;localhost:9090&quot;]

  # 监控Kubernetes的节点
  - job_name: &quot;kube-nodes&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: node
    relabel_configs:
    - source_labels: [&quot;__address__&quot;]
      regex: &quot;(.*):10250&quot;
      replacement: &quot;$1:9100&quot;
      target_label: __address__
      action: replace
    - regex: __meta_kubernetes_node_label_(.*)
      replacement: $1
      action: labelmap

  # 监控APIServer
  - job_name: &quot;kube-apiserver&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: endpoints
    scheme: https
    tls_config:
      insecure_skip_verify: true   # 跳过证书验证
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    # 标签重写
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
      regex: &quot;apiserver&quot;
      action: &quot;keep&quot;
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: service_name
    - regex: __meta_kubernetes_service_label_(.*)        #通过标签映射获取标签
      replacement: $1
      action: labelmap


  # 监控controllerManager
  - job_name: &quot;kube-controller&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: https
    kubernetes_sd_configs:
    - role: pod
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    # 仅保留标签名是component 值为kube-controller-manager
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;kube-controller-manager&quot;
      action: keep
    # 替换抓取的实例端口为10257
    - source_labels: [__address__]
      regex: (.*)
      replacement: $1:10257
      target_label: __address__
    # 保留特定标签
    - source_labels: [__meta_kubernetes_namespace]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [__meta_kubernetes_pod_name]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控Scheduler
  - job_name: &quot;kube-schduler&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: https
    kubernetes_sd_configs:
    - role: pod
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

    # 基于标签进行过滤
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;kube-scheduler&quot;
      action: keep

    # 修订抓取的端口
    - source_labels: [&quot;__address__&quot;]
      regex: (.*)
      replacement: $1:10259
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控etcd
  - job_name: &quot;kube-etcd&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: http
    kubernetes_sd_configs:
    - role: pod

    # 保留对应标签的Pod
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;etcd&quot;
      action: keep

    # 修订端口
    - source_labels: [&quot;__address__&quot;]
      regex: (.*)
      replacement: $1:2381
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控CoreDNS
  - job_name: &quot;kube-dns&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: http
    kubernetes_sd_configs:
    - role: endpoints

    # 保留对应标签的Pod
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_service_label_k8s_app&quot;]
      regex: &quot;kube-dns&quot;
      action: keep

    # 修订端口
    - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
      regex: (.*)
      replacement: $1:9153
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name
    - source_labels: [&quot;__meta_kubernetes_service_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: service_name

  # 监控kube-proxy
  - job_name: &quot;kube-proxy&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: http
    kubernetes_sd_configs:
    - role: pod

    # 保留对应标签的Pod
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_k8s_app&quot;]
      regex: &quot;kube-proxy&quot;
      action: keep

    # 修订端口
    - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
      regex: (.*)
      replacement: $1:10249
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控kube-state-metrics
  - job_name: &quot;kube-state-metrics&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: http
    kubernetes_sd_configs:
    - role: endpoints

    # 保留对应标签的Pod
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_service_label_app_kubernetes_io_name&quot;]
      regex: &quot;kube-state-metrics&quot;
      action: keep

    # 修订端口
    - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
      regex: (.*)
      replacement: $1:8080
      target_label: __address__

    # 添加维度标签
    - regex: __meta_kubernetes_service_label_(.*)
      action: labelmap

  # 监控kubelet(Pod)
  - job_name: &quot;kube-kubelet&quot;
    metrics_path: &quot;/metrics/cadvisor&quot;
    scheme: https
    kubernetes_sd_configs:
    - role: node
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

    # 添加标签的映射
    relabel_configs:
    - regex: __meta_kubernetes_node_label_(.*)
      action: labelmap
</code></pre><p>3、重新加载 Prometheus，然后检查节点的 targets，能正常监控 Kubernets 的节点</p><pre><code>[root@k8s-master01 04-prometheus]# curl -X POST http://k8s-prom.hmallleasing.com/-/reload
</code></pre><p>4、检查 Prometheus 抓取的结果</p><p><img loading="lazy" data-src="C:%5CUsers%5CAdministrator%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240317212313946.png" alt="image-20240317212313946"></p><p>3、检查此前创建好的 kube_pods_rules.yml 告警规则⽂件</p><pre><code>  kube_pods_rules.yml: |-
    groups:
    - name: Pods的告警规则文件
      rules:
      - alert: Pod中容器的CPU利用率高
        expr: sum (rate(container_cpu_usage_seconds_total&#123;image!=&quot;&quot;&#125;[5m])) by (instance,job,pod,namespace) * 100 &gt; 80
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: &quot;在 '&#123;&#123; $labels.instance &#125;&#125;' 节点上运行的 '&#123;&#123; $labels.pod &#125;&#125;' Pod CPU利用率高&quot;
          description: &quot;在 '&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod &#125;&#125;' Pod的CPU利用率当前为 &#123;&#123; $value &#125;&#125;%，超过了80%的阈值。&quot;
    
      - alert: Pod中容器内存利用率高
        expr: |
          sum(container_memory_working_set_bytes&#123;name!=&quot;&quot;&#125;) by (instance,job,pod,namespace)
          /
          sum(container_spec_memory_limit_bytes&#123;name!=&quot;&quot;&#125; &gt; 0) by (instance,job,pod,namespace) * 100 &gt; 80
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: &quot;在 '&#123;&#123; $labels.instance &#125;&#125;' 节点上运行的 '&#123;&#123; $labels.pod &#125;&#125;' Pod内存利用率高&quot;
          description: 在 '&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod &#125;&#125;' Pod的内存最大限制是 &#123;&#123; printf `sum (container_spec_memory_limit_bytes&#123;namespace="%s",pod="%s"&#125; > 0 ) /1024 /1024` $labels.namespace $labels.pod | query | first | value &#125;&#125;MB , 目前利用率已达&#123;&#123; $value &#125;&#125;%，超过限制的80%。

      - alert: Pod容器网络发送速率过高
        expr: sum(rate(container_network_transmit_bytes_total&#123;image!=&quot;&quot;&#125;[1m])) by (instance,job,pod,namespace) * 8 /1024 /1024 &gt; 50
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: &quot;在 '&#123;&#123; $labels.instance &#125;&#125;' 节点上运行的 '&#123;&#123; $labels.pod &#125;&#125;' Pod网络发送速率过高&quot;
          description: &quot;在 '&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod &#125;&#125;' Pod的网络发送速率达到&#123;&#123; $value &#125;&#125;Mbps，超过了50Mbps的阈值。&quot;
    
      - alert: Pod容器网络接收速率过高
        expr: sum(rate(container_network_receive_bytes_total&#123;image!=&quot;&quot;&#125;[1m])) by (instance,job,pod,namespace) * 8 /1024 /1024 &gt; 50
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: &quot;在 '&#123;&#123; $labels.instance &#125;&#125;' 节点上运行的 '&#123;&#123; $labels.pod &#125;&#125;' Pod网络发送速率过高&quot;
          description: &quot;在 '&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod &#125;&#125;' Pod的网络接收速率达到&#123;&#123; $value &#125;&#125;Mbps，超过了50Mbps的阈值。&quot;
    
      - alert: Pod容器磁盘写入吞吐量过大
        expr: sum (rate(container_fs_writes_bytes_total&#123;name!=&quot;&quot;&#125;[1m])) by (instance,job,pod,namespace) /1024 /1024 &gt; 20
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: &quot;在 '&#123;&#123; $labels.instance &#125;&#125;' 节点上运行的 '&#123;&#123; $labels.pod &#125;&#125;' Pod磁盘写入吞吐量过大&quot;
          description: &quot;在 '&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod &#125;&#125;' Pod的磁盘写入吞吐量达到&#123;&#123; $value &#125;&#125;MB/s，超过了20MB/s的阈值。&quot;
    
      - alert: Pod容器磁盘读取吞吐量过大
        expr: sum (rate(container_fs_reads_bytes_total&#123;name!=&quot;&quot;&#125;[1m])) by (instance,job,pod,namespace) /1024 /1024 &gt; 20
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: &quot;在 '&#123;&#123; $labels.instance &#125;&#125;' 节点上运行的 '&#123;&#123; $labels.pod &#125;&#125;' Pod磁盘读取吞吐量过大&quot;
          description: &quot;在 '&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod &#125;&#125;' Pod的磁盘读取吞吐量达到&#123;&#123; $value &#125;&#125;MB/s，超过了20MB/s的阈值。&quot;
</code></pre><h5 id="711-监控kubernetes集群service资源"><a class="anchor" href="#711-监控kubernetes集群service资源">#</a> 7.11 监控 Kubernetes 集群 Service 资源</h5><h6 id="7111-为何需要监控service资源"><a class="anchor" href="#7111-为何需要监控service资源">#</a> 7.11.1 为何需要监控 Service 资源</h6><p>监控 Service 资源是为了确保我们的服务，时刻处于持续运⾏状态，通常关注如下两个维度；</p><p>● 1、可⽤性：确保 Service 始终是可以被访问的，从⽽保障服务的连续性。</p><p>● 2、性能：监控 Service 的响应时间，确保其处理请求的速度，始终处于⼀个稳定的时间。</p><p>为了确保 Service 的服务始终可⽤，我们通常会采⽤ Blackbox 的 TCP 探测⽅法来进⾏监控。</p><p>之前 Blackbox 监控⽅式⽐较固定，不够灵活。为了改进这⼀点，在监控 Service 时，我们可以将监控⽬标配置为⾃动发现机制。这样，每当有新的 Service 出现或现有 Service 发⽣变化时，监控系统能够⾃动识别并开始监控，⽽不需要⼿动更新 Prometheus 的配置。</p><pre><code>  - job_name: 'blackbox_http'
    metrics_path: /probe # metrics的path这次不是/metrics，⽽是/probe
    params: # 传递参数
      module: [http_2xx] # 调⽤哪个模块进⾏探测
    static_configs:
    - targets: [&quot;https://www.xuliangwei.com&quot;,&quot;http://www.oldxu.net&quot;,&quot;https://www.baidu.com&quot;,&quot;http://httpbin.org/status/400&quot;,&quot;https://httpstat.us/500&quot;,&quot;https://httpstat.us/502&quot;]
    relabel_configs:
    - source_labels: [__address__]
      target_label: __param_target
    - source_labels: [__param_target]
      target_label: instance
    - target_label: __address__
      replacement: prom-node04.oldxu.net:9115
      
# relabel_configs是标签重写的配置，这⾥进⾏了三次操作：
# 1、将⽬标地址（__address__）赋予给__param_target，这是Blackbox Exporter需要的⽬标target参数。
# 2、将__param_target的内容复制到instance标签，这样Prometheus UI中显示的instance实例名称会是⽬标站点地址，⽽不是Blackbox的地址。
# 3、最后，将实际发送探测请求的地址（__address__）设置为运⾏Blackbox Exporter的节点地址和端⼝（prom-node04.oldxu.net:9115），这样Prometheus就会向这个地址发送探测请求。
</code></pre><h6 id="7112-配置prometheus监控service"><a class="anchor" href="#7112-配置prometheus监控service">#</a> 7.11.2 配置 Prometheus 监控 Service</h6><p>1、添加⼀个新的 Job，名为： kube-blackbox-tcp ，协议是 tcp ， metrics 路径是 /probe</p><p>2、基于 Kubernetes 的 service 来实现⾃动发现所有的 Service，⽽后进⾏⾃动监控；</p><p>3、使⽤ relabel_configs，保留 __meta_kubernetes_namespace、__meta_kubernetes_service_name 这两个维度的标签。</p><p>1、配置 Prometheus</p><pre><code>[root@k8s-master01 04-prometheus]# cat 01-prom-configs-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prom-configs
  namespace: monitoring
data:
  prometheus.yml: |-
    global:
      scrape_interval: 15s
      scrape_timeout:  15s
    
    # 告警地址(填写AlertManager的负载均衡地址即可)
    alerting:
      alertmanagers:
      - static_configs:
        - targets: [&quot;alertmanager-svc:9093&quot;]
    
    # 告警规则文件
    rule_files:
      - &quot;/etc/prometheus/rules/*.yml&quot;

    scrape_configs:
      - job_name: &quot;prometheus&quot;
        metrics_path: &quot;/metrics&quot;
        static_configs:
        - targets: [&quot;localhost:9090&quot;]

      # 监控Kubernetes的节点
      - job_name: &quot;kube-nodes&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - source_labels: [&quot;__address__&quot;]
          regex: &quot;(.*):10250&quot;
          replacement: &quot;$1:9100&quot;
          target_label: __address__
          action: replace
        - regex: __meta_kubernetes_node_label_(.*)
          replacement: $1
          action: labelmap

      # 监控APIServer
      - job_name: &quot;kube-apiserver&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
        tls_config:
          insecure_skip_verify: true   # 跳过证书验证
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        # 标签重写
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
          regex: &quot;apiserver&quot;
          action: &quot;keep&quot;
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: service_name
        - regex: __meta_kubernetes_service_label_(.*)        #通过标签映射获取标签
          replacement: $1
          action: labelmap


      # 监控controllerManager
      - job_name: &quot;kube-controller&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: pod
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        # 仅保留标签名是component 值为kube-controller-manager
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;kube-controller-manager&quot;
          action: keep
        # 替换抓取的实例端口为10257
        - source_labels: [__address__]
          regex: (.*)
          replacement: $1:10257
          target_label: __address__
        # 保留特定标签
        - source_labels: [__meta_kubernetes_namespace]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [__meta_kubernetes_pod_name]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控Scheduler
      - job_name: &quot;kube-schduler&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: pod
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        # 基于标签进行过滤
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;kube-scheduler&quot;
          action: keep

        # 修订抓取的端口
        - source_labels: [&quot;__address__&quot;]
          regex: (.*)
          replacement: $1:10259
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控etcd
      - job_name: &quot;kube-etcd&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: pod

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;etcd&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__address__&quot;]
          regex: (.*)
          replacement: $1:2381
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控CoreDNS
      - job_name: &quot;kube-dns&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: endpoints

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_k8s_app&quot;]
          regex: &quot;kube-dns&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
          regex: (.*)
          replacement: $1:9153
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name
        - source_labels: [&quot;__meta_kubernetes_service_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: service_name

      # 监控kube-proxy
      - job_name: &quot;kube-proxy&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: pod

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_k8s_app&quot;]
          regex: &quot;kube-proxy&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
          regex: (.*)
          replacement: $1:10249
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控kube-state-metrics
      - job_name: &quot;kube-state-metrics&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: endpoints

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_app_kubernetes_io_name&quot;]
          regex: &quot;kube-state-metrics&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
          regex: (.*)
          replacement: $1:8080
          target_label: __address__

        # 添加维度标签
        - regex: __meta_kubernetes_service_label_(.*)
          action: labelmap

      # 监控kubelet(Pod)
      - job_name: &quot;kube-kubelet&quot;
        metrics_path: &quot;/metrics/cadvisor&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: node
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        # 添加标签的映射
        relabel_configs:
        - regex: __meta_kubernetes_node_label_(.*)
          action: labelmap

      # 监控service
      - job_name: &quot;kube-blackbox-tcp&quot;
        metrics_path: &quot;/probe&quot;
        params:
          module: [tcp_connect]         # 使用tcp_connect模块
        kubernetes_sd_configs:
        - role: service
        relabel_configs:
        - source_labels: [__address__]
          target_label: __param_target
        - source_labels: [__param_target]
          target_label: instance
        - target_label: __address__
          replacement: blackbox-svc:9115
        # 保留特定标签
        - source_labels: [__meta_kubernetes_namespace]
          regex: (.*)
          replacement: $1
          target_label: namespace
        - source_labels: [__meta_kubernetes_service_name]
          regex: (.*)
          replacement: $1
          target_label: service_name

[root@k8s-master01 04-prometheus]# kubectl apply -f 01-prom-configs-configmap.yaml
</code></pre><p>2、检查配置是否更新</p><pre><code>[root@k8s-master01 04-prometheus]#  kubectl exec -it prometheus-0 -n monitoring -- cat /etc/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  scrape_timeout:  15s

# 告警地址(填写AlertManager的负载均衡地址即可)
alerting:
  alertmanagers:
  - static_configs:
    - targets: [&quot;alertmanager-svc:9093&quot;]

# 告警规则文件
rule_files:
  - &quot;/etc/prometheus/rules/*.yml&quot;

scrape_configs:
  - job_name: &quot;prometheus&quot;
    metrics_path: &quot;/metrics&quot;
    static_configs:
    - targets: [&quot;localhost:9090&quot;]

  # 监控Kubernetes的节点
  - job_name: &quot;kube-nodes&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: node
    relabel_configs:
    - source_labels: [&quot;__address__&quot;]
      regex: &quot;(.*):10250&quot;
      replacement: &quot;$1:9100&quot;
      target_label: __address__
      action: replace
    - regex: __meta_kubernetes_node_label_(.*)
      replacement: $1
      action: labelmap

  # 监控APIServer
  - job_name: &quot;kube-apiserver&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: endpoints
    scheme: https
    tls_config:
      insecure_skip_verify: true   # 跳过证书验证
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    # 标签重写
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
      regex: &quot;apiserver&quot;
      action: &quot;keep&quot;
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: service_name
    - regex: __meta_kubernetes_service_label_(.*)        #通过标签映射获取标签
      replacement: $1
      action: labelmap


  # 监控controllerManager
  - job_name: &quot;kube-controller&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: https
    kubernetes_sd_configs:
    - role: pod
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    # 仅保留标签名是component 值为kube-controller-manager
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;kube-controller-manager&quot;
      action: keep
    # 替换抓取的实例端口为10257
    - source_labels: [__address__]
      regex: (.*)
      replacement: $1:10257
      target_label: __address__
    # 保留特定标签
    - source_labels: [__meta_kubernetes_namespace]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [__meta_kubernetes_pod_name]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控Scheduler
  - job_name: &quot;kube-schduler&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: https
    kubernetes_sd_configs:
    - role: pod
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

    # 基于标签进行过滤
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;kube-scheduler&quot;
      action: keep

    # 修订抓取的端口
    - source_labels: [&quot;__address__&quot;]
      regex: (.*)
      replacement: $1:10259
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控etcd
  - job_name: &quot;kube-etcd&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: http
    kubernetes_sd_configs:
    - role: pod

    # 保留对应标签的Pod
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;etcd&quot;
      action: keep

    # 修订端口
    - source_labels: [&quot;__address__&quot;]
      regex: (.*)
      replacement: $1:2381
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控CoreDNS
  - job_name: &quot;kube-dns&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: http
    kubernetes_sd_configs:
    - role: endpoints

    # 保留对应标签的Pod
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_service_label_k8s_app&quot;]
      regex: &quot;kube-dns&quot;
      action: keep

    # 修订端口
    - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
      regex: (.*)
      replacement: $1:9153
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name
    - source_labels: [&quot;__meta_kubernetes_service_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: service_name

  # 监控kube-proxy
  - job_name: &quot;kube-proxy&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: http
    kubernetes_sd_configs:
    - role: pod

    # 保留对应标签的Pod
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_k8s_app&quot;]
      regex: &quot;kube-proxy&quot;
      action: keep

    # 修订端口
    - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
      regex: (.*)
      replacement: $1:10249
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控kube-state-metrics
  - job_name: &quot;kube-state-metrics&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: http
    kubernetes_sd_configs:
    - role: endpoints

    # 保留对应标签的Pod
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_service_label_app_kubernetes_io_name&quot;]
      regex: &quot;kube-state-metrics&quot;
      action: keep

    # 修订端口
    - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
      regex: (.*)
      replacement: $1:8080
      target_label: __address__

    # 添加维度标签
    - regex: __meta_kubernetes_service_label_(.*)
      action: labelmap

  # 监控kubelet(Pod)
  - job_name: &quot;kube-kubelet&quot;
    metrics_path: &quot;/metrics/cadvisor&quot;
    scheme: https
    kubernetes_sd_configs:
    - role: node
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

    # 添加标签的映射
    relabel_configs:
    - regex: __meta_kubernetes_node_label_(.*)
      action: labelmap

  # 监控service
  - job_name: &quot;kube-blackbox-tcp&quot;
    metrics_path: &quot;/probe&quot;
    params:
      module: [tcp_connect]         # 使用tcp_connect模块
    kubernetes_sd_configs:
    - role: service
    relabel_configs:
    - source_labels: [__address__]
      target_label: __param_target
    - source_labels: [__param_target]
      target_label: instance
    - target_label: __address__
      replacement: blackbox-svc:9115
    # 保留特定标签
    - source_labels: [__meta_kubernetes_namespace]
      regex: (.*)
      replacement: $1
      target_label: namespace
    - source_labels: [__meta_kubernetes_service_name]
      regex: (.*)
      replacement: $1
      target_label: service_name
</code></pre><p>3、重新加载 Prometheus，然后检查节点的 targets，能正常监控 Kubernets 的节点</p><pre><code>[root@k8s-master01 04-prometheus]# curl -X POST http://k8s-prom.hmallleasing.com/-/reload
</code></pre><p>4、检查 Prometheus 抓取的结果</p><p><img loading="lazy" data-src="C:%5CUsers%5CAdministrator%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240317214533161.png" alt="image-20240317214533161"></p><p>5、检查此前创建好的 kube_blackbox_tcp_rules.yml 告警规则⽂件</p><pre><code> blackbox_tcp_rules.yml: |-
    groups:
    - name: Blackbox_tcp告警规则文件
      rules:
      - alert: Service TCP探测失败
        expr: sum(probe_success&#123;job=~&quot;.*tcp&quot;&#125;) by (instance,job,namespace,service_name) == 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;探测 '&#123;&#123; $labels.instance &#125;&#125;' Service 的TCP接口探测失败。&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中的 '&#123;&#123; $labels.service_name &#125;&#125;' Service资源 '&#123;&#123; $labels.instance &#125;&#125;' 地址探测失败。&quot;
    
      - alert: Service TCP请求的响应时间过长
        expr: probe_duration_seconds&#123;job=~&quot;.*tcp&quot;&#125; &gt; 0.500
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;探测 '&#123;&#123; $labels.instance &#125;&#125;' Service 的TCP响应时间超过了500毫秒。&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中的 '&#123;&#123; $labels.service_name &#125;&#125;' Service资源 '&#123;&#123; $labels.instance &#125;&#125;' 当前响应时长为 &#123;&#123; $value &#125;&#125; 秒。&quot;

      - alert: Service的DNS解析响应时间过长
        expr: probe_dns_lookup_time_seconds&#123;job=~&quot;.*tcp&quot;&#125; &gt; 0.500
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;探测 '&#123;&#123; $labels.instance &#125;&#125;' Service 的DNS解析响应时间超过了500毫秒。&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中的 '&#123;&#123; $labels.service_name &#125;&#125;' Service资源 '&#123;&#123; $labels.instance &#125;&#125;' 当前响应时长为 &#123;&#123; $value &#125;&#125; 秒。&quot;	
</code></pre><h5 id="712-监控kubernetes集群ingress资源"><a class="anchor" href="#712-监控kubernetes集群ingress资源">#</a> 7.12 监控 Kubernetes 集群 Ingress 资源</h5><h6 id="7121-为何需要监控ingress资源"><a class="anchor" href="#7121-为何需要监控ingress资源">#</a> 7.12.1 为何需要监控 Ingress 资源</h6><p>监控 Ingress 对应的域名，主要是为了确保⽤户，能时刻访问到对应域名所提供的服务；监控域名维度如下；</p><ol><li><p>HTTP 请求延迟：监控站点处理请求的延迟，如果请求延迟过⾼可以推送告警消息，这样就可以第⼀时间进⾏处理。</p></li><li><p>证书过期时间：监控 TLS/SSL 证书的有效期，以便及时更新证书，避免因为证书过期造成访问中断。</p></li><li><p>可⽤性：持续检查 Ingress 绑定的域名是否可被持续访问，确保⽤户的访问不会中断。</p></li></ol><p>为了实现这样的监控，通常会利⽤ Blackbox Exporter 的 HTTP 探测功能来检查 Ingress 对应域名的健康状态和响应时间。</p><p>之前 Blackbox 监控⽅式⽐较固定，不够灵活。为了改进这⼀点，在监控 Ingress 时，我们可以将监控⽬标配置为⾃动发现机制。这样，每当有新的 ingress 出现或现有 ingress 发⽣变化时，监控系统能够⾃动识别并开始监控，⽽不需要⼿动更新 Prometheus 的配置。</p><pre><code>  - job_name: 'blackbox_http'
    metrics_path: /probe # metrics的path这次不是/metrics，⽽是/probe
    params: # 传递参数
      module: [http_2xx] # 调⽤哪个模块进⾏探测
    static_configs:
    - targets: [&quot;https://www.xuliangwei.com&quot;,&quot;http://www.oldxu.net&quot;,&quot;https://www.baidu.com&quot;,&quot;http://httpbin.org/status/400&quot;,&quot;https://httpstat.us/500&quot;,&quot;https://httpstat.us/502&quot;]
    relabel_configs:
    - source_labels: [__address__]
      target_label: __param_target
    - source_labels: [__param_target]
      target_label: instance
    - target_label: __address__
      replacement: prom-node04.oldxu.net:9115
      
# relabel_configs是标签重写的配置，这⾥进⾏了三次操作：
# 1、将⽬标地址（__address__）赋予给__param_target，这是Blackbox Exporter需要的⽬标target参数。
# 2、将__param_target的内容复制到instance标签，这样Prometheus UI中显示的instance实例名称会是⽬标站点地址，⽽不是Blackbox的地址。
# 3、最后，将实际发送探测请求的地址（__address__）设置为运⾏Blackbox Exporter的节点地址和端⼝（prom-node04.oldxu.net:9115），这样Prometheus就会向这个地址发送探测请求。
</code></pre><h6 id="7122-配置prometheus监控ingress"><a class="anchor" href="#7122-配置prometheus监控ingress">#</a> 7.12.2 配置 Prometheus 监控 Ingress</h6><ul><li>1、添加⼀个新的 Job，名为： kube-blackbox-http ，协议是 http</li><li>2、基于 Kubernetes 的 ingress 来⾃动发现所有的 Ingress 资源，⽽后进⾏监控。</li><li>3、使⽤ relabel_configs，保留 __meta_kubernetes_namespace、__meta_kubernetes_ingress_name、__meta_kubernetes_ingress_class_name 这三个维度的标签。</li></ul><p>1、配置 Prometheus</p><pre><code>[root@k8s-master01 04-prometheus]# cat 01-prom-configs-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prom-configs
  namespace: monitoring
data:
  prometheus.yml: |-
    global:
      scrape_interval: 15s
      scrape_timeout:  15s
    
    # 告警地址(填写AlertManager的负载均衡地址即可)
    alerting:
      alertmanagers:
      - static_configs:
        - targets: [&quot;alertmanager-svc:9093&quot;]
    
    # 告警规则文件
    rule_files:
      - &quot;/etc/prometheus/rules/*.yml&quot;

    scrape_configs:
      - job_name: &quot;prometheus&quot;
        metrics_path: &quot;/metrics&quot;
        static_configs:
        - targets: [&quot;localhost:9090&quot;]

      # 监控Kubernetes的节点
      - job_name: &quot;kube-nodes&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - source_labels: [&quot;__address__&quot;]
          regex: &quot;(.*):10250&quot;
          replacement: &quot;$1:9100&quot;
          target_label: __address__
          action: replace
        - regex: __meta_kubernetes_node_label_(.*)
          replacement: $1
          action: labelmap

      # 监控APIServer
      - job_name: &quot;kube-apiserver&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
        tls_config:
          insecure_skip_verify: true   # 跳过证书验证
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        # 标签重写
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
          regex: &quot;apiserver&quot;
          action: &quot;keep&quot;
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: service_name
        - regex: __meta_kubernetes_service_label_(.*)        #通过标签映射获取标签
          replacement: $1
          action: labelmap


      # 监控controllerManager
      - job_name: &quot;kube-controller&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: pod
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        # 仅保留标签名是component 值为kube-controller-manager
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;kube-controller-manager&quot;
          action: keep
        # 替换抓取的实例端口为10257
        - source_labels: [__address__]
          regex: (.*)
          replacement: $1:10257
          target_label: __address__
        # 保留特定标签
        - source_labels: [__meta_kubernetes_namespace]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [__meta_kubernetes_pod_name]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控Scheduler
      - job_name: &quot;kube-schduler&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: pod
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        # 基于标签进行过滤
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;kube-scheduler&quot;
          action: keep

        # 修订抓取的端口
        - source_labels: [&quot;__address__&quot;]
          regex: (.*)
          replacement: $1:10259
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控etcd
      - job_name: &quot;kube-etcd&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: pod

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;etcd&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__address__&quot;]
          regex: (.*)
          replacement: $1:2381
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控CoreDNS
      - job_name: &quot;kube-dns&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: endpoints

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_k8s_app&quot;]
          regex: &quot;kube-dns&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
          regex: (.*)
          replacement: $1:9153
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name
        - source_labels: [&quot;__meta_kubernetes_service_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: service_name

      # 监控kube-proxy
      - job_name: &quot;kube-proxy&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: pod

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_k8s_app&quot;]
          regex: &quot;kube-proxy&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
          regex: (.*)
          replacement: $1:10249
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控kube-state-metrics
      - job_name: &quot;kube-state-metrics&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: endpoints

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_app_kubernetes_io_name&quot;]
          regex: &quot;kube-state-metrics&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
          regex: (.*)
          replacement: $1:8080
          target_label: __address__

        # 添加维度标签
        - regex: __meta_kubernetes_service_label_(.*)
          action: labelmap

      # 监控kubelet(Pod)
      - job_name: &quot;kube-kubelet&quot;
        metrics_path: &quot;/metrics/cadvisor&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: node
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        # 添加标签的映射
        relabel_configs:
        - regex: __meta_kubernetes_node_label_(.*)
          action: labelmap

      # 监控service
      - job_name: &quot;kube-blackbox-tcp&quot;
        metrics_path: &quot;/probe&quot;
        params:
          module: [tcp_connect]         # 使用tcp_connect模块
        kubernetes_sd_configs:
        - role: service
        relabel_configs:
        - source_labels: [__address__]
          target_label: __param_target
        - source_labels: [__param_target]
          target_label: instance
        - target_label: __address__
          replacement: blackbox-svc:9115
        # 保留特定标签
        - source_labels: [__meta_kubernetes_namespace]
          regex: (.*)
          replacement: $1
          target_label: namespace
        - source_labels: [__meta_kubernetes_service_name]
          regex: (.*)
          replacement: $1
          target_label: service_name

      # 监控ingress
      - job_name: &quot;kube-blackbox-http&quot;
        metrics_path: &quot;/probe&quot;
        params:
          module: [http_2xx]            # 使用http模块进行探测
        kubernetes_sd_configs:
        - role: ingress
        relabel_configs:
        # 协议有可能是http或https，因此需要根据抓取到的协议+端⼝，拼接出具体的探测示例
        - source_labels: [__meta_kubernetes_ingress_scheme,__address__]
          regex: (.*);(.*)
          replacement: $1://$2
          target_label: __param_target
        - source_labels: [__param_target]
          target_label: instance
        - target_label: __address__
          replacement: blackbox-svc:9115
        # 保留特定标签
        - source_labels: [__meta_kubernetes_namespace]
          target_label: namespace
        - source_labels: [__meta_kubernetes_ingress_name]
          target_label: ingress_name
        - source_labels: [__meta_kubernetes_ingress_class_name]
          target_label: ingress_class_name
          
[root@k8s-master01 04-prometheus]# kubectl apply -f 01-prom-configs-configmap.yaml
</code></pre><p>2、检查配置是否更新</p><pre><code>[root@k8s-master01 04-prometheus]#  kubectl exec -it prometheus-0 -n monitoring -- cat /etc/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  scrape_timeout:  15s

# 告警地址(填写AlertManager的负载均衡地址即可)
alerting:
  alertmanagers:
  - static_configs:
    - targets: [&quot;alertmanager-svc:9093&quot;]

# 告警规则文件
rule_files:
  - &quot;/etc/prometheus/rules/*.yml&quot;

scrape_configs:
  - job_name: &quot;prometheus&quot;
    metrics_path: &quot;/metrics&quot;
    static_configs:
    - targets: [&quot;localhost:9090&quot;]

  # 监控Kubernetes的节点
  - job_name: &quot;kube-nodes&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: node
    relabel_configs:
    - source_labels: [&quot;__address__&quot;]
      regex: &quot;(.*):10250&quot;
      replacement: &quot;$1:9100&quot;
      target_label: __address__
      action: replace
    - regex: __meta_kubernetes_node_label_(.*)
      replacement: $1
      action: labelmap

  # 监控APIServer
  - job_name: &quot;kube-apiserver&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: endpoints
    scheme: https
    tls_config:
      insecure_skip_verify: true   # 跳过证书验证
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    # 标签重写
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
      regex: &quot;apiserver&quot;
      action: &quot;keep&quot;
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: service_name
    - regex: __meta_kubernetes_service_label_(.*)        #通过标签映射获取标签
      replacement: $1
      action: labelmap


  # 监控controllerManager
  - job_name: &quot;kube-controller&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: https
    kubernetes_sd_configs:
    - role: pod
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    # 仅保留标签名是component 值为kube-controller-manager
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;kube-controller-manager&quot;
      action: keep
    # 替换抓取的实例端口为10257
    - source_labels: [__address__]
      regex: (.*)
      replacement: $1:10257
      target_label: __address__
    # 保留特定标签
    - source_labels: [__meta_kubernetes_namespace]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [__meta_kubernetes_pod_name]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控Scheduler
  - job_name: &quot;kube-schduler&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: https
    kubernetes_sd_configs:
    - role: pod
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

    # 基于标签进行过滤
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;kube-scheduler&quot;
      action: keep

    # 修订抓取的端口
    - source_labels: [&quot;__address__&quot;]
      regex: (.*)
      replacement: $1:10259
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控etcd
  - job_name: &quot;kube-etcd&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: http
    kubernetes_sd_configs:
    - role: pod

    # 保留对应标签的Pod
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;etcd&quot;
      action: keep

    # 修订端口
    - source_labels: [&quot;__address__&quot;]
      regex: (.*)
      replacement: $1:2381
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控CoreDNS
  - job_name: &quot;kube-dns&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: http
    kubernetes_sd_configs:
    - role: endpoints

    # 保留对应标签的Pod
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_service_label_k8s_app&quot;]
      regex: &quot;kube-dns&quot;
      action: keep

    # 修订端口
    - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
      regex: (.*)
      replacement: $1:9153
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name
    - source_labels: [&quot;__meta_kubernetes_service_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: service_name

  # 监控kube-proxy
  - job_name: &quot;kube-proxy&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: http
    kubernetes_sd_configs:
    - role: pod

    # 保留对应标签的Pod
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_k8s_app&quot;]
      regex: &quot;kube-proxy&quot;
      action: keep

    # 修订端口
    - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
      regex: (.*)
      replacement: $1:10249
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控kube-state-metrics
  - job_name: &quot;kube-state-metrics&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: http
    kubernetes_sd_configs:
    - role: endpoints

    # 保留对应标签的Pod
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_service_label_app_kubernetes_io_name&quot;]
      regex: &quot;kube-state-metrics&quot;
      action: keep

    # 修订端口
    - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
      regex: (.*)
      replacement: $1:8080
      target_label: __address__

    # 添加维度标签
    - regex: __meta_kubernetes_service_label_(.*)
      action: labelmap

  # 监控kubelet(Pod)
  - job_name: &quot;kube-kubelet&quot;
    metrics_path: &quot;/metrics/cadvisor&quot;
    scheme: https
    kubernetes_sd_configs:
    - role: node
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

    # 添加标签的映射
    relabel_configs:
    - regex: __meta_kubernetes_node_label_(.*)
      action: labelmap

  # 监控service
  - job_name: &quot;kube-blackbox-tcp&quot;
    metrics_path: &quot;/probe&quot;
    params:
      module: [tcp_connect]         # 使用tcp_connect模块
    kubernetes_sd_configs:
    - role: service
    relabel_configs:
    - source_labels: [__address__]
      target_label: __param_target
    - source_labels: [__param_target]
      target_label: instance
    - target_label: __address__
      replacement: blackbox-svc:9115
    # 保留特定标签
    - source_labels: [__meta_kubernetes_namespace]
      regex: (.*)
      replacement: $1
      target_label: namespace
    - source_labels: [__meta_kubernetes_service_name]
      regex: (.*)
      replacement: $1
      target_label: service_name

  # 监控ingress
  - job_name: &quot;kube-blackbox-http&quot;
    metrics_path: &quot;/probe&quot;
    params:
      module: [http_2xx]            # 使用http模块进行探测
    kubernetes_sd_configs:
    - role: ingress
    relabel_configs:
    # 协议有可能是http或https，因此需要根据抓取到的协议+端⼝，拼接出具体的探测示例
    - source_labels: [__meta_kubernetes_ingress_scheme,__address__]
      regex: (.*);(.*)
      replacement: $1://$2
      target_label: __param_target
    - source_labels: [__param_target]
      target_label: instance
    - target_label: __address__
      replacement: blackbox-svc:9115
    # 保留特定标签
    - source_labels: [__meta_kubernetes_namespace]
      target_label: namespace
    - source_labels: [__meta_kubernetes_ingress_name]
      target_label: ingress_name
    - source_labels: [__meta_kubernetes_ingress_class_name]
      target_label: ingress_class_name
</code></pre><p>3、重新加载 Prometheus，然后检查节点的 targets，能正常监控 Kubernets 的节点</p><pre><code>[root@k8s-master01 04-prometheus]# curl -X POST http://k8s-prom.hmallleasing.com/-/reload
</code></pre><p>4、检查 Prometheus 抓取的结果</p><p><img loading="lazy" data-src="C:%5CUsers%5CAdministrator%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240317215901654.png" alt="image-20240317215901654"></p><p>5、检查此前创建好的 blackbox_http_rules.yml 告警规则⽂件</p><pre><code> blackbox_http_rules.yml: |-
    groups:
    - name: Blackbox_http告警规则文件
      rules:
      - alert: 站点平均请求过长
        expr: sum (avg_over_time(probe_http_duration_seconds[1m])) by (instance,job,namespace,ingress_name) &gt; 3
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' 域名整体请求时间超过了3秒。&quot;
          description: &quot;&#123;&#123; $labels.namespace &#125;&#125; 名称空间 '&#123;&#123; $labels.instance &#125;&#125;' 域名最近1分钟的平均请求时间超过3秒。当前平均请求时间：&#123;&#123; $value &#125;&#125;秒。&quot;

      - alert: 站点阶段耗时过长
        expr: |
          (
            probe_http_duration_seconds&#123;phase=&quot;connect&quot;&#125; &gt; 1 or
            probe_http_duration_seconds&#123;phase=&quot;processing&quot;&#125; &gt; 1 or
            probe_http_duration_seconds&#123;phase=&quot;resolve&quot;&#125; &gt; 1 or
            probe_http_duration_seconds&#123;phase=&quot;tls&quot;&#125; &gt; 1 or
            probe_http_duration_seconds&#123;phase=&quot;transfer&quot;&#125; &gt; 1
          )
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' 域名在 '&#123;&#123; $labels.phase &#125;&#125;' 阶段耗时过长&quot;
          description: &quot;&#123;&#123; $labels.namespace &#125;&#125; 名称空间 '&#123;&#123; $labels.instance &#125;&#125;' 域名在阶段 '&#123;&#123; $labels.phase &#125;&#125;' 的耗时超过0.5秒。当前耗时：&#123;&#123; $value &#125;&#125;秒。&quot;

      - alert: 站点响应状态码异常
        expr: probe_http_status_code &lt;= 199 or probe_http_status_code &gt;= 400
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' 域名返回异常状态码&quot;
          description: &quot;&#123;&#123; $labels.namespace &#125;&#125; 名称空间 '&#123;&#123; $labels.instance &#125;&#125;' 域名返回的状态码为 &#123;&#123; $value &#125;&#125;，表明请求可能存在问题。&quot;
    
      - alert: 重定向次数过多
        expr: probe_http_redirects &gt; 5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' 域名重定向次数过多&quot;
          description: &quot;&#123;&#123; $labels.namespace &#125;&#125; 名称空间 '&#123;&#123; $labels.instance &#125;&#125;' 域名在最近的探测中重定向次数超过5次。当前次数：&#123;&#123; $value &#125;&#125;次。&quot;

      - alert: 证书即将过期&lt;30
        expr: (probe_ssl_earliest_cert_expiry - time()) /86400 &lt; 30
        for: 24h
        labels:
          severity: critical
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' 域名的 SSL 证书即将过期&quot;
          description: &quot;&#123;&#123; $labels.namespace &#125;&#125; 名称空间 '&#123;&#123; $labels.instance &#125;&#125;' 域名的 SSL 证书将在 &#123;&#123; $value &#125;&#125; 天内过期。&quot;
    
      - alert: 证书即将过期&lt;7
        expr: (probe_ssl_earliest_cert_expiry - time()) /86400 &lt; 7
        for: 24h
        labels:
          severity: critical
        annotations:
          summary: &quot;&#123;&#123; $labels.instance &#125;&#125;' 域名的 SSL 证书即将过期&quot;
          description: &quot;&#123;&#123; $labels.namespace &#125;&#125; 名称空间 &#123;&#123; $labels.instance &#125;&#125;' 域名的 SSL 证书将在 &#123;&#123; $value &#125;&#125; 天内过期。&quot;
</code></pre><h4 id="8-prometheus监控redis应用的pod"><a class="anchor" href="#8-prometheus监控redis应用的pod">#</a> 8、Prometheus 监控 Redis 应⽤的 Pod</h4><h5 id="81-监控redis应用场景说明"><a class="anchor" href="#81-监控redis应用场景说明">#</a> 8.1 监控 Redis 应⽤场景说明</h5><p>运⾏ redis 的 Pod，⽽后为其创建⼀个 Service，我们现在希望监控它的 Pod 状态，Pod 资源的使⽤，redis 的指标、以及 redis 的 Service 的延迟和存活性。</p><ul><li>1、redis 应⽤指标：可以在 Pod 中注⼊⼀个 redis_exporter 来抓取对应的 redis 指标，并暴露给 Prometheus；</li><li>2、pod 的运⾏状态：kube-state-metrics 能⾃动获取，因此⽆需考虑；</li><li>3、pod 的资源使⽤：kubelet 的 CadVisor 能⾃动获取到每个 Pod 的资源使⽤，因此⽆需考虑；</li><li>4、Pod 的存活性以及延迟：可以通过 Blackbox 来监控 6379、9121 端⼝，在此前创建的 Blackbox-tcp 会⾃动的将这些 Service 资源给监控起来，因此⽆需考虑。</li></ul><h5 id="82-运行redis基础服务pod"><a class="anchor" href="#82-运行redis基础服务pod">#</a> 8.2 运⾏ Redis 基础服务 Pod</h5><p>1、在⼀个 Pod 中同时运⾏ Redis 和 Redis_exporter，清单⽂件如下：</p><pre><code>[root@k8s-master01 08-redis-exporter]# cat 01-redis-deployment.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis
  namespace: default
spec:
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
      annotations:
        prometheus.io/scrape: &quot;true&quot;
        prometheus.io/scheme: &quot;http&quot;
        prometheus.io/path: &quot;/metrics&quot;
        prometheus.io/port: &quot;9121&quot;
    spec:
      containers:
      - name: redis
        image: redis:6
        # 设定redis最大的内存，默认最大内存为0
        command: [&quot;redis-server&quot;]
        args: [&quot;--maxmemory&quot;, &quot;200mb&quot;]
        ports:
        - containerPort: 6379
      - name: redis-exporter
        image: oliver006/redis_exporter:v1.57.0
        ports:
        - containerPort: 9121
</code></pre><p>2、创建 Service 资源，需要暴露两个端⼝</p><pre><code>[root@k8s-master01 08-redis-exporter]# cat 02-redis-service.yaml 
kind: Service
apiVersion: v1
metadata:
  name: redis-svc
  namespace: default
  labels:
    app: redis
spec:
  selector:
    app: redis
  ports:
  - name: redis
    port: 6379
    targetPort: 6379
  - name: exporter
    port: 9121
    targetPort: 9121
</code></pre><p>3、查看 Service 详情</p><pre><code>[root@k8s-master01 08-redis-exporter]# kubectl apply -f .
[root@k8s-master01 08-redis-exporter]#  kubectl describe service redis-svc
Name:              redis-svc
Namespace:         default
Labels:            app=redis
Annotations:       &lt;none&gt;
Selector:          app=redis
Type:              ClusterIP
IP Family Policy:  SingleStack
IP Families:       IPv4
IP:                10.96.140.137
IPs:               10.96.140.137
# 端点1
Port:              redis  6379/TCP
TargetPort:        6379/TCP
Endpoints:         172.16.85.208:6379
# 端点2
Port:              exporter  9121/TCP
TargetPort:        9121/TCP
Endpoints:         172.16.85.208:9121
Session Affinity:  None
Events:            &lt;none&gt;
</code></pre><h5 id="83-配置prometheus监控redis"><a class="anchor" href="#83-配置prometheus监控redis">#</a> 8.3 配置 Prometheus 监控 Redis</h5><ul><li>1、添加⼀个新的 Job，名为： redis-pod</li><li>2、基于 Kubernetes 的 endpints 来实现⾃动发现</li><li>3、使⽤ relabel_configs，保留 <strong>address</strong> 地址对应的端⼝是 9121 的实例。</li><li>4、使⽤ relabel_configs，保留 __meta_kubernetes_namespace、__meta_kubernetes_service_name、__meta_kubernetes_pod_name 这三个维度的标签。</li></ul><p>1、配置 Prometheus</p><pre><code>[root@k8s-master01 04-prometheus]# cat 01-prom-configs-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prom-configs
  namespace: monitoring
data:
  prometheus.yml: |-
    global:
      scrape_interval: 15s
      scrape_timeout:  15s
    
    # 告警地址(填写AlertManager的负载均衡地址即可)
    alerting:
      alertmanagers:
      - static_configs:
        - targets: [&quot;alertmanager-svc:9093&quot;]
    
    # 告警规则文件
    rule_files:
      - &quot;/etc/prometheus/rules/*.yml&quot;

    scrape_configs:
      - job_name: &quot;prometheus&quot;
        metrics_path: &quot;/metrics&quot;
        static_configs:
        - targets: [&quot;localhost:9090&quot;]

      # 监控Kubernetes的节点
      - job_name: &quot;kube-nodes&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - source_labels: [&quot;__address__&quot;]
          regex: &quot;(.*):10250&quot;
          replacement: &quot;$1:9100&quot;
          target_label: __address__
          action: replace
        - regex: __meta_kubernetes_node_label_(.*)
          replacement: $1
          action: labelmap

      # 监控APIServer
      - job_name: &quot;kube-apiserver&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
        tls_config:
          insecure_skip_verify: true   # 跳过证书验证
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        # 标签重写
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
          regex: &quot;apiserver&quot;
          action: &quot;keep&quot;
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: service_name
        - regex: __meta_kubernetes_service_label_(.*)        #通过标签映射获取标签
          replacement: $1
          action: labelmap


      # 监控controllerManager
      - job_name: &quot;kube-controller&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: pod
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        # 仅保留标签名是component 值为kube-controller-manager
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;kube-controller-manager&quot;
          action: keep
        # 替换抓取的实例端口为10257
        - source_labels: [__address__]
          regex: (.*)
          replacement: $1:10257
          target_label: __address__
        # 保留特定标签
        - source_labels: [__meta_kubernetes_namespace]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [__meta_kubernetes_pod_name]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控Scheduler
      - job_name: &quot;kube-schduler&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: pod
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        # 基于标签进行过滤
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;kube-scheduler&quot;
          action: keep

        # 修订抓取的端口
        - source_labels: [&quot;__address__&quot;]
          regex: (.*)
          replacement: $1:10259
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控etcd
      - job_name: &quot;kube-etcd&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: pod

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;etcd&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__address__&quot;]
          regex: (.*)
          replacement: $1:2381
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控CoreDNS
      - job_name: &quot;kube-dns&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: endpoints

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_k8s_app&quot;]
          regex: &quot;kube-dns&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
          regex: (.*)
          replacement: $1:9153
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name
        - source_labels: [&quot;__meta_kubernetes_service_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: service_name

      # 监控kube-proxy
      - job_name: &quot;kube-proxy&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: pod

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_k8s_app&quot;]
          regex: &quot;kube-proxy&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
          regex: (.*)
          replacement: $1:10249
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控kube-state-metrics
      - job_name: &quot;kube-state-metrics&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: endpoints

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_app_kubernetes_io_name&quot;]
          regex: &quot;kube-state-metrics&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
          regex: (.*)
          replacement: $1:8080
          target_label: __address__

        # 添加维度标签
        - regex: __meta_kubernetes_service_label_(.*)
          action: labelmap

      # 监控kubelet(Pod)
      - job_name: &quot;kube-kubelet&quot;
        metrics_path: &quot;/metrics/cadvisor&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: node
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        # 添加标签的映射
        relabel_configs:
        - regex: __meta_kubernetes_node_label_(.*)
          action: labelmap

      # 监控service
      - job_name: &quot;kube-blackbox-tcp&quot;
        metrics_path: &quot;/probe&quot;
        params:
          module: [tcp_connect]         # 使用tcp_connect模块
        kubernetes_sd_configs:
        - role: service
        relabel_configs:
        - source_labels: [__address__]
          target_label: __param_target
        - source_labels: [__param_target]
          target_label: instance
        - target_label: __address__
          replacement: blackbox-svc:9115
        # 保留特定标签
        - source_labels: [__meta_kubernetes_namespace]
          regex: (.*)
          replacement: $1
          target_label: namespace
        - source_labels: [__meta_kubernetes_service_name]
          regex: (.*)
          replacement: $1
          target_label: service_name

      # 监控ingress
      - job_name: &quot;kube-blackbox-http&quot;
        metrics_path: &quot;/probe&quot;
        params:
          module: [http_2xx]            # 使用http模块进行探测
        kubernetes_sd_configs:
        - role: ingress
        relabel_configs:
        # 协议有可能是http或https，因此需要根据抓取到的协议+端⼝，拼接出具体的探测示例
        - source_labels: [__meta_kubernetes_ingress_scheme,__address__]
          regex: (.*);(.*)
          replacement: $1://$2
          target_label: __param_target
        - source_labels: [__param_target]
          target_label: instance
        - target_label: __address__
          replacement: blackbox-svc:9115
        # 保留特定标签
        - source_labels: [__meta_kubernetes_namespace]
          target_label: namespace
        - source_labels: [__meta_kubernetes_ingress_name]
          target_label: ingress_name
        - source_labels: [__meta_kubernetes_ingress_class_name]
          target_label: ingress_class_name

      # 监控redis
      - job_name: &quot;kube-redis&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: endpoints

        # 保留端口为9121的Pod实例
        relabel_configs:
        - source_labels: [__address__]
          regex: (.*):9121
          action: keep

        # 保留特定维度的标签
        - source_labels: [__meta_kubernetes_namespace]
          target_label: namespace
        - source_labels: [__meta_kubernetes_service_name]
          target_label: service_name
        - source_labels: [__meta_kubernetes_pod_name]
          target_label: pod_name

[root@k8s-master01 04-prometheus]# kubectl apply -f 01-prom-configs-configmap.yaml
</code></pre><p>2、检查配置是否更新</p><pre><code>[root@k8s-master01 04-prometheus]# kubectl exec -it prometheus-0 -n monitoring -- cat /etc/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  scrape_timeout:  15s

# 告警地址(填写AlertManager的负载均衡地址即可)
alerting:
  alertmanagers:
  - static_configs:
    - targets: [&quot;alertmanager-svc:9093&quot;]

# 告警规则文件
rule_files:
  - &quot;/etc/prometheus/rules/*.yml&quot;

scrape_configs:
  - job_name: &quot;prometheus&quot;
    metrics_path: &quot;/metrics&quot;
    static_configs:
    - targets: [&quot;localhost:9090&quot;]

  # 监控Kubernetes的节点
  - job_name: &quot;kube-nodes&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: node
    relabel_configs:
    - source_labels: [&quot;__address__&quot;]
      regex: &quot;(.*):10250&quot;
      replacement: &quot;$1:9100&quot;
      target_label: __address__
      action: replace
    - regex: __meta_kubernetes_node_label_(.*)
      replacement: $1
      action: labelmap

  # 监控APIServer
  - job_name: &quot;kube-apiserver&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: endpoints
    scheme: https
    tls_config:
      insecure_skip_verify: true   # 跳过证书验证
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    # 标签重写
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
      regex: &quot;apiserver&quot;
      action: &quot;keep&quot;
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: service_name
    - regex: __meta_kubernetes_service_label_(.*)        #通过标签映射获取标签
      replacement: $1
      action: labelmap


  # 监控controllerManager
  - job_name: &quot;kube-controller&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: https
    kubernetes_sd_configs:
    - role: pod
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    # 仅保留标签名是component 值为kube-controller-manager
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;kube-controller-manager&quot;
      action: keep
    # 替换抓取的实例端口为10257
    - source_labels: [__address__]
      regex: (.*)
      replacement: $1:10257
      target_label: __address__
    # 保留特定标签
    - source_labels: [__meta_kubernetes_namespace]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [__meta_kubernetes_pod_name]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控Scheduler
  - job_name: &quot;kube-schduler&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: https
    kubernetes_sd_configs:
    - role: pod
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

    # 基于标签进行过滤
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;kube-scheduler&quot;
      action: keep

    # 修订抓取的端口
    - source_labels: [&quot;__address__&quot;]
      regex: (.*)
      replacement: $1:10259
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控etcd
  - job_name: &quot;kube-etcd&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: http
    kubernetes_sd_configs:
    - role: pod

    # 保留对应标签的Pod
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
      regex: &quot;etcd&quot;
      action: keep

    # 修订端口
    - source_labels: [&quot;__address__&quot;]
      regex: (.*)
      replacement: $1:2381
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控CoreDNS
  - job_name: &quot;kube-dns&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: http
    kubernetes_sd_configs:
    - role: endpoints

    # 保留对应标签的Pod
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_service_label_k8s_app&quot;]
      regex: &quot;kube-dns&quot;
      action: keep

    # 修订端口
    - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
      regex: (.*)
      replacement: $1:9153
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name
    - source_labels: [&quot;__meta_kubernetes_service_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: service_name

  # 监控kube-proxy
  - job_name: &quot;kube-proxy&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: http
    kubernetes_sd_configs:
    - role: pod

    # 保留对应标签的Pod
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_pod_label_k8s_app&quot;]
      regex: &quot;kube-proxy&quot;
      action: keep

    # 修订端口
    - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
      regex: (.*)
      replacement: $1:10249
      target_label: __address__

    # 添加维度标签
    - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: namespace
    - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
      regex: &quot;(.*)&quot;
      replacement: $1
      target_label: pod_name

  # 监控kube-state-metrics
  - job_name: &quot;kube-state-metrics&quot;
    metrics_path: &quot;/metrics&quot;
    scheme: http
    kubernetes_sd_configs:
    - role: endpoints

    # 保留对应标签的Pod
    relabel_configs:
    - source_labels: [&quot;__meta_kubernetes_service_label_app_kubernetes_io_name&quot;]
      regex: &quot;kube-state-metrics&quot;
      action: keep

    # 修订端口
    - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
      regex: (.*)
      replacement: $1:8080
      target_label: __address__

    # 添加维度标签
    - regex: __meta_kubernetes_service_label_(.*)
      action: labelmap

  # 监控kubelet(Pod)
  - job_name: &quot;kube-kubelet&quot;
    metrics_path: &quot;/metrics/cadvisor&quot;
    scheme: https
    kubernetes_sd_configs:
    - role: node
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

    # 添加标签的映射
    relabel_configs:
    - regex: __meta_kubernetes_node_label_(.*)
      action: labelmap

  # 监控service
  - job_name: &quot;kube-blackbox-tcp&quot;
    metrics_path: &quot;/probe&quot;
    params:
      module: [tcp_connect]         # 使用tcp_connect模块
    kubernetes_sd_configs:
    - role: service
    relabel_configs:
    - source_labels: [__address__]
      target_label: __param_target
    - source_labels: [__param_target]
      target_label: instance
    - target_label: __address__
      replacement: blackbox-svc:9115
    # 保留特定标签
    - source_labels: [__meta_kubernetes_namespace]
      regex: (.*)
      replacement: $1
      target_label: namespace
    - source_labels: [__meta_kubernetes_service_name]
      regex: (.*)
      replacement: $1
      target_label: service_name

  # 监控ingress
  - job_name: &quot;kube-blackbox-http&quot;
    metrics_path: &quot;/probe&quot;
    params:
      module: [http_2xx]            # 使用http模块进行探测
    kubernetes_sd_configs:
    - role: ingress
    relabel_configs:
    # 协议有可能是http或https，因此需要根据抓取到的协议+端⼝，拼接出具体的探测示例
    - source_labels: [__meta_kubernetes_ingress_scheme,__address__]
      regex: (.*);(.*)
      replacement: $1://$2
      target_label: __param_target
    - source_labels: [__param_target]
      target_label: instance
    - target_label: __address__
      replacement: blackbox-svc:9115
    # 保留特定标签
    - source_labels: [__meta_kubernetes_namespace]
      target_label: namespace
    - source_labels: [__meta_kubernetes_ingress_name]
      target_label: ingress_name
    - source_labels: [__meta_kubernetes_ingress_class_name]
      target_label: ingress_class_name

  # 监控redis
  - job_name: &quot;kube-redis&quot;
    metrics_path: &quot;/metrics&quot;
    kubernetes_sd_configs:
    - role: endpoints

    # 保留端口为9121的Pod实例
    relabel_configs:
    - source_labels: [__address__]
      regex: (.*):9121
      action: keep

    # 保留特定维度的标签
    - source_labels: [__meta_kubernetes_namespace]
      target_label: namespace
    - source_labels: [__meta_kubernetes_service_name]
      target_label: service_name
    - source_labels: [__meta_kubernetes_pod_name]
      target_label: pod_name
</code></pre><p>3、重新加载 Prometheus，然后检查节点的 targets，能正常监控 Kubernets 的节点</p><pre><code>[root@k8s-master01 04-prometheus]# curl -X POST http://k8s-prom.hmallleasing.com/-/reload
</code></pre><p>4、检查 Prometheus 抓取的结果</p><p><img loading="lazy" data-src="C:%5CUsers%5CAdministrator%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240318214141751.png" alt="image-20240318214141751"></p><p>5、检查此前创建好的 redis_rules.yml 告警规则⽂件</p><pre><code>  redis_rules.yml: |-
    groups:
    - name: redis告警规则
      rules:
      - alert: Redis实例宕机
        expr: redis_up == 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' Redis实例宕机&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod_name &#125;&#125;' Pod在过去5分钟内无法连接。&quot;

      - alert: Redis连接数过高
        expr: redis_connected_clients / redis_config_maxclients * 100 &gt; 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' Redis实例连接数超过80%&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod_name &#125;&#125;' Pod当前连接数占最大连接数的比率超过80%。当前比率: &#123;&#123; $value &#125;&#125;%。&quot;

      - alert: Redis连接被拒绝
        expr: increase(redis_rejected_connections_total[1h]) &gt; 0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' Redis实例有连接被拒绝&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod_name &#125;&#125;' Pod在过去1小时内有连接被拒绝。当前被拒绝的连接数: &#123;&#123; $value &#125;&#125;。&quot;

      - alert: Redis内存使用率过高
        expr: redis_memory_used_bytes / redis_memory_max_bytes * 100 &gt; 80
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' Redis实例内存使用率超过80%&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod_name &#125;&#125;' Pod的内存使用率超过配置的最大内存值的80%。当前内存使用率: &#123;&#123; $value &#125;&#125;%。&quot;

      - alert: Redis缓存命中率低
        expr: |
          irate(redis_keyspace_hits_total[5m])
          / 
          (irate(redis_keyspace_hits_total[5m]) + irate(redis_keyspace_misses_total[5m])) * 100 &lt; 90
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' Redis实例缓存命中率低于90%&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod_name &#125;&#125;' Pod最近5分钟内的缓存命中率低于90%。当前命中率: &#123;&#123; $value &#125;&#125;%。&quot;

      - alert: Redis即将过期的Key数量过多
        expr: |
          sum(redis_db_keys_expiring) by (instance, job, namespace,pod_name,db)
          / 
          sum(redis_db_keys) by (instance, job, namespace,pod_name,db) * 100 &gt; 50
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' Redis实例中的 '&#123;&#123; $labels.db &#125;&#125;' 数据库有大量即将过期的Key&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod_name &#125;&#125;' Pod中的 '&#123;&#123; $labels.db &#125;&#125;' 数据库有超过50%的Key即将过期。当前过期比率: &#123;&#123; $value &#125;&#125;%。&quot;

      - alert: RedisRDB备份失败
        expr: redis_rdb_last_bgsave_status == 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' Redis实例 RDB备份失败&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod_name &#125;&#125;' Pod最近的RDB备份失败。&quot;

      - alert: RedisRDB备份时间过长
        expr: redis_rdb_last_bgsave_duration_sec &gt; 3 and redis_rdb_last_bgsave_status == 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' Redis实例 RDB备份成功但耗时超过3秒&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod_name &#125;&#125;' Pod, RDB备份成功但耗时超过了3秒。持续时间: &#123;&#123; $value &#125;&#125;秒。&quot;

      - alert: RedisRDB备份过期
        expr: (time() - redis_rdb_last_save_timestamp_seconds) &gt; 36000
        for: 24h
        labels:
          severity: critical
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' Redis实例超过10小时未进行RDB备份&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod_name &#125;&#125;' Pod已超过10小时没有生成新的RDB备份文件。&quot;

      - alert: Redis命令拒绝率过高
        expr: |
          sum(irate(redis_commands_rejected_calls_total[5m])) by (instance,job,namespace,pod_name)
          / 
          sum(irate(redis_commands_total[5m])) by (instance,job,namespace,pod_name) * 100 &gt; 25
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' Redis实例命令拒绝率超过25%&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod_name &#125;&#125;' Pod的命令拒绝率超过了25%。当前拒绝率: &#123;&#123; $value &#125;&#125;%。&quot;

      - alert: Redis命令平均响应时间过长
        expr: |
          sum(rate(redis_commands_duration_seconds_total[5m])) by (instance,job,namespace,pod_name)
          / 
          sum(rate(redis_commands_processed_total[5m])) by (instance,job,namespace,pod_name) &gt; 0.250
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' Redis实例命令平均响应时间超过250ms&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间中 '&#123;&#123; $labels.pod_name &#125;&#125;' Pod的执行命令平均响应时间超过了250毫秒。当前平均响应时间: &#123;&#123; $value &#125;&#125;秒。&quot;
</code></pre><h4 id="9-prometheus监控java业务应用的pod"><a class="anchor" href="#9-prometheus监控java业务应用的pod">#</a> 9、Prometheus 监控 java 业务应⽤的 Pod</h4><h5 id="91-监控业务应用场景说明"><a class="anchor" href="#91-监控业务应用场景说明">#</a> 9.1 监控业务应⽤场景说明</h5><p>运⾏ javaapp 的业务应⽤ Pod，⽽后为其创建⼀个 Service、Ingress，现在我们希望监控 Pod 状态，Pod 资源的使⽤，jvm 内存相关指标、Service 的 TCP 检测、以及域名响应状态、延迟、存活性等检测。</p><ul><li><p>1、java 应⽤指标：在初始化容器运⾏⼀个 jmx_exporter 的容器，并将相关的 jar 和 config.yaml 共享给主容器，主容器通过 JVM 环境变量传递相关启动参数，完成 jvm 的监控；</p></li><li><p>2、pod 的运⾏状态：kube-state-metrics 能⾃动获取，因此⽆需考虑；</p></li><li><p>3、pod 的资源使⽤：kubelet 的 CadVisor 能⾃动获取到每个 Pod 的资源使⽤，因此⽆需考虑；</p></li><li><p>4、service 的存活性以及延迟：通过此前 kube-blackbox-tcp，能⾃动监控其 Service 的 8080 端⼝和 12345 端⼝；</p></li><li><p>5、ingress 的 http 状态监控，通过此前 kube-blackbox-http，能⾃动监控其 ingress 的域名状态；</p></li></ul><h5 id="92-运行业务应用容器pod"><a class="anchor" href="#92-运行业务应用容器pod">#</a> 9.2 运⾏业务应⽤容器 Pod</h5><p>1、由于官⽅没有提供 jmx_prometheus 的镜像，因此需要先⾃⾏制作镜像。（也可以直接使⽤我制作好的镜像 oldxu3957/jmx_prometheus:v0.20.0 ）</p><pre><code>[root@k8s-master01 dockerfile]# wget https://repo.maven.apache.org/maven2/io/prometheus/jmx/jmx_prometheus_javaagent/0.20.0/jmx_prometheus_javaagent-0.20.0.jar

[root@k8s-master01 dockerfile]# cat config.yaml
rules:
- pattern: &quot;.*&quot;

# Dockerfile⽂件
[root@prom-node03 jmx_exporter]# cat Dockerfile
FROM alpine:latest
ENV VERSION=&quot;0.20.0&quot;
ENV DIR=/jmx
COPY ./config.yaml $&#123;DIR&#125;/config.yaml
COPY ./jmx_prometheus_javaagent-$&#123;VERSION&#125;.jar $&#123;DIR&#125;/jmx_prometheus.jar
</code></pre><p>2、运⾏ java 应⽤ Pod</p><pre><code>[root@k8s-master01 09-java-exporter]# cat 01-javaapp-deployment.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: java-app
  namespace: default
spec:
  replicas: 2
  selector:
    matchLabels:
      app: java
  template:
    metadata:
      labels:
        app: java
    spec:
      volumes:
      - name: javaagent
        emptyDir: &#123;&#125;
      initContainers:                # 运⾏初始化容器（将⽂件夹整体拷⻉⾄javaagent共享卷）
      - name: jmx-prometheus
        image: oldxu3957/jmx_prometheus:v0.20.0
        command: [&quot;sh&quot;,&quot;-c&quot;,&quot;cp -rp /jmx /data/&quot;]
        volumeMounts:
        - name: javaagent
          mountPath: /data
      containers:
      - name: javaapp
        image: oldxu3957/javaapp:v1.0
        env:
        - name: JAVA_TOOL_OPTIONS     # 通过JAVA_TOOL_OPTIONS传递JVM相关参数
          value: &quot;-Xms100m -Xmx100m \
                 -javaagent:/agent/jmx/jmx_prometheus.jar=12345:/agent/jmx/config.yaml&quot;
        volumeMounts:
        - name: javaagent
          mountPath: /agent
        ports:
        - name: java
          containerPort: 8080
        - name: jmx
          containerPort: 12345
        resources:
          requests:
            cpu: 100m
            memory: 200Mi
          limits:
            cpu: 100m
            memory: 200Mi
</code></pre><h5 id="93-对外发布java业务应用"><a class="anchor" href="#93-对外发布java业务应用">#</a> 9.3 对外发布 java 业务应⽤</h5><p>1、创建 Service，需要暴露 8080 端⼝和 12345 端⼝</p><pre><code>[root@k8s-master01 09-java-exporter]# cat 02-javaapp-service.yaml 
kind: Service
apiVersion: v1
metadata:
  name: javaapp-svc
  namespace: default
  labels:
    app: java
  annotations:
    prometheus.io/scrape: &quot;true&quot;
    prometheus.io/scheme: &quot;http&quot;
    prometheus.io/path: &quot;/metrics&quot;
    prometheus.io/port: &quot;12345&quot;
spec:
  selector:
    app: java
  ports:
  - name: javaapp
    port: 8080
    targetPort: 8080
  - name: jmx
    port: 12345
    targetPort: 12345
</code></pre><p>2、创建 Ingress</p><pre><code>[root@k8s-master01 09-java-exporter]# cat 03-javaapp-ingress.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: javaapp-ingress
  namespace: default
spec:
  ingressClassName: &quot;nginx&quot;
  rules:
  - host: &quot;javaapp.hmallleasing.com&quot;
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: javaapp-svc
            port:
              number: 8080
</code></pre><p>3、更新资源清单</p><pre><code>[root@k8s-master01 09-java-exporter]# kubectl apply -f .
</code></pre><h5 id="94-配置prometheus监控业务应用"><a class="anchor" href="#94-配置prometheus监控业务应用">#</a> 9.4 配置 Prometheus 监控业务应⽤</h5><ul><li>1、添加⼀个新的 Job，名为： java-pod</li><li>2、基于 Kubernetes 的 endpints 来实现⾃动发现</li><li>3、使⽤ relabel_configs，仅抓取 <strong>address</strong> 地址对应的端⼝是 12345 的实例。</li><li>4、使⽤ relabel_configs，保留 __meta_kubernetes_namespace、__meta_kubernetes_service_name、__meta_kubernetes_pod_name 这三个维度的标签。</li></ul><p>1、配置 Prometheus</p><pre><code>[root@k8s-master01 04-prometheus]# cat 01-prom-configs-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prom-configs
  namespace: monitoring
data:
  prometheus.yml: |-
    global:
      scrape_interval: 15s
      scrape_timeout:  15s
    
    # 告警地址(填写AlertManager的负载均衡地址即可)
    alerting:
      alertmanagers:
      - static_configs:
        - targets: [&quot;alertmanager-svc:9093&quot;]
    
    # 告警规则文件
    rule_files:
      - &quot;/etc/prometheus/rules/*.yml&quot;

    scrape_configs:
      - job_name: &quot;prometheus&quot;
        metrics_path: &quot;/metrics&quot;
        static_configs:
        - targets: [&quot;localhost:9090&quot;]

      # 监控Kubernetes的节点
      - job_name: &quot;kube-nodes&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - source_labels: [&quot;__address__&quot;]
          regex: &quot;(.*):10250&quot;
          replacement: &quot;$1:9100&quot;
          target_label: __address__
          action: replace
        - regex: __meta_kubernetes_node_label_(.*)
          replacement: $1
          action: labelmap

      # 监控APIServer
      - job_name: &quot;kube-apiserver&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
        tls_config:
          insecure_skip_verify: true   # 跳过证书验证
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        # 标签重写
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_component&quot;]  #保留label为apiserver实例
          regex: &quot;apiserver&quot;
          action: &quot;keep&quot;
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]        #匹配__meta_kubernetes_namespace值，并赋值给namespace
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_service_name&quot;]    #__meta_kubernetes_service_name值并赋值给service_name
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: service_name
        - regex: __meta_kubernetes_service_label_(.*)        #通过标签映射获取标签
          replacement: $1
          action: labelmap


      # 监控controllerManager
      - job_name: &quot;kube-controller&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: pod
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        # 仅保留标签名是component 值为kube-controller-manager
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;kube-controller-manager&quot;
          action: keep
        # 替换抓取的实例端口为10257
        - source_labels: [__address__]
          regex: (.*)
          replacement: $1:10257
          target_label: __address__
        # 保留特定标签
        - source_labels: [__meta_kubernetes_namespace]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [__meta_kubernetes_pod_name]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控Scheduler
      - job_name: &quot;kube-schduler&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: pod
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        # 基于标签进行过滤
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;kube-scheduler&quot;
          action: keep

        # 修订抓取的端口
        - source_labels: [&quot;__address__&quot;]
          regex: (.*)
          replacement: $1:10259
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控etcd
      - job_name: &quot;kube-etcd&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: pod

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_component&quot;]
          regex: &quot;etcd&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__address__&quot;]
          regex: (.*)
          replacement: $1:2381
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控CoreDNS
      - job_name: &quot;kube-dns&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: endpoints

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_k8s_app&quot;]
          regex: &quot;kube-dns&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
          regex: (.*)
          replacement: $1:9153
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name
        - source_labels: [&quot;__meta_kubernetes_service_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: service_name

      # 监控kube-proxy
      - job_name: &quot;kube-proxy&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: pod

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_pod_label_k8s_app&quot;]
          regex: &quot;kube-proxy&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
          regex: (.*)
          replacement: $1:10249
          target_label: __address__

        # 添加维度标签
        - source_labels: [&quot;__meta_kubernetes_namespace&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: namespace
        - source_labels: [&quot;__meta_kubernetes_pod_name&quot;]
          regex: &quot;(.*)&quot;
          replacement: $1
          target_label: pod_name

      # 监控kube-state-metrics
      - job_name: &quot;kube-state-metrics&quot;
        metrics_path: &quot;/metrics&quot;
        scheme: http
        kubernetes_sd_configs:
        - role: endpoints

        # 保留对应标签的Pod
        relabel_configs:
        - source_labels: [&quot;__meta_kubernetes_service_label_app_kubernetes_io_name&quot;]
          regex: &quot;kube-state-metrics&quot;
          action: keep

        # 修订端口
        - source_labels: [&quot;__meta_kubernetes_pod_ip&quot;]
          regex: (.*)
          replacement: $1:8080
          target_label: __address__

        # 添加维度标签
        - regex: __meta_kubernetes_service_label_(.*)
          action: labelmap

      # 监控kubelet(Pod)
      - job_name: &quot;kube-kubelet&quot;
        metrics_path: &quot;/metrics/cadvisor&quot;
        scheme: https
        kubernetes_sd_configs:
        - role: node
        tls_config:
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        # 添加标签的映射
        relabel_configs:
        - regex: __meta_kubernetes_node_label_(.*)
          action: labelmap

      # 监控service
      - job_name: &quot;kube-blackbox-tcp&quot;
        metrics_path: &quot;/probe&quot;
        params:
          module: [tcp_connect]         # 使用tcp_connect模块
        kubernetes_sd_configs:
        - role: service
        relabel_configs:
        - source_labels: [__address__]
          target_label: __param_target
        - source_labels: [__param_target]
          target_label: instance
        - target_label: __address__
          replacement: blackbox-svc:9115
        # 保留特定标签
        - source_labels: [__meta_kubernetes_namespace]
          regex: (.*)
          replacement: $1
          target_label: namespace
        - source_labels: [__meta_kubernetes_service_name]
          regex: (.*)
          replacement: $1
          target_label: service_name

      # 监控ingress
      - job_name: &quot;kube-blackbox-http&quot;
        metrics_path: &quot;/probe&quot;
        params:
          module: [http_2xx]            # 使用http模块进行探测
        kubernetes_sd_configs:
        - role: ingress
        relabel_configs:
        # 协议有可能是http或https，因此需要根据抓取到的协议+端⼝，拼接出具体的探测示例
        - source_labels: [__meta_kubernetes_ingress_scheme,__address__]
          regex: (.*);(.*)
          replacement: $1://$2
          target_label: __param_target
        - source_labels: [__param_target]
          target_label: instance
        - target_label: __address__
          replacement: blackbox-svc:9115
        # 保留特定标签
        - source_labels: [__meta_kubernetes_namespace]
          target_label: namespace
        - source_labels: [__meta_kubernetes_ingress_name]
          target_label: ingress_name
        - source_labels: [__meta_kubernetes_ingress_class_name]
          target_label: ingress_class_name

      # 监控redis
      - job_name: &quot;kube-redis&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: endpoints

        # 保留端口为9121的Pod实例
        relabel_configs:
        - source_labels: [__address__]
          regex: (.*):9121
          action: keep

        # 保留特定维度的标签
        - source_labels: [__meta_kubernetes_namespace]
          target_label: namespace
        - source_labels: [__meta_kubernetes_service_name]
          target_label: service_name
        - source_labels: [__meta_kubernetes_pod_name]
          target_label: pod_name

      # 监控java
      - job_name: &quot;kube-java-pod&quot;
        metrics_path: &quot;/metrics&quot;
        kubernetes_sd_configs:
        - role: endpoints

        # 保留端口为12345的Pod实例
        relabel_configs:
        - source_labels: [__address__]
          regex: (.*):12345
          action: keep

        # 保留特定维度的标签
        - source_labels: [__meta_kubernetes_namespace]
          target_label: namespace
        - source_labels: [__meta_kubernetes_service_name]
          target_label: service_name
        - source_labels: [__meta_kubernetes_pod_name]
          target_label: pod_name

[root@k8s-master01 04-prometheus]# kubectl apply -f 01-prom-configs-configmap.yaml
</code></pre><p>2、检查配置是否更新</p><pre><code>[root@k8s-master01 04-prometheus]# kubectl exec -it prometheus-0 -n monitoring -- cat /etc/prometheus/prometheus.yml
</code></pre><p>3、重新加载 Prometheus，然后检查节点的 targets，能正常监控 Kubernets 的节点</p><pre><code>[root@k8s-master01 04-prometheus]# curl -X POST http://k8s-prom.hmallleasing.com/-/reload
</code></pre><p>4、检查 Prometheus 抓取的结果</p><h5 id="95-检查此前创建好的-jvm_rulesyml-告警规则文件"><a class="anchor" href="#95-检查此前创建好的-jvm_rulesyml-告警规则文件">#</a> 9.5 检查此前创建好的 jvm_rules.yml 告警规则⽂件</h5><pre><code>  jvm_rules.yml: |-
    groups:
    - name: &quot;JVM告警规则&quot;
      rules:
      - alert: JVM堆内存使用率过高
        expr: jvm_memory_bytes_used&#123;area=&quot;heap&quot;,&#125; / jvm_memory_bytes_max&#123;area=&quot;heap&quot;,&#125; * 100 &gt; 90
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' 实例的JVM 堆内存使用率超过80%&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间下的 '&#123;&#123; $labels.pod_name &#125;&#125;' PodJVM堆内存使用率超过80%, 当前使用率是 &#123;&#123; $value &#125;&#125;%&quot;

      - alert: JVMGC时间过长
        expr: sum (rate(jvm_gc_collection_seconds_sum[5m]) / rate(jvm_gc_collection_seconds_count[5m])) by (instance,job,gc,namespace,pod_name) &gt; 1
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: &quot;'&#123;&#123; $labels.instance &#125;&#125;' 实例的JVM  GC时间超过了1秒。&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间下的 '&#123;&#123; $labels.pod_name &#125;&#125;' Pod使用 &#123;&#123; $labels.gc &#125;&#125; GC垃圾回收算法时间超过1s，当前值 &#123;&#123; $value &#125;&#125;秒&quot;

      - alert: JVM死锁线程过多
        expr: min_over_time(jvm_threads_deadlocked[5m]) &gt; 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: &quot;JVM检测到'&#123;&#123; $labels.instance &#125;&#125;' 实例有死锁线程&quot;
          description: &quot;'&#123;&#123; $labels.namespace &#125;&#125;' 名称空间下的 '&#123;&#123; $labels.pod_name &#125;&#125;' Pod，在过去5分钟检测到死锁线程, 当前死锁线程数是 &#123;&#123; $value &#125;&#125;。&quot;
</code></pre><div class="tags"><a href="/tags/Prometheus/" rel="tag"><i class="ic i-tag"></i>Prometheus</a></div></div><footer><div class="meta"><span class="icon"><i class="ic i-eye"></i></span><span>此文章已被阅读次数:</span><span class="waline-pageview-count" id="twikoo_visitors" data-path="/posts/2041568856.html">正在加载...</span><span class="item"><span class="icon"><i class="ic i-calendar-check"></i></span><span class="text">更新于</span><time title="修改时间：2025-06-29 22:04:20" itemprop="dateModified" datetime="2025-06-29T22:04:20+08:00">2025-06-29</time></span></div><div class="reward"><button><i class="ic i-heartbeat"></i>赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img loading="lazy" data-src="/assets/wechatpay.png" alt="Xu Yong 微信支付"><p>微信支付</p></div><div><img loading="lazy" data-src="/assets/alipay.png" alt="Xu Yong 支付宝"><p>支付宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者：</strong>Xu Yong<i class="ic i-at"><em>@</em></i>LinuxSre云原生</li><li class="link"><strong>本文链接：</strong><a href="http://ixuyong.cn/posts/2041568856.html" title="Prometheus监控Kubernetes">http://ixuyong.cn/posts/2041568856.html</a></li><li class="license"><strong>版权声明：</strong>本站所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/posts/4081185382.html" rel="prev" itemprop="url" data-background-image="https:&#x2F;&#x2F;wp-cdn.4ce.cn&#x2F;v2&#x2F;o1ceeNN.jpeg" title="Prometheus监控实战（四）"><span class="type">上一篇</span><span class="category"><i class="ic i-flag"></i>Prometheus</span><h3>Prometheus监控实战（四）</h3></a></div><div class="item right"></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#prometheus%E7%9B%91%E6%8E%A7kubernetes"><span class="toc-number">1.</span> <span class="toc-text">Prometheus 监控 Kubernetes</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E7%9B%91%E6%8E%A7kubernetes%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="toc-number">1.1.</span> <span class="toc-text">1、监控 Kubernetes 环境准备</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E9%83%A8%E7%BD%B2alertmanager%E8%87%B3kubernetes"><span class="toc-number">1.2.</span> <span class="toc-text">2、部署 AlertManager ⾄ Kubernetes</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#21-%E9%83%A8%E7%BD%B2webhook_wechat"><span class="toc-number">1.2.1.</span> <span class="toc-text">2.1 部署 webhook_wechat</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#22-%E9%83%A8%E7%BD%B2webhook_dingding"><span class="toc-number">1.2.2.</span> <span class="toc-text">2.2 部署 webhook_dingding</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#23-%E5%88%9B%E5%BB%BAalertmanager%E9%85%8D%E7%BD%AE"><span class="toc-number">1.2.3.</span> <span class="toc-text">2.3 创建 AlertManager 配置</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#24-%E5%88%9B%E5%BB%BAheadlessservice"><span class="toc-number">1.2.4.</span> <span class="toc-text">2.4 创建 HeadLessService</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#25-%E9%83%A8%E7%BD%B2alertmanager%E6%9C%8D%E5%8A%A1"><span class="toc-number">1.2.5.</span> <span class="toc-text">2.5 部署 AlertManager 服务</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#26-%E5%8F%91%E5%B8%83alertmanager%E6%9C%8D%E5%8A%A1"><span class="toc-number">1.2.6.</span> <span class="toc-text">2.6 发布 AlertManager 服务</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#27-%E6%B5%8B%E8%AF%95alertmanager%E5%91%8A%E8%AD%A6"><span class="toc-number">1.2.7.</span> <span class="toc-text">2.7 测试 AlertManager 告警</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E9%83%A8%E7%BD%B2prometheus%E8%87%B3kubernetes"><span class="toc-number">1.3.</span> <span class="toc-text">3、部署 Prometheus ⾄ Kubernetes</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#31-%E5%88%9B%E5%BB%BAprometheus%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">1.3.1.</span> <span class="toc-text">3.1 创建 Prometheus 配置⽂件</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#32-%E5%88%9B%E5%BB%BAprometheus%E5%91%8A%E8%AD%A6%E8%A7%84%E5%88%99"><span class="toc-number">1.3.2.</span> <span class="toc-text">3.2 创建 Prometheus 告警规则</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#33-%E5%88%9B%E5%BB%BAprometheusrbac%E6%9D%83%E9%99%90"><span class="toc-number">1.3.3.</span> <span class="toc-text">3.3 创建 PrometheusRBAC 权限</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#34-%E5%88%9B%E5%BB%BAheadlesssevice"><span class="toc-number">1.3.4.</span> <span class="toc-text">3.4 创建 headlessSevice</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#35-%E9%83%A8%E7%BD%B2prometheus%E6%9C%8D%E5%8A%A1"><span class="toc-number">1.3.5.</span> <span class="toc-text">3.5 部署 Prometheus 服务</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#36-%E5%8F%91%E5%B8%83prometheus%E6%9C%8D%E5%8A%A1"><span class="toc-number">1.3.6.</span> <span class="toc-text">3.6 发布 Prometheus 服务</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-%E9%83%A8%E7%BD%B2grafana%E8%87%B3kubernetes"><span class="toc-number">1.4.</span> <span class="toc-text">4、部署 Grafana ⾄ Kubernetes</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#41-%E5%88%9B%E5%BB%BAheadlessservice"><span class="toc-number">1.4.1.</span> <span class="toc-text">4.1 创建 HeadlessService</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#42-%E9%83%A8%E7%BD%B2grafana%E6%9C%8D%E5%8A%A1"><span class="toc-number">1.4.2.</span> <span class="toc-text">4.2 部署 Grafana 服务</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#43-%E5%8F%91%E5%B8%83grafana%E6%9C%8D%E5%8A%A1"><span class="toc-number">1.4.3.</span> <span class="toc-text">4.3 发布 Grafana 服务</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#44-%E9%85%8D%E7%BD%AEgrafana%E8%BF%9E%E6%8E%A5prometheus"><span class="toc-number">1.4.4.</span> <span class="toc-text">4.4 配置 Grafana 连接 Prometheus</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-%E9%83%A8%E7%BD%B2blackbox%E8%87%B3kubernetes"><span class="toc-number">1.5.</span> <span class="toc-text">5、部署 blackbox ⾄ Kubernetes</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#51-%E5%88%9B%E5%BB%BAblackbox%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">1.5.1.</span> <span class="toc-text">5.1 创建 Blackbox 的配置⽂件</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#52-%E9%83%A8%E7%BD%B2blackbox%E6%9C%8D%E5%8A%A1"><span class="toc-number">1.5.2.</span> <span class="toc-text">5.2 部署 Blackbox 服务</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#53-%E5%8F%91%E5%B8%83blackbox%E6%9C%8D%E5%8A%A1"><span class="toc-number">1.5.3.</span> <span class="toc-text">5.3 发布 blackbox 服务</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#image-202403112132301406-%E7%9B%91%E6%8E%A7kubernetes%E9%9B%86%E7%BE%A4%E8%8A%82%E7%82%B9"><span class="toc-number">1.6.</span> <span class="toc-text">6、监控 Kubernetes 集群节点</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#61-%E9%83%A8%E7%BD%B2node-exporter"><span class="toc-number">1.6.1.</span> <span class="toc-text">6.1 部署 Node-Exporter</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#62-%E9%85%8D%E7%BD%AEprometheus%E7%9B%91%E6%8E%A7node"><span class="toc-number">1.6.2.</span> <span class="toc-text">6.2 配置 Prometheus 监控 Node</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#63-relabel%E4%BF%AE%E6%94%B9%E6%8A%93%E5%8F%96%E7%9A%84%E8%8A%82%E7%82%B9%E7%AB%AF%E5%8F%A3"><span class="toc-number">1.6.3.</span> <span class="toc-text">6.3 relabel 修改抓取的节点端⼝</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#64-relabel%E4%B8%BA%E8%8A%82%E7%82%B9%E6%B7%BB%E5%8A%A0%E6%96%B0%E6%A0%87%E7%AD%BE"><span class="toc-number">1.6.4.</span> <span class="toc-text">6.4 relabel 为节点添加新标签</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#65-%E5%AF%BC%E5%85%A5%E8%8A%82%E7%82%B9%E5%8F%AF%E8%A7%86%E5%8C%96%E5%9B%BE%E5%BD%A2"><span class="toc-number">1.6.5.</span> <span class="toc-text">6.5 导⼊节点可视化图形</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-%E7%9B%91%E6%8E%A7k8s%E6%8E%A7%E5%88%B6%E7%BB%84%E4%BB%B6"><span class="toc-number">1.7.</span> <span class="toc-text">7、监控 K8S 控制组件</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#71-%E7%9B%91%E6%8E%A7%E6%8E%A7%E5%88%B6%E5%B9%B3%E9%9D%A2%E7%BB%84%E4%BB%B6"><span class="toc-number">1.7.1.</span> <span class="toc-text">7.1 监控控制平⾯组件</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#72-%E7%9B%91%E6%8E%A7%E6%8E%A7%E5%88%B6%E5%B9%B3%E9%9D%A2%E7%BB%84%E4%BB%B6%E7%AD%96%E7%95%A5"><span class="toc-number">1.7.2.</span> <span class="toc-text">7.2 监控控制平⾯组件策略</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#73-%E7%9B%91%E6%8E%A7apiserver"><span class="toc-number">1.7.3.</span> <span class="toc-text">7.3 监控 APIServer</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#731-%E8%8E%B7%E5%8F%96apiserver%E7%9A%84metrics"><span class="toc-number">1.7.3.1.</span> <span class="toc-text">7.3.1 获取 APIServer 的 Metrics</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#732-%E9%85%8D%E7%BD%AEprometheus%E7%9B%91%E6%8E%A7apiserver"><span class="toc-number">1.7.3.2.</span> <span class="toc-text">7.3.2 配置 Prometheus 监控 APIServer</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#733-apiserver%E5%91%8A%E8%AD%A6%E8%A7%84%E5%88%99%E6%96%87%E4%BB%B6"><span class="toc-number">1.7.3.3.</span> <span class="toc-text">7.3.3 APIServer 告警规则⽂件</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#74-%E7%9B%91%E6%8E%A7k8s%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6-controller"><span class="toc-number">1.7.4.</span> <span class="toc-text">7.4 监控 K8S 核⼼组件 - Controller</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#741-%E8%8E%B7%E5%8F%96controller%E7%9A%84metrics"><span class="toc-number">1.7.4.1.</span> <span class="toc-text">7.4.1 获取 Controller 的 Metrics</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#742-%E9%85%8D%E7%BD%AEprometheus%E7%9B%91%E6%8E%A7controller"><span class="toc-number">1.7.4.2.</span> <span class="toc-text">7.4.2 配置 Prometheus 监控 Controller</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#743-relabel%E4%BF%AE%E6%94%B9%E6%8A%93%E5%8F%96%E7%9A%84pod%E7%AB%AF%E5%8F%A3"><span class="toc-number">1.7.4.3.</span> <span class="toc-text">7.4.3 relabel 修改抓取的 Pod 端⼝</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#744-relabel%E4%B8%BApod%E6%B7%BB%E5%8A%A0%E6%96%B0%E6%A0%87%E7%AD%BE"><span class="toc-number">1.7.4.4.</span> <span class="toc-text">7.4.4 relabel 为 Pod 添加新标签</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#75-%E7%9B%91%E6%8E%A7k8s%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6-scheduler"><span class="toc-number">1.7.5.</span> <span class="toc-text">7.5 监控 K8S 核⼼组件 - Scheduler</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#751-%E8%8E%B7%E5%8F%96scheduler%E7%9A%84metrics"><span class="toc-number">1.7.5.1.</span> <span class="toc-text">7.5.1 获取 Scheduler 的 Metrics</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#752-%E9%85%8D%E7%BD%AEprometheus%E7%9B%91%E6%8E%A7scheduler"><span class="toc-number">1.7.5.2.</span> <span class="toc-text">7.5.2 配置 Prometheus 监控 Scheduler</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#753-schedule%E5%91%8A%E8%AD%A6%E8%A7%84%E5%88%99%E6%96%87%E4%BB%B6"><span class="toc-number">1.7.5.3.</span> <span class="toc-text">7.5.3 Schedule 告警规则⽂件</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#76-%E7%9B%91%E6%8E%A7k8s%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6-etcd"><span class="toc-number">1.7.6.</span> <span class="toc-text">7.6 监控 K8S 核⼼组件 - Etcd</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#761-%E8%8E%B7%E5%8F%96etcd%E7%9A%84metrics"><span class="toc-number">1.7.6.1.</span> <span class="toc-text">7.6.1 获取 Etcd 的 Metrics</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#762-%E9%85%8D%E7%BD%AEprometheus%E7%9B%91%E6%8E%A7etcd"><span class="toc-number">1.7.6.2.</span> <span class="toc-text">7.6.2 配置 Prometheus 监控 Etcd</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#763-etcd%E5%91%8A%E8%AD%A6%E8%A7%84%E5%88%99%E6%96%87%E4%BB%B6"><span class="toc-number">1.7.6.3.</span> <span class="toc-text">7.6.3 Etcd 告警规则⽂件</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#764-%E5%AF%BC%E5%85%A5etcd%E5%9B%BE%E5%BD%A2"><span class="toc-number">1.7.6.4.</span> <span class="toc-text">7.6.4 导⼊ Etcd 图形</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#77-%E7%9B%91%E6%8E%A7k8s%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6-coredns"><span class="toc-number">1.7.7.</span> <span class="toc-text">7.7 监控 K8S 核⼼组件 - CoreDNS</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#771-%E8%8E%B7%E5%8F%96coredns%E7%9A%84metrics"><span class="toc-number">1.7.7.1.</span> <span class="toc-text">7.7.1 获取 CoreDNS 的 Metrics</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#772-%E9%85%8D%E7%BD%AEprometheus%E7%9B%91%E6%8E%A7dns"><span class="toc-number">1.7.7.2.</span> <span class="toc-text">7.7.2 配置 Prometheus 监控 DNS</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#773-coredns%E5%91%8A%E8%AD%A6%E8%A7%84%E5%88%99%E6%96%87%E4%BB%B6"><span class="toc-number">1.7.7.3.</span> <span class="toc-text">7.7.3 CoreDNS 告警规则⽂件</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#774-%E5%AF%BC%E5%85%A5coredns%E5%9B%BE%E5%BD%A2"><span class="toc-number">1.7.7.4.</span> <span class="toc-text">7.7.4 导⼊ CoreDNS 图形</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#78-%E7%9B%91%E6%8E%A7k8s%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6-kubeproxy"><span class="toc-number">1.7.8.</span> <span class="toc-text">7.8 监控 K8S 核⼼组件 - Kubeproxy</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#781-%E8%8E%B7%E5%8F%96kube-proxy%E7%9A%84metrics"><span class="toc-number">1.7.8.1.</span> <span class="toc-text">7.8.1 获取 kube-proxy 的 Metrics</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#782-%E9%85%8D%E7%BD%AEprometheus%E7%9B%91%E6%8E%A7kube-proxy"><span class="toc-number">1.7.8.2.</span> <span class="toc-text">7.8.2 配置 Prometheus 监控 kube-proxy</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#783-kube-proxy%E5%91%8A%E8%AD%A6%E8%A7%84%E5%88%99%E6%96%87%E4%BB%B6"><span class="toc-number">1.7.8.3.</span> <span class="toc-text">7.8.3 Kube-Proxy 告警规则⽂件</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#79-%E7%9B%91%E6%8E%A7kubernetes%E9%9B%86%E7%BE%A4%E8%B5%84%E6%BA%90%E7%8A%B6%E6%80%81"><span class="toc-number">1.7.9.</span> <span class="toc-text">7.9 监控 Kubernetes 集群资源状态</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#791-%E4%BB%80%E4%B9%88%E6%98%AF%E9%9B%86%E7%BE%A4%E8%B5%84%E6%BA%90%E7%8A%B6%E6%80%81"><span class="toc-number">1.7.9.1.</span> <span class="toc-text">7.9.1 什么是集群资源状态</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#792-%E5%AE%89%E8%A3%85kube-state-metrics"><span class="toc-number">1.7.9.2.</span> <span class="toc-text">7.9.2 安装 Kube-State-Metrics</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#793-%E9%85%8D%E7%BD%AEprometheus%E7%9B%91%E6%8E%A7ksm"><span class="toc-number">1.7.9.3.</span> <span class="toc-text">7.9.3 配置 Prometheus 监控 KSM</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#794-%E8%B5%84%E6%BA%90%E7%8A%B6%E6%80%81%E5%91%8A%E8%AD%A6%E8%A7%84%E5%88%99%E6%96%87%E4%BB%B6"><span class="toc-number">1.7.9.4.</span> <span class="toc-text">7.9.4 资源状态告警规则⽂件</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#795-%E5%AF%BC%E5%85%A5%E8%B5%84%E6%BA%90%E7%8A%B6%E6%80%81%E5%9B%BE%E5%BD%A2"><span class="toc-number">1.7.9.5.</span> <span class="toc-text">7.9.5 导⼊资源状态图形</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#710-%E7%9B%91%E6%8E%A7kubernetes%E9%9B%86%E7%BE%A4pod%E8%B5%84%E6%BA%90"><span class="toc-number">1.7.10.</span> <span class="toc-text">7.10 监控 Kubernetes 集群 Pod 资源</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#7101-pod%E8%B5%84%E6%BA%90%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-number">1.7.10.1.</span> <span class="toc-text">7.10.1 Pod 资源是什么</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#7102-%E9%85%8D%E7%BD%AEprometheus%E7%9B%91%E6%8E%A7pod"><span class="toc-number">1.7.10.2.</span> <span class="toc-text">7.10.2 配置 Prometheus 监控 Pod</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#711-%E7%9B%91%E6%8E%A7kubernetes%E9%9B%86%E7%BE%A4service%E8%B5%84%E6%BA%90"><span class="toc-number">1.7.11.</span> <span class="toc-text">7.11 监控 Kubernetes 集群 Service 资源</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#7111-%E4%B8%BA%E4%BD%95%E9%9C%80%E8%A6%81%E7%9B%91%E6%8E%A7service%E8%B5%84%E6%BA%90"><span class="toc-number">1.7.11.1.</span> <span class="toc-text">7.11.1 为何需要监控 Service 资源</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#7112-%E9%85%8D%E7%BD%AEprometheus%E7%9B%91%E6%8E%A7service"><span class="toc-number">1.7.11.2.</span> <span class="toc-text">7.11.2 配置 Prometheus 监控 Service</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#712-%E7%9B%91%E6%8E%A7kubernetes%E9%9B%86%E7%BE%A4ingress%E8%B5%84%E6%BA%90"><span class="toc-number">1.7.12.</span> <span class="toc-text">7.12 监控 Kubernetes 集群 Ingress 资源</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#7121-%E4%B8%BA%E4%BD%95%E9%9C%80%E8%A6%81%E7%9B%91%E6%8E%A7ingress%E8%B5%84%E6%BA%90"><span class="toc-number">1.7.12.1.</span> <span class="toc-text">7.12.1 为何需要监控 Ingress 资源</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#7122-%E9%85%8D%E7%BD%AEprometheus%E7%9B%91%E6%8E%A7ingress"><span class="toc-number">1.7.12.2.</span> <span class="toc-text">7.12.2 配置 Prometheus 监控 Ingress</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-prometheus%E7%9B%91%E6%8E%A7redis%E5%BA%94%E7%94%A8%E7%9A%84pod"><span class="toc-number">1.8.</span> <span class="toc-text">8、Prometheus 监控 Redis 应⽤的 Pod</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#81-%E7%9B%91%E6%8E%A7redis%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%E8%AF%B4%E6%98%8E"><span class="toc-number">1.8.1.</span> <span class="toc-text">8.1 监控 Redis 应⽤场景说明</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#82-%E8%BF%90%E8%A1%8Credis%E5%9F%BA%E7%A1%80%E6%9C%8D%E5%8A%A1pod"><span class="toc-number">1.8.2.</span> <span class="toc-text">8.2 运⾏ Redis 基础服务 Pod</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#83-%E9%85%8D%E7%BD%AEprometheus%E7%9B%91%E6%8E%A7redis"><span class="toc-number">1.8.3.</span> <span class="toc-text">8.3 配置 Prometheus 监控 Redis</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-prometheus%E7%9B%91%E6%8E%A7java%E4%B8%9A%E5%8A%A1%E5%BA%94%E7%94%A8%E7%9A%84pod"><span class="toc-number">1.9.</span> <span class="toc-text">9、Prometheus 监控 java 业务应⽤的 Pod</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#91-%E7%9B%91%E6%8E%A7%E4%B8%9A%E5%8A%A1%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%E8%AF%B4%E6%98%8E"><span class="toc-number">1.9.1.</span> <span class="toc-text">9.1 监控业务应⽤场景说明</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#92-%E8%BF%90%E8%A1%8C%E4%B8%9A%E5%8A%A1%E5%BA%94%E7%94%A8%E5%AE%B9%E5%99%A8pod"><span class="toc-number">1.9.2.</span> <span class="toc-text">9.2 运⾏业务应⽤容器 Pod</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#93-%E5%AF%B9%E5%A4%96%E5%8F%91%E5%B8%83java%E4%B8%9A%E5%8A%A1%E5%BA%94%E7%94%A8"><span class="toc-number">1.9.3.</span> <span class="toc-text">9.3 对外发布 java 业务应⽤</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#94-%E9%85%8D%E7%BD%AEprometheus%E7%9B%91%E6%8E%A7%E4%B8%9A%E5%8A%A1%E5%BA%94%E7%94%A8"><span class="toc-number">1.9.4.</span> <span class="toc-text">9.4 配置 Prometheus 监控业务应⽤</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#95-%E6%A3%80%E6%9F%A5%E6%AD%A4%E5%89%8D%E5%88%9B%E5%BB%BA%E5%A5%BD%E7%9A%84-jvm_rulesyml-%E5%91%8A%E8%AD%A6%E8%A7%84%E5%88%99%E6%96%87%E4%BB%B6"><span class="toc-number">1.9.5.</span> <span class="toc-text">9.5 检查此前创建好的 jvm_rules.yml 告警规则⽂件</span></a></li></ol></li></ol></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li><a href="/posts/1595025559.html" rel="bookmark" title="Prometheus监控实战（一）">Prometheus监控实战（一）</a></li><li><a href="/posts/3386060324.html" rel="bookmark" title="PromQL快速入门（二）">PromQL快速入门（二）</a></li><li><a href="/posts/4081185381.html" rel="bookmark" title="Prometheus监控实战（三）">Prometheus监控实战（三）</a></li><li><a href="/posts/4081185382.html" rel="bookmark" title="Prometheus监控实战（四）">Prometheus监控实战（四）</a></li><li class="active"><a href="/posts/2041568856.html" rel="bookmark" title="Prometheus监控Kubernetes">Prometheus监控Kubernetes</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" loading="lazy" decoding="async" itemprop="image" alt="Xu Yong" src="/assets/avatar.png"><p class="name" itemprop="name">Xu Yong</p><div class="description" itemprop="description">专注于 Linux 运维、云计算、云原⽣等技术</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">48</span><span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">15</span><span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">18</span><span class="name">标签</span></a></div></nav><div class="social"><a target="_blank" rel="noopener" href="https://github.com/xyapples" class="item github" title="https:&#x2F;&#x2F;github.com&#x2F;xyapples"><i class="ic i-github"></i></a><a target="_blank" rel="noopener" href="https://gitee.com/chinagei" class="item gitee" title="https:&#x2F;&#x2F;gitee.com&#x2F;chinagei"><i class="ic i-gitee"></i></a><a href="mailto:373370405@qq.com" class="item email" title="mailto:373370405@qq.com"><i class="ic i-envelope"></i></a></div><div class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-about"></i>关于</a></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>友链</a></li></div></div></div></div><ul id="quick"><li class="prev pjax"></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/posts/4081185382.html" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/DevOps/" title="分类于DevOps">DevOps</a></div><span><a href="/posts/889219339.html">K8S基于Jenkins实现SpringCloud微服务CI与CD实践（三）</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Redis/" title="分类于Redis">Redis</a></div><span><a href="/posts/1414180692.html">Redis集群（主从+哨兵）模式</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Kubernetes/" title="分类于Kubernetes">Kubernetes</a></div><span><a href="/posts/108692210.html">K8s资源调度deployment、statefulset、daemonset</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Harbor/" title="分类于Harbor">Harbor</a></div><span><a href="/posts/3071070978.html">企业级私有仓库Harbor搭建</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Kubernetes/" title="分类于Kubernetes">Kubernetes</a></div><span><a href="/posts/3833778957.html">K8s计划任务Job、Cronjob</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Linux/" title="分类于Linux">Linux</a></div><span><a href="/posts/1922841233.html">Rsync服务实践</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Kubernetes/" title="分类于Kubernetes">Kubernetes</a></div><span><a href="/posts/3992668367.html">K8s配置管理Configmap</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Kubernetes/" title="分类于Kubernetes">Kubernetes</a></div><span><a href="/posts/3142072607.html">K8s初始化容器、临时容器</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Kubernetes/" title="分类于Kubernetes">Kubernetes</a></div><span><a href="/posts/169153047.html">K8s持久化存储</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Kubernetes/" title="分类于Kubernetes">Kubernetes</a></div><span><a href="/posts/3890389502.html">K8S持久化存储NFS+StorageClass</a></span></li></ul></div><div class="rpost pjax"><h2>最新评论</h2><ul class="leancloud-recent-comment" id="new-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2022 -<span itemprop="copyrightYear">2025</span><span class="with-love"><i class="ic i-sakura rotate"></i></span><span class="author" itemprop="copyrightHolder">Xu Yong @ LinuxSre云原生</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i></span><span title="站点总字数">1.4m 字</span><span class="post-meta-divider"> | </span><span class="post-meta-item-icon"><i class="ic i-coffee"></i></span><span title="站点阅读时长">21:46</span></div><div class="powered-by">基于 <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a> & Theme.<a target="_blank" rel="noopener" href="https://github.com/theme-shoka-x/hexo-theme-shokaX/">ShokaX</a></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL = {
    ispost: true,
        path: `posts/2041568856.html`,
        favicon: {
        show: `（●´3｀●）やれやれだぜ`,
        hide: `(´Д｀)大変だ！`
    },
    search: {
        placeholder: "文章搜索",
        empty: "关于 「 ${query} 」，什么也没搜到",
        stats: "${time} ms 内找到 ${hits} 条结果"
    },
    copy_tex: false,
    katex: false,
    mermaid: false,
    audio: undefined,
    fancybox: true,
    nocopy: false,
    outime: true,
    template: `<div class="note warning"><p><span class="label warning">文章时效性提示</span><br>这是一篇发布于 {{publish}} 天前，最后一次更新在 {{updated}} 天前的文章，部分信息可能已经发生改变，请注意甄别。</p></div>`,
    quiz: {
        choice: `单选题`,
        multiple: `多选题`,
        true_false: `判断题`,
        essay: `问答题`,
        gap_fill: `填空题`,
        mistake: `错题备注`
    },
    ignores: [
        (uri) => uri.includes('#'),
        (uri) => new RegExp(LOCAL.path + '$').test(uri),
            []
    ]
};</script><script src="https://s4.zstatic.net/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha384-k6YtvFUEIuEFBdrLKJ3YAUbBki333tj1CSUisai5Cswsg9wcLNaPzsTHDswp4Az8" crossorigin="anonymous" fetchpriority="high"></script><script src="https://s4.zstatic.net/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha384-ZvpUoO&#x2F;+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn&#x2F;6Z&#x2F;hRTt8+pR6L4N2" crossorigin="anonymous" fetchpriority="high"></script><script src="/js/siteInit.js?v=0.4.17" type="module" fetchpriority="high" defer></script></body></html><!-- rebuild by hrmmi -->