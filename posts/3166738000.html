<!-- build time:Mon Apr 14 2025 20:53:01 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta http-equiv="X-UA-COMPATIBLE" content="IE=edge,chrome=1"><meta name="renderer" content="webkit"><link rel="icon" type="image/ico" sizes="32x32" href="/assets/favicon.ico"><link rel="apple-touch-icon" sizes="180x180" href="/assets/favicon.ico"><link rel="alternate" href="/rss.xml" title="LinuxSre云原生" type="application/rss+xml"><link rel="alternate" href="/atom.xml" title="LinuxSre云原生" type="application/atom+xml"><link rel="alternate" type="application/json" title="LinuxSre云原生" href="http://xuyong.cn/feed.json"><link rel="preconnect" href="https://s4.zstatic.net"><link rel="preconnect" href="https://at.alicdn.com"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Mulish:400,400italic,700,700italic%7CFredericka%20the%20Great:400,400italic,700,700italic%7CNoto%20Serif%20JP:400,400italic,700,700italic%7CNoto%20Serif%20SC:400,400italic,700,700italic%7CInconsolata:400,400italic,700,700italic&display=swap&subset=latin,latin-ext" media="none" onload="this.media&#x3D;&#39;all&#39;"><link rel="stylesheet" href="/css/app.css?v=0.4.17"><link rel="modulepreload" href="/js/chunk-57ZYAG33.js"><link rel="modulepreload" href="/js/chunk-ADGZCACO.js"><link rel="modulepreload" href="/js/chunk-IYTJIE5B.js"><link rel="modulepreload" href="/js/chunk-TZQK3JVR.js"><link rel="modulepreload" href="/js/chunk-WIQECBEN.js"><link rel="modulepreload" href="/js/comments-4BEIUNYT.js"><link rel="modulepreload" href="/js/copy-tex-KYHZPCUS.js"><link rel="modulepreload" href="/js/post-QGZVMRN2.js"><link rel="modulepreload" href="/js/quicklink-2TNLIWKF.js"><link rel="modulepreload" href="/js/search-DHWZLS3W.js"><link rel="modulepreload" href="/js/siteInit.js"><link rel="modulepreload" href="/js/waline-NNBYRQEE.js"><link rel="stylesheet" href="/css/comments-F4ZGS7LD.css" media="none" onload="this.media&#x3D;&#39;all&#39;"><link rel="stylesheet" href="/css/siteInit.css" media="none" onload="this.media&#x3D;&#39;all&#39;"><link rel="stylesheet" href="/css/waline-IDNZKML2.css" media="none" onload="this.media&#x3D;&#39;all&#39;"><link rel="preload" href="https://s21.ax1x.com/2025/03/29/pEsS0hD.png" as="image" fetchpriority="high"><meta name="keywords" content="Kubernetes"><meta name="description" content="专注于 Linux 运维、云计算、云原⽣等技术"><link rel="canonical" href="http://xuyong.cn/posts/3166738000.html"><title>Kubeadm高可用安装K8s集群</title><meta name="generator" content="Hexo 7.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">Kubeadm高可用安装K8s集群</h1><div class="meta"><span class="item" title="创建时间：2025-04-09 18:28:34"><span class="icon"><i class="ic i-calendar"></i></span><span class="text">发表于</span><time itemprop="dateCreated datePublished" datetime="2025-04-09T18:28:34+08:00">2025-04-09</time></span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i></span><span class="text">本文字数</span><span>32k</span><span class="text">字</span></span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i></span><span class="text">阅读时长</span><span>29 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span><span class="line"></span><span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">LinuxSre云原生</a></li></ul><ul class="right" id="rightNav"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div class="pjax" id="imgs"><img src="https://s21.ax1x.com/2025/03/29/pEsS0hD.png" loading="eager" decoding="async" fetchpriority="high" alt="LinuxSre云原生"></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"></path></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"></use><use xlink:href="#gentle-wave" x="48" y="3"></use><use xlink:href="#gentle-wave" x="48" y="5"></use><use xlink:href="#gentle-wave" x="48" y="7"></use></g></svg></div><main><div class="inner"><div class="pjax" id="main"><div class="article wrap"><div class="breadcrumb" itemlistelement itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i><span><a href="/">首页</a></span><i class="ic i-angle-right"></i><span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/Kubernetes/" itemprop="item" rel="index" title="分类于Kubernetes"><span itemprop="name">Kubernetes<meta itemprop="position" content="0"></span></a></span></div><article class="post block" itemscope itemtype="http://schema.org/Article" lang="zh-CN"><link itemprop="mainEntityOfPage" href="http://xuyong.cn/posts/3166738000.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/assets/avatar.png"><meta itemprop="name" content="Xu Yong"><meta itemprop="description" content="致力于技术布道、普及前沿技术、打造云原生系列标杆博客, 专注于 Linux 运维、云计算、云原⽣等技术"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="LinuxSre云原生"></span><div class="body md" itemprop="articleBody"><h2 id="kubeadm高可用安装k8s集群"><a class="anchor" href="#kubeadm高可用安装k8s集群">#</a> Kubeadm 高可用安装 K8s 集群</h2><h4 id="1-基本配置"><a class="anchor" href="#1-基本配置">#</a> 1. 基本配置</h4><h5 id="11-基本环境配置"><a class="anchor" href="#11-基本环境配置">#</a> 1.1 基本环境配置</h5><table><thead><tr><th>主机名</th><th>IP 地址</th><th>说明</th></tr></thead><tbody><tr><td>k8s-master01 ~ 03</td><td>192.168.1.71 ~ 73</td><td>master 节点 * 3</td></tr><tr><td>/</td><td>192.168.1.70</td><td>keepalived 虚拟 IP（不占用机器）</td></tr><tr><td>k8s-node01 ~ 02</td><td>192.168.1.74/75</td><td>worker 节点 * 2</td></tr></tbody></table><p><em>请统一替换这些网段，Pod 网段和 service 和宿主机网段不要重复！！！</em></p><table><thead><tr><th><em><strong>* 配置信息 *</strong></em></th><th>备注</th></tr></thead><tbody><tr><td>系统版本</td><td>Rocky Linux 8/9</td></tr><tr><td>Containerd</td><td>latest</td></tr><tr><td>Pod 网段</td><td>172.16.0.0/16</td></tr><tr><td>Service 网段</td><td>10.96.0.0/16</td></tr></tbody></table><p><mark>所有节点</mark>更改主机名（其它节点按需修改）：</p><pre><code>hostnamectl set-hostname k8s-master01 
</code></pre><p><mark>所有节点</mark>配置 hosts，修改 /etc/hosts 如下：</p><pre><code>[root@k8s-master01 ~]# cat /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
192.168.1.71 k8s-master01
192.168.1.72 k8s-master02
192.168.1.73 k8s-master03
192.168.1.74 k8s-node01
192.168.1.75 k8s-node02
</code></pre><p><mark>所有节点</mark>配置 yum 源：</p><pre><code># 配置基础源
sed -e 's|^mirrorlist=|#mirrorlist=|g' \
    -e 's|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g' \
    -i.bak \
    /etc/yum.repos.d/*.repo

yum makecache
</code></pre><p><mark>所有节点</mark>必备工具安装：</p><pre><code>yum install wget jq psmisc vim net-tools telnet yum-utils device-mapper-persistent-data lvm2 git rsyslog -y
</code></pre><p><mark>所有节点</mark>关闭防火墙、selinux、dnsmasq、swap、开启 rsyslog。服务器配置如下：</p><pre><code>systemctl disable --now firewalld 
systemctl disable --now dnsmasq
setenforce 0
sed -i 's#SELINUX=enforcing#SELINUX=disabled#g' /etc/sysconfig/selinux
sed -i 's#SELINUX=enforcing#SELINUX=disabled#g' /etc/selinux/config
systemctl enable --now rsyslog
</code></pre><p><mark>所有节点</mark>关闭 swap 分区：</p><pre><code>swapoff -a &amp;&amp; sysctl -w vm.swappiness=0
sed -ri '/^[^#]*swap/s@^@#@' /etc/fstab
</code></pre><p><mark>所有节点</mark>安装 ntpdate：</p><pre><code>sudo dnf install epel-release -y
sudo dnf config-manager --set-enabled epel
sudo dnf install ntpsec
</code></pre><p><mark>所有节点</mark>同步时间并配置上海时区：</p><pre><code>ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
echo 'Asia/Shanghai' &gt;/etc/timezone
ntpdate time2.aliyun.com
# 加入到crontab
crontab -e
*/5 * * * * /usr/sbin/ntpdate time2.aliyun.com
</code></pre><p><mark>所有节点</mark>配置 limit：</p><pre><code>ulimit -SHn 65535
vim /etc/security/limits.conf
# 末尾添加如下内容
* soft nofile 65536
* hard nofile 131072
* soft nproc 65535
* hard nproc 655350
* soft memlock unlimited
* hard memlock unlimited
</code></pre><p><mark>所有节点</mark>升级系统：</p><pre><code>yum update -y
</code></pre><p><mark>Master01 节点</mark>免密钥登录其他节点，安装过程中生成配置文件和证书均在 Master01 上操作，集群管理也在 Master01 上操作：</p><pre><code>ssh-keygen -t rsa
for i in k8s-master01 k8s-master02 k8s-master03 k8s-node01 k8s-node02;do ssh-copy-id -i .ssh/id_rsa.pub $i;done
</code></pre><p><em>注意：公有云环境，可能需要把 kubectl 放在一个非 Master 节点上</em></p><p><mark>Master01 节点</mark>下载安装所有的源码文件：</p><pre><code>cd /root/ ; git clone https://gitee.com/chinagei/k8s-ha-install
</code></pre><h5 id="12-内核配置"><a class="anchor" href="#12-内核配置">#</a> 1.2 内核配置</h5><p><mark>所有节点</mark>安装 ipvsadm：</p><pre><code>yum install ipvsadm ipset sysstat conntrack libseccomp -y
</code></pre><p><mark>所有节点</mark>配置 ipvs 模块：</p><pre><code>modprobe -- ip_vs
modprobe -- ip_vs_rr
modprobe -- ip_vs_wrr
modprobe -- ip_vs_sh
modprobe -- nf_conntrack
</code></pre><p><mark>所有节点</mark>创建 ipvs.conf，并配置开机自动加载：</p><pre><code>vim /etc/modules-load.d/ipvs.conf 
# 加入以下内容
ip_vs
ip_vs_lc
ip_vs_wlc
ip_vs_rr
ip_vs_wrr
ip_vs_lblc
ip_vs_lblcr
ip_vs_dh
ip_vs_sh
ip_vs_fo
ip_vs_nq
ip_vs_sed
ip_vs_ftp
ip_vs_sh
nf_conntrack
ip_tables
ip_set
xt_set
ipt_set
ipt_rpfilter
ipt_REJECT
ipip
</code></pre><p><mark>所有节点</mark>然后执行 systemctl enable --now systemd-modules-load.service 即可（报错不用管）</p><pre><code>systemctl enable --now systemd-modules-load.service
</code></pre><p><mark>所有节点</mark>内核优化配置：</p><pre><code>cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.conf
net.ipv4.ip_forward = 1
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-ip6tables = 1
fs.may_detach_mounts = 1
net.ipv4.conf.all.route_localnet = 1
vm.overcommit_memory=1
vm.panic_on_oom=0
fs.inotify.max_user_watches=89100
fs.file-max=52706963
fs.nr_open=52706963
net.netfilter.nf_conntrack_max=2310720

net.ipv4.tcp_keepalive_time = 600
net.ipv4.tcp_keepalive_probes = 3
net.ipv4.tcp_keepalive_intvl =15
net.ipv4.tcp_max_tw_buckets = 36000
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_max_orphans = 327680
net.ipv4.tcp_orphan_retries = 3
net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_max_syn_backlog = 16384
net.ipv4.ip_conntrack_max = 65536
net.ipv4.tcp_max_syn_backlog = 16384
net.ipv4.tcp_timestamps = 0
net.core.somaxconn = 16384
EOF
</code></pre><p><mark>所有节点</mark>应用配置：</p><pre><code>sysctl --system
</code></pre><p><mark>所有节点</mark>配置完内核后，重启机器，之后查看内核模块是否已自动加载：</p><pre><code>reboot
lsmod | grep --color=auto -e ip_vs -e nf_conntrack
</code></pre><h4 id="2-高可用组件安装"><a class="anchor" href="#2-高可用组件安装">#</a> 2. 高可用组件安装</h4><p><em>注意：如果安装的不是高可用集群，haproxy 和 keepalived 无需安装</em></p><p><em>注意：公有云要用公有云自带的负载均衡，比如阿里云的 SLB、NLB，腾讯云的 ELB，用来替代 haproxy 和 keepalived，因为公有云大部分都是不支持 keepalived 的。</em></p><p><mark>所有 Master 节点</mark>通过 yum 安装 HAProxy 和 KeepAlived：</p><pre><code>yum install keepalived haproxy -y
</code></pre><p><mark>所有 Master 节点</mark>配置 HAProxy，需要注意黄色部分的 IP：</p><pre><code>[root@k8s-master01 etc]# mkdir /etc/haproxy
[root@k8s-master01 etc]# vim /etc/haproxy/haproxy.cfg 
global
  maxconn  2000
  ulimit-n  16384
  log  127.0.0.1 local0 err
  stats timeout 30s

defaults
  log global
  mode  http
  option  httplog
  timeout connect 5000
  timeout client  50000
  timeout server  50000
  timeout http-request 15s
  timeout http-keep-alive 15s

frontend monitor-in
  bind *:33305
  mode http
  option httplog
  monitor-uri /monitor

frontend k8s-master
  bind 0.0.0.0:16443       #HAProxy监听端口
  bind 127.0.0.1:16443     #HAProxy监听端口
  mode tcp
  option tcplog
  tcp-request inspect-delay 5s
  default_backend k8s-master

backend k8s-master
  mode tcp
  option tcplog
  option tcp-check
  balance roundrobin
  default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100
  server k8s-master01	192.168.1.71:6443  check       #API Server IP地址
  server k8s-master02	192.168.1.72:6443  check       #API Server IP地址
  server k8s-master03	192.168.1.73:6443  check       #API Server IP地址
</code></pre><p><mark>所有 Master 节点</mark>配置 KeepAlived，需要注意黄色部分的配置。</p><p><mark>Master01 节点</mark>的配置：</p><pre><code>[root@k8s-master01 etc]# mkdir /etc/keepalived

[root@k8s-master01 ~]# vim /etc/keepalived/keepalived.conf 
! Configuration File for keepalived
global_defs &#123;
    router_id LVS_DEVEL
script_user root
    enable_script_security
&#125;
vrrp_script chk_apiserver &#123;
    script &quot;/etc/keepalived/check_apiserver.sh&quot;
    interval 5
    weight -5
    fall 2  
rise 1
&#125;
vrrp_instance VI_1 &#123;
    state MASTER
    interface ens160               #网卡名称
    mcast_src_ip 192.168.1.71      #K8s-master01 IP地址
    virtual_router_id 51
    priority 101
    advert_int 2
    authentication &#123;
        auth_type PASS
        auth_pass K8SHA_KA_AUTH
    &#125;
    virtual_ipaddress &#123;
        192.168.1.70        #VIP地址
    &#125;
    track_script &#123;
       chk_apiserver
    &#125;
&#125;	
</code></pre><p><mark>Master02 节点</mark>的配置：</p><pre><code># vim /etc/keepalived/keepalived.conf 

! Configuration File for keepalived
global_defs &#123;
    router_id LVS_DEVEL
script_user root
    enable_script_security
&#125;
vrrp_script chk_apiserver &#123;
    script &quot;/etc/keepalived/check_apiserver.sh&quot;
   interval 5
    weight -5
    fall 2  
rise 1
&#125;
vrrp_instance VI_1 &#123;
    state BACKUP
    interface ens160                #网卡名称
    mcast_src_ip 192.168.1.72       #K8s-master02 IP地址
    virtual_router_id 51
    priority 100
    advert_int 2
    authentication &#123;
        auth_type PASS
        auth_pass K8SHA_KA_AUTH
    &#125;
    virtual_ipaddress &#123;
        192.168.1.70              #VIP地址
    &#125;
    track_script &#123;
       chk_apiserver
    &#125;
&#125;
</code></pre><p><mark>Master03 节点</mark>的配置：</p><pre><code># vim /etc/keepalived/keepalived.conf 

! Configuration File for keepalived
global_defs &#123;
    router_id LVS_DEVEL
script_user root
    enable_script_security
&#125;
vrrp_script chk_apiserver &#123;
    script &quot;/etc/keepalived/check_apiserver.sh&quot;
 interval 5
    weight -5
    fall 2  
rise 1
&#125;
vrrp_instance VI_1 &#123;
    state BACKUP
    interface ens160                 #网卡名称
    mcast_src_ip 192.168.1.73        #K8s-master03 IP地址
    virtual_router_id 51
    priority 100
    advert_int 2
    authentication &#123;
        auth_type PASS
        auth_pass K8SHA_KA_AUTH
    &#125;
    virtual_ipaddress &#123;
        192.168.1.70          #VIP地址
    &#125;
    track_script &#123;
       chk_apiserver
    &#125;
&#125;
</code></pre><p><mark>所有 master 节点</mark>配置 KeepAlived 健康检查文件：</p><pre><code>[root@k8s-master01 keepalived]# vim /etc/keepalived/check_apiserver.sh 
#!/bin/bash

err=0
for k in $(seq 1 3)
do
    check_code=$(pgrep haproxy)
    if [[ $check_code == &quot;&quot; ]]; then
        err=$(expr $err + 1)
        sleep 1
        continue
    else
        err=0
        break
    fi
done

if [[ $err != &quot;0&quot; ]]; then
    echo &quot;systemctl stop keepalived&quot;
    /usr/bin/systemctl stop keepalived
    exit 1
else
    exit 0
fi
</code></pre><p><mark>所有 master 节点</mark>配置健康检查文件添加执行权限：</p><pre><code>chmod +x /etc/keepalived/check_apiserver.sh
</code></pre><p><mark>所有 master 节点</mark>启动 haproxy 和 keepalived：</p><pre><code>[root@k8s-master01 keepalived]# systemctl daemon-reload
[root@k8s-master01 keepalived]# systemctl enable --now haproxy
[root@k8s-master01 keepalived]# systemctl enable --now keepalived
</code></pre><p>重要：如果安装了 keepalived 和 haproxy，需要测试 keepalived 是否是正常的</p><pre><code>所有节点测试VIP
[root@k8s-master01 ~]# ping 192.168.1.70 -c 4
PING 192.168.1.70 (192.168.1.70) 56(84) bytes of data.
64 bytes from 192.168.1.70: icmp_seq=1 ttl=64 time=0.464 ms
64 bytes from 192.168.1.70: icmp_seq=2 ttl=64 time=0.063 ms
64 bytes from 192.168.1.70: icmp_seq=3 ttl=64 time=0.062 ms
64 bytes from 192.168.1.70: icmp_seq=4 ttl=64 time=0.063 ms

[root@k8s-master01 ~]# telnet 192.168.1.70 16443
Trying 192.168.1.70...
Connected to 192.168.1.70.
Escape character is '^]'.
Connection closed by foreign host.
</code></pre><p>如果 ping 不通且 telnet 没有出现 ] ，则认为 VIP 不可以，不可在继续往下执行，需要排查 keepalived 的问题，比如防火墙和 selinux，haproxy 和 keepalived 的状态，监听端口等</p><ul><li>所有节点查看防火墙状态必须为 disable 和 inactive：systemctl status firewalld</li><li>所有节点查看 selinux 状态，必须为 disable：getenforce</li><li>master 节点查看 haproxy 和 keepalived 状态：systemctl status keepalived haproxy</li><li>master 节点查看监听端口：netstat -lntp</li></ul><p>如果以上都没有问题，需要确认：</p><ol><li><p>是否是公有云机器</p></li><li><p>是否是私有云机器（类似 OpenStack）</p></li></ol><p>上述公有云一般都是不支持 keepalived，私有云可能也有限制，需要和自己的私有云管理员咨询</p><h4 id="3-runtime安装"><a class="anchor" href="#3-runtime安装">#</a> 3. Runtime 安装</h4><p>如果安装的版本低于 1.24，选择 Docker 和 Containerd 均可，高于 1.24 建议选择 Containerd 作为 Runtime，不再推荐使用 Docker 作为 Runtime。</p><h5 id="31-安装containerd"><a class="anchor" href="#31-安装containerd">#</a> 3.1 安装 Containerd</h5><p><mark>所有节点</mark>配置安装源：</p><pre><code>yum install wget jq psmisc vim net-tools telnet yum-utils device-mapper-persistent-data lvm2 git -y
yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
</code></pre><p><mark>所有节点</mark>安装 docker-ce（如果在以前已经安装过，需要重新安装更新一下）：</p><pre><code># yum install docker-ce containerd -y
</code></pre><p><em>可以无需启动 Docker，只需要配置和启动 Containerd 即可。</em></p><p>首先配置 Containerd 所需的模块（<mark>所有节点</mark>）：</p><pre><code># cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf
overlay
br_netfilter
EOF
</code></pre><p><mark>所有节点</mark>加载模块：</p><pre><code># modprobe -- overlay
# modprobe -- br_netfilter
</code></pre><p><mark>所有节点</mark>，配置 Containerd 所需的内核：</p><pre><code># cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
net.bridge.bridge-nf-call-iptables  = 1
net.ipv4.ip_forward                 = 1
net.bridge.bridge-nf-call-ip6tables = 1
EOF
</code></pre><p><mark>所有节点</mark>加载内核：</p><pre><code># sysctl --system
</code></pre><p><mark>所有节点</mark>生成 Containerd 的配置文件：</p><pre><code># mkdir -p /etc/containerd
# containerd config default | tee /etc/containerd/config.toml
</code></pre><p><mark>所有节点</mark>更改 Containerd 的 Cgroup 和 Pause 镜像配置：</p><pre><code>sed -i 's#SystemdCgroup = false#SystemdCgroup = true#g' /etc/containerd/config.toml
sed -i 's#k8s.gcr.io/pause#registry.cn-hangzhou.aliyuncs.com/google_containers/pause#g'  /etc/containerd/config.toml
sed -i 's#registry.gcr.io/pause#registry.cn-hangzhou.aliyuncs.com/google_containers/pause#g'  /etc/containerd/config.toml
sed -i 's#registry.k8s.io/pause#registry.cn-hangzhou.aliyuncs.com/google_containers/pause#g'  /etc/containerd/config.toml
</code></pre><p><mark>所有节点</mark>启动 Containerd，并配置开机自启动：</p><pre><code># systemctl daemon-reload
# systemctl enable --now containerd
</code></pre><p><mark>所有节点</mark>配置 crictl 客户端连接的运行时位置（可选）：</p><pre><code># cat &gt; /etc/crictl.yaml &lt;&lt;EOF
runtime-endpoint: unix:///run/containerd/containerd.sock
image-endpoint: unix:///run/containerd/containerd.sock
timeout: 10
debug: false
EOF
</code></pre><h4 id="4-安装kubernetes组件"><a class="anchor" href="#4-安装kubernetes组件">#</a> 4 . 安装 Kubernetes 组件</h4><p><mark>所有节点</mark>配置源（注意更改版本号）：</p><pre><code>cat &lt;&lt;EOF | tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/rpm/
enabled=1
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/rpm/repodata/repomd.xml.key
EOF
</code></pre><p>首先在<mark> Master01 节点</mark>查看最新的 Kubernetes 版本是多少：</p><pre><code># yum list kubeadm.x86_64 --showduplicates | sort -r
</code></pre><p><mark>所有节点</mark>安装 1.32 最新版本 kubeadm、kubelet 和 kubectl：</p><pre><code># yum install kubeadm-1.32* kubelet-1.32* kubectl-1.32* -y
</code></pre><p><mark>所有节点</mark>设置 Kubelet 开机自启动（由于还未初始化，没有 kubelet 的配置文件，此时 kubelet 无法启动，无需关心）：</p><pre><code># systemctl daemon-reload
# systemctl enable --now kubelet
</code></pre><p><em>此时 kubelet 是起不来的，日志会有报错不影响！</em></p><h4 id="5-集群初始化"><a class="anchor" href="#5-集群初始化">#</a> 5 . 集群初始化</h4><p>以下操作在<mark> master01</mark>（注意黄色部分）：</p><pre><code>vim kubeadm-config.yaml
apiVersion: kubeadm.k8s.io/v1beta3
bootstrapTokens:
- groups:
  - system:bootstrappers:kubeadm:default-node-token
  token: 7t2weq.bjbawausm0jaxury
  ttl: 24h0m0s
  usages:
  - signing
  - authentication
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.1.71
  bindPort: 6443
nodeRegistration:
  criSocket: unix:///var/run/containerd/containerd.sock
  name: k8s-master01
  taints:
  - effect: NoSchedule
    key: node-role.kubernetes.io/control-plane
---
apiServer:
  certSANs:
  - 192.168.1.70               # 如果搭建的不是高可用集群，把此处改为master的IP
  timeoutForControlPlane: 4m0s
apiVersion: kubeadm.k8s.io/v1beta3
certificatesDir: /etc/kubernetes/pki
clusterName: kubernetes
controlPlaneEndpoint: 192.168.1.70:16443 # 如果搭建的不是高可用集群，把此处IP改为master的IP，端口改成6443
controllerManager: &#123;&#125;
etcd:
  local:
    dataDir: /var/lib/etcd
imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers
kind: ClusterConfiguration
kubernetesVersion: v1.32.3    # 更改此处的版本号和kubeadm version一致
networking:
  dnsDomain: cluster.local
  podSubnet: 172.16.0.0/16    # 注意此处的网段，不要与service和节点网段冲突
  serviceSubnet: 10.96.0.0/16 # 注意此处的网段，不要与pod和节点网段冲突
scheduler: &#123;&#125;
</code></pre><p><mark>master01 节点</mark>更新 kubeadm 文件：</p><pre><code>kubeadm config migrate --old-config kubeadm-config.yaml --new-config new.yaml
</code></pre><p>将 new.yaml 文件复制到<mark>其他 master 节点</mark>:</p><pre><code>for i in k8s-master02 k8s-master03; do scp new.yaml $i:/root/; done
</code></pre><p>之后<mark>所有 Master 节点</mark>提前下载镜像，可以节省初始化时间（其他节点不需要更改任何配置，包括 IP 地址也不需要更改）：</p><pre><code>kubeadm config images pull --config /root/new.yaml 
</code></pre><p>正确的反馈信息如下（<em><strong>* 版本可能不一样 *</strong></em>）：</p><pre><code>[root@k8s-master02 ~]# kubeadm config images pull --config /root/new.yaml 
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.32.0
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.32.0
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.32.0
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.32.0
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.11.3
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.10
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.5.16-0
</code></pre><p><mark>Master01 节点</mark>初始化，初始化以后会在 /etc/kubernetes 目录下生成对应的证书和配置文件，之后其他 Master 节点加入 Master01 即可：</p><pre><code>kubeadm init --config /root/new.yaml  --upload-certs
</code></pre><p>初始化成功以后，会产生 Token 值，用于其他节点加入时使用，因此要记录下初始化成功生成的 token 值（令牌值）：</p><pre><code>Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of the control-plane node running the following command on each as root:

# 不要复制文档当中的，要去使用节点生成的
  kubeadm join 192.168.1.70:16443 --token 7t2weq.bjbawausm0jaxury \
	--discovery-token-ca-cert-hash sha256:df72788de04bbc2e8fca70becb8a9e8503a962b5d7cd9b1842a0c39930d08c94 \
	--control-plane --certificate-key c595f7f4a7a3beb0d5bdb75d9e4eff0a60b977447e76c1d6885e82c3aa43c94c

Please note that the certificate-key gives access to cluster sensitive data, keep it secret!
As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use
&quot;kubeadm init phase upload-certs --upload-certs&quot; to reload certs afterward.

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 192.168.1.70:16443 --token 7t2weq.bjbawausm0jaxury \
	--discovery-token-ca-cert-hash sha256:df72788de04bbc2e8fca70becb8a9e8503a962b5d7cd9b1842a0c39930d08c94
</code></pre><p><mark>Master01 节点</mark>配置环境变量，用于访问 Kubernetes 集群：</p><pre><code>cat &lt;&lt;EOF &gt;&gt; /root/.bashrc
export KUBECONFIG=/etc/kubernetes/admin.conf
EOF
source /root/.bashrc
</code></pre><p><mark>Master01 节点</mark>查看节点状态：（显示 NotReady 不影响）</p><pre><code># kubectl get node
NAME           STATUS     ROLES           AGE   VERSION
k8s-master01   NotReady   control-plane   24s   v1.32.3
</code></pre><p>采用初始化安装方式，所有的系统组件均以容器的方式运行并且在 kube-system 命名空间内，此时可以查看 Pod 状态（显示 pending 不影响）：</p><pre><code class="language-\"># kubectl get pods -n kube-system
</code></pre><h5 id="51-初始化失败排查"><a class="anchor" href="#51-初始化失败排查">#</a> 5.1 初始化失败排查</h5><p>如果初始化失败，重置后再次初始化，命令如下（没有失败不要执行）：</p><pre><code>kubeadm reset -f ; ipvsadm --clear  ; rm -rf ~/.kube
</code></pre><p>如果多次尝试都是初始化失败，需要看系统日志，CentOS/RockyLinux 日志路径:/var/log/messages，Ubuntu 系列日志路径:/var/log/syslog：</p><pre><code>tail -f /var/log/messages | grep -v &quot;not found&quot;
</code></pre><p>经常出错的原因：</p><ol><li>Containerd 的配置文件修改的不对，自行参考《安装 containerd》小节核对</li><li>new.yaml 配置问题，比如非高可用集群忘记修改 16443 端口为 6443</li><li>new.yaml 配置问题，三个网段有交叉，出现 IP 地址冲突</li><li>VIP 不通导致无法初始化成功，此时 messages 日志会有 VIP 超时的报错</li></ol><h5 id="52-高可用master"><a class="anchor" href="#52-高可用master">#</a> 5.2 高可用 Master</h5><p><strong>其他 master</strong> 加入集群，master02 和 master03 分别执行 (千万不要在 master01 再次执行，不能直接复制文档当中的命令，而是你自己刚才 master01 初始化之后产生的命令)</p><pre><code>kubeadm join 192.168.1.70:16443 --token 7t2weq.bjbawausm0jaxury \
	--discovery-token-ca-cert-hash sha256:df72788de04bbc2e8fca70becb8a9e8503a962b5d7cd9b1842a0c39930d08c94 \
	--control-plane --certificate-key c595f7f4a7a3beb0d5bdb75d9e4eff0a60b977447e76c1d6885e82c3aa43c94c
</code></pre><p>查看当前状态：（如果显示 NotReady 不影响）</p><pre><code># kubectl get node
NAME           STATUS     ROLES           AGE     VERSION
k8s-master01   NotReady   control-plane   4m23s   v1.32.3
k8s-master02   NotReady   control-plane   66s     v1.32.3
k8s-master03   NotReady   control-plane   14s     v1.32.3
</code></pre><h5 id="53-token过期处理"><a class="anchor" href="#53-token过期处理">#</a> 5.3 Token 过期处理</h5><p>注意：以下步骤是上述 init 命令产生的 Token 过期了才需要执行以下步骤，如果没有过期不需要执行，直接 join 即可。</p><p>Token 过期后生成新的 token：</p><pre><code>kubeadm token create --print-join-command
</code></pre><p>Master 需要生成 --certificate-key：</p><pre><code>kubeadm init phase upload-certs  --upload-certs
</code></pre><h4 id="6-node节点的配置"><a class="anchor" href="#6-node节点的配置">#</a> 6. Node 节点的配置</h4><p>Node 节点上主要部署公司的一些业务应用，生产环境中不建议 Master 节点部署系统组件之外的其他 Pod，测试环境可以允许 Master 节点部署 Pod 以节省系统资源。</p><pre><code>kubeadm join 192.168.1.70:16443 --token 7t2weq.bjbawausm0jaxury \
	--discovery-token-ca-cert-hash sha256:377702f508fe70b9d8ab68beccaa9af1b4609b754e4cc2fcc6185974e1d620b5
</code></pre><p>所有节点初始化完成后，查看集群状态（NotReady 不影响）</p><pre><code># kubectl get node
NAME           STATUS     ROLES           AGE     VERSION
k8s-master01   NotReady   control-plane   4m23s   v1.32.3
k8s-master02   NotReady   control-plane   66s     v1.32.3
k8s-master03   NotReady   control-plane   14s     v1.32.3
k8s-node01     NotReady   &lt;none&gt;          13s     v1.32.3
k8s-node02     NotReady   &lt;none&gt;          10s     v1.32.3
</code></pre><h4 id="7-calico组件的安装"><a class="anchor" href="#7-calico组件的安装">#</a> 7. Calico 组件的安装</h4><p><mark>所有节点</mark>禁止 NetworkManager 管理 Calico 的网络接口，防止有冲突或干扰：</p><pre><code>cat &gt;&gt;/etc/NetworkManager/conf.d/calico.conf&lt;&lt;EOF
[keyfile]
unmanaged-devices=interface-name:cali*;interface-name:tunl*;interface-name:vxlan.calico;interface-name:vxlan-v6.calico;interface-name:wireguard.cali;interface-name:wg-v6.cali
EOF
systemctl daemon-reload
systemctl restart NetworkManager
</code></pre><p>以下步骤只在<mark> master01</mark> 执行（.x 不需要更改）：</p><pre><code>cd /root/k8s-ha-install &amp;&amp; git checkout manual-installation-v1.32.x &amp;&amp; cd calico/
</code></pre><p>修改 Pod 网段：</p><pre><code>POD_SUBNET=`cat /etc/kubernetes/manifests/kube-controller-manager.yaml | grep cluster-cidr= | awk -F= '&#123;print $NF&#125;'`

sed -i &quot;s#POD_CIDR#$&#123;POD_SUBNET&#125;#g&quot; calico.yaml
kubectl apply -f calico.yaml
</code></pre><p>查看容器和节点状态：</p><pre><code>[root@k8s-master01 ~]# kubectl get pods -n kube-system
NAME                                       READY   STATUS    RESTARTS   AGE
calico-kube-controllers-6f497d8478-v2q8c   1/1     Running   0          24h
calico-node-7mzmb                          1/1     Running   0          24h
calico-node-ljqnl                          1/1     Running   0          24h
calico-node-njqlb                          1/1     Running   0          24h
calico-node-ph4m4                          1/1     Running   0          24h
calico-node-rx8rl                          1/1     Running   0          24h
coredns-76fccbbb6b-76559                   1/1     Running   0          24h
coredns-76fccbbb6b-hkvn7                   1/1     Running   0          24h
etcd-k8s-master01                          1/1     Running   0          24h
etcd-k8s-master02                          1/1     Running   0          24h
etcd-k8s-master03                          1/1     Running   0          24h
kube-apiserver-k8s-master01                1/1     Running   0          24h
kube-apiserver-k8s-master02                1/1     Running   0          24h
kube-apiserver-k8s-master03                1/1     Running   0          24h
kube-controller-manager-k8s-master01       1/1     Running   0          24h
kube-controller-manager-k8s-master02       1/1     Running   0          24h
kube-controller-manager-k8s-master03       1/1     Running   0          24h
kube-proxy-9dtz4                           1/1     Running   0          24h
kube-proxy-jh7rl                           1/1     Running   0          24h
kube-proxy-jvvwt                           1/1     Running   0          24h
kube-proxy-sh89l                           1/1     Running   0          24h
kube-proxy-t2j49                           1/1     Running   0          24h
kube-scheduler-k8s-master01                1/1     Running   0          24h
kube-scheduler-k8s-master02                1/1     Running   0          24h
kube-scheduler-k8s-master03                1/1     Running   0          24h
metrics-server-7d9d8df576-jgnp2            1/1     Running   0          24h
</code></pre><p>此时节点全部变为 Ready 状态：</p><pre><code>[root@k8s-master01 ~]# kubectl get nodes
NAME           STATUS   ROLES           AGE   VERSION
k8s-master01   Ready    control-plane   24h   v1.32.3
k8s-master02   Ready    control-plane   24h   v1.32.3
k8s-master03   Ready    control-plane   24h   v1.32.3
k8s-node01     Ready    &lt;none&gt;          24h   v1.32.3
k8s-node02     Ready    &lt;none&gt;          24h   v1.32.3
</code></pre><h4 id="8-metrics部署"><a class="anchor" href="#8-metrics部署">#</a> 8. Metrics 部署</h4><p>在新版的 Kubernetes 中系统资源的采集均使用 Metrics-server，可以通过 Metrics 采集节点和 Pod 的内存、磁盘、CPU 和网络的使用率。</p><p>将<mark> Master01 节点</mark>的 front-proxy-ca.crt 复制到所有 Node 节点</p><pre><code>scp /etc/kubernetes/pki/front-proxy-ca.crt k8s-node01:/etc/kubernetes/pki/front-proxy-ca.crt

scp /etc/kubernetes/pki/front-proxy-ca.crt k8s-node(其他节点自行拷贝):/etc/kubernetes/pki/front-proxy-ca.crt
</code></pre><p>以下操作均在<mark> master01 节点</mark>执行:</p><p>安装 metrics server</p><pre><code>cd /root/k8s-ha-install/kubeadm-metrics-server

# kubectl  create -f comp.yaml 
serviceaccount/metrics-server created
clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created
clusterrole.rbac.authorization.k8s.io/system:metrics-server created
rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created
clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created
clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created
service/metrics-server created
deployment.apps/metrics-server created
apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created
</code></pre><p>查看状态：</p><pre><code>[root@k8s-master01 ~]# kubectl get po -n kube-system -l k8s-app=metrics-server
NAME                              READY   STATUS    RESTARTS   AGE
metrics-server-7d9d8df576-jgnp2   1/1     Running   0          24h
</code></pre><p>等 Pod 变成 1/1 Running 后，查看节点和 Pod 资源使用率：</p><pre><code>[root@k8s-master01 ~]#  kubectl top node
NAME           CPU(cores)   CPU(%)   MEMORY(bytes)   MEMORY(%)   
k8s-master01   132m         3%       932Mi           5%          
k8s-master02   131m         3%       845Mi           5%          
k8s-master03   148m         3%       912Mi           5%          
k8s-node01     54m          1%       600Mi           3%          
k8s-node02     49m          1%       602Mi           3%          
[root@k8s-master01 ~]#  kubectl top po -A
NAMESPACE              NAME                                         CPU(cores)   MEMORY(bytes)   
ingress-nginx          ingress-nginx-controller-5v9gl               2m           98Mi            
ingress-nginx          ingress-nginx-controller-r978m               1m           104Mi           
krm                    krm-backend-d7ff675d8-vmt9z                  1m           21Mi            
krm                    krm-frontend-588ffd677b-c2pgj                1m           4Mi             
krm                    nginx-574cf48959-vcfjs                       0m           2Mi             
kube-system            calico-kube-controllers-6f497d8478-v2q8c     6m           17Mi            
kube-system            calico-node-7mzmb                            16m          176Mi           
kube-system            calico-node-ljqnl                            15m          182Mi           
kube-system            calico-node-njqlb                            19m          180Mi           
kube-system            calico-node-ph4m4                            15m          178Mi           
kube-system            calico-node-rx8rl                            17m          180Mi           
kube-system            coredns-76fccbbb6b-76559                     2m           16Mi            
kube-system            coredns-76fccbbb6b-hkvn7                     2m           16Mi            
kube-system            etcd-k8s-master01                            22m          86Mi            
kube-system            etcd-k8s-master02                            27m          84Mi            
kube-system            etcd-k8s-master03                            22m          84Mi            
kube-system            kube-apiserver-k8s-master01                  22m          267Mi           
kube-system            kube-apiserver-k8s-master02                  20m          242Mi           
kube-system            kube-apiserver-k8s-master03                  18m          241Mi           
kube-system            kube-controller-manager-k8s-master01         6m           69Mi            
kube-system            kube-controller-manager-k8s-master02         2m           21Mi            
kube-system            kube-controller-manager-k8s-master03         1m           19Mi            
kube-system            kube-proxy-9dtz4                             11m          30Mi            
kube-system            kube-proxy-jh7rl                             1m           27Mi            
kube-system            kube-proxy-jvvwt                             17m          29Mi            
kube-system            kube-proxy-sh89l                             1m           29Mi            
kube-system            kube-proxy-t2j49                             16m          29Mi            
kube-system            kube-scheduler-k8s-master01                  6m           25Mi            
kube-system            kube-scheduler-k8s-master02                  6m           25Mi            
kube-system            kube-scheduler-k8s-master03                  6m           25Mi            
kube-system            metrics-server-7d9d8df576-jgnp2              2m           26Mi            
kubernetes-dashboard   dashboard-metrics-scraper-69b4796d9b-klnwr   1m           19Mi            
kubernetes-dashboard   kubernetes-dashboard-778584b9dd-pd5ln        1m           31Mi  
</code></pre><h4 id="9-dashboard部署"><a class="anchor" href="#9-dashboard部署">#</a> 9. Dashboard 部署</h4><h5 id="91-安装dashboard"><a class="anchor" href="#91-安装dashboard">#</a> 9.1 安装 Dashboard</h5><p>Dashboard 用于展示集群中的各类资源，同时也可以通过 Dashboard 实时查看 Pod 的日志和在容器中执行一些命令等。</p><pre><code>cd /root/k8s-ha-install/dashboard/

[root@k8s-master01 dashboard]# kubectl  create -f .
serviceaccount/admin-user created
clusterrolebinding.rbac.authorization.k8s.io/admin-user created
namespace/kubernetes-dashboard created
serviceaccount/kubernetes-dashboard created
service/kubernetes-dashboard created
secret/kubernetes-dashboard-certs created
secret/kubernetes-dashboard-csrf created
secret/kubernetes-dashboard-key-holder created
configmap/kubernetes-dashboard-settings created
role.rbac.authorization.k8s.io/kubernetes-dashboard created
clusterrole.rbac.authorization.k8s.io/kubernetes-dashboard created
rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created
clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created
deployment.apps/kubernetes-dashboard created
service/dashboard-metrics-scraper created
deployment.apps/dashboard-metrics-scraper created
</code></pre><h5 id="92-登录dashboard"><a class="anchor" href="#92-登录dashboard">#</a> 9.2 登录 dashboard</h5><p>在谷歌浏览器（Chrome）启动文件中加入启动参数，用于解决无法访问 Dashboard 的问题，参考下图：</p><pre><code>--test-type --ignore-certificate-errors
</code></pre><p><a target="_blank" rel="noopener" href="https://imgse.com/i/pEgWfHJ"><img loading="lazy" data-src="https://s21.ax1x.com/2025/04/09/pEgWfHJ.png" alt="pEgWfHJ.png"></a></p><p>更改 dashboard 的 svc 为 NodePort:</p><pre><code>kubectl edit svc kubernetes-dashboard -n kubernetes-dashboard
</code></pre><p><a target="_blank" rel="noopener" href="https://imgse.com/i/pEgW5NR"><img loading="lazy" data-src="https://s21.ax1x.com/2025/04/09/pEgW5NR.png" alt="pEgW5NR.png"></a></p><p><em>将 ClusterIP 更改为 NodePort（如果已经为 NodePort 忽略此步骤）</em></p><p>查看端口号：</p><pre><code>[root@k8s-master01 ~]# kubectl get svc kubernetes-dashboard -n kubernetes-dashboard
NAME                   TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)         AGE
kubernetes-dashboard   NodePort   10.96.139.11   &lt;none&gt;        443:32409/TCP   24h
</code></pre><p>根据自己的实例端口号，通过任意安装了 kube-proxy 的宿主机的 IP + 端口即可访问到 dashboard：</p><p>访问 Dashboard：<a target="_blank" rel="noopener" href="https://192.168.181.129:31106">https://192.168.1.71:32409</a> （把 IP 地址和端口改成你自己的）选择登录方式为令牌（即 token 方式），参考下图：</p><p><a target="_blank" rel="noopener" href="https://imgse.com/i/pEgW736"><img loading="lazy" data-src="https://s21.ax1x.com/2025/04/09/pEgW736.png" alt="pEgW736.png"></a></p><p>创建登录 Token：</p><pre><code>kubectl create token admin-user -n kube-system
</code></pre><p>将 token 值输入到令牌后，单击登录即可访问 Dashboard，参考下图：</p><p><a target="_blank" rel="noopener" href="https://imgse.com/i/pEgfPv8"><img loading="lazy" data-src="https://s21.ax1x.com/2025/04/09/pEgfPv8.png" alt="pEgfPv8.png"></a></p><h4 id="10必看一些必须的配置更改"><a class="anchor" href="#10必看一些必须的配置更改">#</a> 10.【必看】一些必须的配置更改</h4><p>将 Kube-proxy 改为 ipvs 模式，因为在初始化集群的时候注释了 ipvs 配置，所以需要自行修改一下：</p><p>在 master01 节点执行：</p><pre><code>kubectl edit cm kube-proxy -n kube-system
mode: ipvs
</code></pre><p>更新 Kube-Proxy 的 Pod：</p><pre><code>kubectl patch daemonset kube-proxy -p &quot;&#123;\&quot;spec\&quot;:&#123;\&quot;template\&quot;:&#123;\&quot;metadata\&quot;:&#123;\&quot;annotations\&quot;:&#123;\&quot;date\&quot;:\&quot;`date +'%s'`\&quot;&#125;&#125;&#125;&#125;&#125;&quot; -n kube-system
</code></pre><p>验证 Kube-Proxy 模式:</p><pre><code>[root@k8s-master01]# curl 127.0.0.1:10249/proxyMode
ipvs
</code></pre><h4 id="11必看注意事项"><a class="anchor" href="#11必看注意事项">#</a> 11.【必看】注意事项</h4><p>注意：kubeadm 安装的集群，证书有效期默认是一年。master 节点的 kube-apiserver、kube-scheduler、kube-controller-manager、etcd 都是以容器运行的。可以通过 kubectl get po -n kube-system 查看。</p><p>启动和二进制不同的是，kubelet 的配置文件在 /etc/sysconfig/kubelet 和 /var/lib/kubelet/config.yaml，修改后需要重启 kubelet 进程。</p><p>其他组件的配置文件在 /etc/kubernetes/manifests 目录下，比如 kube-apiserver.yaml，该 yaml 文件更改后，kubelet 会自动刷新配置，也就是会重启 pod。不能再次创建该文件。</p><p>kube-proxy 的配置在 kube-system 命名空间下的 configmap 中，可以通过</p><pre><code>kubectl edit cm kube-proxy -n kube-system
</code></pre><p>进行更改，更改完成后，可以通过 patch 重启 kube-proxy</p><pre><code>kubectl patch daemonset kube-proxy -p &quot;&#123;\&quot;spec\&quot;:&#123;\&quot;template\&quot;:&#123;\&quot;metadata\&quot;:&#123;\&quot;annotations\&quot;:&#123;\&quot;date\&quot;:\&quot;`date +'%s'`\&quot;&#125;&#125;&#125;&#125;&#125;&quot; -n kube-system
</code></pre><p>Kubeadm 安装后，master 节点默认不允许部署 pod，可以通过以下方式删除 Taint，即可部署 Pod：</p><pre><code>[root@k8s-master01 ~]# kubectl  taint node  -l node-role.kubernetes.io/control-plane node-role.kubernetes.io/control-plane:NoSchedule-
</code></pre><h4 id="12-containerd配置镜像加速"><a class="anchor" href="#12-containerd配置镜像加速">#</a> 12. Containerd 配置镜像加速</h4><pre><code># vim /etc/containerd/config.toml
#添加以下配置镜像加速服务
       [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.mirrors.&quot;docker.io&quot;]
        endpoint=[&quot;https://dockerproxy.com&quot;, &quot;https://mirror.baidubce.com&quot;,&quot;https://ccr.ccs.tencentyun.com&quot;,&quot;https://docker.m.daocloud.io&quot;,&quot;https://docker.nju.edu.cn&quot;,&quot;https://docker.mirrors.ustc.edu.cn&quot;,&quot;https://registry-1.docker.io&quot;, &quot;https://hbv0b596.mirror.aliyuncs.com&quot;]
       [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.mirrors.&quot;registry.k8s.io&quot;]
        endpoint=[&quot;https://dockerproxy.com&quot;, &quot;https://mirror.baidubce.com&quot;,&quot;https://ccr.ccs.tencentyun.com&quot;,&quot;https://docker.m.daocloud.io&quot;,&quot;https://docker.nju.edu.cn&quot;,&quot;https://docker.mirrors.ustc.edu.cn&quot;,&quot;https://hbv0b596.mirror.aliyuncs.com&quot;, &quot;https://k8s.m.daocloud.io&quot;, &quot;https://docker.mirrors.ustc.edu.cn&quot;,&quot;https://hub-mirror.c.163.com&quot;]
</code></pre><p>所有节点重新启动 Containerd：</p><pre><code># systemctl daemon-reload
# systemctl restart containerd
</code></pre><h4 id="13-docker配置镜像加速"><a class="anchor" href="#13-docker配置镜像加速">#</a> 13. Docker 配置镜像加速</h4><pre><code># sudo mkdir -p /etc/docker
# sudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'
&#123;
  &quot;registry-mirrors&quot;: [
	  &quot;https://docker.credclouds.com&quot;,
	  &quot;https://k8s.credclouds.com&quot;,
	  &quot;https://quay.credclouds.com&quot;,
	  &quot;https://gcr.credclouds.com&quot;,
	  &quot;https://k8s-gcr.credclouds.com&quot;,
	  &quot;https://ghcr.credclouds.com&quot;,
	  &quot;https://do.nark.eu.org&quot;,
	  &quot;https://docker.m.daocloud.io&quot;,
	  &quot;https://docker.nju.edu.cn&quot;,
	  &quot;https://docker.mirrors.sjtug.sjtu.edu.cn&quot;,
	  &quot;https://docker.1panel.live&quot;,
	  &quot;https://docker.rainbond.cc&quot;
  ], 
  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;] 
&#125;
EOF
</code></pre><p>所有节点重新启动 Docker：</p><pre><code># systemctl daemon-reload
# systemctl enable --now docker
</code></pre><p><em>本文出自于：<a target="_blank" rel="noopener" href="https://edu.51cto.com/course/23845.html">https://edu.51cto.com/course/23845.html</a></em></p><div class="tags"><a href="/tags/Kubernetes/" rel="tag"><i class="ic i-tag"></i>Kubernetes</a></div></div><footer><div class="meta"><span class="icon"><i class="ic i-eye"></i></span><span>此文章已被阅读次数:</span><span class="waline-pageview-count" id="twikoo_visitors" data-path="/posts/3166738000.html">正在加载...</span><span class="item"><span class="icon"><i class="ic i-calendar-check"></i></span><span class="text">更新于</span><time title="修改时间：2025-04-09 21:40:46" itemprop="dateModified" datetime="2025-04-09T21:40:46+08:00">2025-04-09</time></span></div><div class="reward"><button><i class="ic i-heartbeat"></i>赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img loading="lazy" data-src="/assets/wechatpay.png" alt="Xu Yong 微信支付"><p>微信支付</p></div><div><img loading="lazy" data-src="/assets/alipay.png" alt="Xu Yong 支付宝"><p>支付宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者：</strong>Xu Yong<i class="ic i-at"><em>@</em></i>LinuxSre云原生</li><li class="link"><strong>本文链接：</strong><a href="http://xuyong.cn/posts/3166738000.html" title="Kubeadm高可用安装K8s集群">http://xuyong.cn/posts/3166738000.html</a></li><li class="license"><strong>版权声明：</strong>本站所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/posts/1922841233.html" rel="prev" itemprop="url" data-background-image="https:&#x2F;&#x2F;s21.ax1x.com&#x2F;2025&#x2F;04&#x2F;09&#x2F;pEgIIlq.jpg" title="Rsync服务实践"><span class="type">上一篇</span><span class="category"><i class="ic i-flag"></i>Linux</span><h3>Rsync服务实践</h3></a></div><div class="item right"><a href="/posts/1414180692.html" rel="next" itemprop="url" data-background-image="https:&#x2F;&#x2F;s21.ax1x.com&#x2F;2025&#x2F;04&#x2F;09&#x2F;pEgTYIe.jpg" title="Redis集群（主从+哨兵）模式"><span class="type">下一篇</span><span class="category"><i class="ic i-flag"></i>Redis</span><h3>Redis集群（主从+哨兵）模式</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#kubeadm%E9%AB%98%E5%8F%AF%E7%94%A8%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4"><span class="toc-number">1.</span> <span class="toc-text">Kubeadm 高可用安装 K8s 集群</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE"><span class="toc-number">1.0.1.</span> <span class="toc-text">1. 基本配置</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#11-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE"><span class="toc-number">1.0.1.1.</span> <span class="toc-text">1.1 基本环境配置</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#12-%E5%86%85%E6%A0%B8%E9%85%8D%E7%BD%AE"><span class="toc-number">1.0.1.2.</span> <span class="toc-text">1.2 内核配置</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E9%AB%98%E5%8F%AF%E7%94%A8%E7%BB%84%E4%BB%B6%E5%AE%89%E8%A3%85"><span class="toc-number">1.0.2.</span> <span class="toc-text">2. 高可用组件安装</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-runtime%E5%AE%89%E8%A3%85"><span class="toc-number">1.0.3.</span> <span class="toc-text">3. Runtime 安装</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#31-%E5%AE%89%E8%A3%85containerd"><span class="toc-number">1.0.3.1.</span> <span class="toc-text">3.1 安装 Containerd</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-%E5%AE%89%E8%A3%85kubernetes%E7%BB%84%E4%BB%B6"><span class="toc-number">1.0.4.</span> <span class="toc-text">4 . 安装 Kubernetes 组件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-%E9%9B%86%E7%BE%A4%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-number">1.0.5.</span> <span class="toc-text">5 . 集群初始化</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#51-%E5%88%9D%E5%A7%8B%E5%8C%96%E5%A4%B1%E8%B4%A5%E6%8E%92%E6%9F%A5"><span class="toc-number">1.0.5.1.</span> <span class="toc-text">5.1 初始化失败排查</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#52-%E9%AB%98%E5%8F%AF%E7%94%A8master"><span class="toc-number">1.0.5.2.</span> <span class="toc-text">5.2 高可用 Master</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#53-token%E8%BF%87%E6%9C%9F%E5%A4%84%E7%90%86"><span class="toc-number">1.0.5.3.</span> <span class="toc-text">5.3 Token 过期处理</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-node%E8%8A%82%E7%82%B9%E7%9A%84%E9%85%8D%E7%BD%AE"><span class="toc-number">1.0.6.</span> <span class="toc-text">6. Node 节点的配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-calico%E7%BB%84%E4%BB%B6%E7%9A%84%E5%AE%89%E8%A3%85"><span class="toc-number">1.0.7.</span> <span class="toc-text">7. Calico 组件的安装</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-metrics%E9%83%A8%E7%BD%B2"><span class="toc-number">1.0.8.</span> <span class="toc-text">8. Metrics 部署</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-dashboard%E9%83%A8%E7%BD%B2"><span class="toc-number">1.0.9.</span> <span class="toc-text">9. Dashboard 部署</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#91-%E5%AE%89%E8%A3%85dashboard"><span class="toc-number">1.0.9.1.</span> <span class="toc-text">9.1 安装 Dashboard</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#92-%E7%99%BB%E5%BD%95dashboard"><span class="toc-number">1.0.9.2.</span> <span class="toc-text">9.2 登录 dashboard</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#10%E5%BF%85%E7%9C%8B%E4%B8%80%E4%BA%9B%E5%BF%85%E9%A1%BB%E7%9A%84%E9%85%8D%E7%BD%AE%E6%9B%B4%E6%94%B9"><span class="toc-number">1.0.10.</span> <span class="toc-text">10.【必看】一些必须的配置更改</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#11%E5%BF%85%E7%9C%8B%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"><span class="toc-number">1.0.11.</span> <span class="toc-text">11.【必看】注意事项</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#12-containerd%E9%85%8D%E7%BD%AE%E9%95%9C%E5%83%8F%E5%8A%A0%E9%80%9F"><span class="toc-number">1.0.12.</span> <span class="toc-text">12. Containerd 配置镜像加速</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#13-docker%E9%85%8D%E7%BD%AE%E9%95%9C%E5%83%8F%E5%8A%A0%E9%80%9F"><span class="toc-number">1.0.13.</span> <span class="toc-text">13. Docker 配置镜像加速</span></a></li></ol></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li class="active"><a href="/posts/3166738000.html" rel="bookmark" title="Kubeadm高可用安装K8s集群">Kubeadm高可用安装K8s集群</a></li><li><a href="/posts/2771271649.html" rel="bookmark" title="云原生K8s安全专家CKS认证考题详解">云原生K8s安全专家CKS认证考题详解</a></li><li><a href="/posts/985149017.html" rel="bookmark" title="二进制高可用安装K8S集群">二进制高可用安装K8S集群</a></li><li><a href="/posts/1771242682.html" rel="bookmark" title="K8s零宕机服务发布-探针">K8s零宕机服务发布-探针</a></li><li><a href="/posts/108692210.html" rel="bookmark" title="K8s资源调度deployment、statefulset、daemonset">K8s资源调度deployment、statefulset、daemonset</a></li><li><a href="/posts/858611107.html" rel="bookmark" title="K8s服务发布Service">K8s服务发布Service</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" loading="lazy" decoding="async" itemprop="image" alt="Xu Yong" src="/assets/avatar.png"><p class="name" itemprop="name">Xu Yong</p><div class="description" itemprop="description">专注于 Linux 运维、云计算、云原⽣等技术</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">11</span><span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">6</span><span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">6</span><span class="name">标签</span></a></div></nav><div class="social"><a target="_blank" rel="noopener" href="https://github.com/xyapples" class="item github" title="https:&#x2F;&#x2F;github.com&#x2F;xyapples"><i class="ic i-github"></i></a><a target="_blank" rel="noopener" href="https://gitee.com/chinagei" class="item gitee" title="https:&#x2F;&#x2F;gitee.com&#x2F;chinagei"><i class="ic i-gitee"></i></a><a href="mailto:373370405@qq.com" class="item email" title="mailto:373370405@qq.com"><i class="ic i-envelope"></i></a></div><div class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-about"></i>关于</a></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>友链</a></li></div></div></div></div><ul id="quick"><li class="prev pjax"><a href="/posts/1414180692.html" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/posts/1922841233.html" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/MySQL/" title="分类于MySQL">MySQL</a></div><span><a href="/posts/2628187572.html">MySQL运维DBA应用与实践</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Windows/" title="分类于Windows">Windows</a></div><span><a href="/posts/3071070979.html">一键永久激活Window、office教程</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Kubernetes/" title="分类于Kubernetes">Kubernetes</a></div><span><a href="/posts/108692210.html">K8s资源调度deployment、statefulset、daemonset</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Linux/" title="分类于Linux">Linux</a></div><span><a href="/posts/1922841233.html">Rsync服务实践</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Kubernetes/" title="分类于Kubernetes">Kubernetes</a></div><span><a href="/posts/3166738000.html">Kubeadm高可用安装K8s集群</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Kubernetes/" title="分类于Kubernetes">Kubernetes</a></div><span><a href="/posts/858611107.html">K8s服务发布Service</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Kubernetes/" title="分类于Kubernetes">Kubernetes</a></div><span><a href="/posts/2771271649.html">云原生K8s安全专家CKS认证考题详解</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Redis/" title="分类于Redis">Redis</a></div><span><a href="/posts/1414180692.html">Redis集群（主从+哨兵）模式</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Harbor/" title="分类于Harbor">Harbor</a></div><span><a href="/posts/3071070978.html">企业级私有仓库Harbor搭建</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Kubernetes/" title="分类于Kubernetes">Kubernetes</a></div><span><a href="/posts/1771242682.html">K8s零宕机服务发布-探针</a></span></li></ul></div><div class="rpost pjax"><h2>最新评论</h2><ul class="leancloud-recent-comment" id="new-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2022 -<span itemprop="copyrightYear">2025</span><span class="with-love"><i class="ic i-sakura rotate"></i></span><span class="author" itemprop="copyrightHolder">Xu Yong @ LinuxSre云原生</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i></span><span title="站点总字数">226k 字</span><span class="post-meta-divider"> | </span><span class="post-meta-item-icon"><i class="ic i-coffee"></i></span><span title="站点阅读时长">3:26</span></div><div class="powered-by">基于 <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a> & Theme.<a target="_blank" rel="noopener" href="https://github.com/theme-shoka-x/hexo-theme-shokaX/">ShokaX</a></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL = {
    ispost: true,
        path: `posts/3166738000.html`,
        favicon: {
        show: `（●´3｀●）やれやれだぜ`,
        hide: `(´Д｀)大変だ！`
    },
    search: {
        placeholder: "文章搜索",
        empty: "关于 「 ${query} 」，什么也没搜到",
        stats: "${time} ms 内找到 ${hits} 条结果"
    },
    copy_tex: false,
    katex: false,
    mermaid: false,
    audio: undefined,
    fancybox: true,
    nocopy: false,
    outime: true,
    template: `<div class="note warning"><p><span class="label warning">文章时效性提示</span><br>这是一篇发布于 {{publish}} 天前，最后一次更新在 {{updated}} 天前的文章，部分信息可能已经发生改变，请注意甄别。</p></div>`,
    quiz: {
        choice: `单选题`,
        multiple: `多选题`,
        true_false: `判断题`,
        essay: `问答题`,
        gap_fill: `填空题`,
        mistake: `错题备注`
    },
    ignores: [
        (uri) => uri.includes('#'),
        (uri) => new RegExp(LOCAL.path + '$').test(uri),
            []
    ]
};</script><script src="https://s4.zstatic.net/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha384-k6YtvFUEIuEFBdrLKJ3YAUbBki333tj1CSUisai5Cswsg9wcLNaPzsTHDswp4Az8" crossorigin="anonymous" fetchpriority="high"></script><script src="https://s4.zstatic.net/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha384-ZvpUoO&#x2F;+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn&#x2F;6Z&#x2F;hRTt8+pR6L4N2" crossorigin="anonymous" fetchpriority="high"></script><script src="/js/siteInit.js?v=0.4.17" type="module" fetchpriority="high" defer></script></body></html><!-- rebuild by hrmmi -->