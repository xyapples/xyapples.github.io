<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>http://ixuyong.cn</id>
    <title>LinuxSreäº‘åŸç”Ÿ</title>
    <link href="http://ixuyong.cn" />
    <updated>2025-05-14T12:29:07.000Z</updated>
    <category term="Docker" />
    <category term="Harbor" />
    <category term="Kubernetes" />
    <category term="Redis" />
    <category term="rsync" />
    <category term="MySQL" />
    <category term="Windows" />
    <entry>
        <id>http://ixuyong.cn/posts/1888662579.html</id>
        <title>Containerdå¸¸ç”¨å‘½ä»¤</title>
        <link rel="alternate" href="http://ixuyong.cn/posts/1888662579.html"/>
        <content type="html">&lt;h3 id=&#34;containerdå¸¸ç”¨å‘½ä»¤&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#containerdå¸¸ç”¨å‘½ä»¤&#34;&gt;#&lt;/a&gt; Containerd å¸¸ç”¨å‘½ä»¤&lt;/h3&gt;
&lt;h4 id=&#34;å®‰è£…containerd&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#å®‰è£…containerd&#34;&gt;#&lt;/a&gt; å®‰è£… Containerd&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;é…ç½®å®‰è£…æº&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yum install wget jq psmisc vim net-tools telnet yum-utils device-mapper-persistent-data lvm2 git -y
yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;å®‰è£… docker-ceã€containerd&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yum install docker-ce containerd -y
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;å¯ä»¥æ— éœ€å¯åŠ¨ Dockerï¼Œåªéœ€è¦é…ç½®å’Œå¯åŠ¨ Containerd å³å¯ã€‚&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;é…ç½® Containerd æ‰€éœ€çš„æ¨¡å—&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cat &amp;lt;&amp;lt;EOF | sudo tee /etc/modules-load.d/containerd.conf
overlay
br_netfilter
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;åŠ è½½æ¨¡å—&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cat &amp;lt;&amp;lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
net.bridge.bridge-nf-call-iptables  = 1
net.ipv4.ip_forward                 = 1
net.bridge.bridge-nf-call-ip6tables = 1
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;é…ç½® Containerd æ‰€éœ€çš„å†…æ ¸&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cat &amp;lt;&amp;lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
net.bridge.bridge-nf-call-iptables  = 1
net.ipv4.ip_forward                 = 1
net.bridge.bridge-nf-call-ip6tables = 1
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;åŠ è½½å†…æ ¸&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sysctl --system
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;ç”Ÿæˆ Containerd çš„é…ç½®æ–‡ä»¶&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mkdir -p /etc/containerd
containerd config default | tee /etc/containerd/config.toml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;æ›´æ”¹ Containerd çš„ Cgroup å’Œ Pause é•œåƒ&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sed -i &#39;s#SystemdCgroup = false#SystemdCgroup = true#g&#39; /etc/containerd/config.toml
sed -i &#39;s#k8s.gcr.io/pause#registry.cn-hangzhou.aliyuncs.com/google_containers/pause#g&#39;  /etc/containerd/config.toml
sed -i &#39;s#registry.gcr.io/pause#registry.cn-hangzhou.aliyuncs.com/google_containers/pause#g&#39;  /etc/containerd/config.toml
sed -i &#39;s#registry.k8s.io/pause#registry.cn-hangzhou.aliyuncs.com/google_containers/pause#g&#39;  /etc/containerd/config.toml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;å¯åŠ¨ Containerdï¼Œå¹¶é…ç½®å¼€æœºè‡ªå¯åŠ¨&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;systemctl daemon-reload
systemctl enable --now containerd
systemctl status  containerd 
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;containerd-é…ç½®é•œåƒåŠ é€Ÿ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#containerd-é…ç½®é•œåƒåŠ é€Ÿ&#34;&gt;#&lt;/a&gt; Containerd é…ç½®é•œåƒåŠ é€Ÿ&lt;/h4&gt;
&lt;p&gt;æ‰“å¼€ /etc/containerd/config.toml æ–‡ä»¶ï¼Œæ‰¾åˆ° [plugins.&amp;quot;io.containerd.grpc.v1.cri&amp;quot;.registry.mirrors] éƒ¨åˆ†ï¼Œæ·»åŠ æ‰€éœ€çš„é•œåƒæºé…ç½®&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# vim /etc/containerd/config.toml
#æ·»åŠ ä»¥ä¸‹é…ç½®é•œåƒåŠ é€ŸæœåŠ¡
[plugins.&amp;quot;io.containerd.grpc.v1.cri&amp;quot;.registry.mirrors]
  [plugins.&amp;quot;io.containerd.grpc.v1.cri&amp;quot;.registry.mirrors.&amp;quot;docker.io&amp;quot;]
    endpoint = [
      &amp;quot;https://docker.io&amp;quot;,
      &amp;quot;https://6qxc6b6n.mirror.aliyuncs.com&amp;quot;,
      &amp;quot;https://docker.m.daocloud.io&amp;quot;,
      &amp;quot;https://dockerproxy.com/&amp;quot;
    ]
  [plugins.&amp;quot;io.containerd.grpc.v1.cri&amp;quot;.registry.mirrors.&amp;quot;gcr.io&amp;quot;]
    endpoint = [
      &amp;quot;https://gcr.m.daocloud.io&amp;quot;,
      &amp;quot;https://gcr.nju.edu.cn&amp;quot;,
      &amp;quot;https://gcr.dockerproxy.com&amp;quot;
    ]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;é‡æ–°å¯åŠ¨ Containerd&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;systemctl daemon-reload
systemctl restart containerd
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;containerdå¸¸ç”¨æ“ä½œå‘½ä»¤å®è·µ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#containerdå¸¸ç”¨æ“ä½œå‘½ä»¤å®è·µ&#34;&gt;#&lt;/a&gt; Containerd å¸¸ç”¨æ“ä½œå‘½ä»¤å®è·µ&lt;/h4&gt;
&lt;h5 id=&#34;æŸ¥çœ‹containerdå‘½åç©ºé—´&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#æŸ¥çœ‹containerdå‘½åç©ºé—´&#34;&gt;#&lt;/a&gt; &lt;strong&gt;æŸ¥çœ‹ Containerd å‘½åç©ºé—´&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;namespace æ¥äºæŒ‡å®šç±»ä¼¼äºå·¥ä½œç©ºé—´çš„éš”ç¦»åŒºåŸŸ&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-node02 ~]# ctr namespace ls 
NAME    LABELS 
default        
k8s.io         
moby 
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;æŸ¥çœ‹containerdé•œåƒ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#æŸ¥çœ‹containerdé•œåƒ&#34;&gt;#&lt;/a&gt; &lt;strong&gt;æŸ¥çœ‹ Containerd é•œåƒ&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;å› ä¸ºæ²¡æœ‰æŒ‡å®š namespaceï¼Œæ‰€ä»¥æŸ¥çœ‹çš„æ˜¯é»˜è®¤å‘½åç©ºé—´ä¸‹çš„é•œåƒ&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ctr images ls
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æŸ¥çœ‹æŒ‡å®šå‘½åç©ºé—´ k8s.io ä¸‹çš„é•œåƒ&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ctr -n k8s.io images ls
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;æ‹‰å–containerdé•œåƒ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#æ‹‰å–containerdé•œåƒ&#34;&gt;#&lt;/a&gt; &lt;strong&gt;æ‹‰å– Containerd é•œåƒ&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;æ‹‰å–æŒ‡å®šå‘½åç©ºé—´ k8s.io é•œåƒ pause-amd64:3.2&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; ctr -n k8s.io images pull registry.aliyuncs.com/google_containers/pause-amd64:3.2
 ctr -n k8s.io images pull docker.io/library/nginx:1.21
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;åˆ é™¤containerdé•œåƒ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#åˆ é™¤containerdé•œåƒ&#34;&gt;#&lt;/a&gt; &lt;strong&gt;åˆ é™¤ containerd é•œåƒ&lt;/strong&gt;&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;ctr -n k8s.io images rm registry.aliyuncs.com/google_containers/pause-amd64:3.2
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;å¯¼å‡ºcontainerdé•œåƒ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#å¯¼å‡ºcontainerdé•œåƒ&#34;&gt;#&lt;/a&gt; &lt;strong&gt;å¯¼å‡º Containerd é•œåƒ&lt;/strong&gt;&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;ctr -n k8s.io images export pause.tar.gz registry.aliyuncs.com/google_containers/pause-amd64:3.2
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;å¯¼å…¥containerdé•œåƒ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#å¯¼å…¥containerdé•œåƒ&#34;&gt;#&lt;/a&gt; &lt;strong&gt;å¯¼å…¥ Containerd é•œåƒ&lt;/strong&gt;&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;ctr -n k8s.io image import pause.tar.gz
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;docker save -o å‘½ä»¤å¯¼å‡ºæ¥çš„é•œåƒå¯ä»¥ç”¨ ctr images import å¯¼å‡ºï¼ŒåŒç† ctr images export å¯¼å‡ºæ¥çš„é•œåƒä¹Ÿå¯ä»¥æœ‰ docker load è¿˜åŸã€‚&lt;/em&gt;&lt;/p&gt;
&lt;h5 id=&#34;æ ‡è®°containerdé•œåƒ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#æ ‡è®°containerdé•œåƒ&#34;&gt;#&lt;/a&gt; &lt;strong&gt;æ ‡è®° Containerd é•œåƒ&lt;/strong&gt;&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;ctr -n k8s.io images tag registry.aliyuncs.com/google_containers/pause-amd64:3.2 pause:3.2
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;è¿è¡Œcontainerdå®¹å™¨&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#è¿è¡Œcontainerdå®¹å™¨&#34;&gt;#&lt;/a&gt; ** è¿è¡Œ Containerd å®¹å™¨ **&lt;/h5&gt;
&lt;p&gt;åœ¨åå°è¿è¡Œä¸€ä¸ª centos é•œåƒçš„å®¹å™¨ï¼Œåç§°å«åš centos_k8s&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; ctr -n k8s.io  run -d  docker.io/library/nginx:1.21 web
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;æŸ¥çœ‹è¿è¡Œå®¹å™¨çš„task&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#æŸ¥çœ‹è¿è¡Œå®¹å™¨çš„task&#34;&gt;#&lt;/a&gt; &lt;strong&gt;æŸ¥çœ‹è¿è¡Œå®¹å™¨çš„ task&lt;/strong&gt;&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;ctr -n k8s.io task ls
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;å¯åŠ¨æŒ‡å®šå®¹å™¨task&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#å¯åŠ¨æŒ‡å®šå®¹å™¨task&#34;&gt;#&lt;/a&gt; å¯åŠ¨æŒ‡å®šå®¹å™¨ task&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;ctr -n k8s.io task start -d centos_k8s
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;è¿›å…¥æŒ‡å®šå®¹å™¨task&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#è¿›å…¥æŒ‡å®šå®¹å™¨task&#34;&gt;#&lt;/a&gt; è¿›å…¥æŒ‡å®šå®¹å™¨ task&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;ctr -n k8s.io task exec --exec-id 3118 -t web /bin/bash
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;åˆ é™¤æŒ‡å®šå®¹å™¨task&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#åˆ é™¤æŒ‡å®šå®¹å™¨task&#34;&gt;#&lt;/a&gt; åˆ é™¤æŒ‡å®šå®¹å™¨ task&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;ctr -n k8s.io task rm -f web
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;åœæ­¢æŒ‡å®šå®¹å™¨task&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#åœæ­¢æŒ‡å®šå®¹å™¨task&#34;&gt;#&lt;/a&gt; åœæ­¢æŒ‡å®šå®¹å™¨ task&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;ctr -n k8s.io task kill --signal 9 centos_k8s
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;314-æŸ¥çœ‹å®¹å™¨&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#314-æŸ¥çœ‹å®¹å™¨&#34;&gt;#&lt;/a&gt; 3.14 æŸ¥çœ‹å®¹å™¨&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;ctr -n k8s.io c list
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;åˆ é™¤å®¹å™¨&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#åˆ é™¤å®¹å™¨&#34;&gt;#&lt;/a&gt; åˆ é™¤å®¹å™¨&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;ctr -n k8s.io c rm centos
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;åˆ é™¤å®¹å™¨ä»¥å‰éœ€è¦å°† task åˆ é™¤ï¼Œä¸ç„¶ä¼šæŠ¥ä»¥ä¸‹é”™è¯¯&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-node02 ~]# ctr -n k8s.io c rm web 
ERRO[0000] failed to delete container &amp;quot;web&amp;quot;              error=&amp;quot;cannot delete a non stopped container: &amp;#123;running 0 0001-01-01 00:00:00 +0000 UTC&amp;#125;&amp;quot;
ctr: cannot delete a non stopped container: &amp;#123;running 0 0001-01-01 00:00:00 +0000 UTC&amp;#125;
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;dockerä¸containerdå¸¸ç”¨å‘½ä»¤å¯¹æ¯”&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#dockerä¸containerdå¸¸ç”¨å‘½ä»¤å¯¹æ¯”&#34;&gt;#&lt;/a&gt; Docker ä¸ Containerd å¸¸ç”¨å‘½ä»¤å¯¹æ¯”&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;è¯´æ˜&lt;/th&gt;
&lt;th&gt;docker å‘½ä»¤&lt;/th&gt;
&lt;th&gt;containerd å‘½ä»¤&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;æŸ¥çœ‹æœ¬åœ°é•œåƒ&lt;/td&gt;
&lt;td&gt;docker images&lt;/td&gt;
&lt;td&gt;ctr images ls&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æ‹‰å–é•œåƒ&lt;/td&gt;
&lt;td&gt;docker pull imagename&lt;/td&gt;
&lt;td&gt;ctr images pull imagename&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æ¨é€é•œåƒ&lt;/td&gt;
&lt;td&gt;docker push imagename&lt;/td&gt;
&lt;td&gt;ctr images push imagename&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ç»™é•œåƒæ‰“æ ‡ç­¾&lt;/td&gt;
&lt;td&gt;docker tag imagename tagname&lt;/td&gt;
&lt;td&gt;ctr images tag imagename tagname&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;å¯¼å‡ºé•œåƒ&lt;/td&gt;
&lt;td&gt;docker save filename imagename&lt;/td&gt;
&lt;td&gt;ctr images export filename imagename&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;å¯¼å…¥é•œåƒ&lt;/td&gt;
&lt;td&gt;docker load filename&lt;/td&gt;
&lt;td&gt;ctr image import filename&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;è¿è¡Œå¹¶åˆ›å»ºå®¹å™¨&lt;/td&gt;
&lt;td&gt;docker run [options] imagename commond&lt;/td&gt;
&lt;td&gt;ctr run [options]  imagenamecontainername&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;è¿›å…¥å®¹å™¨&lt;/td&gt;
&lt;td&gt;docker exec [options] names commond&lt;/td&gt;
&lt;td&gt;ctr task exec [options]  names commond&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;æŸ¥çœ‹è¿è¡Œçš„å®¹å™¨&lt;/td&gt;
&lt;td&gt;docker ps&lt;/td&gt;
&lt;td&gt;ctr task list&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;åˆ é™¤å®¹å™¨&lt;/td&gt;
&lt;td&gt;docker rm [options] names&lt;/td&gt;
&lt;td&gt;1.ctr task rm -f names 2. ctr c rm -f names&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</content>
        <category term="Docker" />
        <updated>2025-05-14T12:29:07.000Z</updated>
    </entry>
    <entry>
        <id>http://ixuyong.cn/posts/1490514396.html</id>
        <title>Redis Clusteré›†ç¾¤éƒ¨ç½²</title>
        <link rel="alternate" href="http://ixuyong.cn/posts/1490514396.html"/>
        <content type="html">&lt;h3 id=&#34;redis-clusteré›†ç¾¤éƒ¨ç½²&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#redis-clusteré›†ç¾¤éƒ¨ç½²&#34;&gt;#&lt;/a&gt; Redis Cluster é›†ç¾¤éƒ¨ç½²&lt;/h3&gt;
&lt;h4 id=&#34;1-ç¯å¢ƒé…ç½®&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-ç¯å¢ƒé…ç½®&#34;&gt;#&lt;/a&gt; 1ã€ç¯å¢ƒé…ç½®&lt;/h4&gt;
&lt;h5 id=&#34;11-å…³é—­é˜²ç«å¢™-selinux&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#11-å…³é—­é˜²ç«å¢™-selinux&#34;&gt;#&lt;/a&gt; 1.1 å…³é—­é˜²ç«å¢™ã€Selinux&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;systemctl disable --now firewalld 
setenforce 0
sed -i &#39;s#SELINUX=enforcing#SELINUX=disabled#g&#39; /etc/sysconfig/selinux
sed -i &#39;s#SELINUX=enforcing#SELINUX=disabled#g&#39; /etc/selinux/config
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;11-é…ç½®yumæº&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#11-é…ç½®yumæº&#34;&gt;#&lt;/a&gt; 1.1 é…ç½® yum æº&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;#rocky linuxé…ç½®
sed -e &#39;s|^mirrorlist=|#mirrorlist=|g&#39; \
    -e &#39;s|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g&#39; \
    -i.bak \
    /etc/yum.repos.d/rocky-*.repo
yum clean all &amp;amp;&amp;amp; yum makecache
mkdir /soft /data /scripts /backup
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;13-é…ç½®æ–‡ä»¶æè¿°ç¬¦&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#13-é…ç½®æ–‡ä»¶æè¿°ç¬¦&#34;&gt;#&lt;/a&gt; 1.3 é…ç½®æ–‡ä»¶æè¿°ç¬¦&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;ulimit -SHn 65535
vim /etc/security/limits.conf
# æœ«å°¾æ·»åŠ å¦‚ä¸‹å†…å®¹
* soft nofile 65536
* hard nofile 131072
* soft nproc 65535
* hard nproc 655350
* soft memlock unlimited
* hard memlock unlimited
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;14-ç³»ç»Ÿå†…æ ¸å‚æ•°è°ƒä¼˜&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#14-ç³»ç»Ÿå†…æ ¸å‚æ•°è°ƒä¼˜&#34;&gt;#&lt;/a&gt; 1.4 ç³»ç»Ÿå†…æ ¸å‚æ•°è°ƒä¼˜&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;# ä¿®æ”¹/etc/sysctl.confæ–‡ä»¶
catÂ &amp;gt;&amp;gt; /etc/sysctl.conf &amp;lt;&amp;lt;EOF
vm.max_map_count =Â 262144
vm.swappiness=1

net.ipv4.tcp_fin_timeout=2
net.ipv4.tcp_tw_reuse=1
#net.ipv4.tcp_tw_recycle=1
net.ipv4.tcp_syncookies=1
net.ipv4.tcp_keepalive_time=600
net.ipv4.ip_local_port_range=4000Â 65000
net.ipv4.tcp_max_syn_backlog=16384
net.ipv4.route.gc_timeout=100
net.ipv4.tcp_max_tw_buckets=Â 5000

net.ipv4.tcp_syn_retries=1
net.ipv4.tcp_synack_retries=1
net.core.somaxconn=16384
net.core.netdev_max_backlog=16384
net.ipv4.tcp_max_orphans=16384

# è®¾ç½®æœ€å¤§å†…å­˜å…±äº«æ®µå¤§å°bytes
kernel.shmmax=15461882265
kernel.shmall=3774873
# ä¿®æ”¹æ¶ˆæ¯é˜Ÿåˆ—é•¿åº¦
kernel.msgmax=65535
kernel.msgmnb=65535
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;15-ä¿®æ”¹é»˜è®¤é™åˆ¶å†…å­˜&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#15-ä¿®æ”¹é»˜è®¤é™åˆ¶å†…å­˜&#34;&gt;#&lt;/a&gt; 1.5 ä¿®æ”¹é»˜è®¤é™åˆ¶å†…å­˜&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;gt;&amp;gt;/etc/systemd/system.conf&amp;lt;&amp;lt; EOF
DefaultLimitNOFILE=65536
DefaultLimitNPROC=32000
DefaultLimitMEMLOCK=infinity
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;16-æ‰§è¡Œå‘½ä»¤ç”Ÿæ•ˆçŠ¶æ€&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#16-æ‰§è¡Œå‘½ä»¤ç”Ÿæ•ˆçŠ¶æ€&#34;&gt;#&lt;/a&gt; 1.6 æ‰§è¡Œå‘½ä»¤ç”Ÿæ•ˆçŠ¶æ€&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;sysctl -p
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;17-å®‰è£…åŸºç¡€è½¯ä»¶åŒ…&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#17-å®‰è£…åŸºç¡€è½¯ä»¶åŒ…&#34;&gt;#&lt;/a&gt; 1.7 å®‰è£…åŸºç¡€è½¯ä»¶åŒ…&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;yum install wget jq psmisc vim unzip net-tools telnet tree yum-utils device-mapper-persistent-data \
lvm2 git ntpdate nfs-utils iotop httpd-tools dos2unix lrzsz -y
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;18-å‡çº§ç³»ç»Ÿ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#18-å‡çº§ç³»ç»Ÿ&#34;&gt;#&lt;/a&gt; 1.8 å‡çº§ç³»ç»Ÿ&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;yum update -y --exclude=kernel* &amp;amp;&amp;amp; reboot
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2-redis-clusteréƒ¨ç½²&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-redis-clusteréƒ¨ç½²&#34;&gt;#&lt;/a&gt; 2ã€Redis cluster éƒ¨ç½²&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;192.168.1.135&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;192.168.1.136&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;192.168.1.137&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;node1ï¼š7001&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;node1ï¼š7001&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;node1ï¼š7001&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;node2ï¼š7002&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;node2ï¼š7002&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;node2ï¼š7002&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;node3ï¼š7003&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;node3ï¼š7003&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;node3ï¼š7003&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h5 id=&#34;21-å®‰è£…åŒ…ä¸‹è½½&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#21-å®‰è£…åŒ…ä¸‹è½½&#34;&gt;#&lt;/a&gt; 2.1 å®‰è£…åŒ…ä¸‹è½½&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;wget https://download.redis.io/releases/redis-7.2.1.tar.gz
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;22-å®‰è£…-redis&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#22-å®‰è£…-redis&#34;&gt;#&lt;/a&gt; 2.2 å®‰è£… redis&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;yum install gcc-c++ -y
mkdirÂ /soft
tar -xzvf redis-7.2.1.tar.gz -C /soft
ln -s /soft/redis-7.2.1 /soft/redis
cd /soft/redis
make
make install prefix=/soft/redis
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;23-ç”Ÿæˆé›†ç¾¤é…ç½®æ–‡ä»¶&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#23-ç”Ÿæˆé›†ç¾¤é…ç½®æ–‡ä»¶&#34;&gt;#&lt;/a&gt; 2.3 ç”Ÿæˆé›†ç¾¤é…ç½®æ–‡ä»¶&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;mkdir -p /soft/redis/data/7001
mkdir -p /soft/redis/data/7002
mkdir -p /soft/redis/data/7003
mkdir -p /soft/redis/log
cd /soft/redis
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;redis_7001.conf é…ç½®æ–‡ä»¶&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;gt; /soft/redis/redis_7001.conf &amp;lt;&amp;lt;EOF
protected-mode yes
port 7001
requirepass admin123
masterauth admin123
cluster-enabled yes
cluster-config-file nodes-7001.conf
cluster-node-timeout 5000
maxmemory 2GB
maxmemory-policy volatile-lru
tcp-backlog 511
timeout 0
tcp-keepalive 300
daemonize yes
pidfile /soft/redis/data/redis7001.pid
loglevel notice
logfile &amp;quot;/soft/redis/log/redis7001.log&amp;quot;
#databases 16
always-show-logo no
set-proc-title yes
proc-title-template &amp;quot;&amp;#123;title&amp;#125; &amp;#123;listen-addr&amp;#125; &amp;#123;server-mode&amp;#125;&amp;quot;
locale-collate &amp;quot;&amp;quot;
stop-writes-on-bgsave-error yes
rdbcompression yes
rdbchecksum yes
dbfilename dump.rdb
rdb-del-sync-files no
dir /soft/redis/data/7001
replica-serve-stale-data yes
replica-read-only yes
repl-diskless-sync yes
repl-diskless-sync-delay 5
repl-diskless-sync-max-replicas 0
repl-diskless-load disabled
repl-disable-tcp-nodelay no
replica-priority 100
acllog-max-len 128
lazyfree-lazy-eviction no
lazyfree-lazy-expire no
lazyfree-lazy-server-del no
replica-lazy-flush no
lazyfree-lazy-user-del no
lazyfree-lazy-user-flush no
oom-score-adj no
oom-score-adj-values 0 200 800
disable-thp yes
appendonly no
appendfilename &amp;quot;appendonly.aof&amp;quot;
appenddirname &amp;quot;appendonlydir&amp;quot;
appendfsync everysec
no-appendfsync-on-rewrite no
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
aof-load-truncated yes
aof-use-rdb-preamble yes
aof-timestamp-enabled no
slowlog-log-slower-than 10000
slowlog-max-len 128
latency-monitor-threshold 0
notify-keyspace-events &amp;quot;&amp;quot;
hash-max-listpack-entries 512
hash-max-listpack-value 64
list-max-listpack-size -2
list-compress-depth 0
set-max-intset-entries 512
set-max-listpack-entries 128
set-max-listpack-value 64
zset-max-listpack-entries 128
zset-max-listpack-value 64
hll-sparse-max-bytes 3000
stream-node-max-bytes 4096
stream-node-max-entries 100
activerehashing yes
client-output-buffer-limit normal 0 0 0
client-output-buffer-limit replica 256mb 64mb 60
client-output-buffer-limit pubsub 32mb 8mb 60
hz 10
dynamic-hz yes
aof-rewrite-incremental-fsync yes
rdb-save-incremental-fsync yes
jemalloc-bg-thread yes
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;redis_7002.conf é…ç½®æ–‡ä»¶&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;gt; /soft/redis/redis_7002.conf &amp;lt;&amp;lt;EOF
protected-mode yes
port 7002
requirepass admin123
masterauth admin123
cluster-enabled yes
cluster-config-file nodes-7002.conf
cluster-node-timeout 5000
maxmemory 2GB
maxmemory-policy  volatile-lru
tcp-backlog 511
timeout 0
tcp-keepalive 300
daemonize yes
pidfile /soft/redis/data/redis7002.pid
loglevel notice
logfile &amp;quot;/soft/redis/log/redis7002.log&amp;quot;
#databases 16
always-show-logo no
set-proc-title yes
proc-title-template &amp;quot;&amp;#123;title&amp;#125; &amp;#123;listen-addr&amp;#125; &amp;#123;server-mode&amp;#125;&amp;quot;
locale-collate &amp;quot;&amp;quot;
stop-writes-on-bgsave-error yes
rdbcompression yes
rdbchecksum yes
dbfilename dump.rdb
rdb-del-sync-files no
dir /soft/redis/data/7002
replica-serve-stale-data yes
replica-read-only yes
repl-diskless-sync yes
repl-diskless-sync-delay 5
repl-diskless-sync-max-replicas 0
repl-diskless-load disabled
repl-disable-tcp-nodelay no
replica-priority 100
acllog-max-len 128
lazyfree-lazy-eviction no
lazyfree-lazy-expire no
lazyfree-lazy-server-del no
replica-lazy-flush no
lazyfree-lazy-user-del no
lazyfree-lazy-user-flush no
oom-score-adj no
oom-score-adj-values 0 200 800
disable-thp yes
appendonly no
appendfilename &amp;quot;appendonly.aof&amp;quot;
appenddirname &amp;quot;appendonlydir&amp;quot;
appendfsync everysec
no-appendfsync-on-rewrite no
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
aof-load-truncated yes
aof-use-rdb-preamble yes
aof-timestamp-enabled no
slowlog-log-slower-than 10000
slowlog-max-len 128
latency-monitor-threshold 0
notify-keyspace-events &amp;quot;&amp;quot;
hash-max-listpack-entries 512
hash-max-listpack-value 64
list-max-listpack-size -2
list-compress-depth 0
set-max-intset-entries 512
set-max-listpack-entries 128
set-max-listpack-value 64
zset-max-listpack-entries 128
zset-max-listpack-value 64
hll-sparse-max-bytes 3000
stream-node-max-bytes 4096
stream-node-max-entries 100
activerehashing yes
client-output-buffer-limit normal 0 0 0
client-output-buffer-limit replica 256mb 64mb 60
client-output-buffer-limit pubsub 32mb 8mb 60
hz 10
dynamic-hz yes
aof-rewrite-incremental-fsync yes
rdb-save-incremental-fsync yes
jemalloc-bg-thread yes
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;redis_7003.conf é…ç½®æ–‡ä»¶&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;gt; /soft/redis/redis_7003.conf &amp;lt;&amp;lt;EOF
protected-mode yes
port 7003
requirepass admin123
masterauth admin123
cluster-enabled yes
cluster-config-file nodes-7003.conf
cluster-node-timeout 5000
maxmemory 2GB
maxmemory-policy  volatile-lru
tcp-backlog 511
timeout 0
tcp-keepalive 300
daemonize yes
pidfile /soft/redis/data/redis7003.pid
loglevel notice
logfile &amp;quot;/soft/redis/log/redis7003.log&amp;quot;
#databases 16
always-show-logo no
set-proc-title yes
proc-title-template &amp;quot;&amp;#123;title&amp;#125; &amp;#123;listen-addr&amp;#125; &amp;#123;server-mode&amp;#125;&amp;quot;
locale-collate &amp;quot;&amp;quot;
stop-writes-on-bgsave-error yes
rdbcompression yes
rdbchecksum yes
dbfilename dump.rdb
rdb-del-sync-files no
dir /soft/redis/data/7003
replica-serve-stale-data yes
replica-read-only yes
repl-diskless-sync yes
repl-diskless-sync-delay 5
repl-diskless-sync-max-replicas 0
repl-diskless-load disabled
repl-disable-tcp-nodelay no
replica-priority 100
acllog-max-len 128
lazyfree-lazy-eviction no
lazyfree-lazy-expire no
lazyfree-lazy-server-del no
replica-lazy-flush no
lazyfree-lazy-user-del no
lazyfree-lazy-user-flush no
oom-score-adj no
oom-score-adj-values 0 200 800
disable-thp yes
appendonly no
appendfilename &amp;quot;appendonly.aof&amp;quot;
appenddirname &amp;quot;appendonlydir&amp;quot;
appendfsync everysec
no-appendfsync-on-rewrite no
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
aof-load-truncated yes
aof-use-rdb-preamble yes
aof-timestamp-enabled no
slowlog-log-slower-than 10000
slowlog-max-len 128
latency-monitor-threshold 0
notify-keyspace-events &amp;quot;&amp;quot;
hash-max-listpack-entries 512
hash-max-listpack-value 64
list-max-listpack-size -2
list-compress-depth 0
set-max-intset-entries 512
set-max-listpack-entries 128
set-max-listpack-value 64
zset-max-listpack-entries 128
zset-max-listpack-value 64
hll-sparse-max-bytes 3000
stream-node-max-bytes 4096
stream-node-max-entries 100
activerehashing yes
client-output-buffer-limit normal 0 0 0
client-output-buffer-limit replica 256mb 64mb 60
client-output-buffer-limit pubsub 32mb 8mb 60
hz 10
dynamic-hz yes
aof-rewrite-incremental-fsync yes
rdb-save-incremental-fsync yes
jemalloc-bg-thread yes
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;24-rediså¼€æœºè‡ªå¯&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#24-rediså¼€æœºè‡ªå¯&#34;&gt;#&lt;/a&gt; 2.4 Redis å¼€æœºè‡ªå¯&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;redis_7001.service&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt; &amp;quot;EOF&amp;quot; &amp;gt; /usr/lib/systemd/system/redis_7001.service
[Unit]
Description=Redis 7001 service
Documentation=https://redis.io/documentation
Wants=network-online.target
After=network-online.target
[Service]
Type=forking
LimitNOFILE=10032
User=root
Group=root
ExecStart=/soft/redis/src/redis-server /soft/redis/redis_7001.conf
PrivateTmp=true
[Install]
WantedBy=multi-user.target
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;redis_7002.service&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt; &amp;quot;EOF&amp;quot; &amp;gt; /usr/lib/systemd/system/redis_7002.service
[Unit]
Description=Redis 7002 service
Documentation=https://redis.io/documentation
Wants=network-online.target
After=network-online.target
[Service]
Type=forking
LimitNOFILE=10032
User=root
Group=root
ExecStart=/soft/redis/src/redis-server /soft/redis/redis_7002.conf
PrivateTmp=true
[Install]
WantedBy=multi-user.target
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;redis_7003.service&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt; &amp;quot;EOF&amp;quot; &amp;gt; /usr/lib/systemd/system/redis_7003.service
[Unit]
Description=Redis 7003 service
Documentation=https://redis.io/documentation
Wants=network-online.target
After=network-online.target
[Service]
Type=forking
LimitNOFILE=10032
User=root
Group=root
ExecStart=/soft/redis/src/redis-server /soft/redis/redis_7003.conf
PrivateTmp=true
[Install]
WantedBy=multi-user.target
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;è®¾ç½®å¼€æœºè‡ªå¯&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;chownÂ -R root.root /soft/redis
systemctl daemon-reload
systemctl enable redis_7001.service
systemctl enable redis_7002.service
systemctl enable redis_7003.service
systemctl start redis_7001.service
systemctl start redis_7002.service
systemctl start redis_7003.service
systemctl status redis_7001.service
systemctl status redis_7002.service
systemctl status redis_7003.service
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;25-å¯åŠ¨redisé›†ç¾¤æœåŠ¡&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#25-å¯åŠ¨redisé›†ç¾¤æœåŠ¡&#34;&gt;#&lt;/a&gt; 2.5 å¯åŠ¨ redis é›†ç¾¤æœåŠ¡&lt;/h5&gt;
&lt;p&gt;--cluster-replicas 2 è¡¨ç¤ºä¸ºé›†ç¾¤ä¸­çš„æ¯ä¸ªä¸»èŠ‚ç‚¹åˆ›å»º 2 ä¸ªä»èŠ‚ç‚¹&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd /soft/redis/src
./redis-cli --cluster create \Â Â 
192.168.1.135:7001Â 192.168.1.135:7002 192.168.1.135:7003 \Â Â 
192.168.1.136:7001Â 192.168.1.136:7002 192.168.1.136:7003 \Â 
192.168.1.137:7001Â 192.168.1.137:7002 192.168.1.137:7003 \Â 
--cluster-replicasÂ 2 -a admin123Â 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;è¾“å…¥åˆ›å»ºé›†ç¾¤çš„å‘½ä»¤åä¼šå‡ºç°ä»¥ä¸‹æç¤ºï¼Œæ³¨æ„ Can I set the above configuration? (type &#39;yes&#39; to accept): yesï¼Œè¯¥å¤„è¯·è¾“å…¥ yes&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@qnyp_node01 src]# ./redis-cli --cluster create \
&amp;gt; 192.168.1.135:7001 192.168.1.135:7002 192.168.1.135:7003 \
&amp;gt; 192.168.1.136:7001 192.168.1.136:7002 192.168.1.136:7003 \
&amp;gt; 192.168.1.137:7001 192.168.1.137:7002 192.168.1.137:7003 \
&amp;gt; --cluster-replicas 2 -a admin123
Warning: Using a password with &#39;-a&#39; or &#39;-u&#39; option on the command line interface may not be safe.
&amp;gt;&amp;gt;&amp;gt; Performing hash slots allocation on 9 nodes...
Master[0] -&amp;gt; Slots 0 - 5460
Master[1] -&amp;gt; Slots 5461 - 10922
Master[2] -&amp;gt; Slots 10923 - 16383
Adding replica 192.168.1.136:7002 to 192.168.1.135:7001
Adding replica 192.168.1.137:7002 to 192.168.1.135:7001
Adding replica 192.168.1.135:7003 to 192.168.1.136:7001
Adding replica 192.168.1.137:7003 to 192.168.1.136:7001
Adding replica 192.168.1.136:7003 to 192.168.1.137:7001
Adding replica 192.168.1.135:7002 to 192.168.1.137:7001
M: 928637d72deb6a2e7935f8a7bb5ebd9455cf64a7 192.168.1.135:7001
   slots:[0-5460] (5461 slots) master
S: 4508bee0c33784e0d5be25b64e4c7e677cd9d396 192.168.1.135:7002
   replicates f9133541e2175958117753ef4e206ea43a21f07c
S: a0e13083fcc1d6e96398f3bb2ea5581b7a64e05e 192.168.1.135:7003
   replicates 06ea827f8d328d9d776c9643109317b0100727a6
M: 06ea827f8d328d9d776c9643109317b0100727a6 192.168.1.136:7001
   slots:[5461-10922] (5462 slots) master
S: 1d1b9817e39ee8987a3518f62a9b91c3ab666eff 192.168.1.136:7002
   replicates 928637d72deb6a2e7935f8a7bb5ebd9455cf64a7
S: a73c099dcc63f5d46a11d0f61c91270ef61290ff 192.168.1.136:7003
   replicates f9133541e2175958117753ef4e206ea43a21f07c
M: f9133541e2175958117753ef4e206ea43a21f07c 192.168.1.137:7001
   slots:[10923-16383] (5461 slots) master
S: 626dc659bb1059ec40039869241f7de88a49cd87 192.168.1.137:7002
   replicates 928637d72deb6a2e7935f8a7bb5ebd9455cf64a7
S: 622f73cd06c5658f8d02056925ac708750f12c1a 192.168.1.137:7003
   replicates 06ea827f8d328d9d776c9643109317b0100727a6
Can I set the above configuration? (type &#39;yes&#39; to accept):
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;è¾“å®Œ yes åï¼Œä¼šå‡ºç°å¦‚ä¸‹æç¤ºï¼Œ[OK] All 16384 slots covered. è¯´æ˜æˆåŠŸå•¦&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Can I set the above configuration? (type &#39;yes&#39; to accept): yes
&amp;gt;&amp;gt;&amp;gt; Nodes configuration updated
&amp;gt;&amp;gt;&amp;gt; Assign a different config epoch to each node
&amp;gt;&amp;gt;&amp;gt; Sending CLUSTER MEET messages to join the cluster
Waiting for the cluster to join
..
&amp;gt;&amp;gt;&amp;gt; Performing Cluster Check (using node 192.168.1.135:7001)
M: 928637d72deb6a2e7935f8a7bb5ebd9455cf64a7 192.168.1.135:7001
   slots:[0-5460] (5461 slots) master
   2 additional replica(s)
M: 06ea827f8d328d9d776c9643109317b0100727a6 192.168.1.136:7001
   slots:[5461-10922] (5462 slots) master
   2 additional replica(s)
S: 622f73cd06c5658f8d02056925ac708750f12c1a 192.168.1.137:7003
   slots: (0 slots) slave
   replicates 06ea827f8d328d9d776c9643109317b0100727a6
S: 1d1b9817e39ee8987a3518f62a9b91c3ab666eff 192.168.1.136:7002
   slots: (0 slots) slave
   replicates 928637d72deb6a2e7935f8a7bb5ebd9455cf64a7
S: a73c099dcc63f5d46a11d0f61c91270ef61290ff 192.168.1.136:7003
   slots: (0 slots) slave
   replicates f9133541e2175958117753ef4e206ea43a21f07c
S: a0e13083fcc1d6e96398f3bb2ea5581b7a64e05e 192.168.1.135:7003
   slots: (0 slots) slave
   replicates 06ea827f8d328d9d776c9643109317b0100727a6
M: f9133541e2175958117753ef4e206ea43a21f07c 192.168.1.137:7001
   slots:[10923-16383] (5461 slots) master
   2 additional replica(s)
S: 626dc659bb1059ec40039869241f7de88a49cd87 192.168.1.137:7002
   slots: (0 slots) slave
   replicates 928637d72deb6a2e7935f8a7bb5ebd9455cf64a7
S: 4508bee0c33784e0d5be25b64e4c7e677cd9d396 192.168.1.135:7002
   slots: (0 slots) slave
   replicates f9133541e2175958117753ef4e206ea43a21f07c
[OK] All nodes agree about slots configuration.
&amp;gt;&amp;gt;&amp;gt; Check for open slots...
&amp;gt;&amp;gt;&amp;gt; Check slots coverage...
[OK] All 16384 slots covered.
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;26-è®¿é—®reidsé›†ç¾¤å¹¶éªŒè¯&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#26-è®¿é—®reidsé›†ç¾¤å¹¶éªŒè¯&#34;&gt;#&lt;/a&gt; 2.6 è®¿é—® reids é›†ç¾¤å¹¶éªŒè¯&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;cd /data/redis/src
./redis-cli -h 192.168.1.135 -p 7001 -c -a admin123
#åˆ—å‡ºå½“å‰èŠ‚ç‚¹çš„ä¿¡æ¯ï¼šcluster info
Warning: Using a password with &#39;-a&#39; or &#39;-u&#39; option on the command line interface may not be safe.
192.168.1.135:7001&amp;gt; cluster info
cluster_state:ok
cluster_slots_assigned:16384
cluster_slots_ok:16384
cluster_slots_pfail:0
cluster_slots_fail:0
cluster_known_nodes:9
cluster_size:3
cluster_current_epoch:9
cluster_my_epoch:1
cluster_stats_messages_ping_sent:344
cluster_stats_messages_pong_sent:354
cluster_stats_messages_sent:698
cluster_stats_messages_ping_received:346
cluster_stats_messages_pong_received:344
cluster_stats_messages_meet_received:8
cluster_stats_messages_received:698
total_cluster_links_buffer_limit_exceeded:0
åˆ—å‡ºé›†ç¾¤çš„èŠ‚ç‚¹çš„ä¿¡æ¯ï¼šcluster nodes
192.168.1.135:7001&amp;gt; cluster nodes
06ea827f8d328d9d776c9643109317b0100727a6 192.168.1.136:7001@17001 master - 0 1747034145581 4 connected 5461-10922
622f73cd06c5658f8d02056925ac708750f12c1a 192.168.1.137:7003@17003 slave 06ea827f8d328d9d776c9643109317b0100727a6 0 1747034145581 4 connected
1d1b9817e39ee8987a3518f62a9b91c3ab666eff 192.168.1.136:7002@17002 slave 928637d72deb6a2e7935f8a7bb5ebd9455cf64a7 0 1747034145581 1 connected
a73c099dcc63f5d46a11d0f61c91270ef61290ff 192.168.1.136:7003@17003 slave f9133541e2175958117753ef4e206ea43a21f07c 0 1747034145581 7 connected
a0e13083fcc1d6e96398f3bb2ea5581b7a64e05e 192.168.1.135:7003@17003 slave 06ea827f8d328d9d776c9643109317b0100727a6 0 1747034144077 4 connected
f9133541e2175958117753ef4e206ea43a21f07c 192.168.1.137:7001@17001 master - 0 1747034145079 7 connected 10923-16383
626dc659bb1059ec40039869241f7de88a49cd87 192.168.1.137:7002@17002 slave 928637d72deb6a2e7935f8a7bb5ebd9455cf64a7 0 1747034144000 1 connected
928637d72deb6a2e7935f8a7bb5ebd9455cf64a7 192.168.1.135:7001@17001 myself,master - 0 1747034144000 1 connected 0-5460
4508bee0c33784e0d5be25b64e4c7e677cd9d396 192.168.1.135:7002@17002 slave f9133541e2175958117753ef4e206ea43a21f07c 0 1747034144578 7 connected
&lt;/code&gt;&lt;/pre&gt;
</content>
        <category term="Redis" />
        <updated>2025-05-12T13:21:44.000Z</updated>
    </entry>
    <entry>
        <id>http://ixuyong.cn/posts/170573601.html</id>
        <title>K8sæœåŠ¡å‘å¸ƒIngress</title>
        <link rel="alternate" href="http://ixuyong.cn/posts/170573601.html"/>
        <content type="html">&lt;h4 id=&#34;1-ingress-nginx-controller-å®‰è£…&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-ingress-nginx-controller-å®‰è£…&#34;&gt;#&lt;/a&gt; 1. Ingress Nginx Controller å®‰è£…&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Supported&lt;/th&gt;
&lt;th&gt;Ingress-NGINX version&lt;/th&gt;
&lt;th&gt;k8s supported version&lt;/th&gt;
&lt;th&gt;Alpine Version&lt;/th&gt;
&lt;th&gt;Nginx Version&lt;/th&gt;
&lt;th&gt;Helm Chart Version&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;ğŸ”„&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;v1.12.1&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1.32, 1.31, 1.30, 1.29, 1.28&lt;/td&gt;
&lt;td&gt;3.21.3&lt;/td&gt;
&lt;td&gt;1.25.5&lt;/td&gt;
&lt;td&gt;4.12.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ğŸ”„&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;v1.12.0&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1.32, 1.31, 1.30, 1.29, 1.28&lt;/td&gt;
&lt;td&gt;3.21.0&lt;/td&gt;
&lt;td&gt;1.25.5&lt;/td&gt;
&lt;td&gt;4.12.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ğŸ”„&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;v1.12.0-beta.0&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1.32, 1.31, 1.30, 1.29, 1.28&lt;/td&gt;
&lt;td&gt;3.20.3&lt;/td&gt;
&lt;td&gt;1.25.5&lt;/td&gt;
&lt;td&gt;4.12.0-beta.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ğŸ”„&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;v1.11.5&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt;
&lt;td&gt;3.21.3&lt;/td&gt;
&lt;td&gt;1.25.5&lt;/td&gt;
&lt;td&gt;4.11.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ğŸ”„&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;v1.11.4&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt;
&lt;td&gt;3.21.0&lt;/td&gt;
&lt;td&gt;1.25.5&lt;/td&gt;
&lt;td&gt;4.11.4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ğŸ”„&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;v1.11.3&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt;
&lt;td&gt;3.20.3&lt;/td&gt;
&lt;td&gt;1.25.5&lt;/td&gt;
&lt;td&gt;4.11.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ğŸ”„&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;v1.11.2&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt;
&lt;td&gt;3.20.0&lt;/td&gt;
&lt;td&gt;1.25.5&lt;/td&gt;
&lt;td&gt;4.11.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ğŸ”„&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;v1.11.1&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt;
&lt;td&gt;3.20.0&lt;/td&gt;
&lt;td&gt;1.25.5&lt;/td&gt;
&lt;td&gt;4.11.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ğŸ”„&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;v1.11.0&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt;
&lt;td&gt;3.20.0&lt;/td&gt;
&lt;td&gt;1.25.5&lt;/td&gt;
&lt;td&gt;4.11.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;v1.10.6&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt;
&lt;td&gt;3.21.0&lt;/td&gt;
&lt;td&gt;1.25.5&lt;/td&gt;
&lt;td&gt;4.10.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;v1.10.5&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt;
&lt;td&gt;3.20.3&lt;/td&gt;
&lt;td&gt;1.25.5&lt;/td&gt;
&lt;td&gt;4.10.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;v1.10.4&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt;
&lt;td&gt;3.20.0&lt;/td&gt;
&lt;td&gt;1.25.5&lt;/td&gt;
&lt;td&gt;4.10.4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;v1.10.3&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt;
&lt;td&gt;3.20.0&lt;/td&gt;
&lt;td&gt;1.25.5&lt;/td&gt;
&lt;td&gt;4.10.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;v1.10.2&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt;
&lt;td&gt;3.20.0&lt;/td&gt;
&lt;td&gt;1.25.5&lt;/td&gt;
&lt;td&gt;4.10.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;v1.10.1&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1.30, 1.29, 1.28, 1.27, 1.26&lt;/td&gt;
&lt;td&gt;3.19.1&lt;/td&gt;
&lt;td&gt;1.25.3&lt;/td&gt;
&lt;td&gt;4.10.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;v1.10.0&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1.29, 1.28, 1.27, 1.26&lt;/td&gt;
&lt;td&gt;3.19.1&lt;/td&gt;
&lt;td&gt;1.25.3&lt;/td&gt;
&lt;td&gt;4.10.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;v1.9.6&lt;/td&gt;
&lt;td&gt;1.29, 1.28, 1.27, 1.26, 1.25&lt;/td&gt;
&lt;td&gt;3.19.0&lt;/td&gt;
&lt;td&gt;1.21.6&lt;/td&gt;
&lt;td&gt;4.9.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;v1.9.5&lt;/td&gt;
&lt;td&gt;1.28, 1.27, 1.26, 1.25&lt;/td&gt;
&lt;td&gt;3.18.4&lt;/td&gt;
&lt;td&gt;1.21.6&lt;/td&gt;
&lt;td&gt;4.9.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;v1.9.4&lt;/td&gt;
&lt;td&gt;1.28, 1.27, 1.26, 1.25&lt;/td&gt;
&lt;td&gt;3.18.4&lt;/td&gt;
&lt;td&gt;1.21.6&lt;/td&gt;
&lt;td&gt;4.8.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;v1.9.3&lt;/td&gt;
&lt;td&gt;1.28, 1.27, 1.26, 1.25&lt;/td&gt;
&lt;td&gt;3.18.4&lt;/td&gt;
&lt;td&gt;1.21.6&lt;/td&gt;
&lt;td&gt;4.8.*&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;v1.9.1&lt;/td&gt;
&lt;td&gt;1.28, 1.27, 1.26, 1.25&lt;/td&gt;
&lt;td&gt;3.18.4&lt;/td&gt;
&lt;td&gt;1.21.6&lt;/td&gt;
&lt;td&gt;4.8.*&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;v1.9.0&lt;/td&gt;
&lt;td&gt;1.28, 1.27, 1.26, 1.25&lt;/td&gt;
&lt;td&gt;3.18.2&lt;/td&gt;
&lt;td&gt;1.21.6&lt;/td&gt;
&lt;td&gt;4.8.*&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;v1.8.4&lt;/td&gt;
&lt;td&gt;1.27, 1.26, 1.25, 1.24&lt;/td&gt;
&lt;td&gt;3.18.2&lt;/td&gt;
&lt;td&gt;1.21.6&lt;/td&gt;
&lt;td&gt;4.7.*&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;v1.7.1&lt;/td&gt;
&lt;td&gt;1.27, 1.26, 1.25, 1.24&lt;/td&gt;
&lt;td&gt;3.17.2&lt;/td&gt;
&lt;td&gt;1.21.6&lt;/td&gt;
&lt;td&gt;4.6.*&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;v1.6.4&lt;/td&gt;
&lt;td&gt;1.26, 1.25, 1.24, 1.23&lt;/td&gt;
&lt;td&gt;3.17.0&lt;/td&gt;
&lt;td&gt;1.21.6&lt;/td&gt;
&lt;td&gt;4.5.*&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;v1.5.1&lt;/td&gt;
&lt;td&gt;1.25, 1.24, 1.23&lt;/td&gt;
&lt;td&gt;3.16.2&lt;/td&gt;
&lt;td&gt;1.21.6&lt;/td&gt;
&lt;td&gt;4.4.*&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;v1.4.0&lt;/td&gt;
&lt;td&gt;1.25, 1.24, 1.23, 1.22&lt;/td&gt;
&lt;td&gt;3.16.2&lt;/td&gt;
&lt;td&gt;1.19.10â€ &lt;/td&gt;
&lt;td&gt;4.3.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;v1.3.1&lt;/td&gt;
&lt;td&gt;1.24, 1.23, 1.22, 1.21, 1.20&lt;/td&gt;
&lt;td&gt;3.16.2&lt;/td&gt;
&lt;td&gt;1.19.10â€ &lt;/td&gt;
&lt;td&gt;4.2.5&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h5 id=&#34;11-helmå®‰è£…ingress-nginx-controller&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#11-helmå®‰è£…ingress-nginx-controller&#34;&gt;#&lt;/a&gt; 1.1 Helm å®‰è£… Ingress Nginx Controller&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;å®‰è£… Helm&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;# wget https://get.helm.sh/helm-v3.6.3-linux-amd64.tar.gz
# tar xf helm-v3.6.3-linux-amd64.tar.gz
# mv linux-amd64/helm /usr/local/bin/helm
# helm version
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;ä¸‹è½½ Ingress Nginx Controller å®‰è£…åŒ…&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;å®˜æ–¹æ–‡æ¡£ï¼šhttps://github.com/kubernetes/ingress-nginx/tree/helm-chart-4.8.2         #æ ¹æ®è‡ªå·±k8sç‰ˆæœ¬ä¸‹è½½
# helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
# helm repo update
# helm repo list
# helm pull ingress-nginx/ingress-nginx --version 4.8.2
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;é…ç½® Ingress Nginx Controller&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;# tar xf ingress-nginx-4.8.2.tgz
# cd ingress-nginx
# vim values.yaml
...
 16 controller:
 17   name: controller
 18   enableAnnotationValidations: false
 19   image:
 20     ## Keep false as default for now!
 21     chroot: false
 22     registry: registry.cn-hangzhou.aliyuncs.com
 23     image: kubernetes_public/ingress-nginx-controller
 24     ## for backwards compatibility consider setting the full image url via the repository value below
 25     ## use *either* current default registry/image or repository format or installing chart by providing the values.yaml wil    l fail
 26     ## repository:
 27     tag: &amp;quot;v1.9.3&amp;quot;
 28     #digest: sha256:8fd21d59428507671ce0fb47f818b1d859c92d2ad07bb7c947268d433030ba98
...
 42   # -- Will add custom configuration options to Nginx https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configurat    ion/configmap/
 43   config:
 44     allow-snippet-annotations: true          #å¼€å¯server snippetçš„é…ç½®
...
 67   dnsPolicy: ClusterFirstWithHostNet
...
 88   hostNetwork: true
...
107   ingressClassResource:
108     # -- Name of the ingressClass
109     name: nginx
110     # -- Is this ingressClass enabled or not
111     enabled: true
112     # -- Is this the default ingressClass for the cluster
113     default: true
...
184   kind: DaemonSet
...
287   nodeSelector:
288     kubernetes.io/os: linux
289     ingress: &amp;quot;true&amp;quot;
...
638       image:
639         registry: registry.cn-hangzhou.aliyuncs.com
640         image: kubernetes_public/kube-webhook-certgen
641         ## for backwards compatibility consider setting the full image url via the repository value below
642         ## use *either* current default registry/image or repository format or installing chart by providing the values.yaml     will fail
643         ## repository:
644         tag: v20231011-8b53cabe0
645         #digest: sha256:a7943503b45d552785aa3b5e457f169a5661fb94d82b8a3373bcd9ebaf9aac80
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;4. ç»™éœ€è¦éƒ¨ç½² ingress çš„èŠ‚ç‚¹ä¸Šæ‰“æ ‡ç­¾&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# kubectl label node k8s-node02 ingress=true
# kubectl label node k8s-node01 ingress=true
# kubectl create ns ingress-nginx
# helm install ingress-nginx -n ingress-nginx .     #å®‰è£…
# helm upgrade ingress-nginx -n ingress-nginx .     #æ›´æ–°
# kubectl get pods -n ingress-nginx 
NAME                             READY   STATUS    RESTARTS   AGE
ingress-nginx-controller-7nfqn   1/1     Running   0          27s
ingress-nginx-controller-k4p2n   1/1     Running   0          17m
ingress-nginx-controller-kw5jk   1/1     Running   0          24s
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;12-bare-metalå®‰è£…ingress-nginx-controller&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#12-bare-metalå®‰è£…ingress-nginx-controller&#34;&gt;#&lt;/a&gt; 1.2 Bare metal å®‰è£… Ingress Nginx Controller&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;ä¸‹è½½ Ingress éƒ¨ç½²æ–‡ä»¶ï¼Œé“¾æ¥åœ°å€ï¼š&lt;a href=&#34;https://kubernetes.github.io/ingress-nginx/deploy/#bare-metal-clusters&#34;&gt;https://kubernetes.github.io/ingress-nginx/deploy/#bare-metal-clusters&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.12.1/deploy/static/provider/baremetal/deploy.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;é…ç½® Ingress&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ingress-master]# cat deploy.yaml 
apiVersion: v1
kind: Namespace
metadata:
  labels:
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
  name: ingress-nginx
---
apiVersion: v1
automountServiceAccountToken: true
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.12.1
  name: ingress-nginx
  namespace: ingress-nginx
---
apiVersion: v1
automountServiceAccountToken: true
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/component: admission-webhook
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.12.1
  name: ingress-nginx-admission
  namespace: ingress-nginx
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.12.1
  name: ingress-nginx
  namespace: ingress-nginx
rules:
- apiGroups:
  - &amp;quot;&amp;quot;
  resources:
  - namespaces
  verbs:
  - get
- apiGroups:
  - &amp;quot;&amp;quot;
  resources:
  - configmaps
  - pods
  - secrets
  - endpoints
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - &amp;quot;&amp;quot;
  resources:
  - services
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - networking.k8s.io
  resources:
  - ingresses
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - networking.k8s.io
  resources:
  - ingresses/status
  verbs:
  - update
- apiGroups:
  - networking.k8s.io
  resources:
  - ingressclasses
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - coordination.k8s.io
  resourceNames:
  - ingress-nginx-leader
  resources:
  - leases
  verbs:
  - get
  - update
- apiGroups:
  - coordination.k8s.io
  resources:
  - leases
  verbs:
  - create
- apiGroups:
  - &amp;quot;&amp;quot;
  resources:
  - events
  verbs:
  - create
  - patch
- apiGroups:
  - discovery.k8s.io
  resources:
  - endpointslices
  verbs:
  - list
  - watch
  - get
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  labels:
    app.kubernetes.io/component: admission-webhook
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.12.1
  name: ingress-nginx-admission
  namespace: ingress-nginx
rules:
- apiGroups:
  - &amp;quot;&amp;quot;
  resources:
  - secrets
  verbs:
  - get
  - create
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.12.1
  name: ingress-nginx
rules:
- apiGroups:
  - &amp;quot;&amp;quot;
  resources:
  - configmaps
  - endpoints
  - nodes
  - pods
  - secrets
  - namespaces
  verbs:
  - list
  - watch
- apiGroups:
  - coordination.k8s.io
  resources:
  - leases
  verbs:
  - list
  - watch
- apiGroups:
  - &amp;quot;&amp;quot;
  resources:
  - nodes
  verbs:
  - get
- apiGroups:
  - &amp;quot;&amp;quot;
  resources:
  - services
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - networking.k8s.io
  resources:
  - ingresses
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - &amp;quot;&amp;quot;
  resources:
  - events
  verbs:
  - create
  - patch
- apiGroups:
  - networking.k8s.io
  resources:
  - ingresses/status
  verbs:
  - update
- apiGroups:
  - networking.k8s.io
  resources:
  - ingressclasses
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - discovery.k8s.io
  resources:
  - endpointslices
  verbs:
  - list
  - watch
  - get
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/component: admission-webhook
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.12.1
  name: ingress-nginx-admission
rules:
- apiGroups:
  - admissionregistration.k8s.io
  resources:
  - validatingwebhookconfigurations
  verbs:
  - get
  - update
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.12.1
  name: ingress-nginx
  namespace: ingress-nginx
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: ingress-nginx
subjects:
- kind: ServiceAccount
  name: ingress-nginx
  namespace: ingress-nginx
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    app.kubernetes.io/component: admission-webhook
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.12.1
  name: ingress-nginx-admission
  namespace: ingress-nginx
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: ingress-nginx-admission
subjects:
- kind: ServiceAccount
  name: ingress-nginx-admission
  namespace: ingress-nginx
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.12.1
  name: ingress-nginx
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: ingress-nginx
subjects:
- kind: ServiceAccount
  name: ingress-nginx
  namespace: ingress-nginx
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/component: admission-webhook
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.12.1
  name: ingress-nginx-admission
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: ingress-nginx-admission
subjects:
- kind: ServiceAccount
  name: ingress-nginx-admission
  namespace: ingress-nginx
---
apiVersion: v1
data: null
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.12.1
  name: ingress-nginx-controller
  namespace: ingress-nginx
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.12.1
  name: ingress-nginx-controller
  namespace: ingress-nginx
spec:
  ipFamilies:
  - IPv4
  ipFamilyPolicy: SingleStack
  ports:
  - appProtocol: http
    name: http
    port: 80
    protocol: TCP
    targetPort: http
  - appProtocol: https
    name: https
    port: 443
    protocol: TCP
    targetPort: https
  selector:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
  #type: NodePort
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.12.1
  name: ingress-nginx-controller-admission
  namespace: ingress-nginx
spec:
  ports:
  - appProtocol: https
    name: https-webhook
    port: 443
    targetPort: webhook
  selector:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
  type: ClusterIP
---
apiVersion: apps/v1
#kind: Deployment
kind: DaemonSet
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.12.1
  name: ingress-nginx-controller
  namespace: ingress-nginx
spec:
  minReadySeconds: 0
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
  template:
    metadata:
      labels:
        app.kubernetes.io/component: controller
        app.kubernetes.io/instance: ingress-nginx
        app.kubernetes.io/name: ingress-nginx
        app.kubernetes.io/part-of: ingress-nginx
        app.kubernetes.io/version: 1.12.1
    spec:
      containers:
      - args:
        - /nginx-ingress-controller
        - --election-id=ingress-nginx-leader
        - --controller-class=k8s.io/ingress-nginx
        - --ingress-class=nginx
        - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller
        - --validating-webhook=:8443
        - --validating-webhook-certificate=/usr/local/certificates/cert
        - --validating-webhook-key=/usr/local/certificates/key
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: LD_PRELOAD
          value: /usr/local/lib/libmimalloc.so
        image: registry.cn-hangzhou.aliyuncs.com/kubernetes_public/ingress-nginx-controller-v1.12.1:v1.12.1 
        imagePullPolicy: IfNotPresent
        lifecycle:
          preStop:
            exec:
              command:
              - /wait-shutdown
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /healthz
            port: 10254
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
        name: controller
        ports:
        - containerPort: 80
          name: http
          protocol: TCP
        - containerPort: 443
          name: https
          protocol: TCP
        - containerPort: 8443
          name: webhook
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /healthz
            port: 10254
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
        resources:
          requests:
            cpu: 100m
            memory: 90Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            add:
            - NET_BIND_SERVICE
            drop:
            - ALL
          readOnlyRootFilesystem: false
          runAsGroup: 82
          runAsNonRoot: true
          runAsUser: 101
          seccompProfile:
            type: RuntimeDefault
        volumeMounts:
        - mountPath: /usr/local/certificates/
          name: webhook-cert
          readOnly: true
      hostNetwork: true                         # ä¸èŠ‚ç‚¹å…±äº«ç½‘ç»œåç§°ç©ºé—´
      #dnsPolicy: ClusterFirst
      dnsPolicy: ClusterFirstWithHostNet        # dns ç­–ç•¥
      nodeSelector:                             # èŠ‚ç‚¹é€‰æ‹©å™¨
        kubernetes.io/os: linux
        ingress: &amp;quot;true&amp;quot;
      serviceAccountName: ingress-nginx
      terminationGracePeriodSeconds: 300
      volumes:
      - name: webhook-cert
        secret:
          secretName: ingress-nginx-admission
---
apiVersion: batch/v1
kind: Job
metadata:
  labels:
    app.kubernetes.io/component: admission-webhook
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.12.1
  name: ingress-nginx-admission-create
  namespace: ingress-nginx
spec:
  template:
    metadata:
      labels:
        app.kubernetes.io/component: admission-webhook
        app.kubernetes.io/instance: ingress-nginx
        app.kubernetes.io/name: ingress-nginx
        app.kubernetes.io/part-of: ingress-nginx
        app.kubernetes.io/version: 1.12.1
      name: ingress-nginx-admission-create
    spec:
      containers:
      - args:
        - create
        - --host=ingress-nginx-controller-admission,ingress-nginx-controller-admission.$(POD_NAMESPACE).svc
        - --namespace=$(POD_NAMESPACE)
        - --secret-name=ingress-nginx-admission
        env:
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        image: registry.cn-hangzhou.aliyuncs.com/kubernetes_public/kube-webhook-certgen-v1.5.2:v1.5.2 
        imagePullPolicy: IfNotPresent
        name: create
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
          runAsGroup: 65532
          runAsNonRoot: true
          runAsUser: 65532
          seccompProfile:
            type: RuntimeDefault
      nodeSelector:
        kubernetes.io/os: linux
      restartPolicy: OnFailure
      serviceAccountName: ingress-nginx-admission
---
apiVersion: batch/v1
kind: Job
metadata:
  labels:
    app.kubernetes.io/component: admission-webhook
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.12.1
  name: ingress-nginx-admission-patch
  namespace: ingress-nginx
spec:
  template:
    metadata:
      labels:
        app.kubernetes.io/component: admission-webhook
        app.kubernetes.io/instance: ingress-nginx
        app.kubernetes.io/name: ingress-nginx
        app.kubernetes.io/part-of: ingress-nginx
        app.kubernetes.io/version: 1.12.1
      name: ingress-nginx-admission-patch
    spec:
      containers:
      - args:
        - patch
        - --webhook-name=ingress-nginx-admission
        - --namespace=$(POD_NAMESPACE)
        - --patch-mutating=false
        - --secret-name=ingress-nginx-admission
        - --patch-failure-policy=Fail
        env:
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        image: registry.cn-hangzhou.aliyuncs.com/kubernetes_public/kube-webhook-certgen-v1.5.2:v1.5.2 
        imagePullPolicy: IfNotPresent
        name: patch
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
          runAsGroup: 65532
          runAsNonRoot: true
          runAsUser: 65532
          seccompProfile:
            type: RuntimeDefault
      nodeSelector:
        kubernetes.io/os: linux
      restartPolicy: OnFailure
      serviceAccountName: ingress-nginx-admission
---
apiVersion: networking.k8s.io/v1
kind: IngressClass
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.12.1
  name: nginx
spec:
  controller: k8s.io/ingress-nginx
---
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  labels:
    app.kubernetes.io/component: admission-webhook
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/part-of: ingress-nginx
    app.kubernetes.io/version: 1.12.1
  name: ingress-nginx-admission
webhooks:
- admissionReviewVersions:
  - v1
  clientConfig:
    service:
      name: ingress-nginx-controller-admission
      namespace: ingress-nginx
      path: /networking/v1/ingresses
      port: 443
  failurePolicy: Fail
  matchPolicy: Equivalent
  name: validate.nginx.ingress.kubernetes.io
  rules:
  - apiGroups:
    - networking.k8s.io
    apiVersions:
    - v1
    operations:
    - CREATE
    - UPDATE
    resources:
    - ingresses
  sideEffects: None
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;type: ClusterIP                                              #service ç±»å‹æ”¹ä¸º ClusterIP&lt;/li&gt;
&lt;li&gt;hostNetwork: true                                      # ä¸èŠ‚ç‚¹å…±äº«ç½‘ç»œåç§°ç©ºé—´&lt;/li&gt;
&lt;li&gt;dnsPolicy: ClusterFirstWithHostNet        # dns ç­–ç•¥&lt;/li&gt;
&lt;li&gt;nodeSelector:                                             # èŠ‚ç‚¹é€‰æ‹©å™¨&lt;/li&gt;
&lt;li&gt;kind: DaemonSet                                        # èµ„æºç±»å‹ DaemonSet&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;åœ¨æŒ‡å®šèŠ‚ç‚¹éƒ¨ç½² Ingress-Controller&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ingress-master]# kubectl apply -f deploy.yaml -n ingress-nginx

[root@k8s-master01 ingress-master]# kubectl label node k8s-node01 ingress=true
[root@k8s-master01 ingress-master]# kubectl label node k8s-node02 ingress=true
[root@k8s-master01 ingress-master]# kubectl label node k8s-master03 ingress-     #å–æ¶ˆèŠ‚ç‚¹éƒ¨ç½²

[root@k8s-master01 ingress-master]# kubectl get pods -n ingress-nginx 
NAME                                   READY   STATUS      RESTARTS   AGE
ingress-nginx-admission-create-zp6mh   0/1     Completed   0          12m
ingress-nginx-admission-patch-f2bpd    0/1     Completed   0          12m
ingress-nginx-controller-rgtkc         1/1     Running     0          3m59s
ingress-nginx-controller-trmn8         1/1     Running     0          3m59s
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2-ingress-nginx-å…¥é—¨ä½¿ç”¨&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-ingress-nginx-å…¥é—¨ä½¿ç”¨&#34;&gt;#&lt;/a&gt; 2. Ingress Nginx å…¥é—¨ä½¿ç”¨&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;# cat web-ingress.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: web-ingress
spec:
  ingressClassName: &amp;quot;nginx&amp;quot;
  rules:
  - host: test.hmallleasing.com
    http:
      paths:
      - backend:
          service:
            name: nginx
            port:
              number: 80
        path: /
        pathType: ImplementationSpecific
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;3-ingress-nginx-åŸŸåé‡å®šå‘-redirect&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3-ingress-nginx-åŸŸåé‡å®šå‘-redirect&#34;&gt;#&lt;/a&gt; 3. Ingress Nginx åŸŸåé‡å®šå‘ Redirect&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;# cat redirect-ingress.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: redirect-ingress
  annotations:
    nginx.ingress.kubernetes.io/permanent-redirect: https://www.baidu.com
spec:
  ingressClassName: &amp;quot;nginx&amp;quot;
  rules:
  - host: redirect.hmallleasing.com
    http:
      paths:
      - backend:
          service:
            name: nginx
            port:
              number: 80
        path: /
        pathType: ImplementationSpecific
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;4-ingress-nginx-å‰åç«¯åˆ†ç¦»-rewrite&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4-ingress-nginx-å‰åç«¯åˆ†ç¦»-rewrite&#34;&gt;#&lt;/a&gt; 4. Ingress Nginx å‰åç«¯åˆ†ç¦» Rewrite&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;# cat rewrite-ingress.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: rewrite-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /$2
spec:
  ingressClassName: &amp;quot;nginx&amp;quot;
  rules:
  - host: rewrite.hmallleasing.com
    http:
      paths:
      - backend:
          service:
            name: nginx
            port:
              number: 80
        path: /api(/|$)(.*)
        pathType: ImplementationSpecif
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;5-ingress-nginx-é”™è¯¯ä»£ç é‡å®šå‘&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#5-ingress-nginx-é”™è¯¯ä»£ç é‡å®šå‘&#34;&gt;#&lt;/a&gt; 5. Ingress Nginx é”™è¯¯ä»£ç é‡å®šå‘&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;6-ingress-nginx-ssl&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#6-ingress-nginx-ssl&#34;&gt;#&lt;/a&gt; 6. Ingress Nginx SSL&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;1.ç”Ÿæˆè¯ä¹¦
# openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.cert -subj &amp;quot;/CN=s.hmallleasing.com/O=tls.hmallleasing.com&amp;quot;

2.åˆ›å»ºè¯ä¹¦
# kubectl create secret tls tls.hmallleasig.com --key tls.key --cert tls.cert

3.ingressé…ç½®
# kubectl create secret tls tls.hmallleasig.com --cert=tls.crt --key=tls.key
# cat tls-ingress.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: tls-ingress
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: &amp;quot;false&amp;quot;    #ç¦ç”¨httpså¼ºåˆ¶è·³è½¬
spec:
  ingressClassName: &amp;quot;nginx&amp;quot;
  rules:
  - host: tls.hmallleasing.com
    http:
      paths:
      - backend:
          service:
            name: nginx
            port:
              number: 80
        path: /
        pathType: ImplementationSpecific
  tls:                  #https
  - hosts:
    - tls.hmallleasing.com
    secretName: &amp;quot;tls.hmallleasig.com&amp;quot;	
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;7-ingress-nginx-åŒ¹é…è¯·æ±‚å¤´&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#7-ingress-nginx-åŒ¹é…è¯·æ±‚å¤´&#34;&gt;#&lt;/a&gt; 7. Ingress Nginx åŒ¹é…è¯·æ±‚å¤´&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;1.éƒ¨ç½²ç§»åŠ¨ç«¯åº”ç”¨
# kubectl create deploy phone --image=registry.cn-beijing.aliyuncs.com/dotbalo/nginx:phone
# kubectl expose deploy phone --port 80
# vim m-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: m-ingress
spec:
  ingressClassName: &amp;quot;nginx&amp;quot;
  rules:
  - host: m.hmallleasing.com
    http:
      paths:
      - backend:
          service:
            name: phone
            port:
              number: 80
        path: /
        pathType: ImplementationSpecific

2.éƒ¨ç½²PCç«¯åº”ç”¨		
# kubectl create deploy laptop --image=registry.cn-beijing.aliyuncs.com/dotbalo/nginx:laptop	
# kubectl expose deploy laptop --port 80
# vim laptop-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/server-snippet: |
      set $agentflag 0;
          if ($http_user_agent ~* &amp;quot;(Android|iPhone|Windows Phone|UC|Kindle)&amp;quot; )&amp;#123;
              set $agentflag 1;
          &amp;#125;
          if ( $agentflag = 1 ) &amp;#123;
              return 301 http://m.hmallleaing.com;
          &amp;#125;
  name: laptop-ingress
spec:
  ingressClassName: &amp;quot;nginx&amp;quot;
  rules:
  - host: hmallleasing.com
    http:
      paths:
      - backend:
          service:
            name: laptop
            port:
              number: 80
        path: /
        pathType: ImplementationSpecific	
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;8ingress-nginx-åŸºæœ¬è®¤è¯&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#8ingress-nginx-åŸºæœ¬è®¤è¯&#34;&gt;#&lt;/a&gt; 8.Ingress Nginx åŸºæœ¬è®¤è¯&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;# yum install httpd -y
# htpasswd -c auth superman
# cat auth 
superman:$apr1$AC1pc3dK$RJyWnyDJFNKY6twneGVrA1		

# kubectl create secret generic basic-auth --from-file=auth
# cat basic-ingress.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: basic-ingress
  annotations:
    nginx.ingress.kubernetes.io/auth-type: basic  # è®¤è¯ç±»å‹
    nginx.ingress.kubernetes.io/auth-secret: basic-auth  # åŒ…å«ç”¨æˆ·å’Œå¯†ç çš„ secret èµ„æºåç§°
    nginx.ingress.kubernetes.io/auth-realm: &#39;Please User password&#39;  # è¦æ˜¾ç¤ºçš„ä¿¡æ¯
spec:
  ingressClassName: &amp;quot;nginx&amp;quot;
  rules:
  - host: basic.hmallleasing.com
    http:
      paths:
      - backend:
          service:
            name: nginx
            port:
              number: 80
        path: /
        pathType: ImplementationSpecific
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;9-ingress-nginx-é»‘ç™½åå•&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#9-ingress-nginx-é»‘ç™½åå•&#34;&gt;#&lt;/a&gt; 9. Ingress Nginx é»‘ / ç™½åå•&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;å†™æ³•ä¸€ï¼š
# cat white-ingress.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: white-ingress
  annotations:
    nginx.ingress.kubernetes.io/whitelist-source-range: &amp;quot;192.168.40.101&amp;quot;
spec:
  ingressClassName: &amp;quot;nginx&amp;quot;
  rules:
  - host: white.hmallleasing.com
    http:
      paths:
      - backend:
          service:
            name: nginx
            port:
              number: 80
        path: /
        pathType: ImplementationSpecific	

å†™æ³•äºŒï¼š		
[root@k8s-master01 ingress]# cat white-ingress.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: white-ingress
  annotations:
    nginx.ingress.kubernetes.io/whitelist-source-range: &amp;quot;192.168.40.0/24&amp;quot;
spec:
  ingressClassName: &amp;quot;nginx&amp;quot;
  rules:
  - host: white.hmallleasing.com
    http:
      paths:
      - backend:
          service:
            name: nginx
            port:
              number: 80
        path: /
        pathType: ImplementationSpecific


å†™æ³•ä¸‰ï¼š
# cat white-ingress.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: white-ingress
  annotations:
    nginx.ingress.kubernetes.io/server-snippet: |
      allow 192.168.40.0/24;
      deny all;
spec:
  ingressClassName: &amp;quot;nginx&amp;quot;
  rules:
  - host: white.hmallleasing.com
    http:
      paths:
      - backend:
          service:
            name: nginx
            port:
              number: 80
        path: /
        pathType: ImplementationSpecific
		

#Master01æµ‹è¯•		
# curl -H &amp;quot;Host:white.hmallleasing.com&amp;quot; http://192.168.40.103 -I
HTTP/1.1 200 OK
Date: Sat, 14 Oct 2023 13:12:03 GMT
Content-Type: text/html
Content-Length: 612
Connection: keep-alive
Last-Modified: Tue, 16 Apr 2019 13:08:19 GMT
ETag: &amp;quot;5cb5d3c3-264&amp;quot;
Accept-Ranges: bytes		

#Master02æµ‹è¯•
# curl -H &amp;quot;Host:white.hmallleasing.com&amp;quot; http://192.168.40.103 -I
HTTP/1.1 403 Forbidden
Date: Sat, 14 Oct 2023 13:13:34 GMT
Content-Type: text/html
Content-Length: 146
Connection: keep-alive
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;10-ingress-nginx-é€Ÿç‡é™åˆ¶&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#10-ingress-nginx-é€Ÿç‡é™åˆ¶&#34;&gt;#&lt;/a&gt; 10. Ingress Nginx é€Ÿç‡é™åˆ¶&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ingress]# cat limit-rate-ingress.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: rate-limit-ingress
  annotations:
    nginx.ingress.kubernetes.io/limit-rps: &amp;quot;50&amp;quot;
spec:
  ingressClassName: &amp;quot;nginx&amp;quot;
  rules:
  - host: rate-limit.hmallleasing.com
    http:
      paths:
      - backend:
          service:
            name: nginx
            port:
              number: 80
        path: /
        pathType: ImplementationSpecific

# ab -c 20 -n 1000 http://rate-limit.hmallleasing.com/ |grep request
Complete requests:      1000
Failed requests:        724
Time per request:       10.301 [ms] (mean)
Time per request:       0.515 [ms] (mean, across all concurrent requests)
Percentage of the requests served within a certain time (ms)
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;11ä½¿ç”¨-nginx-å®ç°ç°åº¦é‡‘ä¸é›€å‘å¸ƒ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#11ä½¿ç”¨-nginx-å®ç°ç°åº¦é‡‘ä¸é›€å‘å¸ƒ&#34;&gt;#&lt;/a&gt; 11. ä½¿ç”¨ Nginx å®ç°ç°åº¦ / é‡‘ä¸é›€å‘å¸ƒ&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;1.åˆ›å»º v1 ç‰ˆæœ¬
# kubectl create deploy canary-v1 --image=registry.cn-beijing.aliyuncs.com/dotbalo/canary:v1	
# kubectl expose deploy canary-v1 --port 8080
# cat canary-v1-ingress.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: canary-v1-ingress
spec:
  ingressClassName: &amp;quot;nginx&amp;quot;
  rules:
  - host: canary.hmallleasing.com
    http:
      paths:
      - backend:
          service:
            name: canary-v1
            port:
              number: 8080
        path: /
        pathType: ImplementationSpecific
		
# curl -H &amp;quot;Host:canary.hmallleasing.com&amp;quot; http://192.168.40.103 	

2.åˆ›å»º v2 ç‰ˆæœ¬
# kubectl create deploy canary-v2 --image=registry.cn-beijing.aliyuncs.com/dotbalo/canary:v2
# kubectl expose deploy canary-v2 --port 8080
# cat canary-v2-ingress.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: canary-v2-ingress
  annotations:
    nginx.ingress.kubernetes.io/canary: &amp;quot;true&amp;quot;    #å¯åŠ¨ç°åº¦å‘å¸ƒ
    nginx.ingress.kubernetes.io/canary-weight: &amp;quot;20&amp;quot;  #åŸºäºæƒé‡,50%æµé‡è°ƒåº¦åˆ°è¿™ä¸ªç°åº¦çš„ç‰ˆæœ¬ä¸Š
spec:
  ingressClassName: &amp;quot;nginx&amp;quot;
  rules:
  - host: canary.hmallleasing.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: canary-v2
            port:
              number: 8080

#æµ‹è¯•ç°åº¦å‘å¸ƒ
[root@k8s-master01 ingress]# cat canary.sh 
#!/bin/bash

while true
do
	curl -H &amp;quot;Host:canary.hmallleasing.com&amp;quot; http://192.168.40.103
	sleep 0.5
done
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;12-kubernetes-dashboardé…ç½®è¯ä¹¦&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#12-kubernetes-dashboardé…ç½®è¯ä¹¦&#34;&gt;#&lt;/a&gt; 12. kubernetes-dashboard é…ç½®è¯ä¹¦&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;1.åˆ›å»ºè¯ä¹¦
kubectl create secret tls kubernetes-dashboard-certs --key *.hmallleasing.com_key.key --cert *.hmallleasing.com_chain.crt -n kubernetes-dashboard

2.ä¿®æ”¹kubernetes-dashboardèµ„æºæ¸…å•
kubectl edit deployment -n kubernetes-dashboard kubernetes-dashboard
...
      - args:
        - --auto-generate-certificates=false
        - --tls-key-file=_.hmallleasing.com_key.key
        - --tls-cert-file=_.hmallleasing.com_chain.crt
        - --token-ttl=21600
        - --authentication-mode=basic,token
        - --namespace=kubernetes-dashboard
...

3.åˆ›å»ºingress
#cat dashboard-ingress.yaml 
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: dashboard-ingress
  namespace: kubernetes-dashboard
  annotations:
    nginx.ingress.kubernetes.io/ssl-passthrough: &amp;quot;true&amp;quot;    
    nginx.ingress.kubernetes.io/backend-protocol: &amp;quot;HTTPS&amp;quot;    
spec:
  ingressClassName: &amp;quot;nginx&amp;quot;
  rules:
  - host: dashboard.hmallleasing.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: kubernetes-dashboard
            port:
              number: 443

# kubectl apply -f dashboard-ingress.yaml 
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;13-å…¥å£lbé…ç½®&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#13-å…¥å£lbé…ç½®&#34;&gt;#&lt;/a&gt; 13. å…¥å£ LB é…ç½®&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@lb nginx]# cat /etc/nginx/conf.d/ingress.conf 
upstream ingress &amp;#123;
	server 192.168.40.103:80 max_conns=2000 max_fails=2 fail_timeout=5s;
	server 192.168.40.104:80 max_conns=2000 max_fails=2 fail_timeout=5s;
	server 192.168.40.105:80 max_conns=2000 max_fails=2 fail_timeout=5s;
&amp;#125;

server &amp;#123;
    listen 443 ssl;
    server_name test.hmallleasing.com;
    client_max_body_size 1G; 
    ssl_prefer_server_ciphers on;
    ssl_certificate  /etc/nginx/sslkey/*.hmallleasing.com_chain.crt;
    ssl_certificate_key  /etc/nginx/sslkey/*.hmallleasing.com_key.key;

    location / &amp;#123;
        proxy_pass http://ingress;
        include proxy_params;
	    proxy_next_upstream error timeout http_500 http_502 http_503 http_504;
	    proxy_next_upstream_tries 2;
	    proxy_next_upstream_timeout 3s;
    &amp;#125;
&amp;#125;

server &amp;#123;
    listen 80;
    server_name test.hmallleasing.com;
    return 302 https://$server_name$request_uri;
&amp;#125;

[root@lb ~]# mkdir /etc/nginx/sslkey -p


[root@lb ~]# cat proxy_params 
proxy_http_version 1.1;
proxy_set_header Connectin &amp;quot;&amp;quot;;

proxy_set_header Host $http_host;
proxy_set_header X-Real-IP $remote_addr;
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

proxy_connect_timeout 60;
proxy_send_timeout 120;
proxy_read_timeout 120;

proxy_buffering on;
proxy_buffer_size 32k;
proxy_buffers 4 128k;
proxy_temp_file_write_size 10240k;
proxy_max_temp_file_size 10240k;
&lt;/code&gt;&lt;/pre&gt;
</content>
        <category term="Kubernetes" />
        <updated>2025-04-26T08:52:06.000Z</updated>
    </entry>
    <entry>
        <id>http://ixuyong.cn/posts/3364424907.html</id>
        <title>é˜¿é‡Œäº‘+Githubæ„å»ºé•œåƒä»“åº“</title>
        <link rel="alternate" href="http://ixuyong.cn/posts/3364424907.html"/>
        <content type="html">&lt;h3 id=&#34;é˜¿é‡Œäº‘githubæ„å»ºé•œåƒä»“åº“è§£å†³-k8sgcrioè®¿é—®&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#é˜¿é‡Œäº‘githubæ„å»ºé•œåƒä»“åº“è§£å†³-k8sgcrioè®¿é—®&#34;&gt;#&lt;/a&gt; é˜¿é‡Œäº‘ + github æ„å»ºé•œåƒä»“åº“è§£å†³ k8s.gcr.io è®¿é—®&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;http://xn--k8s-xi9d897o.gcr.io/&#34;&gt;ç”±äº k8s.gcr.io/&lt;/a&gt; é•œåƒä»“åº“ä½äºå›½å¤–ï¼Œå›½å†…ä½¿ç”¨ kubeadm æ„å»º docker é›†ç¾¤æ—¶æ— æ³•è®¿é—®ç›¸åº”çš„ docker é•œåƒã€‚&lt;/p&gt;
&lt;h4 id=&#34;1-ç™»å½•githubåˆ›å»ºä»“åº“&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-ç™»å½•githubåˆ›å»ºä»“åº“&#34;&gt;#&lt;/a&gt; &lt;strong&gt;1.&lt;/strong&gt; ç™»å½• Github åˆ›å»ºä»“åº“&lt;/h4&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/vgZkKBC.png&#34; alt=&#34;1.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/VnJlhBE.png&#34; alt=&#34;2.png&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;2-åˆ›å»ºdockerfile&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-åˆ›å»ºdockerfile&#34;&gt;#&lt;/a&gt; &lt;strong&gt;2.&lt;/strong&gt; åˆ›å»º Dockerfile&lt;/h4&gt;
&lt;p&gt;ä»“åº“ä¸‹é¢åˆ›å»ºä¸€ä¸ª Dockerfileï¼Œä»¥ ingress-nginx-controller ä¸ºä¾‹ä¸‹çš„ dockerfile å†…å®¹å¦‚ä¸‹ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@manager ~]# mkdir ingress-nginx-controller
[root@manager ~]# cd ingress-nginx-controller/
[root@manager ingress-nginx-controller]# cat Dockerfile 
FROM registry.k8s.io/ingress-nginx/controller:v1.12.1 
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;3-sshå…å¯†ç™»å½•github&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3-sshå…å¯†ç™»å½•github&#34;&gt;#&lt;/a&gt; 3. SSH å…å¯†ç™»å½• GitHub&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@manager ingress-nginx-controller]# ssh-keygen
[root@manager ingress-nginx-controller]# cat ~/.ssh/id_rsa.pub
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;è¿›å…¥&lt;em&gt; GitHub&lt;/em&gt; çš„ä¸ªäººè®¾ç½®ï¼Œæ‰¾åˆ°ã€&lt;em&gt;SSH and GPG keys&lt;/em&gt;ã€‘ï¼Œç„¶åç‚¹å‡»æ–°å¢ SSH Keyï¼Œè¿›å…¥å¦‚ä¸‹ç•Œé¢ï¼Œ&lt;em&gt;title&lt;/em&gt; è¾“å…¥ä½ å¯¹äºå½“å‰&lt;em&gt; SSH key&lt;/em&gt; çš„å¤‡æ³¨ï¼Œä¸‹é¢çš„&lt;em&gt; key&lt;/em&gt; å°±ç²˜è´´ä¸Šä¸€æ­¥ç”Ÿæˆçš„&lt;em&gt; id_rsa.pub&lt;/em&gt; å†…çš„å†…å®¹&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/3djSHRS.png&#34; alt=&#34;3.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/8gVcVu4.png&#34; alt=&#34;5.png&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;4-æ¨é€dockerfileè‡³github&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4-æ¨é€dockerfileè‡³github&#34;&gt;#&lt;/a&gt; 4. æ¨é€ Dockerfile è‡³ Github&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@manager ingress-nginx-controller]# yum install git -y
[root@manager ingress-nginx-controller]# git --version
[root@manager ingress-nginx-controller]# git config --global user.email &amp;quot;373370405@qq.com&amp;quot;
[root@manager ingress-nginx-controller]# git config --global color.ui true
[root@manager ingress-nginx-controller]# git init
[root@manager ingress-nginx-controller]# git add .
[root@manager ingress-nginx-controller]# git commit -m &amp;quot;first commit&amp;quot;
[root@manager ingress-nginx-controller]# git branch -M main
[root@manager ingress-nginx-controller]# git remote add origin git@github.com:xyapples/ingress-nginx-controller.git   #æ·»åŠ è¿œç¨‹ä»“åº“
[root@manager ingress-nginx-controller]# git remote -v
[root@manager ingress-nginx-controller]# git push -u origin main
[root@manager ingress-nginx-controller]# git remote remove origin  #ç§»é™¤è¿œç¨‹ä»“åº“
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/N3t49eX.png&#34; alt=&#34;6.png&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;5-ç™»å½•é˜¿é‡Œäº‘åˆ›å»ºé•œåƒä»“åº“&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#5-ç™»å½•é˜¿é‡Œäº‘åˆ›å»ºé•œåƒä»“åº“&#34;&gt;#&lt;/a&gt; &lt;strong&gt;5.&lt;/strong&gt; ç™»å½•é˜¿é‡Œäº‘åˆ›å»ºé•œåƒä»“åº“&lt;/h4&gt;
&lt;p&gt;ç™»å½•é˜¿é‡Œäº‘é•œåƒï¼š&lt;a href=&#34;https://cr.console.aliyun.com/%EF%BC%8C%E5%88%9B%E5%BB%BA%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93%EF%BC%9A&#34;&gt;https://cr.console.aliyun.com/ï¼Œåˆ›å»ºé•œåƒä»“åº“ï¼š&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/1zFqa35.png&#34; alt=&#34;7.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/PhzoeeT.png&#34; alt=&#34;1.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/iYAbB0x.png&#34; alt=&#34;2.png&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;6-æ„å»ºé•œåƒ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#6-æ„å»ºé•œåƒ&#34;&gt;#&lt;/a&gt; 6. æ„å»ºé•œåƒ&lt;/h4&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/KD3DI7J.png&#34; alt=&#34;3.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/WiwNBRK.png&#34; alt=&#34;4.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/155pUrE.png&#34; alt=&#34;7.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/155pUrE.png&#34; alt=&#34;7.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/AU1371X.png&#34; alt=&#34;8.png&#34; /&gt;&lt;/p&gt;
</content>
        <category term="Docker" />
        <updated>2025-04-26T08:20:14.000Z</updated>
    </entry>
    <entry>
        <id>http://ixuyong.cn/posts/3030097036.html</id>
        <title>K8Säº‘åŸç”Ÿå­˜å‚¨Rook-Ceph</title>
        <link rel="alternate" href="http://ixuyong.cn/posts/3030097036.html"/>
        <content type="html">&lt;h3 id=&#34;k8säº‘åŸç”Ÿå­˜å‚¨rook-ceph&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#k8säº‘åŸç”Ÿå­˜å‚¨rook-ceph&#34;&gt;#&lt;/a&gt; K8S äº‘åŸç”Ÿå­˜å‚¨ Rook-Ceph&lt;/h3&gt;
&lt;h4 id=&#34;1-storageclassåŠ¨æ€å­˜å‚¨&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-storageclassåŠ¨æ€å­˜å‚¨&#34;&gt;#&lt;/a&gt; 1. StorageClass åŠ¨æ€å­˜å‚¨&lt;/h4&gt;
&lt;p&gt;StorageClassï¼šå­˜å‚¨ç±»ï¼Œç”± K8s ç®¡ç†å‘˜åˆ›å»ºï¼Œç”¨äºåŠ¨æ€ PV çš„ç®¡ç†ï¼Œå¯ä»¥é“¾æ¥è‡³ä¸åŒçš„åç«¯å­˜å‚¨ï¼Œæ¯”å¦‚ Cephã€GlusterFS ç­‰ã€‚ä¹‹åå¯¹å­˜å‚¨çš„è¯·æ±‚å¯ä»¥æŒ‡å‘ StorageClassï¼Œç„¶å StorageClass ä¼šè‡ªåŠ¨çš„åˆ›å»ºã€åˆ é™¤ PVã€‚&lt;/p&gt;
&lt;p&gt;å®ç°æ–¹å¼ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;in-tree: å†…ç½®äº K8s æ ¸å¿ƒä»£ç ï¼Œå¯¹äºå­˜å‚¨çš„ç®¡ç†ï¼Œéƒ½éœ€è¦ç¼–å†™ç›¸åº”çš„ä»£ç ã€‚&lt;/li&gt;
&lt;li&gt;out-of-treeï¼šç”±å­˜å‚¨å‚å•†æä¾›ä¸€ä¸ªé©±åŠ¨ï¼ˆCSI æˆ– Flex Volumeï¼‰ï¼Œå®‰è£…åˆ° K8s é›†ç¾¤ï¼Œç„¶å StorageClass åªéœ€è¦é…ç½®è¯¥é©±åŠ¨å³å¯ï¼Œé©±åŠ¨å™¨ä¼šä»£æ›¿ StorageClass ç®¡ç†å­˜å‚¨ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;StorageClass å®˜ç½‘ä»‹ç»ï¼š&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/storage-classes/&#34;&gt;https://kubernetes.io/docs/concepts/storage/storage-classes/&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;2-äº‘åŸç”Ÿå­˜å‚¨rook&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-äº‘åŸç”Ÿå­˜å‚¨rook&#34;&gt;#&lt;/a&gt; 2. äº‘åŸç”Ÿå­˜å‚¨ Rook&lt;/h4&gt;
&lt;p&gt;Rook æ˜¯ä¸€ä¸ªè‡ªæˆ‘ç®¡ç†çš„åˆ†å¸ƒå¼å­˜å‚¨ç¼–æ’ç³»ç»Ÿï¼Œå®ƒæœ¬èº«å¹¶ä¸æ˜¯å­˜å‚¨ç³»ç»Ÿï¼Œåœ¨å­˜å‚¨å’Œ k8s ä¹‹å‰æ­å»ºäº†ä¸€ä¸ªæ¡¥æ¢ï¼Œä½¿å­˜å‚¨ç³»ç»Ÿçš„æ­å»ºæˆ–è€…ç»´æŠ¤å˜å¾—ç‰¹åˆ«ç®€å•ï¼ŒRook å°†åˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿè½¬å˜ä¸ºè‡ªæˆ‘ç®¡ç†ã€è‡ªæˆ‘æ‰©å±•ã€è‡ªæˆ‘ä¿®å¤çš„å­˜å‚¨æœåŠ¡ã€‚å®ƒè®©ä¸€äº›å­˜å‚¨çš„æ“ä½œï¼Œæ¯”å¦‚éƒ¨ç½²ã€é…ç½®ã€æ‰©å®¹ã€å‡çº§ã€è¿ç§»ã€ç¾éš¾æ¢å¤ã€ç›‘è§†å’Œèµ„æºç®¡ç†å˜å¾—è‡ªåŠ¨åŒ–ï¼Œæ— éœ€äººå·¥å¤„ç†ã€‚å¹¶ä¸” Rook æ”¯æŒ CSIï¼Œå¯ä»¥åˆ©ç”¨ CSI åšä¸€äº› PVC çš„å¿«ç…§ã€æ‰©å®¹ã€å…‹éš†ç­‰æ“ä½œã€‚&lt;/p&gt;
&lt;p&gt;Rook å®˜ç½‘ä»‹ç»ï¼š&lt;a href=&#34;https://rook.io/&#34;&gt;https://rook.io/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/CK4Gn1u.jpeg&#34; alt=&#34;Snipaste_2025-05-07_20-15-59.jpg&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;3-rook-å®‰è£…&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3-rook-å®‰è£…&#34;&gt;#&lt;/a&gt; 3. Rook å®‰è£…&lt;/h4&gt;
&lt;p&gt;ç¯å¢ƒå‡†å¤‡&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;K8s é›†ç¾¤è‡³å°‘äº”ä¸ªèŠ‚ç‚¹ï¼Œæ¯ä¸ªèŠ‚ç‚¹çš„å†…å­˜ä¸ä½äº 5Gï¼ŒCPU ä¸ä½äº 2 æ ¸&lt;/li&gt;
&lt;li&gt;æ‰€æœ‰èŠ‚ç‚¹æ—¶é—´åŒæ­¥&lt;/li&gt;
&lt;li&gt;è‡³å°‘æœ‰ä¸‰ä¸ªå­˜å‚¨èŠ‚ç‚¹ï¼Œå¹¶ä¸”æ¯ä¸ªèŠ‚ç‚¹è‡³å°‘æœ‰ä¸€ä¸ªè£¸ç›˜ï¼Œk8s-master03ã€k8s-node01ã€k8s-node02 å¢åŠ è£¸ç›˜&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;31-ä¸‹è½½-rook-å®‰è£…æ–‡ä»¶&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#31-ä¸‹è½½-rook-å®‰è£…æ–‡ä»¶&#34;&gt;#&lt;/a&gt; 3.1 ä¸‹è½½ Rook å®‰è£…æ–‡ä»¶&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# git clone --single-branch --branch v1.17.2 https://github.com/rook/rook.git
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;32-é…ç½®æ›´æ”¹&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#32-é…ç½®æ›´æ”¹&#34;&gt;#&lt;/a&gt; 3.2 é…ç½®æ›´æ”¹&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# cd rook/deploy/examples
[root@k8s-master01 ~]# vim operator.yaml
  ROOK_CSI_CEPH_IMAGE: &amp;quot;registry.cn-hangzhou.aliyuncs.com/kubernetes_public/cephcsi:v3.14.0&amp;quot;
  ROOK_CSI_REGISTRAR_IMAGE: &amp;quot;registry.cn-hangzhou.aliyuncs.com/kubernetes_public/csi-node-driver-registrar:v2.13.0&amp;quot;
  ROOK_CSI_RESIZER_IMAGE: &amp;quot;registry.cn-hangzhou.aliyuncs.com/kubernetes_public/csi-resizer:v1.13.1&amp;quot;
  ROOK_CSI_PROVISIONER_IMAGE: &amp;quot;registry.cn-hangzhou.aliyuncs.com/kubernetes_public/csi-provisioner:v5.1.0&amp;quot;
  ROOK_CSI_SNAPSHOTTER_IMAGE: &amp;quot;registry.cn-hangzhou.aliyuncs.com/kubernetes_public/csi-snapshotter:v8.2.0&amp;quot;
  ROOK_CSI_ATTACHER_IMAGE: &amp;quot;registry.cn-hangzhou.aliyuncs.com/kubernetes_public/csi-attacher:v4.8.0&amp;quot;

#ROOK_ENABLE_DISCOVERY_DAEMON æ”¹æˆ true å³å¯
ROOK_ENABLE_DISCOVERY_DAEMON: &amp;quot;true&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;33-éƒ¨ç½²-rook&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#33-éƒ¨ç½²-rook&#34;&gt;#&lt;/a&gt; 3.3 éƒ¨ç½² rook&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ceph]# kubectl create -f crds.yaml -f common.yaml -f operator.yaml
[root@k8s-master01 examples]# kubectl get pods -n rook-ceph
NAME                                  READY   STATUS    RESTARTS   AGE
rook-ceph-operator-84ff77778b-7ww2w   1/1     Running   0          91m
rook-discover-6j68f                   1/1     Running   0          82m
rook-discover-9w4kt                   1/1     Running   0          82m
rook-discover-h2zfm                   1/1     Running   0          82m
rook-discover-hsz8b                   1/1     Running   0          19m
rook-discover-rj4t7                   1/1     Running   0          82m
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;4åˆ›å»º-ceph-é›†ç¾¤&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4åˆ›å»º-ceph-é›†ç¾¤&#34;&gt;#&lt;/a&gt; 4. åˆ›å»º Ceph é›†ç¾¤&lt;/h4&gt;
&lt;h5 id=&#34;41-é…ç½®æ›´æ”¹&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#41-é…ç½®æ›´æ”¹&#34;&gt;#&lt;/a&gt; 4.1 é…ç½®æ›´æ”¹&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 examples]# vim cluster.yaml
...
    image: registry.cn-hangzhou.aliyuncs.com/kubernetes_public/cephv19.2.2:v19.2.2
...
  skipUpgradeChecks: true     #æ”¹ä¸ºtrueï¼Œè·³è¿‡å‡çº§
....
  dashboard:
    enabled: true
    # serve the dashboard under a subpath (useful when you are accessing the dashboard via a reverse proxy)
    # urlPrefix: /ceph-dashboard
    # serve the dashboard at the given port.
    # port: 8443
    # serve the dashboard using SSL
    ssl: false          #æ”¹ä¸ºfalse
...
  storage: # cluster level storage configuration and selection
    useAllNodes: false      #æ”¹ä¸ºfalse,ä¸ä½¿ç”¨æ‰€æœ‰çš„èŠ‚ç‚¹å½“osd
    useAllDevices: false    #æ”¹ä¸ºfalse,ä¸ä½¿ç”¨æ‰€æœ‰çš„ç£ç›˜å½“osd
...
    #     deviceFilter: &amp;quot;^sd.&amp;quot;
    nodes:
    - name: &amp;quot;k8s-master03&amp;quot;
      devices:
      - name: &amp;quot;sdb&amp;quot;
    - name: &amp;quot;k8s-node01&amp;quot;
      devices:
      - name: &amp;quot;sdb&amp;quot;
    - name: &amp;quot;k8s-node02&amp;quot;
      devices:
      - name: &amp;quot;sdb&amp;quot;
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æ³¨æ„ï¼šæ–°ç‰ˆå¿…é¡»é‡‡ç”¨è£¸ç›˜ï¼Œå³æœªæ ¼å¼åŒ–çš„ç£ç›˜ã€‚å…¶ä¸­ k8s-master03ã€ k8s-node01ã€  k8s-node02 æœ‰æ–°åŠ çš„ä¸€ä¸ªç£ç›˜ï¼Œå¯ä»¥é€šè¿‡ lsblk -f æŸ¥çœ‹æ–°æ·»åŠ çš„ç£ç›˜åç§°ã€‚å»ºè®®æœ€å°‘ä¸‰ä¸ªèŠ‚ç‚¹ï¼Œå¦åˆ™åé¢çš„è¯•éªŒå¯èƒ½ä¼šå‡ºç°é—®é¢˜&lt;/p&gt;
&lt;h5 id=&#34;42-åˆ›å»º-ceph-é›†ç¾¤&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#42-åˆ›å»º-ceph-é›†ç¾¤&#34;&gt;#&lt;/a&gt; 4.2 åˆ›å»º Ceph é›†ç¾¤&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 examples]# kubectl create -f cluster.yaml
[root@k8s-master01 examples]# kubectl get pods -n rook-ceph
NAME                                                     READY   STATUS      RESTARTS        AGE
csi-cephfsplugin-5nmnl                                   3/3     Running     1 (60m ago)     62m
csi-cephfsplugin-6b6ct                                   3/3     Running     1 (60m ago)     62m
csi-cephfsplugin-8xlnl                                   3/3     Running     1 (60m ago)     62m
csi-cephfsplugin-fh9w5                                   3/3     Running     1 (60m ago)     62m
csi-cephfsplugin-mslst                                   3/3     Running     1 (60m ago)     62m
csi-cephfsplugin-provisioner-59bd447c6d-5zwj2            6/6     Running     0               61s
csi-cephfsplugin-provisioner-59bd447c6d-7t2kg            6/6     Running     2 (20s ago)     61s
csi-rbdplugin-5gvmp                                      3/3     Running     1 (60m ago)     62m
csi-rbdplugin-dzcs4                                      3/3     Running     1 (60m ago)     62m
csi-rbdplugin-n82b5                                      3/3     Running     1 (60m ago)     62m
csi-rbdplugin-provisioner-6856fb8b86-86hw8               6/6     Running     0               19s
csi-rbdplugin-provisioner-6856fb8b86-lj9s4               6/6     Running     0               19s
csi-rbdplugin-vh8j2                                      3/3     Running     1 (60m ago)     62m
csi-rbdplugin-xfgwr                                      3/3     Running     1 (60m ago)     62m
rook-ceph-crashcollector-k8s-master01-bbc78d496-bzjk8    1/1     Running     0               8m26s
rook-ceph-crashcollector-k8s-master03-765ff964bb-95wmt   1/1     Running     0               28m
rook-ceph-crashcollector-k8s-node01-7cf4c4b6b6-r4n84     1/1     Running     0               20m
rook-ceph-crashcollector-k8s-node02-f887f8cf9-jz2l8      1/1     Running     0               28m
rook-ceph-detect-version-nsrwj                           0/1     Init:0/1    0               3s
rook-ceph-exporter-k8s-master01-5cd4577b79-ckd4m         1/1     Running     0               8m26s
rook-ceph-exporter-k8s-master03-75f4cf6f7-hc9zb          1/1     Running     0               28m
rook-ceph-exporter-k8s-node01-96fc7cf49-d2r24            1/1     Running     0               20m
rook-ceph-exporter-k8s-node02-777b9f555b-7j6cz           1/1     Running     0               27m
rook-ceph-mgr-a-6f46b4b945-q6cjb                         3/3     Running     3 (14m ago)     35m
rook-ceph-mgr-b-5d4cc5465b-8dfh6                         3/3     Running     0               35m
rook-ceph-mon-a-7c7b7555c7-nlhwg                         2/2     Running     2 (6m14s ago)   51m
rook-ceph-mon-c-559bcf95fd-cl62w                         2/2     Running     0               8m27s
rook-ceph-mon-d-7dbc6b8f5c-8264t                         2/2     Running     0               28m
rook-ceph-operator-645478ff5b-jdcrp                      1/1     Running     0               102m
rook-ceph-osd-0-6d9cf78f76-4zhx8                         2/2     Running     0               12m
rook-ceph-osd-1-88c78bbcb-cn48c                          2/2     Running     0               5m15s
rook-ceph-osd-2-b464c9fc6-458hv                          2/2     Running     0               4m29s
rook-ceph-osd-prepare-k8s-master03-pwnrc                 0/1     Completed   0               86s
rook-ceph-osd-prepare-k8s-node01-xxp2j                   0/1     Completed   0               83s
rook-ceph-osd-prepare-k8s-node02-8nz7x                   0/1     Completed   0               78s
rook-discover-jzmkr                                      1/1     Running     0               91m
rook-discover-k7pxt                                      1/1     Running     0               91m
rook-discover-vqjh5                                      1/1     Running     0               91m
rook-discover-wk8jq                                      1/1     Running     0               91m
rook-discover-x8rsn                                      1/1     Running     0               91m

[root@k8s-master01 examples]# kubectl get cephcluster -n rook-ceph
NAME        DATADIRHOSTPATH   MONCOUNT   AGE   PHASE   MESSAGE                        HEALTH        EXTERNAL   FSID
rook-ceph   /var/lib/rook     3          63m   Ready   Cluster created successfully   HEALTH_WARN              ca429602-66f4-4a1e-9d5c-a5773a0f594f
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;43-å®‰è£…-ceph-snapshot-æ§åˆ¶å™¨&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#43-å®‰è£…-ceph-snapshot-æ§åˆ¶å™¨&#34;&gt;#&lt;/a&gt; 4.3 å®‰è£… ceph snapshot æ§åˆ¶å™¨&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# cd /root/k8s-ha-install/
[root@k8s-master01 k8s-ha-install]# git checkout manual-installation-v1.32.x
[root@k8s-master01 k8s-ha-install]# kubectl create -f snapshotter/ -n kube-system
[root@k8s-master01 k8s-ha-install]# kubectl get po -n kube-system -l app=snapshot-controller
NAME                    READY   STATUS    RESTARTS   AGE
snapshot-controller-0   1/1     Running   0          67s
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;5-å®‰è£…-ceph-å®¢æˆ·ç«¯å·¥å…·&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#5-å®‰è£…-ceph-å®¢æˆ·ç«¯å·¥å…·&#34;&gt;#&lt;/a&gt; 5. å®‰è£… ceph å®¢æˆ·ç«¯å·¥å…·&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 k8s-ha-install]# cd /root/rook/deploy/examples/
[root@k8s-master01 examples]# kubectl create -f toolbox.yaml -n rook-ceph
[root@k8s-master01 examples]# kubectl get po -n rook-ceph -l app=rook-ceph-tools
NAME                               READY   STATUS    RESTARTS   AGE
rook-ceph-tools-7b75b967db-sqddk   1/1     Running   0          8s
[root@k8s-master01 examples]# kubectl exec -it rook-ceph-tools-7b75b967db-sqddk -n rook-ceph -- bash
bash-5.1$ ceph status
  cluster:
    id:     87b85368-9487-4967-a4e4-5970d2e0ec94
    health: HEALTH_WARN
            1 mgr modules have recently crashed
 
  services:
    mon: 3 daemons, quorum b,c (age 12s), out of quorum: a
    mgr: a(active, since 7m), standbys: b
    osd: 3 osds: 3 up (since 8m), 3 in (since 3h)
 
  data:
    pools:   0 pools, 0 pgs
    objects: 0 objects, 0 B
    usage:   82 MiB used, 60 GiB / 60 GiB avail
    pgs: 
	
bash-4.4$  ceph osd status
ID  HOST           USED  AVAIL  WR OPS  WR DATA  RD OPS  RD DATA  STATE      
 0  k8s-master03  20.6M  19.9G      0        0       0        0   exists,up  
 1  k8s-node01    20.6M  19.9G      0        0       0        0   exists,up  
 2  k8s-node02    20.6M  19.9G      0        0       0        0   exists,up 

bash-4.4$ ceph df
--- RAW STORAGE ---
CLASS    SIZE   AVAIL    USED  RAW USED  %RAW USED
hdd    60 GiB  60 GiB  62 MiB    62 MiB       0.10
TOTAL  60 GiB  60 GiB  62 MiB    62 MiB       0.10

--- POOLS ---
POOL  ID  PGS   STORED  OBJECTS     USED  %USED  MAX AVAIL
.mgr   1    1  449 KiB        2  1.3 MiB      0     19 GiB
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;6-ceph-dashboard&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#6-ceph-dashboard&#34;&gt;#&lt;/a&gt; 6. Ceph dashboard&lt;/h4&gt;
&lt;h5 id=&#34;61-æš´éœ²æœåŠ¡&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#61-æš´éœ²æœåŠ¡&#34;&gt;#&lt;/a&gt; 6.1 æš´éœ²æœåŠ¡&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# kubectl get svc -n rook-ceph
NAME                      TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE
rook-ceph-mgr             ClusterIP   10.96.54.15     &amp;lt;none&amp;gt;        9283/TCP            133m
rook-ceph-mgr-dashboard   ClusterIP   10.96.97.117    &amp;lt;none&amp;gt;        7000/TCP            133m        #æš´éœ²ingresssä¹Ÿå¯
rook-ceph-mon-a           ClusterIP   10.96.125.216   &amp;lt;none&amp;gt;        6789/TCP,3300/TCP   170m
rook-ceph-mon-b           ClusterIP   10.96.34.183    &amp;lt;none&amp;gt;        6789/TCP,3300/TCP   133m
rook-ceph-mon-c           ClusterIP   10.96.232.252   &amp;lt;none&amp;gt;        6789/TCP,3300/TCP   133m


[root@k8s-master01 examples]# kubectl create -f dashboard-external-http.yaml           #æš´éœ²nodeport
[root@k8s-master01 examples]# kubectl get svc -n rook-ceph rook-ceph-mgr-dashboard-external-http
NAME                                     TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE
rook-ceph-mgr-dashboard-external-https   NodePort   10.96.11.120   &amp;lt;none&amp;gt;        8443:32611/TCP   45s
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;62-é…ç½®ingressè®¿é—®ceph&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#62-é…ç½®ingressè®¿é—®ceph&#34;&gt;#&lt;/a&gt; 6.2 é…ç½® ingress è®¿é—® ceph&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 examples]# cat dashboard-ingress-https.yaml 
#
# This example is for Kubernetes running an nginx-ingress
# and an ACME (e.g. Let&#39;s Encrypt) certificate service
#
# The nginx-ingress annotations support the dashboard
# running using HTTPS with a self-signed certificate
#
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: rook-ceph-mgr-dashboard
  namespace: rook-ceph # namespace:cluster
#  annotations:
#    kubernetes.io/ingress.class: &amp;quot;nginx&amp;quot;
#    kubernetes.io/tls-acme: &amp;quot;true&amp;quot;
#    nginx.ingress.kubernetes.io/backend-protocol: &amp;quot;HTTPS&amp;quot;
#    nginx.ingress.kubernetes.io/server-snippet: |
#      proxy_ssl_verify off;

spec:
  ingressClassName: &amp;quot;nginx&amp;quot;
#  tls:
#    - hosts:
#        - rook-ceph.hmallleasing.com
#      secretName: rook-ceph.example.com
  rules:
    - host: rook-ceph.hmallleasing.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: rook-ceph-mgr-dashboard
                port:
                  name: http-dashboard
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;63-ç™»å½•&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#63-ç™»å½•&#34;&gt;#&lt;/a&gt; 6.3 ç™»å½•&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;http://192.168.40.100:32611
ç”¨æˆ·åï¼šadmin
å¯†ç ï¼škubectl -n rook-ceph get secret rook-ceph-dashboard-password -o jsonpath=&amp;quot;&amp;#123;[&#39;data&#39;][&#39;password&#39;]&amp;#125;&amp;quot; | base64 --decode &amp;amp;&amp;amp; echo
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;7-ceph-å—å­˜å‚¨çš„ä½¿ç”¨&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#7-ceph-å—å­˜å‚¨çš„ä½¿ç”¨&#34;&gt;#&lt;/a&gt; 7. Ceph å—å­˜å‚¨çš„ä½¿ç”¨&lt;/h4&gt;
&lt;p&gt;å—å­˜å‚¨ä¸€èˆ¬ç”¨äºä¸€ä¸ª Pod æŒ‚è½½ä¸€å—å­˜å‚¨ä½¿ç”¨ï¼Œç›¸å½“äºä¸€ä¸ªæœåŠ¡å™¨æ–°æŒ‚äº†ä¸€ä¸ªç›˜ï¼Œåªç»™ä¸€ä¸ªåº”ç”¨ä½¿ç”¨ã€‚&lt;/p&gt;
&lt;h5 id=&#34;71-åˆ›å»º-storageclass-å’Œ-ceph-çš„å­˜å‚¨æ± &#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#71-åˆ›å»º-storageclass-å’Œ-ceph-çš„å­˜å‚¨æ± &#34;&gt;#&lt;/a&gt; 7.1 åˆ›å»º StorageClass å’Œ ceph çš„å­˜å‚¨æ± &lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 examples]# kubectl get csidriver
NAME                            ATTACHREQUIRED   PODINFOONMOUNT   STORAGECAPACITY   TOKENREQUESTS   REQUIRESREPUBLISH   MODES        AGE
rook-ceph.cephfs.csi.ceph.com   true             false            false             &amp;lt;unset&amp;gt;         false               Persistent   15h       #æ–‡ä»¶å­˜å‚¨csi
rook-ceph.rbd.csi.ceph.com      true             false            false             &amp;lt;unset&amp;gt;         false               Persistent   15h       #å—å­˜å‚¨csi

[root@k8s-master01 ~]# cd /root/rook/deploy/examples/
[root@k8s-master01 examples]# vim csi/rbd/storageclass.yaml
...
apiVersion: ceph.rook.io/v1
kind: CephBlockPool
metadata:
  name: replicapool
  namespace: rook-ceph # namespace:cluster
spec:
  failureDomain: host
  replicated:
    size: 3                #æ•°æ®ä¿å­˜å‡ ä»½ï¼Œæµ‹è¯•ç¯å¢ƒå¯ä»¥å°†å‰¯æœ¬æ•°è®¾ç½®æˆäº† 2ï¼ˆä¸èƒ½è®¾ç½®ä¸º 1ï¼‰ï¼Œç”Ÿäº§ç¯å¢ƒæœ€å°‘ä¸º 3ï¼Œä¸”è¦å°äºç­‰äº osd çš„æ•°é‡
...
allowVolumeExpansion: true     #æ˜¯å¦å¯ä»¥æ‰©å®¹
reclaimPolicy: Delete          #pvå›æ”¶ç­–ç•¥

[root@k8s-master01 examples]# kubectl create -f csi/rbd/storageclass.yaml -n rook-ceph

[root@k8s-master01 examples]# kubectl get cephblockpool -n rook-ceph
NAME          PHASE
replicapool   Ready
[root@k8s-master01 examples]# kubectl get sc
NAME              PROVISIONER                  RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
nfs-storage       nfzl.com/nfs                 Delete          Immediate           false                  16h
rook-ceph-block   rook-ceph.rbd.csi.ceph.com   Delete          Immediate           true                   37s
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;72-æŒ‚è½½æµ‹è¯•&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#72-æŒ‚è½½æµ‹è¯•&#34;&gt;#&lt;/a&gt; 7.2 æŒ‚è½½æµ‹è¯•&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# cat ceph-block-pvc.yaml        #åˆ›å»ºPVC
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: ceph-block-pvc
spec:
  storageClassName: &amp;quot;rook-ceph-block&amp;quot;     # æ˜ç¡®æŒ‡å®šä½¿ç”¨å“ªä¸ªscçš„ä¾›åº”å•†æ¥åˆ›å»ºpv
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi                      # æ ¹æ®ä¸šåŠ¡å®é™…å¤§å°è¿›è¡Œèµ„æºç”³è¯·

[root@k8s-master01 ~]# kubectl apply -f ceph-block-pvc.yaml 

[root@k8s-master01 ~]# kubectl get pvc
NAME             STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS      AGE
ceph-block-pvc   Bound    pvc-86c94d8d-c359-47b8-b5d3-31dcdaf86551   1Gi        RWO            rook-ceph-block   3s

[root@k8s-master01 ~]# kubectl get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                    STORAGECLASS      REASON   AGE
pvc-86c94d8d-c359-47b8-b5d3-31dcdaf86551   1Gi        RWO            Delete           Bound    default/ceph-block-pvc   rook-ceph-block
	  
[root@k8s-master01 ~]# cat ceph-block-pvc-pod.yaml    #æŒ‚è½½PVCæµ‹è¯• 
apiVersion: v1
kind: Pod
metadata:
  name: ceph-block-pvc-pod
spec:
  containers:
  - name: ceph-block-pvc-pod
    image: nginx
    volumeMounts:
    - name: nginx-page
      mountPath: /usr/share/nginx/html
  volumes:
  - name: nginx-page
    persistentVolumeClaim:      
      claimName: ceph-block-pv

[root@k8s-master01 ~]# kubectl apply -f ceph-block-pvc-pod.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;73-statefulset-volumeclaimtemplates&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#73-statefulset-volumeclaimtemplates&#34;&gt;#&lt;/a&gt; 7.3 StatefulSet volumeClaimTemplates&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# cat ceph-block-pvc-sts.yaml 
apiVersion: v1
kind: Service
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  ports:

  - port: 80
    name: web
      clusterIP: None
      selector:
    app: nginx
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: web
spec:
  selector:
    matchLabels:
      app: nginx # å¿…é¡»åŒ¹é… .spec.template.metadata.labels
  serviceName: &amp;quot;nginx&amp;quot;
  replicas: 3 # é»˜è®¤å€¼æ˜¯ 1
  template:
    metadata:
      labels:
        app: nginx # å¿…é¡»åŒ¹é… .spec.selector.matchLabels
    spec:
      containers:
      - name: nginx
        image: nginx:1.20
        ports:
        - containerPort: 80
          name: web
        volumeMounts:
        - name: www
          mountPath: /usr/share/nginx/html
  volumeClaimTemplates:
  - metadata:
    name: www
    spec:
      accessModes: [ &amp;quot;ReadWriteOnce&amp;quot; ]
      storageClassName: &amp;quot;rook-ceph-block&amp;quot;
      resources:
        requests:
          storage: 1Gi
    	  
[root@k8s-master01 ~]# kubectl apply -f ceph-block-pvc-sts.yaml 

[root@k8s-master01 ~]# kubectl get pods
NAME                                      READY   STATUS    RESTARTS       AGE
web-0                                     1/1     Running   0              4m19s
web-1                                     1/1     Running   0              4m10s
web-2                                     1/1     Running   0              2m21s

[root@k8s-master01 ~]# kubectl get pvc
NAME        STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS      AGE
www-web-0   Bound    pvc-27cab5bf-f989-4050-aa84-1b2dac9fa745   1Gi        RWO            rook-ceph-block   4m23s
www-web-1   Bound    pvc-76fb08f4-2195-4678-b6b8-286c2f722cc9   1Gi        RWO            rook-ceph-block   4m14s
www-web-2   Bound    pvc-6b858cd9-288f-48bc-bc96-33e6eb519613   1Gi        RWO            rook-ceph-block   2m25s

[root@k8s-master01 ~]# kubectl get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM               STORAGECLASS      REASON   AGE
pvc-27cab5bf-f989-4050-aa84-1b2dac9fa745   1Gi        RWO            Delete           Bound    default/www-web-0   rook-ceph-block            4m25s
pvc-6b858cd9-288f-48bc-bc96-33e6eb519613   1Gi        RWO            Delete           Bound    default/www-web-2   rook-ceph-block            2m27s
pvc-76fb08f4-2195-4678-b6b8-286c2f722cc9   1Gi        RWO            Delete           Bound    default/www-web-1   rook-ceph-block            4m16s
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;8-å…±äº«æ–‡ä»¶ç³»ç»Ÿçš„ä½¿ç”¨&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#8-å…±äº«æ–‡ä»¶ç³»ç»Ÿçš„ä½¿ç”¨&#34;&gt;#&lt;/a&gt; 8. å…±äº«æ–‡ä»¶ç³»ç»Ÿçš„ä½¿ç”¨&lt;/h4&gt;
&lt;p&gt;å…±äº«æ–‡ä»¶ç³»ç»Ÿä¸€èˆ¬ç”¨äºå¤šä¸ª Pod å…±äº«ä¸€ä¸ªå­˜å‚¨&lt;/p&gt;
&lt;h5 id=&#34;81-åˆ›å»ºå…±äº«ç±»å‹çš„æ–‡ä»¶ç³»ç»Ÿ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#81-åˆ›å»ºå…±äº«ç±»å‹çš„æ–‡ä»¶ç³»ç»Ÿ&#34;&gt;#&lt;/a&gt; 8.1 åˆ›å»ºå…±äº«ç±»å‹çš„æ–‡ä»¶ç³»ç»Ÿ&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# cd /root/rook/deploy/examples/
[root@k8s-master01 examples]# kubectl apply -f filesystem.yaml
[root@k8s-master01 examples]# kubectl get pod -l app=rook-ceph-mds -n rook-ceph
NAME                                    READY   STATUS    RESTARTS   AGE
rook-ceph-mds-myfs-a-7d76cb5988-9nz9p   2/2     Running   0          36s
rook-ceph-mds-myfs-b-76ff7c784c-vs8nm   2/2     Running   0          33s
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;82-åˆ›å»ºå…±äº«ç±»å‹æ–‡ä»¶ç³»ç»Ÿçš„-storageclass&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#82-åˆ›å»ºå…±äº«ç±»å‹æ–‡ä»¶ç³»ç»Ÿçš„-storageclass&#34;&gt;#&lt;/a&gt; 8.2 åˆ›å»ºå…±äº«ç±»å‹æ–‡ä»¶ç³»ç»Ÿçš„ StorageClass&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 examples]# cd csi/cephfs
[root@k8s-master01 cephfs]# kubectl create -f storageclass.yaml
[root@k8s-master01 cephfs]# kubectl get sc
NAME              PROVISIONER                     RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
nfs-storage       nfzl.com/nfs                    Delete          Immediate           false                  17h
rook-ceph-block   rook-ceph.rbd.csi.ceph.com      Delete          Immediate           true                   82m
rook-cephfs       rook-ceph.cephfs.csi.ceph.com   Delete          Immediate           true                   13s
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;83-æŒ‚è½½æµ‹è¯•&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#83-æŒ‚è½½æµ‹è¯•&#34;&gt;#&lt;/a&gt; 8.3 æŒ‚è½½æµ‹è¯•&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# cat cephfs-pvc-deploy.yaml 
apiVersion: v1
kind: Service
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  ports:
  - port: 80
    name: web
  selector:
    app: nginx
  type: ClusterIP
---
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: nginx-share-pvc
spec:
  storageClassName: rook-cephfs 
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 2Gi
---
apiVersion: apps/v1
kind: Deployment 
metadata:
  name: web
spec:
  selector:
    matchLabels:
      app: nginx # has to match .spec.template.metadata.labels
  replicas: 3 # by default is 1
  template:
    metadata:
      labels:
        app: nginx # has to match .spec.selector.matchLabels
    spec:
      containers:
      - name: nginx
        image: nginx 
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 80
          name: web
        volumeMounts:
        - name: www
          mountPath: /usr/share/nginx/html
      volumes:
        - name: www
          persistentVolumeClaim:
            claimName: nginx-share-pvc
			
[root@k8s-master01 ~]# kubectl apply -f cephfs-pvc-deploy.yaml
[root@k8s-master01 ~]# kubectl get pods
NAME                                      READY   STATUS    RESTARTS        AGE
cluster-test-84dfc9c68b-5q4ng             1/1     Running   84 (4m2s ago)   16d
nfs-client-provisioner-5dbbd8d796-lhdgw   1/1     Running   5 (123m ago)    18h
web-6c59f8559-g5xzb                       1/1     Running   0               46s
web-6c59f8559-ns77q                       1/1     Running   0               46s
web-6c59f8559-qxb5f                       1/1     Running   0               46s

[root@k8s-master01 ~]# kubectl get pvc
NAME              STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
nginx-share-pvc   Bound    pvc-4de733fe-c2fb-437b-baff-aaeba0235d54   2Gi        RWX            rook-cephfs    52s

[root@k8s-master01 ~]# kubectl get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                     STORAGECLASS   REASON   AGE
pvc-4de733fe-c2fb-437b-baff-aaeba0235d54   2Gi        RWX            Delete           Bound    default/nginx-share-pvc   rook-cephfs             53s

[root@k8s-master01 ~]# kubectl exec -it web-6c59f8559-g5xzb -- bash
root@web-6c59f8559-g5xzb:/# cd /usr/share/nginx/html/
root@web-6c59f8559-g5xzb:/usr/share/nginx/html# echo &amp;quot;hello cephfs&amp;quot; &amp;gt;&amp;gt; index.html

[root@k8s-master01 ~]# kubectl get svc
NAME                 TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)    AGE
kubernetes           ClusterIP   10.96.0.1     &amp;lt;none&amp;gt;        443/TCP    16d
mysql-svc-external   ClusterIP   None          &amp;lt;none&amp;gt;        3306/TCP   9d
nginx                ClusterIP   10.96.58.17   &amp;lt;none&amp;gt;        80/TCP     4m34s
[root@k8s-master01 ~]# curl 10.96.58.17
hello cephfs
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;9pvc-æ‰©å®¹&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#9pvc-æ‰©å®¹&#34;&gt;#&lt;/a&gt; 9.PVC æ‰©å®¹&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# kubectl get sc
NAME              PROVISIONER                     RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
nfs-storage       nfzl.com/nfs                    Delete          Immediate           false                  18h
rook-ceph-block   rook-ceph.rbd.csi.ceph.com      Delete          Immediate           true                   104m     #trueå…è®¸æ‰©å®¹
rook-cephfs       rook-ceph.cephfs.csi.ceph.com   Delete          Immediate           true                   22m      #trueå…è®¸æ‰©å®¹

[root@k8s-master01 ~]# kubectl get pvc
NAME              STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
nginx-share-pvc   Bound    pvc-4de733fe-c2fb-437b-baff-aaeba0235d54   2Gi        RWX            rook-cephfs    13m
[root@k8s-master01 ~]# kubectl edit pvc nginx-share-pvc
...
  - ReadWriteMany
  resources:
    requests:
      storage: 5Gi         #æ›´æ”¹pvcå¤§å°
  storageClassName: rook-cephfs
...

[root@k8s-master01 ~]# kubectl get pvc       #æŸ¥çœ‹PVCæ˜¯å¦æ‰©å®¹
NAME              STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
nginx-share-pvc   Bound    pvc-4de733fe-c2fb-437b-baff-aaeba0235d54   5Gi        RWX            rook-cephfs    15m

[root@k8s-master01 ~]# kubectl get pv         #æŸ¥çœ‹PVæ˜¯å¦æ‰©å®¹
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                     STORAGECLASS   REASON   AGE
pvc-4de733fe-c2fb-437b-baff-aaeba0235d54   5Gi        RWX            Delete           Bound    default/nginx-share-pvc   rook-cephfs             15m

[root@k8s-master01 ~]# kubectl exec -it web-6c59f8559-g5xzb -- bash       #è¿›å…¥å®¹å™¨ï¼ŒæŸ¥çœ‹podæ˜¯å¦æ‰©å®¹  
root@web-6c59f8559-g5xzb:/# df -h 
Filesystem                                                                                                                                             Size  Used Avail Use% Mounted on
overlay                                                                                                                                                 17G   13G  4.1G  76% /
tmpfs                                                                                                                                                   64M     0   64M   0% /dev
tmpfs                                                                                                                                                  2.0G     0  2.0G   0% /sys/fs/cgroup
/dev/sda3                                                                                                                                               17G   13G  4.1G  76% /etc/hosts
shm                                                                                                                                                     64M     0   64M   0% /dev/shm
10.96.121.140:6789,10.96.131.130:6789,10.96.62.64:6789:/volumes/csi/csi-vol-3b645a11-58f4-475a-9404-5d84964f5291/e4bdf743-eb18-42c8-b04f-41964f76de4f  5.0G     0  5.0G   0% /usr/share/nginx/html
tmpfs                                                                                                                                                  3.8G   12K  3.8G   1% /run/secrets/kubernetes.io/serviceaccount
tmpfs                                                                                                                                                  2.0G     0  2.0G   0% /proc/asound
tmpfs                                                                                                                                                  2.0G     0  2.0G   0% /proc/acpi
tmpfs                                                                                                                                                  2.0G     0  2.0G   0% /proc/scsi
tmpfs                                                                                                                                                  2.0G     0  2.0G   0% /sys/firmware
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;10-pvc-å¿«ç…§&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#10-pvc-å¿«ç…§&#34;&gt;#&lt;/a&gt; 10. PVC å¿«ç…§&lt;/h4&gt;
&lt;h5 id=&#34;101-æ–‡ä»¶å…±äº«ç±»å‹å¿«ç…§&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#101-æ–‡ä»¶å…±äº«ç±»å‹å¿«ç…§&#34;&gt;#&lt;/a&gt; 10.1 æ–‡ä»¶å…±äº«ç±»å‹å¿«ç…§&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# cd rook/deploy/examples
[root@k8s-master01 examples]# kubectl create -f csi/cephfs/snapshotclass.yaml 

[root@k8s-master01 examples]# kubectl get volumesnapshotclass
NAME                         DRIVER                          DELETIONPOLICY   AGE
csi-cephfsplugin-snapclass   rook-ceph.cephfs.csi.ceph.com   Delete           25s


#æ‹æ‘„å¿«ç…§	
[root@k8s-master01 examples]# kubectl exec -it web-6c59f8559-g5xzb -- bash         #pvcæ–°å¢æ•°æ®
root@web-6c59f8559-g5xzb:/# cd /usr/share/nginx/html/
root@web-6c59f8559-g5xzb:/usr/share/nginx/html# touch &amp;#123;1..10&amp;#125;
root@web-6c59f8559-g5xzb:/usr/share/nginx/html# ls
1  10  2  3  4	5  6  7  8  9  index.html

[root@k8s-master01 examples]# kubectl get pvc       #æŸ¥çœ‹pvså¹¶å¯¹nginx-share-pvcæ‹æ‘„å¿«ç…§
NAME              STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
nginx-share-pvc   Bound    pvc-4de733fe-c2fb-437b-baff-aaeba0235d54   5Gi        RWX            rook-cephfs    4h23m

[root@k8s-master01 examples]# cat csi/cephfs/snapshot.yaml         #æ‹æ‘„å¿«ç…§
---
# 1.17 &amp;lt;= K8s &amp;lt;= v1.19
# apiVersion: snapshot.storage.k8s.io/v1beta1
# K8s &amp;gt;= v1.20
apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshot
metadata:
  name: cephfs-pvc-snapshot
spec:
  volumeSnapshotClassName: csi-cephfsplugin-snapclass
  source:
    persistentVolumeClaimName: nginx-share-pvc         #åŸºäºé‚£ä¸ªPVCæ‹æ‘„å¿«ç…§
	
[root@k8s-master01 examples]# kubectl apply -f csi/cephfs/snapshot.yaml
[root@k8s-master01 examples]# kubectl get volumesnapshot
NAME                  READYTOUSE   SOURCEPVC         SOURCESNAPSHOTCONTENT   RESTORESIZE   SNAPSHOTCLASS                SNAPSHOTCONTENT                                    CREATIONTIME   AGE
cephfs-pvc-snapshot   true         nginx-share-pvc                           5Gi           csi-cephfsplugin-snapclass   snapcontent-bdaddb97-debe-4f42-9423-13bf1c5b5402   4m6s           4m8s

#åˆ é™¤pvcæ•°æ®
[root@k8s-master01 examples]# kubectl exec -it web-6c59f8559-g5xzb -- bash
root@web-6c59f8559-g5xzb:/# cd /usr/share/nginx/html/
root@web-6c59f8559-g5xzb:/usr/share/nginx/html# ls
1  10  2  3  4	5  6  7  8  9  index.html
root@web-6c59f8559-g5xzb:/usr/share/nginx/html# rm -rf &amp;#123;1..10&amp;#125;
root@web-6c59f8559-g5xzb:/usr/share/nginx/html# ls
index.html

#pvcå›æ»šæ•°æ®
[root@k8s-master01 examples]# kubectl get volumesnapshot
NAME                  READYTOUSE   SOURCEPVC         SOURCESNAPSHOTCONTENT   RESTORESIZE   SNAPSHOTCLASS                SNAPSHOTCONTENT                                    CREATIONTIME   AGE
cephfs-pvc-snapshot   true         nginx-share-pvc                           5Gi           csi-cephfsplugin-snapclass   snapcontent-bdaddb97-debe-4f42-9423-13bf1c5b5402   7m39s          7m41s
	
[root@k8s-master01 examples]# cat csi/cephfs/pvc-restore.yaml 
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: cephfs-pvc-restore
spec:
  storageClassName: rook-cephfs       #åˆ›å»ºpvçš„storageclassåç§°ç›¸åŒ
  dataSource:
    name: cephfs-pvc-snapshot         #volumesnapshotæ•°æ®æº
    kind: VolumeSnapshot
    apiGroup: snapshot.storage.k8s.io
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 5Gi      #å¤§å°ç­‰äºsnapshotå¤§å°

[root@k8s-master01 examples]# kubectl apply -f csi/cephfs/pvc-restore.yaml

[root@k8s-master01 examples]# kubectl get pvc
NAME                 STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
cephfs-pvc-restore   Bound    pvc-9e845f2b-df1f-450d-8aa2-f9a46db6adb6   5Gi        RWX            rook-cephfs    54s          
nginx-share-pvc      Bound    pvc-4de733fe-c2fb-437b-baff-aaeba0235d54   5Gi        RWX            rook-cephfs    4h50m

#æŒ‚è½½PVCæµ‹è¯•æ•°æ®æ˜¯å¦æ¢å¤
[root@k8s-master01 examples]# cat csi/cephfs/pod.yaml 
---
apiVersion: v1
kind: Pod
metadata:
  name: csicephfs-demo-pod
spec:
  containers:
    - name: web-server
      image: nginx
      volumeMounts:
        - name: mypvc
          mountPath: /var/lib/www/html
  volumes:
    - name: mypvc
      persistentVolumeClaim:
        claimName: cephfs-pvc-restore        #æŒ‚è½½æ¢å¤pvc
        readOnly: false

[root@k8s-master01 examples]# kubectl apply -f csi/cephfs/pod.yaml
[root@k8s-master01 examples]# kubectl get pods
NAME                                      READY   STATUS    RESTARTS        AGE
cluster-test-84dfc9c68b-5q4ng             1/1     Running   88 (57m ago)    16d
csicephfs-demo-pod                        1/1     Running   0               24s
nfs-client-provisioner-5dbbd8d796-lhdgw   1/1     Running   5 (6h57m ago)   23h
web-6c59f8559-g5xzb                       1/1     Running   0               4h54m
web-6c59f8559-ns77q                       1/1     Running   0               4h54m
web-6c59f8559-qxb5f                       1/1     Running   0               4h54m
[root@k8s-master01 examples]# kubectl exec -it csicephfs-demo-pod -- bash
root@csicephfs-demo-pod:/# ls /var/lib/www/html/               #såˆ é™¤æ•°æ®å·²ç»æ¢å¤
1  10  2  3  4	5  6  7  8  9  index.html
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;102-pvc-å…‹éš†&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#102-pvc-å…‹éš†&#34;&gt;#&lt;/a&gt; 10.2 PVC å…‹éš†&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 examples]# kubectl get pvc
NAME                 STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
cephfs-pvc-restore   Bound    pvc-9e845f2b-df1f-450d-8aa2-f9a46db6adb6   5Gi        RWX            rook-cephfs    11m
nginx-share-pvc      Bound    pvc-4de733fe-c2fb-437b-baff-aaeba0235d54   5Gi        RWX            rook-cephfs    5h1m


[root@k8s-master01 examples]# cat csi/cephfs/pvc-clone.yaml 
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: cephfs-pvc-clone
spec:
  storageClassName: rook-cephfs      # pvc çš„ storageClass åç§°
  dataSource:
    name: nginx-share-pvc          #å…‹éš†çš„PVCåç§°
    kind: PersistentVolumeClaim
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 5Gi                 #å¤§å°ç­‰äºæ‰€å…‹éš†çš„PVCå¤§å°

[root@k8s-master01 examples]# kubectl apply -f csi/cephfs/pvc-clone.yaml

[root@k8s-master01 examples]# kubectl get pvc
NAME                 STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
cephfs-pvc-clone     Bound    pvc-0a19b65e-cb5e-4379-a7f7-e0783fcf8ddf   5Gi        RWX            rook-cephfs    22s
cephfs-pvc-restore   Bound    pvc-9e845f2b-df1f-450d-8aa2-f9a46db6adb6   5Gi        RWX            rook-cephfs    15m
nginx-share-pvc      Bound    pvc-4de733fe-c2fb-437b-baff-aaeba0235d54   5Gi        RWX            rook-cephfs    5h4m

#æŒ‚è½½å…‹éš†PVCæµ‹è¯•
[root@k8s-master01 examples]# cat csi/cephfs/pod.yaml 
---
apiVersion: v1
kind: Pod
metadata:
  name: csicephfs-demo-pod
spec:
  containers:
    - name: web-server
      image: nginx
      volumeMounts:
        - name: mypvc
          mountPath: /var/lib/www/html
  volumes:
    - name: mypvc
      persistentVolumeClaim:
        claimName: cephfs-pvc-clone      #æŒ‚è½½å…‹éš†çš„pvc
        readOnly: false

[root@k8s-master01 examples]# kubectl apply -f csi/cephfs/pod.yaml          
[root@k8s-master01 examples]# kubectl get pods
NAME                                      READY   STATUS    RESTARTS         AGE
cluster-test-84dfc9c68b-5q4ng             1/1     Running   89 (9m54s ago)   16d
csicephfs-demo-pod                        1/1     Running   0                17s
nfs-client-provisioner-5dbbd8d796-lhdgw   1/1     Running   5 (7h9m ago)     23h
web-6c59f8559-g5xzb                       1/1     Running   0                5h6m
web-6c59f8559-ns77q                       1/1     Running   0                5h6m
web-6c59f8559-qxb5f                       1/1     Running   0                5h6m

[root@k8s-master01 examples]# kubectl exec -it csicephfs-demo-pod -- bash
root@csicephfs-demo-pod:/# cat /var/lib/www/html/index.html 
hello cephfs
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;11-æµ‹è¯•æ•°æ®æ¸…ç†&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#11-æµ‹è¯•æ•°æ®æ¸…ç†&#34;&gt;#&lt;/a&gt; 11. æµ‹è¯•æ•°æ®æ¸…ç†&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;å‚è€ƒæ–‡æ¡£ï¼šhttps://rook.io/docs/rook/v1.11/Getting-Started/ceph-teardown/#delete-the-cephcluster-crd
[root@k8s-master01 ~]# kubectl delete deploy web

[root@k8s-master01 ~]# kubectl delete pods csicephfs-demo-pod

[root@k8s-master01 ~]# kubectl delete pvc --all
[root@k8s-master01 ~]# kubectl get pvc
No resources found in default namespace.
[root@k8s-master01 ~]# kubectl get pv
No resources found


[root@k8s-master01 ~]# kubectl get volumesnapshot
NAME                  READYTOUSE   SOURCEPVC         SOURCESNAPSHOTCONTENT   RESTORESIZE   SNAPSHOTCLASS                SNAPSHOTCONTENT                                    CREATIONTIME   AGE
cephfs-pvc-snapshot   true         nginx-share-pvc                           5Gi           csi-cephfsplugin-snapclass   snapcontent-bdaddb97-debe-4f42-9423-13bf1c5b5402   61m            61m
[root@k8s-master01 ~]# kubectl delete volumesnapshot cephfs-pvc-snapshot
volumesnapshot.snapshot.storage.k8s.io &amp;quot;cephfs-pvc-snapshot&amp;quot; deleted

kubectl delete -n rook-ceph cephblockpool replicapool
kubectl delete -n rook-ceph cephfilesystem myfs

kubectl delete storageclass rook-ceph-block
kubectl delete storageclass rook-cephfs
kubectl delete -f csi/cephfs/kube-registry.yaml
kubectl delete storageclass csi-cephfs

kubectl -n rook-ceph delete cephcluster rook-ceph

kubectl delete -f operator.yaml
kubectl delete -f common.yaml
kubectl delete -f crds.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;æœ¬æ–‡å‡ºè‡ªäºï¼š&lt;a href=&#34;https://edu.51cto.com/course/23845.html&#34;&gt;https://edu.51cto.com/course/23845.html&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</content>
        <category term="Kubernetes" />
        <updated>2025-04-24T13:43:19.000Z</updated>
    </entry>
    <entry>
        <id>http://ixuyong.cn/posts/3890389502.html</id>
        <title>K8SæŒä¹…åŒ–å­˜å‚¨NFS+StorageClass</title>
        <link rel="alternate" href="http://ixuyong.cn/posts/3890389502.html"/>
        <content type="html">&lt;h3 id=&#34;k8sæŒä¹…åŒ–å­˜å‚¨nfsstorageclass&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#k8sæŒä¹…åŒ–å­˜å‚¨nfsstorageclass&#34;&gt;#&lt;/a&gt; K8S æŒä¹…åŒ–å­˜å‚¨ NFS+StorageClass&lt;/h3&gt;
&lt;h4 id=&#34;1-æ­å»ºnfsæœåŠ¡å™¨&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-æ­å»ºnfsæœåŠ¡å™¨&#34;&gt;#&lt;/a&gt; 1. æ­å»º NFS æœåŠ¡å™¨&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;#æ‰€æœ‰K8SèŠ‚ç‚¹å®‰è£…nfs-utils
[root@k8s-node02 ~]# yum install nfs-utils -y    

#K8S-node02èŠ‚ç‚¹é…ç½®nfsæœåŠ¡
[root@k8s-node02 ~]# mkdir /data/nfs -p
[root@k8s-node02 ~]# cat /etc/exports
/data/nfs 192.168.1.0/24(rw,no_root_squash)
[root@k8s-node02 ~]# exportfs -arv   #NFSé…ç½®ç”Ÿæ•ˆ 
[root@k8s-node02 ~]# systemctl start nfs-server &amp;amp;&amp;amp; systemctl enable nfs-server &amp;amp;&amp;amp; systemctl status nfs-server
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2-åˆ›å»ºrbac&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-åˆ›å»ºrbac&#34;&gt;#&lt;/a&gt; 2.  åˆ›å»º RBAC&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-node02 ~]# cat 01-rbac.yaml 
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nfs-client-provisioner
  # replace with namespace where provisioner is deployed
  namespace: default
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: nfs-client-provisioner-runner
rules:
  - apiGroups: [&amp;quot;&amp;quot;]
    resources: [&amp;quot;nodes&amp;quot;]
    verbs: [&amp;quot;get&amp;quot;, &amp;quot;list&amp;quot;, &amp;quot;watch&amp;quot;]
  - apiGroups: [&amp;quot;&amp;quot;]
    resources: [&amp;quot;persistentvolumes&amp;quot;]
    verbs: [&amp;quot;get&amp;quot;, &amp;quot;list&amp;quot;, &amp;quot;watch&amp;quot;, &amp;quot;create&amp;quot;, &amp;quot;delete&amp;quot;]
  - apiGroups: [&amp;quot;&amp;quot;]
    resources: [&amp;quot;persistentvolumeclaims&amp;quot;]
    verbs: [&amp;quot;get&amp;quot;, &amp;quot;list&amp;quot;, &amp;quot;watch&amp;quot;, &amp;quot;update&amp;quot;]
  - apiGroups: [&amp;quot;storage.k8s.io&amp;quot;]
    resources: [&amp;quot;storageclasses&amp;quot;]
    verbs: [&amp;quot;get&amp;quot;, &amp;quot;list&amp;quot;, &amp;quot;watch&amp;quot;]
  - apiGroups: [&amp;quot;&amp;quot;]
    resources: [&amp;quot;events&amp;quot;]
    verbs: [&amp;quot;create&amp;quot;, &amp;quot;update&amp;quot;, &amp;quot;patch&amp;quot;]
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: run-nfs-client-provisioner
subjects:
  - kind: ServiceAccount
    name: nfs-client-provisioner
    # replace with namespace where provisioner is deployed
    namespace: default
roleRef:
  kind: ClusterRole
  name: nfs-client-provisioner-runner
  apiGroup: rbac.authorization.k8s.io
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: leader-locking-nfs-client-provisioner
  # replace with namespace where provisioner is deployed
  namespace: default
rules:
  - apiGroups: [&amp;quot;&amp;quot;]
    resources: [&amp;quot;endpoints&amp;quot;]
    verbs: [&amp;quot;get&amp;quot;, &amp;quot;list&amp;quot;, &amp;quot;watch&amp;quot;, &amp;quot;create&amp;quot;, &amp;quot;update&amp;quot;, &amp;quot;patch&amp;quot;]
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: leader-locking-nfs-client-provisioner
  # replace with namespace where provisioner is deployed
  namespace: default
subjects:
  - kind: ServiceAccount
    name: nfs-client-provisioner
    # replace with namespace where provisioner is deployed
    namespace: default
roleRef:
  kind: Role
  name: leader-locking-nfs-client-provisioner
  apiGroup: rbac.authorization.k8s.io
  
  
[root@k8s-master01 ~]# kubectl apply -f 01-rbac.yaml 
serviceaccount/nfs-client-provisioner created
clusterrole.rbac.authorization.k8s.io/nfs-client-provisioner-runner created
clusterrolebinding.rbac.authorization.k8s.io/run-nfs-client-provisioner created
role.rbac.authorization.k8s.io/leader-locking-nfs-client-provisioner created
rolebinding.rbac.authorization.k8s.io/leader-locking-nfs-client-provisioner created
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;3-åˆ›å»ºnfs-provisioner&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3-åˆ›å»ºnfs-provisioner&#34;&gt;#&lt;/a&gt; 3. åˆ›å»º nfs-provisioner&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# cat 02-nfs-provisioner.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nfs-client-provisioner
  labels:
    app: nfs-client-provisioner
  # replace with namespace where provisioner is deployed
  namespace: default
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: nfs-client-provisioner
  template:
    metadata:
      labels:
        app: nfs-client-provisioner
    spec:
      serviceAccountName: nfs-client-provisioner
      containers:
        - name: nfs-client-provisioner
          image: registry.cn-hangzhou.aliyuncs.com/old_xu/nfs-subdir-external-provisioner:v4.0.2
          volumeMounts:
            - name: nfs-client-root
              mountPath: /persistentvolumes
          env:
            - name: PROVISIONER_NAME	# nfs-provisionerçš„åç§°ï¼Œåç»­storageClassè¦ä¸è¯¥åç§°ä¸€è‡´
              value: nfzl.com/nfs
            - name: NFS_SERVER		# NFSæœåŠ¡çš„IPåœ°å€
              value: 192.168.1.75
            - name: NFS_PATH		# NFSæœåŠ¡å…±äº«çš„è·¯å¾„
              value: /data/nfs
      volumes:
        - name: nfs-client-root
          nfs:
            server: 192.168.1.75
            path: /data/nfs

[root@k8s-master01 ~]# kubectl apply -f 02-nfs-provisioner.yaml 
[root@k8s-master01 ~]# kubectl get pods
NAME                                      READY   STATUS    RESTARTS   AGE
nfs-client-provisioner-6bcc4587f8-zp8qc   1/1     Running   0          17s
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;4-åˆ›å»ºstorageclass&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4-åˆ›å»ºstorageclass&#34;&gt;#&lt;/a&gt; 4. åˆ›å»º StorageClass&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# cat 03-storageClass.yaml 
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: nfs-storage 	# pvcç”³è¯·æ—¶éœ€æ˜ç¡®æŒ‡å®šçš„storageClassåç§°
provisioner: nfzl.com/nfs        # ä¾›åº”å•†åç§°ï¼Œå¿…é¡»å’Œä¸Šé¢åˆ›å»ºçš„&amp;quot;PROVISIONER_NAME&amp;quot;å˜é‡å€¼è‡´
parameters:
  archiveOnDelete: &amp;quot;false&amp;quot;     # å¦‚æœå€¼ä¸ºfalseï¼Œåˆ é™¤PVCåä¹Ÿä¼šåˆ é™¤ç›®å½•å†…å®¹, &amp;quot;true&amp;quot;åˆ™ä¼šå¯¹æ•°æ®è¿›è¡Œä¿ç•™
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;5-åˆ›å»ºpvc&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#5-åˆ›å»ºpvc&#34;&gt;#&lt;/a&gt; 5. åˆ›å»º PVC&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# cat 04-nginx-pvc.yaml 
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: sc-pvc-001
spec:
  storageClassName: &amp;quot;nfs-storage&amp;quot;     # æ˜ç¡®æŒ‡å®šä½¿ç”¨å“ªä¸ªscçš„ä¾›åº”å•†æ¥åˆ›å»ºpv
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 1Gi                      # æ ¹æ®ä¸šåŠ¡å®é™…å¤§å°è¿›è¡Œèµ„æºç”³è¯·
      
[root@k8s-master01 ~]# kubectl apply -f 04-nginx-pvc.yaml 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/fgpaP15.png&#34; alt=&#34;1.png&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;6-æŒ‚è½½pvcæµ‹è¯•&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#6-æŒ‚è½½pvcæµ‹è¯•&#34;&gt;#&lt;/a&gt; 6. æŒ‚è½½ PVC æµ‹è¯•&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# cat 05-nginx-pod.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: nginx-sc-001
spec:
  containers:
  - name: nginx-sc-001
    image: nginx
    volumeMounts:
    - name: nginx-page
      mountPath: /usr/share/nginx/html
  volumes:
  - name: nginx-page
    persistentVolumeClaim:      
      claimName: sc-pvc-001

[root@k8s-master01 ~]# kubectl apply -f 05-nginx-pod.yaml
[root@k8s-master01 ~]# kubectl get pods -o wide
NAME                                      READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATES
nginx-sc-001                              1/1     Running   0          15s   172.16.85.244   k8s-node01   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;

[root@k8s-master01 ~]# curl 172.16.85.244
hello world
&lt;/code&gt;&lt;/pre&gt;
</content>
        <category term="Kubernetes" />
        <updated>2025-04-23T12:08:26.000Z</updated>
    </entry>
    <entry>
        <id>http://ixuyong.cn/posts/722512536.html</id>
        <title>K8sç»†ç²’åº¦æƒé™æ§åˆ¶RBAC</title>
        <link rel="alternate" href="http://ixuyong.cn/posts/722512536.html"/>
        <content type="html">&lt;h3 id=&#34;k8sç»†ç²’åº¦æƒé™æ§åˆ¶rbac&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#k8sç»†ç²’åº¦æƒé™æ§åˆ¶rbac&#34;&gt;#&lt;/a&gt; K8s ç»†ç²’åº¦æƒé™æ§åˆ¶ RBAC&lt;/h3&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/KCZPPkv.jpeg&#34; alt=&#34;rbac.jpg&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;1-åˆ›å»ºä¸åŒæƒé™çš„clusterrole&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-åˆ›å»ºä¸åŒæƒé™çš„clusterrole&#34;&gt;#&lt;/a&gt; 1. åˆ›å»ºä¸åŒæƒé™çš„ clusterrole&lt;/h4&gt;
&lt;h5 id=&#34;11-å‘½ä»¤ç©ºé—´åªè¯»namespace-readonly&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#11-å‘½ä»¤ç©ºé—´åªè¯»namespace-readonly&#34;&gt;#&lt;/a&gt; 1.1 å‘½ä»¤ç©ºé—´åªè¯» namespace-readonly&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;# cat namespace-readonly.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: namespace-readonly
rules:
- apiGroups:
  - &amp;quot;&amp;quot;
  resources:
  - namespaces
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - metrics.k8s.io
  resources:
  - pods
  verbs:
  - get
  - list
  - watch
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;12-èµ„æºæŸ¥çœ‹resource-readonly&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#12-èµ„æºæŸ¥çœ‹resource-readonly&#34;&gt;#&lt;/a&gt; 1.2 èµ„æºæŸ¥çœ‹ resource-readonly&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;# cat resource-readonly.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: resource-readonly
rules:
- apiGroups:
  - &amp;quot;&amp;quot;
  resources:
  - configmaps
  - endpoints
  - persistentvolumeclaims
  - pods
  - replicationcontrollers
  - replicationcontrollers/scale
  - serviceaccounts
  - services
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - &amp;quot;&amp;quot;
  resources:
  - bindings
  - events
  - limitranges
  - namespaces/status
  - pods/log
  - pods/status
  - replicationcontrollers/status
  - resourcequotas
  - resourcequotas/status
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - &amp;quot;&amp;quot;
  resources:
  - namespaces
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - apps
  resources:
  - controllerrevisions
  - daemonsets
  - deployments
  - deployments/scale
  - replicasets
  - replicasets/scale
  - statefulsets
  - statefulsets/scale
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - autoscaling
  resources:
  - horizontalpodautoscalers
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - batch
  resources:
  - cronjobs
  - jobs
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - extensions
  resources:
  - daemonsets
  - deployments
  - deployments/scale
  - ingresses
  - networkpolicies
  - replicasets
  - replicasets/scale
  - replicationcontrollers/scale
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - policy
  resources:
  - poddisruptionbudgets
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - networking.k8s.io
  resources:
  - networkpolicies
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - metrics.k8s.io
  resources:
  - pods
  verbs:
  - get
  - list
  - watch
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;13-podæ—¥å¿—æŸ¥çœ‹&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#13-podæ—¥å¿—æŸ¥çœ‹&#34;&gt;#&lt;/a&gt; 1.3 pod æ—¥å¿—æŸ¥çœ‹&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;# cat pod-log.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: pod-log
rules:
- apiGroups:
  - &amp;quot;&amp;quot;
  resources:
  - pods
  - pods/log
  verbs:
  - get
  - list
  - watch
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;14-podåˆ é™¤&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#14-podåˆ é™¤&#34;&gt;#&lt;/a&gt; 1.4 Pod åˆ é™¤&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;# cat pod-delete.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: pod-delete
rules:
- apiGroups:
  - &amp;quot;&amp;quot;
  resources:
  - pods
  verbs:
  - get
  - list
  - delete
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;15-podæ‰§è¡Œ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#15-podæ‰§è¡Œ&#34;&gt;#&lt;/a&gt; 1.5 Pod æ‰§è¡Œ&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;# cat pod-exec.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: pod-exec
rules:
- apiGroups:
  - &amp;quot;&amp;quot;
  resources:
  - pods
  verbs:
  - get
  - list
- apiGroups:
  - &amp;quot;&amp;quot;
  resources:
  - pods/exec
  verbs:
  - create
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;16-åˆ›å»ºä¸åŒæƒé™çš„clusterrole&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#16-åˆ›å»ºä¸åŒæƒé™çš„clusterrole&#34;&gt;#&lt;/a&gt; 1.6 åˆ›å»ºä¸åŒæƒé™çš„ clusterrole&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 rbac]# kubectl apply -f .
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2-åˆ›å»ºserviceaccount&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-åˆ›å»ºserviceaccount&#34;&gt;#&lt;/a&gt; 2. åˆ›å»º serviceaccount&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;# kubectl create ns kube-users

# kubectl create sa test -n kube-users   
# kubectl create sa dev -n kube-users    
# kubectl create sa ops -n kube-users    

# kubectl create token test -n kube-users
# kubectl create token dev -n kube-users
# kubectl create token ops -n kube-users
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;3-åˆ›å»ºclusterrolebinding&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3-åˆ›å»ºclusterrolebinding&#34;&gt;#&lt;/a&gt; 3. åˆ›å»º ClusterRoleBinding&lt;/h4&gt;
&lt;h5 id=&#34;31-ç»‘å®šå…¨å±€å‘½åç©ºé—´æŸ¥çœ‹æƒé™&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#31-ç»‘å®šå…¨å±€å‘½åç©ºé—´æŸ¥çœ‹æƒé™&#34;&gt;#&lt;/a&gt; 3.1 ç»‘å®šå…¨å±€å‘½åç©ºé—´æŸ¥çœ‹æƒé™&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;# cat clusterrolebinding-namespace-readonly.yaml 
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: clusterrolebinding-namespace-readonly 
subjects:
- kind: Group
  name: system:serviceaccounts:kube-users
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: namespace-readonly
  apiGroup: rbac.authorization.k8s.io
  
# kubectl apply -f clusterrolebinding-namespace-readonly.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;32-ç»‘å®šæ—¥å¿—æŸ¥çœ‹æƒé™&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#32-ç»‘å®šæ—¥å¿—æŸ¥çœ‹æƒé™&#34;&gt;#&lt;/a&gt; 3.2 ç»‘å®šæ—¥å¿—æŸ¥çœ‹æƒé™&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;# kubectl create rolebinding ops-pod-log --clusterrole=pod-log --serviceaccount=kube-users:ops --namespace=projectA
# kubectl create rolebinding ops-pod-log --clusterrole=pod-log --serviceaccount=kube-users:ops --namespace=projectB
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;33-ç»‘å®šèµ„æºæŸ¥çœ‹æƒé™&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#33-ç»‘å®šèµ„æºæŸ¥çœ‹æƒé™&#34;&gt;#&lt;/a&gt; 3.3 ç»‘å®šèµ„æºæŸ¥çœ‹æƒé™&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;# kubectl create rolebinding ops-resource-readonly --clusterrole=resource-readonly --serviceaccount=kube-users:ops --namespace=projectA
# kubectl create rolebinding ops-resource-readonly --clusterrole=resource-readonly --serviceaccount=kube-users:ops --namespace=projectB
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;34-ç»‘å®špodæ‰§è¡Œæƒé™&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#34-ç»‘å®špodæ‰§è¡Œæƒé™&#34;&gt;#&lt;/a&gt; 3.4 ç»‘å®š Pod æ‰§è¡Œæƒé™&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;# kubectl create rolebinding ops-pod-exec --clusterrole=pod-exec --serviceaccount=kube-users:ops --namespace=projectA
# kubectl create rolebinding ops-pod-exec --clusterrole=pod-exec --serviceaccount=kube-users:ops --namespace=projectB
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;35-ç»‘å®špodåˆ é™¤æƒé™&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#35-ç»‘å®špodåˆ é™¤æƒé™&#34;&gt;#&lt;/a&gt; 3.5 ç»‘å®š Pod åˆ é™¤æƒé™&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;# kubectl create rolebinding ops-pod-delete --clusterrole=pod-delete --serviceaccount=kube-users:ops --namespace=projectA
# kubectl create rolebinding ops-pod-delete --clusterrole=pod-delete --serviceaccount=kube-users:ops --namespace=projectB
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;æœ¬æ–‡å‡ºè‡ªäºï¼š&lt;a href=&#34;https://edu.51cto.com/course/23845.html&#34;&gt;https://edu.51cto.com/course/23845.html&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</content>
        <category term="Kubernetes" />
        <updated>2025-04-23T12:04:03.000Z</updated>
    </entry>
    <entry>
        <id>http://ixuyong.cn/posts/176412055.html</id>
        <title>K8så‡†å…¥æ§åˆ¶ResourceQuotaã€LimitRangeã€QoSæœåŠ¡è´¨é‡</title>
        <link rel="alternate" href="http://ixuyong.cn/posts/176412055.html"/>
        <content type="html">&lt;h3 id=&#34;k8så‡†å…¥æ§åˆ¶resourcequota-limitrange-qosæœåŠ¡è´¨é‡&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#k8så‡†å…¥æ§åˆ¶resourcequota-limitrange-qosæœåŠ¡è´¨é‡&#34;&gt;#&lt;/a&gt; K8s å‡†å…¥æ§åˆ¶ ResourceQuotaã€LimitRangeã€QoS æœåŠ¡è´¨é‡&lt;/h3&gt;
&lt;h4 id=&#34;1-resourcequotaé…ç½®è§£æ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-resourcequotaé…ç½®è§£æ&#34;&gt;#&lt;/a&gt; 1. ResourceQuota é…ç½®è§£æ&lt;/h4&gt;
&lt;p&gt;ResourceQuotas å®ç°èµ„æºé…é¢ï¼Œé¿å…è¿‡åº¦åˆ›å»ºèµ„æºï¼Œé’ˆå¯¹ namespace è¿›è¡Œé™åˆ¶ã€‚cpu å†…å­˜åˆ™æ˜¯æ ¹æ® pod é…ç½®çš„ resources æ€»é¢è¿›è¡Œé™åˆ¶ï¼Œå¦‚æœæ²¡æœ‰é…ç½® resources å‚æ•°åˆ™æ— æ³•é™åˆ¶ã€‚&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: ResourceQuota
metadata:
  name: resourcequota-test
  namespace: test
  labels:
    app: resourcequota
spec:
  hard:
    pods: 3
    requests.cpu: 3
    requests.memory: 512Mi
    limits.cpu: 8
    limits.memory: 16Gi
    configmaps: 201
    requests.storage: 40Gi
    persistentvolumeclaims: 20
    replicationcontrollers: 20
    secrets: 20
    services: 50
    services.loadbalancers: &amp;quot;2&amp;quot;
    services.nodeports: &amp;quot;10&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;podsï¼šé™åˆ¶æœ€å¤šå¯åŠ¨ Pod çš„ä¸ªæ•°&lt;/li&gt;
&lt;li&gt;requests.cpuï¼šé™åˆ¶æœ€é«˜ CPU è¯·æ±‚æ•°&lt;/li&gt;
&lt;li&gt;requests.memoryï¼šé™åˆ¶æœ€é«˜å†…å­˜çš„è¯·æ±‚æ•°&lt;/li&gt;
&lt;li&gt;limits.cpuï¼šé™åˆ¶æœ€é«˜ CPU çš„ limit ä¸Šé™&lt;/li&gt;
&lt;li&gt;limits.memoryï¼šé™åˆ¶æœ€é«˜å†…å­˜çš„ limit ä¸Šé™&lt;/li&gt;
&lt;li&gt;servicesï¼šé™åˆ¶ services æ•°é‡&lt;/li&gt;
&lt;li&gt;services.nodeportsï¼šé™åˆ¶ services ä¸­ nodeport ç±»å‹ service æ•°é‡&lt;/li&gt;
&lt;li&gt;services.loadbalancersï¼šé™åˆ¶ services ä¸­ loadbalancers ç±»å‹ service æ•°é‡&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;11-resourcequotaé…ç½®ç¤ºä¾‹&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#11-resourcequotaé…ç½®ç¤ºä¾‹&#34;&gt;#&lt;/a&gt; 1.1 ResourceQuota é…ç½®ç¤ºä¾‹&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;#1.é™åˆ¶testå‘½åç©ºé—´podsæ•°é‡é‡ä¸º3ã€configmapæ•°é‡ä¸º2
[root@k8s-master01 resourcequota]# cat rq-test.yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: resourcequota-test
  namespace: test
  labels:
    app: resourcequota
spec:
  hard:
    pods: 3
#    requests.cpu: 3
#    requests.memory: 512Mi
#    limits.cpu: 8
#    limits.memory: 16Gi
    configmaps: 2
#    requests.storage: 40Gi
#    persistentvolumeclaims: 20
#    replicationcontrollers: 20
#    secrets: 20
#    services: 50
#    services.loadbalancers: &amp;quot;2&amp;quot;
#    services.nodeports: &amp;quot;10&amp;quot;

#2.testå‘½åç©ºé—´å·²åˆ›å»ºconfigmapæ•°é‡ä¸º1,é™åˆ¶æ•°é‡ä¸º2
[root@k8s-master01 resourcequota]# kubectl get resourcequota -n test
NAME                 AGE   REQUEST                      LIMIT
resourcequota-test   61s   configmaps: 1/2, pods: 0/3  

#3.testå‘½åç©ºé—´åˆ›å»ºç¬¬2ä¸ªconfigmapæ—¶æ­£å¸¸ï¼Œåˆ›å»ºç¬¬3ä¸ªconfigmapæ—¶æŠ¥é”™
[root@k8s-master01 resourcequota]# kubectl create cm rq-cm1 -n test --from-literal=key1=value1
[root@k8s-master01 resourcequota]# kubectl create cm rq-cm2 -n test --from-literal=key2=value2
error: failed to create configmap: configmaps &amp;quot;rq-cm2&amp;quot; is forbidden: exceeded quota: resourcequota-test, requested: configmaps=1, used: configmaps=2, limited: configmaps=2
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2-limitrangeé…ç½®è§£æ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-limitrangeé…ç½®è§£æ&#34;&gt;#&lt;/a&gt; 2. LimitRange é…ç½®è§£æ&lt;/h4&gt;
&lt;p&gt;è™½ç„¶ ResourceQuota å¯ä»¥å®ç°èµ„æºé…é¢ï¼Œå¯ä»¥é™åˆ¶æŸä¸ªå‘½åç©ºé—´å†…å­˜å’Œ CPUï¼Œä½†æ˜¯å¦‚æœåˆ›å»ºçš„ Pod éƒ½æ²¡æœ‰é…ç½® resources å‚æ•°åˆ™æ— æ³•é™åˆ¶ã€‚å¦‚æœé…ç½® LimitRangeï¼ŒPod æ²¡æœ‰é…ç½® resources æƒ…å†µä¸‹ï¼Œåˆ›å»ºçš„ Pod ä¼šæ ¹æ® LimitRange é…ç½®è‡ªåŠ¨æ·»åŠ  CPU å†…å­˜é…ç½®ï¼Œå¹¶ä¸”å¯ä»¥é™åˆ¶ resources å‚æ•°æœ€å¤§é…ç½®å’Œæœ€å°é…ç½®ï¼ŒLimitRange é’ˆå¯¹ Pod è¿›è¡Œé™åˆ¶ã€‚&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: LimitRange
metadata:
  name: cpu-mem-limit-range
  namespace: test
spec:
  limits:
  - default:         #é™åˆ¶CPUå†…å­˜é»˜è®¤limitsé…ç½®
      cpu: 1
      memory: 512Mi
    defaultRequest:  #é™åˆ¶CPUå†…å­˜é»˜è®¤requesté…ç½®
      cpu: 0.5
      memory: 256Mi
    max:                #é™åˆ¶CPUå†…å­˜æœ€å¤§é…ç½® 
      cpu: &amp;quot;4000m&amp;quot;
      memory: 4Gi
    min:                #é™åˆ¶CPUå†…å­˜æœ€å°é…ç½®
      cpu: &amp;quot;100m&amp;quot;
      memory: 100Mi
    type: Container
  - type: PersistentVolumeClaim    #é™åˆ¶pvcå¤§å°
    max:
      storage: 2Gi
    min:
      storage: 1Gi
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;defaultï¼šé»˜è®¤ limits é…ç½®&lt;/li&gt;
&lt;li&gt;defaultRequestï¼šé»˜è®¤ requests é…ç½®&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;21-é…ç½®é»˜è®¤çš„requestså’Œlimits&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#21-é…ç½®é»˜è®¤çš„requestså’Œlimits&#34;&gt;#&lt;/a&gt; 2.1 é…ç½®é»˜è®¤çš„ requests å’Œ limits&lt;/h5&gt;
&lt;p&gt;Pod æ²¡æœ‰é…ç½® resources æƒ…å†µä¸‹ï¼Œåˆ›å»ºçš„ Pod ä¼šæ ¹æ® LimitRange é…ç½®è‡ªåŠ¨æ·»åŠ  CPU å†…å­˜é…ç½®ã€‚&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#1.åˆ›å»ºLimitRange
[root@k8s-master01 resourcequota]# cat limitrange.yaml 
apiVersion: v1
kind: LimitRange
metadata:
  name: cpu-mem-limit-range
  namespace: test
spec:
  limits:
  - default:         #é™åˆ¶CPUå†…å­˜é»˜è®¤limitsé…ç½®
      cpu: 1
      memory: 512Mi
    defaultRequest:  #é™åˆ¶CPUå†…å­˜é»˜è®¤requesté…ç½®
      cpu: 0.5
      memory: 256Mi
    max:                #é™åˆ¶CPUå†…å­˜æœ€å¤§é…ç½® 
      cpu: &amp;quot;4000m&amp;quot;
      memory: 4Gi
    min:                #é™åˆ¶CPUå†…å­˜æœ€å°é…ç½®
      cpu: &amp;quot;100m&amp;quot;
      memory: 100Mi
    type: Container
  - type: PersistentVolumeClaim    #é™åˆ¶pvcå¤§å°
    max:
      storage: 2Gi
    min:
      storage: 1Gi  
      
[root@k8s-master01 resourcequota]# kubectl apply -f limitrange.yaml
[root@k8s-master01 resourcequota]# kubectl get limitrange -n test
NAME                  CREATED AT
cpu-mem-limit-range   2025-04-23T07:55:03Z

#2.åˆ›å»ºdeployment, æŸ¥çœ‹æ˜¯å¦ä¼šæ ¹æ®LimitRangeè‡ªåŠ¨æ·»åŠ CPUå†…å­˜é…ç½®
[root@k8s-master01 resourcequota]# cat deploy-limitrange.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deploy-limirange
  labels:
    app: deploy-limirange
  namespace: test
spec:
  selector:
    matchLabels:
      app: deploy-limirange
  replicas: 1
  template:
    metadata:
      labels:
        app: deploy-limirange
    spec:
      restartPolicy: Always
      containers:
        - name: deploy-limirange
          image: nginx
          imagePullPolicy: IfNotPresent

[root@k8s-master01 resourcequota]# kubectl get pod -n test
NAME                                READY   STATUS    RESTARTS   AGE
deploy-limirange-854c9545ff-grpxr   1/1     Running   0          39s
[root@k8s-master01 resourcequota]# kubectl get pod -n test -oyaml
...
  spec:
    containers:
    - image: nginx
      imagePullPolicy: IfNotPresent
      name: deploy-limirange
      resources:
        limits:
          cpu: &amp;quot;1&amp;quot;
          memory: 512Mi
        requests:
          cpu: 500m
          memory: 256Mi
...
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;22-é™åˆ¶requestså’ŒlimitsèŒƒå›´&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#22-é™åˆ¶requestså’ŒlimitsèŒƒå›´&#34;&gt;#&lt;/a&gt; 2.2 é™åˆ¶ requests å’Œ limits èŒƒå›´&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;#1.åˆ›å»ºLimitRange
[root@k8s-master01 resourcequota]# cat limitrange.yaml 
apiVersion: v1
kind: LimitRange
metadata:
  name: cpu-mem-limit-range
  namespace: test
spec:
  limits:
  - default:         #é™åˆ¶CPUå†…å­˜é»˜è®¤limitsé…ç½®
      cpu: 1
      memory: 512Mi
    defaultRequest:  #é™åˆ¶CPUå†…å­˜é»˜è®¤requesté…ç½®
      cpu: 0.5
      memory: 256Mi
    max:                #é™åˆ¶CPUå†…å­˜æœ€å¤§é…ç½® 
      cpu: &amp;quot;4000m&amp;quot;
      memory: 4Gi
    min:                #é™åˆ¶CPUå†…å­˜æœ€å°é…ç½®
      cpu: &amp;quot;100m&amp;quot;
      memory: 100Mi
    type: Container
  - type: PersistentVolumeClaim    #é™åˆ¶pvcå¤§å°
    max:
      storage: 2Gi
    min:
      storage: 1Gi  

#2.åˆ›å»ºdeployment, CPUå†…å­˜limitså’Œrequestsé«˜äº/ä½äºLimitRangeCPUå†…å­˜maxã€miné…ç½®
[root@k8s-master01 resourcequota]# cat deploy-limitrange.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deploy-limirange
  labels:
    app: deploy-limirange
  namespace: test
spec:
  selector:
    matchLabels:
      app: deploy-limirange
  replicas: 1
  template:
    metadata:
      labels:
        app: deploy-limirange
    spec:
      restartPolicy: Always
      containers:
        - name: deploy-limirange
          image: nginx
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              memory: 8096Mi
              cpu: 5
            requests:
              memory: 64Mi
              cpu: 10m

#3.ç”±äºåˆ›å»ºdeployment, CPUå†…å­˜limitså’Œrequestsé«˜äº/ä½äºLimitRangeCPUå†…å­˜maxã€miné…ç½®ï¼Œpodæ²¡æœ‰åˆ›å»º
[root@k8s-master01 resourcequota]# kubectl create -f deploy-limitrange.yaml 

[root@k8s-master01 resourcequota]# kubectl get deploy deploy-limirange -n test
NAME               READY   UP-TO-DATE   AVAILABLE   AGE
deploy-limirange   0/1     0            0           2m7s
[root@k8s-master01 resourcequota]# kubectl get pods -n test

[root@k8s-master01 resourcequota]# kubectl describe rs deploy-limirange-54c5d69b4b -n test
Name:           deploy-limirange-54c5d69b4b
Namespace:      test
Selector:       app=deploy-limirange,pod-template-hash=54c5d69b4b
Labels:         app=deploy-limirange
                pod-template-hash=54c5d69b4b
Annotations:    deployment.kubernetes.io/desired-replicas: 1
                deployment.kubernetes.io/max-replicas: 2
                deployment.kubernetes.io/revision: 1
Controlled By:  Deployment/deploy-limirange
Replicas:       0 current / 1 desired
Pods Status:    0 Running / 0 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:  app=deploy-limirange
           pod-template-hash=54c5d69b4b
  Containers:
   deploy-limirange:
    Image:      nginx
    Port:       &amp;lt;none&amp;gt;
    Host Port:  &amp;lt;none&amp;gt;
    Limits:
      cpu:     5
      memory:  8096Mi
    Requests:
      cpu:         10m
      memory:      64Mi
    Environment:   &amp;lt;none&amp;gt;
    Mounts:        &amp;lt;none&amp;gt;
  Volumes:         &amp;lt;none&amp;gt;
  Node-Selectors:  &amp;lt;none&amp;gt;
  Tolerations:     &amp;lt;none&amp;gt;
Conditions:
  Type             Status  Reason
  ----             ------  ------
  ReplicaFailure   True    FailedCreate
Events:
  Type     Reason        Age                 From                   Message
  ----     ------        ----                ----                   -------
  Warning  FailedCreate  3m8s                replicaset-controller  Error creating: pods &amp;quot;deploy-limirange-54c5d69b4b-zxhzk&amp;quot; is forbidden: [minimum cpu usage per Container is 100m, but request is 10m, minimum memory usage per Container is 100Mi, but request is 64Mi, maximum cpu usage per Container is 4, but limit is 5, maximum memory usage per Container is 4Gi, but limit is 8096Mi]
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;23-é™åˆ¶å­˜å‚¨ç©ºé—´å¤§å°&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#23-é™åˆ¶å­˜å‚¨ç©ºé—´å¤§å°&#34;&gt;#&lt;/a&gt; 2.3 é™åˆ¶å­˜å‚¨ç©ºé—´å¤§å°&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;#1.åˆ›å»ºLimitRange
[root@k8s-master01 resourcequota]# cat limitrange.yaml 
apiVersion: v1
kind: LimitRange
metadata:
  name: cpu-mem-limit-range
  namespace: test
spec:
  limits:
  - default:         #é™åˆ¶CPUå†…å­˜é»˜è®¤limitsé…ç½®
      cpu: 1
      memory: 512Mi
    defaultRequest:  #é™åˆ¶CPUå†…å­˜é»˜è®¤requesté…ç½®
      cpu: 0.5
      memory: 256Mi
    max:                #é™åˆ¶CPUå†…å­˜æœ€å¤§é…ç½® 
      cpu: &amp;quot;4000m&amp;quot;
      memory: 4Gi
    min:                #é™åˆ¶CPUå†…å­˜æœ€å°é…ç½®
      cpu: &amp;quot;100m&amp;quot;
      memory: 100Mi
    type: Container
  - type: PersistentVolumeClaim    #é™åˆ¶pvcå¤§å°
    max:
      storage: 2Gi
    min:
      storage: 1Gi  
  
#2.ç”±äºåˆ›å»ºçš„pvcå¤§äº2Gï¼Œæ‰€ä»¥æŠ¥é”™  
[root@k8s-master01 ~]# cat pvc.yaml 
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: sc-pvc-001
spec:
  storageClassName: &amp;quot;nfs-storage&amp;quot;     # æ˜ç¡®æŒ‡å®šä½¿ç”¨å“ªä¸ªscçš„ä¾›åº”å•†æ¥åˆ›å»ºpv
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 3Gi                      # æ ¹æ®ä¸šåŠ¡å®é™…å¤§å°è¿›è¡Œèµ„æºç”³è¯·  
[root@k8s-master01 ~]# kubectl create -f pvc.yaml -n test
Error from server (Forbidden): error when creating &amp;quot;pvc.yaml&amp;quot;: persistentvolumeclaims &amp;quot;sc-pvc-001&amp;quot; is forbidden: maximum storage usage per PersistentVolumeClaim is 2Gi, but request is 3Gi
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;3-æœåŠ¡è´¨é‡-qos&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3-æœåŠ¡è´¨é‡-qos&#34;&gt;#&lt;/a&gt; 3. æœåŠ¡è´¨é‡ QoS&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Guaranteedï¼šæœ€é«˜æœåŠ¡è´¨é‡ï¼Œå½“å®¿ä¸»æœºå†…å­˜ä¸å¤Ÿæ—¶ï¼Œä¼šå…ˆ kill æ‰ QoS ä¸º BestEffort å’Œ Burstable çš„ Podï¼Œå¦‚æœå†…å­˜è¿˜æ˜¯ä¸å¤Ÿï¼Œæ‰ä¼š kill æ‰ QoS ä¸º Guaranteedï¼Œè¯¥çº§åˆ« Pod çš„èµ„æºå ç”¨é‡ä¸€èˆ¬æ¯”è¾ƒæ˜ç¡®ï¼Œå³ requests çš„ cpu å’Œ memory å’Œ limits çš„ cpu å’Œ memory é…ç½®çš„ä¸€è‡´ã€‚&lt;/li&gt;
&lt;li&gt;Burstableï¼š æœåŠ¡è´¨é‡ä½äº Guaranteedï¼Œå½“å®¿ä¸»æœºå†…å­˜ä¸å¤Ÿæ—¶ï¼Œä¼šå…ˆ kill æ‰ QoS ä¸º BestEffort çš„ Podï¼Œå¦‚æœå†…å­˜è¿˜æ˜¯ä¸å¤Ÿä¹‹åå°±ä¼š kill æ‰ QoS çº§åˆ«ä¸º Burstable çš„ Podï¼Œç”¨æ¥ä¿è¯ QoS è´¨é‡ä¸º Guaranteed çš„ Podï¼Œè¯¥çº§åˆ« Pod ä¸€èˆ¬çŸ¥é“æœ€å°èµ„æºä½¿ç”¨é‡ï¼Œä½†æ˜¯å½“æœºå™¨èµ„æºå……è¶³æ—¶ï¼Œè¿˜æ˜¯æƒ³å°½å¯èƒ½çš„ä½¿ç”¨æ›´å¤šçš„èµ„æºï¼Œå³ limits å­—æ®µçš„ cpu å’Œ memory å¤§äº requests çš„ cpu å’Œ memory çš„é…ç½®ã€‚&lt;/li&gt;
&lt;li&gt;BestEffortï¼šå°½åŠ›è€Œä¸ºï¼Œå½“å®¿ä¸»æœºå†…å­˜ä¸å¤Ÿæ—¶ï¼Œé¦–å…ˆ kill çš„å°±æ˜¯è¯¥ QoS çš„ Podï¼Œç”¨ä»¥ä¿è¯ Burstable å’Œ Guaranteed çº§åˆ«çš„ Pod æ­£å¸¸è¿è¡Œã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;31-å®ç°qosä¸ºguaranteedçš„pod&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#31-å®ç°qosä¸ºguaranteedçš„pod&#34;&gt;#&lt;/a&gt; 3.1 å®ç° QoS ä¸º Guaranteed çš„ Pod&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Pod ä¸­çš„æ¯ä¸ªå®¹å™¨å¿…é¡»æŒ‡å®š limits.memory å’Œ requests.memoryï¼Œå¹¶ä¸”ä¸¤è€…éœ€è¦ç›¸ç­‰ï¼›&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pod ä¸­çš„æ¯ä¸ªå®¹å™¨å¿…é¡»æŒ‡å®š limits.cpu å’Œ limits.memoryï¼Œå¹¶ä¸”ä¸¤è€…éœ€è¦ç›¸ç­‰ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deploy
  labels:
    app: nginx-deploy
  namespace: default
spec:
  selector:
    matchLabels:
      app: nginx-deploy
  replicas: 1
  template:
    metadata:
      labels:
        app: nginx-deploy
    spec:
      restartPolicy: Always
      containers:
        - name: nginx-deploy
          image: nginx
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              memory: 1024Mi
              cpu: 1
            requests:
              memory: 1024Mi
              cpu: 1
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;32-å®ç°qosä¸ºburstableçš„pod&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#32-å®ç°qosä¸ºburstableçš„pod&#34;&gt;#&lt;/a&gt; 3.2 å®ç° QoS ä¸º Burstable çš„ Pod&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Pod ä¸ç¬¦åˆ Guaranteed çš„é…ç½®è¦æ±‚ï¼›&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pod ä¸­è‡³å°‘æœ‰ä¸€ä¸ªå®¹å™¨é…ç½®äº† requests.cpu æˆ– requests.memoryã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deploy
  labels:
    app: nginx-deploy
  namespace: default
spec:
  selector:
    matchLabels:
      app: nginx-deploy
  replicas: 1
  template:
    metadata:
      labels:
        app: nginx-deploy
    spec:
      restartPolicy: Always
      containers:
        - name: nginx-deploy
          image: nginx
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              memory: 1024Mi
              cpu: 1
            requests:
              memory: 128Mi
              cpu: 100m
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;33-å®ç°qosä¸ºbesteffortçš„pod&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#33-å®ç°qosä¸ºbesteffortçš„pod&#34;&gt;#&lt;/a&gt; 3.3 å®ç° QoS ä¸º BestEffort çš„ Pod&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;ä¸è®¾ç½® resources å‚æ•°&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deploy
  labels:
    app: nginx-deploy
  namespace: default
spec:
  selector:
    matchLabels:
      app: nginx-deploy
  replicas: 1
  template:
    metadata:
      labels:
        app: nginx-deploy
    spec:
      restartPolicy: Always
      containers:
        - name: nginx-deploy
          image: nginx
          imagePullPolicy: IfNotPresent
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;æœ¬æ–‡å‡ºè‡ªäºï¼š&lt;a href=&#34;https://edu.51cto.com/course/23845.html&#34;&gt;https://edu.51cto.com/course/23845.html&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</content>
        <category term="Kubernetes" />
        <updated>2025-04-23T11:55:19.000Z</updated>
    </entry>
    <entry>
        <id>http://ixuyong.cn/posts/312010518.html</id>
        <title>K8säº²å’ŒåŠ›Affinity</title>
        <link rel="alternate" href="http://ixuyong.cn/posts/312010518.html"/>
        <content type="html">&lt;h3 id=&#34;k8säº²å’ŒåŠ›affinity&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#k8säº²å’ŒåŠ›affinity&#34;&gt;#&lt;/a&gt; K8s äº²å’ŒåŠ› Affinity&lt;/h3&gt;
&lt;p&gt;Pod å’ŒèŠ‚ç‚¹ä¹‹é—´çš„å…³ç³»ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;æŸäº› Pod ä¼˜å…ˆé€‰æ‹©æœ‰ ssd=true æ ‡ç­¾çš„èŠ‚ç‚¹ï¼Œå¦‚æœæ²¡æœ‰åœ¨è€ƒè™‘éƒ¨ç½²åˆ°å…¶å®ƒèŠ‚ç‚¹ï¼›&lt;/li&gt;
&lt;li&gt;æŸäº› Pod éœ€è¦éƒ¨ç½²åœ¨ ssd=true å’Œ type=physical çš„èŠ‚ç‚¹ä¸Šï¼Œä½†æ˜¯ä¼˜å…ˆéƒ¨ç½²åœ¨ ssd=true çš„èŠ‚ç‚¹ä¸Šã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Pod å’Œ Pod ä¹‹é—´çš„å…³ç³»ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;åŒä¸€ä¸ªåº”ç”¨çš„ Pod ä¸åŒçš„å‰¯æœ¬æˆ–è€…åŒä¸€ä¸ªé¡¹ç›®çš„åº”ç”¨å°½é‡æˆ–å¿…é¡»ä¸éƒ¨ç½²åœ¨åŒä¸€ä¸ªèŠ‚ç‚¹æˆ–è€…ç¬¦åˆæŸä¸ªæ ‡ç­¾çš„ä¸€ç±»èŠ‚ç‚¹ä¸Šæˆ–è€…ä¸åŒçš„åŒºåŸŸï¼›&lt;/li&gt;
&lt;li&gt;ç›¸äº’ä¾èµ–çš„ä¸¤ä¸ª Pod å°½é‡æˆ–å¿…é¡»éƒ¨ç½²åœ¨åŒä¸€ä¸ªèŠ‚ç‚¹ä¸Šæˆ–è€…åŒä¸€ä¸ªåŸŸå†…ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;1-affinityåˆ†ç±»&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-affinityåˆ†ç±»&#34;&gt;#&lt;/a&gt; 1. Affinity åˆ†ç±»&lt;/h4&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/hTd0wmD.png&#34; alt=&#34;1.png&#34; /&gt;&lt;/p&gt;
&lt;h4 id=&#34;2-èŠ‚ç‚¹äº²å’ŒåŠ›é…ç½®è¯¦è§£&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-èŠ‚ç‚¹äº²å’ŒåŠ›é…ç½®è¯¦è§£&#34;&gt;#&lt;/a&gt; 2. èŠ‚ç‚¹äº²å’ŒåŠ›é…ç½®è¯¦è§£&lt;/h4&gt;
&lt;h5 id=&#34;21-ç¡¬äº²å’ŒåŠ›required&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#21-ç¡¬äº²å’ŒåŠ›required&#34;&gt;#&lt;/a&gt; 2.1 ç¡¬äº²å’ŒåŠ› required&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;# cat nginx-deploy.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deploy
  labels:
    app: nginx-deploy
  annotations:
    app: nginx-deploy
  namespace: default
spec:
  selector:
    matchLabels:
      app: nginx-deploy
  replicas: 5
  template:
    metadata:
      labels:
        app: nginx-deploy
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: kubernetes.io/hostname
                    operator: In
                    values:
                      - k8s-node01
                      - k8s-node02
      restartPolicy: Always
      containers:
        - name: nginx-deploy
          image: nginx:latest
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              memory: 1024Mi
              cpu: 1
            requests:
              memory: 128Mi
              cpu: 100m
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;requiredDuringSchedulingIgnoredDuringExecutionï¼šç¡¬äº²å’ŒåŠ›é…ç½®&lt;/li&gt;
&lt;li&gt;nodeSelectorTermsï¼šèŠ‚ç‚¹é€‰æ‹©å™¨é…ç½®ï¼Œå¯ä»¥é…ç½®å¤šä¸ª matchExpressionsï¼ˆæ»¡è¶³å…¶ä¸€å³å¯ï¼‰&lt;/li&gt;
&lt;li&gt;matchExpressionsï¼šmatchExpressions ä¸‹å¯ä»¥é…ç½®å¤šä¸ª keyã€valuesï¼ˆéƒ½éœ€è¦æ»¡è¶³ï¼‰ï¼Œå…¶ä¸­ values å¯ä»¥é…ç½®å¤šä¸ªï¼ˆæ»¡è¶³å…¶ä¸€å³å¯ï¼‰&lt;/li&gt;
&lt;li&gt;operatorï¼š
&lt;ul&gt;
&lt;li&gt;IN ç›¸å½“äº key = value çš„å½¢å¼ï¼Œ&lt;strong&gt;NotIn ç›¸å½“äº key!=value çš„å½¢å¼ (åäº²å’ŒåŠ›)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Exists: èŠ‚ç‚¹å­˜åœ¨ label çš„ key ä¸ºæŒ‡å®šçš„å€¼å³å¯ï¼Œä¸èƒ½é…ç½® values å­—æ®µ&lt;/li&gt;
&lt;li&gt;DoesNotExist: èŠ‚ç‚¹ä¸å­˜åœ¨ label çš„ key ä¸ºæŒ‡å®šçš„å€¼å³å¯ï¼Œä¸èƒ½é…ç½® values å­—æ®µ&lt;/li&gt;
&lt;li&gt;Gtï¼šå¤§äº value æŒ‡å®šçš„å€¼&lt;/li&gt;
&lt;li&gt;Ltï¼šå°äº value æŒ‡å®šçš„å€¼&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;22-è½¯äº²å’ŒåŠ›preferred&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#22-è½¯äº²å’ŒåŠ›preferred&#34;&gt;#&lt;/a&gt; 2.2 è½¯äº²å’ŒåŠ› preferred&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;# cat nginx-deploy.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deploy
  labels:
    app: nginx-deploy
  namespace: default
spec:
  selector:
    matchLabels:
      app: nginx-deploy
  replicas: 6
  template:
    metadata:
      labels:
        app: nginx-deploy
    spec:
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              preference:
                matchExpressions:
                  - key: ssd
                    operator: In
                    values:
                      - &#39;true&#39;
            - weight: 50
              preference:
                matchExpressions:
                  - key: kubernetes.io/hostname
                    operator: In
                    values:
                      - k8s-master01
      restartPolicy: Always
      containers:
        - name: nginx-deploy
          image: nginx
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              memory: 1024Mi
              cpu: 1
            requests:
              memory: 128Mi
              cpu: 100m
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;preferredDuringSchedulingIgnoredDuringExecutionï¼šè½¯äº²å’ŒåŠ›é…ç½®&lt;/li&gt;
&lt;li&gt;weightï¼šè½¯äº²å’ŒåŠ›çš„æƒé‡ï¼Œæƒé‡è¶Šé«˜ä¼˜å…ˆçº§è¶Šå¤§ï¼ŒèŒƒå›´ 1-100&lt;/li&gt;
&lt;li&gt;matchExpressionsï¼šmatchExpressions ä¸‹å¯ä»¥é…ç½®å¤šä¸ª keyã€valuesï¼ˆéƒ½éœ€è¦æ»¡è¶³ï¼‰ï¼Œå…¶ä¸­ values å¯ä»¥é…ç½®å¤šä¸ªï¼ˆæ»¡è¶³å…¶ä¸€å³å¯ï¼‰&lt;/li&gt;
&lt;li&gt;operatorï¼š
&lt;ul&gt;
&lt;li&gt;IN ç›¸å½“äº key = value çš„å½¢å¼ï¼Œ&lt;strong&gt;NotIn ç›¸å½“äº key!=value çš„å½¢å¼ (åäº²å’ŒåŠ›)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Exists: èŠ‚ç‚¹å­˜åœ¨ label çš„ key ä¸ºæŒ‡å®šçš„å€¼å³å¯ï¼Œä¸èƒ½é…ç½® values å­—æ®µ&lt;/li&gt;
&lt;li&gt;DoesNotExist: èŠ‚ç‚¹ä¸å­˜åœ¨ label çš„ key ä¸ºæŒ‡å®šçš„å€¼å³å¯ï¼Œä¸èƒ½é…ç½® values å­—æ®µ&lt;/li&gt;
&lt;li&gt;Gtï¼šå¤§äº value æŒ‡å®šçš„å€¼&lt;/li&gt;
&lt;li&gt;Ltï¼šå°äº value æŒ‡å®šçš„å€¼&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;3-podäº²å’ŒåŠ›è¯¦è§£&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3-podäº²å’ŒåŠ›è¯¦è§£&#34;&gt;#&lt;/a&gt; 3. Pod äº²å’ŒåŠ›è¯¦è§£&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# cat nginx-deploy.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: nginx-deploy
  name: nginx-deploy
spec:
  replicas: 4
  selector:
    matchLabels:
      app: nginx-deploy
  template:
    metadata:
      labels:
        app: nginx-deploy
    spec:
      affinity:              
        podAntiAffinity:   #podç¡¬åäº²å’ŒåŠ›
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - nginx-deploy
            topologyKey: kubernetes.io/hostname
        podAntiAffinity:       #podè½¯åäº²å’ŒåŠ›
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - nginx-deploy
              namespaces:     #å’Œå“ªä¸ªå‘½åç©ºé—´çš„Podè¿›è¡ŒåŒ¹é…ï¼Œä¸ºç©ºä¸ºå½“å‰å‘½åç©ºé—´
              - default
              topologyKey: kubernetes.io/hostname
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;labelSelectorï¼šPod é€‰æ‹©å™¨é…ç½®ï¼Œå¯ä»¥é…ç½®å¤šä¸ª&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;matchExpressionsï¼šmatchExpressions ä¸‹å¯ä»¥é…ç½®å¤šä¸ª keyã€valuesï¼ˆéƒ½éœ€è¦æ»¡è¶³ï¼‰ï¼Œå…¶ä¸­ values å¯ä»¥é…ç½®å¤šä¸ªï¼ˆæ»¡è¶³å…¶ä¸€å³å¯ï¼‰&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;topologyKeyï¼šåŒ¹é…çš„æ‹“æ‰‘åŸŸçš„ keyï¼Œä¹Ÿå°±æ˜¯èŠ‚ç‚¹ä¸Š label çš„ keyï¼Œkey å’Œ value ç›¸åŒçš„ä¸ºåŒä¸€ä¸ªåŸŸï¼Œå¯ä»¥ç”¨äºæ ‡æ³¨ä¸åŒçš„æœºæˆ¿å’Œåœ°åŒº&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Namespaces: å’Œå“ªä¸ªå‘½åç©ºé—´çš„ Pod è¿›è¡ŒåŒ¹é…ï¼Œä¸ºç©ºä¸ºå½“å‰å‘½åç©ºé—´&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;operatorï¼šé…ç½®å’ŒèŠ‚ç‚¹äº²å’ŒåŠ›ä¸€è‡´ï¼Œä½†æ˜¯æ²¡æœ‰ Gt å’Œ Lt&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;IN ç›¸å½“äº key = value çš„å½¢å¼ï¼›&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Exists: èŠ‚ç‚¹å­˜åœ¨ label çš„ key ä¸ºæŒ‡å®šçš„å€¼å³å¯ï¼Œä¸èƒ½é…ç½® values å­—æ®µï¼›&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DoesNotExist: èŠ‚ç‚¹ä¸å­˜åœ¨ label çš„ key ä¸ºæŒ‡å®šçš„å€¼å³å¯ï¼Œä¸èƒ½é…ç½® values å­—æ®µ&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;4-èŠ‚ç‚¹äº²å’ŒåŠ›é…ç½®ç¤ºä¾‹&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4-èŠ‚ç‚¹äº²å’ŒåŠ›é…ç½®ç¤ºä¾‹&#34;&gt;#&lt;/a&gt; 4. èŠ‚ç‚¹äº²å’ŒåŠ›é…ç½®ç¤ºä¾‹&lt;/h4&gt;
&lt;p&gt;Pod å°½é‡éƒ¨ç½²åœ¨ ssd=true å’Œ type=physical çš„èŠ‚ç‚¹ä¸Šï¼Œä½†æ˜¯ä¼˜å…ˆéƒ¨ç½²åœ¨ ssd=true çš„èŠ‚ç‚¹ä¸Šï¼Œä¸èƒ½éƒ¨ç½² label ä¸º gpu=true çš„èŠ‚ç‚¹ã€‚&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# kubectl label nodes k8s-node01 ssd=true
[root@k8s-master01 ~]# kubectl label nodes k8s-master01 ssd=true
[root@k8s-master01 ~]# kubectl label nodes k8s-master01 gpu=true
[root@k8s-master01 ~]# kubectl label nodes k8s-node02 type=physical

[root@k8s-master01 ~]# cat nginx-deploy.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deploy
  labels:
    app: nginx-deploy
  annotations:
    app: nginx-deploy
  namespace: default
spec:
  selector:
    matchLabels:
      app: nginx-deploy
  replicas: 5
  template:
    metadata:
      labels:
        app: nginx-deploy
      annotations:
        app: nginx-deploy
    spec:
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              preference:
                matchExpressions:
                  - key: ssd
                    operator: In
                    values:
                      - &#39;true&#39;
                  - key: gpu
                    operator: NotIn
                    values:
                      - &#39;true&#39;
            - weight: 50
              preference:
                matchExpressions:
                  - key: type
                    operator: In
                    values:
                      - physical
      restartPolicy: Always
      containers:
        - name: nginx-deploy
          image: nginx
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              memory: 1024Mi
              cpu: 1
            requests:
              memory: 128Mi
              cpu: 100m
          volumeMounts:
          - name: tz-config
            mountPath: /usr/share/zoneinfo/Asia/Shanghai
          - name: tz-config
            mountPath: /etc/localtime
          - name: timezone
            mountPath: /etc/timezone
      volumes:
      - name: tz-config
        hostPath:
          path: /usr/share/zoneinfo/Asia/Shanghai
          type: &amp;quot;&amp;quot;
      - name: timezone
        hostPath:
          path: /etc/timezone
          type: &amp;quot;&amp;quot;


[root@k8s-master01 ~]# kubectl apply -f nginx-deploy.yaml 
[root@k8s-master01 ~]# kubectl get pods -o wide
NAME                          READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATES
nginx-deploy-7d65fbdf-2b4jr   1/1     Running   0          5s    172.16.85.236   k8s-node01   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-deploy-7d65fbdf-jjzwr   1/1     Running   0          5s    172.16.58.251   k8s-node02   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-deploy-7d65fbdf-kx5lm   1/1     Running   0          5s    172.16.85.237   k8s-node01   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-deploy-7d65fbdf-lrmcg   1/1     Running   0          5s    172.16.85.238   k8s-node01   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-deploy-7d65fbdf-n6mlp   1/1     Running   0          5s    172.16.58.250   k8s-node02   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;5-podäº²å’ŒåŠ›-åäº²å’ŒåŠ›é…ç½®ç¤ºä¾‹&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#5-podäº²å’ŒåŠ›-åäº²å’ŒåŠ›é…ç½®ç¤ºä¾‹&#34;&gt;#&lt;/a&gt; 5. Pod äº²å’ŒåŠ›ã€åäº²å’ŒåŠ›é…ç½®ç¤ºä¾‹&lt;/h4&gt;
&lt;h5 id=&#34;51-podåäº²å’ŒåŠ›required&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#51-podåäº²å’ŒåŠ›required&#34;&gt;#&lt;/a&gt; 5.1 Pod åäº²å’ŒåŠ› required&lt;/h5&gt;
&lt;p&gt;åŒä¸€ä¸ªåº”ç”¨éƒ¨ç½²åœ¨ä¸åŒçš„å®¿ä¸»æœº&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#1.èŠ‚ç‚¹å­˜åœ¨æ±¡ç‚¹podæ— æ³•è°ƒåº¦è‡³è¯¥èŠ‚ç‚¹
# kubectl describe nodes|grep -i taint
Taints:             &amp;lt;none&amp;gt;
Taints:             &amp;lt;none&amp;gt;
Taints:             &amp;lt;none&amp;gt;
Taints:             &amp;lt;none&amp;gt;
Taints:             &amp;lt;none&amp;gt;

#2.podåäº²å’ŒåŠ›required
# cat nginx-deploy.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deploy
  labels:
    app: nginx-deploy
  namespace: default
spec:
  selector:
    matchLabels:
      app: nginx-deploy
  replicas: 5
  template:
    metadata:
      labels:
        app: nginx-deploy
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: app
                    operator: In
                    values:
                      - nginx-deploy
              topologyKey: kubernetes.io/hostname
      restartPolicy: Always
      containers:
        - name: nginx-deploy
          image: nginx
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              memory: 1024Mi
              cpu: 1
            requests:
              memory: 128Mi
              cpu: 100m
          volumeMounts:
          - name: tz-config
            mountPath: /usr/share/zoneinfo/Asia/Shanghai
          - name: tz-config
            mountPath: /etc/localtime
          - name: timezone
            mountPath: /etc/timezone
      volumes:
      - name: tz-config
        hostPath:
          path: /usr/share/zoneinfo/Asia/Shanghai
          type: &amp;quot;&amp;quot;
      - name: timezone
        hostPath:
          path: /etc/timezone
          type: &amp;quot;&amp;quot;

#3.éƒ¨ç½²deployment
[root@k8s-master01 ~]# kubectl apply -f nginx-deploy.yaml 
[root@k8s-master01 ~]# kubectl get pods -o wide
NAME                            READY   STATUS    RESTARTS   AGE   IP               NODE           NOMINATED NODE   READINESS GATES
nginx-deploy-5787887b6f-4654b   1/1     Running   0          4s    172.16.85.234    k8s-node01     &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-deploy-5787887b6f-8mq7s   1/1     Running   0          4s    172.16.122.152   k8s-master02   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-deploy-5787887b6f-fdkft   1/1     Running   0          4s    172.16.58.247    k8s-node02     &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-deploy-5787887b6f-jzcmd   1/1     Running   0          4s    172.16.32.152    k8s-master01   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-deploy-5787887b6f-qdq9g   1/1     Running   0          4s    172.16.195.14    k8s-master03   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;

#4.å°†å‰¯æœ¬æ‰©æˆ6ä¸ªï¼Œç”±äºK8sé›†ç¾¤åªæœ‰5ä¸ªèŠ‚ç‚¹ï¼Œå³5ä¸ªtopologyKeyï¼ˆæ‹“æ‰‘åŸŸï¼‰ï¼Œæ¯ä¸ªåŸŸåªèƒ½æœ‰ä¸€ä¸ªå‰¯æœ¬ï¼Œæ‰€ä»¥æœ‰ä¸€ä¸ªpodä¼špending
[root@k8s-master01 ~]# kubectl scale deploy nginx-deploy --replicas=6 
[root@k8s-master01 ~]# kubectl get pods -o wide
NAME                            READY   STATUS    RESTARTS   AGE     IP               NODE           NOMINATED NODE   READINESS GATES
nginx-deploy-5787887b6f-4654b   1/1     Running   0          4m44s   172.16.85.234    k8s-node01     &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-deploy-5787887b6f-8mq7s   1/1     Running   0          4m44s   172.16.122.152   k8s-master02   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-deploy-5787887b6f-fdkft   1/1     Running   0          4m44s   172.16.58.247    k8s-node02     &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-deploy-5787887b6f-jzcmd   1/1     Running   0          4m44s   172.16.32.152    k8s-master01   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-deploy-5787887b6f-qdq9g   1/1     Running   0          4m44s   172.16.195.14    k8s-master03   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-deploy-5787887b6f-sztm7   0/1     Pending   0          9s      &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;         &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;

[root@k8s-master01 ~]# kubectl describe pods nginx-deploy-5787887b6f-sztm7
...
Events:
  Type     Reason            Age   From               Message
  ----     ------            ----  ----               -------
  Warning  FailedScheduling  102s  default-scheduler  0/5 nodes are available: 5 node(s) didn&#39;t match pod anti-affinity rules. preemption: 0/5 nodes are available: 5 No preemption victims found for incoming pod.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;å°†å‰¯æœ¬æ‰©æˆ 6 ä¸ªï¼Œæœ‰ä¸€ä¸ªä¼š pending çŠ¶æ€ï¼ŒåŸå›  K8s é›†ç¾¤åªæœ‰ 5 ä¸ªèŠ‚ç‚¹ï¼Œå³ 5 ä¸ª topologyKeyï¼ˆæ‹“æ‰‘åŸŸï¼‰ï¼Œæ¯ä¸ªæ‹“æ‰‘åŸŸåªèƒ½æœ‰ä¸€ä¸ªå‰¯æœ¬ï¼Œæ‰€ä»¥æœ‰ä¸€ä¸ª pod ä¼š pendingã€‚&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;topologyKeyï¼šåŒ¹é…çš„æ‹“æ‰‘åŸŸçš„ keyï¼Œä¹Ÿå°±æ˜¯èŠ‚ç‚¹ä¸Š label çš„ keyï¼Œkey å’Œ value ç›¸åŒçš„ä¸ºåŒä¸€ä¸ªåŸŸï¼Œå¯ä»¥ç”¨äºæ ‡æ³¨ä¸åŒçš„æœºæˆ¿å’Œåœ°åŒº&lt;/strong&gt;ã€‚&lt;/p&gt;
&lt;h5 id=&#34;52-podåäº²å’ŒåŠ›preferred&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#52-podåäº²å’ŒåŠ›preferred&#34;&gt;#&lt;/a&gt; 5.2 Pod åäº²å’ŒåŠ› preferred&lt;/h5&gt;
&lt;p&gt;åŒä¸€ä¸ªåº”ç”¨å°½é‡éƒ¨ç½²åœ¨ä¸åŒçš„å®¿ä¸»æœº&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#1.èŠ‚ç‚¹å­˜åœ¨æ±¡ç‚¹podæ— æ³•è°ƒåº¦è‡³è¯¥èŠ‚ç‚¹
# kubectl describe nodes|grep -i taint
Taints:             &amp;lt;none&amp;gt;
Taints:             &amp;lt;none&amp;gt;
Taints:             &amp;lt;none&amp;gt;
Taints:             &amp;lt;none&amp;gt;
Taints:             &amp;lt;none&amp;gt;

#2.podåäº²å’ŒåŠ›preferred
# cat nginx-deploy.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deploy
  labels:
    app: nginx-deploy
  namespace: default
spec:
  selector:
    matchLabels:
      app: nginx-deploy
  replicas: 6
  template:
    metadata:
      labels:
        app: nginx-deploy
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: app
                      operator: In
                      values:
                        - nginx-deploy
                topologyKey: kubernetes.io/hostname
              weight: 100
      restartPolicy: Always
      containers:
        - name: nginx-deploy
          image: nginx
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              memory: 1024Mi
              cpu: 1
            requests:
              memory: 128Mi
              cpu: 100m
          volumeMounts:
          - name: tz-config
            mountPath: /usr/share/zoneinfo/Asia/Shanghai
          - name: tz-config
            mountPath: /etc/localtime
          - name: timezone
            mountPath: /etc/timezone
      volumes:
      - name: tz-config
        hostPath:
          path: /usr/share/zoneinfo/Asia/Shanghai
          type: &amp;quot;&amp;quot;
      - name: timezone
        hostPath:
          path: /etc/timezone
          type: &amp;quot;&amp;quot;

#3.éƒ¨ç½²deployment
[root@k8s-master01 ~]# kubectl apply -f nginx-deploy.yaml 
[root@k8s-master01 ~]# kubectl get pods -o wide
NAME                            READY   STATUS    RESTARTS   AGE   IP               NODE           NOMINATED NODE   READINESS GATES
nginx-deploy-7c47567b79-97qs5   1/1     Running   0          6s    172.16.122.153   k8s-master02   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-deploy-7c47567b79-g49h4   1/1     Running   0          6s    172.16.85.235    k8s-node01     &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-deploy-7c47567b79-g5n2s   1/1     Running   0          6s    172.16.58.248    k8s-node02     &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-deploy-7c47567b79-g5v5b   1/1     Running   0          6s    172.16.195.15    k8s-master03   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-deploy-7c47567b79-pjwws   1/1     Running   0          6s    172.16.58.249    k8s-node02     &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-deploy-7c47567b79-q2hn5   1/1     Running   0          6s    172.16.32.153    k8s-master01   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;53-podäº²å’ŒåŠ›required&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#53-podäº²å’ŒåŠ›required&#34;&gt;#&lt;/a&gt; 5.3 Pod äº²å’ŒåŠ› required&lt;/h5&gt;
&lt;p&gt;åŒä¸€ä¸ªåº”ç”¨å¿…é¡»éƒ¨ç½²åœ¨åŒä¸€ä¸ªå®¿ä¸»æœº&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# cat nginx-deploy.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: nginx-deploy
  name: nginx-deploy
spec:
  replicas: 8
  selector:
    matchLabels:
      app: nginx-deploy
  template:
    metadata:
      labels:
        app: nginx-deploy
    spec:
      affinity:              
        podAffinity:   #podç¡¬äº²å’ŒåŠ›
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - nginx-deploy
            topologyKey: kubernetes.io/hostname
      containers:
      - image: nginx
        name: nginx
        volumeMounts:
        - name: timezone
          mountPath: /etc/timezone
        - name: tz-config
          mountPath: /usr/share/zoneinfo/Asia/Shanghai
        - name: tz-config
          mountPath: /etc/localtime
      volumes:
      - name: timezone
        hostPath:
          path: /etc/timezone
          type: File
      - name: tz-config
        hostPath:
          path: /usr/share/zoneinfo/Asia/Shanghai
          type: File

[root@k8s-master01 ~]# kubectl apply -f nginx-deploy.yaml 
[root@k8s-master01 ~]# kubectl get pods -o wide
NAME                           READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATES
nginx-deploy-dbcc4d65c-2sthn   1/1     Running   0          12s   172.16.58.255   k8s-node02   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-deploy-dbcc4d65c-78nxf   1/1     Running   0          12s   172.16.58.197   k8s-node02   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-deploy-dbcc4d65c-82ssq   1/1     Running   0          12s   172.16.58.194   k8s-node02   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-deploy-dbcc4d65c-986cb   1/1     Running   0          12s   172.16.58.254   k8s-node02   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-deploy-dbcc4d65c-9rnt7   1/1     Running   0          12s   172.16.58.252   k8s-node02   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-deploy-dbcc4d65c-knm8q   1/1     Running   0          12s   172.16.58.195   k8s-node02   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-deploy-dbcc4d65c-kx56f   1/1     Running   0          12s   172.16.58.253   k8s-node02   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-deploy-dbcc4d65c-sqlhf   1/1     Running   0          12s   172.16.58.198   k8s-node02   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;54-podäº²å’ŒåŠ›preferre&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#54-podäº²å’ŒåŠ›preferre&#34;&gt;#&lt;/a&gt; 5.4 Pod äº²å’ŒåŠ› preferre&lt;/h5&gt;
&lt;p&gt;åŒä¸€ä¸ªåº”ç”¨å°½é‡éƒ¨ç½²åœ¨åŒä¸€ä¸ªå®¿ä¸»æœº&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cat nginx-deploy.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: nginx-deploy
  name: nginx-deploy
spec:
  replicas: 20
  selector:
    matchLabels:
      app: nginx-deploy
  template:
    metadata:
      labels:
        app: nginx-deploy
    spec:
      affinity:              
        podAffinity:       #podè½¯äº²å’ŒåŠ›
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - nginx-deploy
              namespaces:     #å’Œå“ªä¸ªå‘½åç©ºé—´çš„Podè¿›è¡ŒåŒ¹é…ï¼Œä¸ºç©ºä¸ºå½“å‰å‘½åç©ºé—´
              - default
              topologyKey: kubernetes.io/hostname
      containers:
      - image: nginx
        name: nginx
        volumeMounts:
        - name: timezone
          mountPath: /etc/timezone
        - name: tz-config
          mountPath: /usr/share/zoneinfo/Asia/Shanghai
        - name: tz-config
          mountPath: /etc/localtime
      volumes:
      - name: timezone
        hostPath:
          path: /etc/timezone
          type: File
      - name: tz-config
        hostPath:
          path: /usr/share/zoneinfo/Asia/Shanghai
          type: File
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;æœ¬æ–‡å‡ºè‡ªäºï¼š&lt;a href=&#34;https://edu.51cto.com/course/23845.html&#34;&gt;https://edu.51cto.com/course/23845.html&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</content>
        <category term="Kubernetes" />
        <updated>2025-04-20T09:59:58.000Z</updated>
    </entry>
    <entry>
        <id>http://ixuyong.cn/posts/3254599477.html</id>
        <title>K8så®¹å¿å’Œæ±¡ç‚¹</title>
        <link rel="alternate" href="http://ixuyong.cn/posts/3254599477.html"/>
        <content type="html">&lt;h3 id=&#34;k8så®¹å¿å’Œæ±¡ç‚¹&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#k8så®¹å¿å’Œæ±¡ç‚¹&#34;&gt;#&lt;/a&gt; K8s å®¹å¿å’Œæ±¡ç‚¹&lt;/h3&gt;
&lt;p&gt;Taint æŒ‡å®šæœåŠ¡å™¨ä¸Šæ‰“ä¸Šæ±¡ç‚¹ï¼Œè®©ä¸èƒ½å®¹å¿è¿™ä¸ªæ±¡ç‚¹çš„ Pod ä¸èƒ½éƒ¨ç½²åœ¨æ‰“äº†æ±¡ç‚¹çš„æœåŠ¡å™¨ä¸Šã€‚Toleration æ˜¯è®© Pod å®¹å¿èŠ‚ç‚¹ä¸Šé…ç½®çš„æ±¡ç‚¹ï¼Œå¯ä»¥è®©ä¸€äº›éœ€è¦ç‰¹æ®Šé…ç½®çš„ Pod èƒ½å¤Ÿè°ƒç”¨åˆ°å…·æœ‰æ±¡ç‚¹å’Œç‰¹æ®Šé…ç½®çš„èŠ‚ç‚¹ä¸Šã€‚&lt;/p&gt;
&lt;h4 id=&#34;1-tainté…ç½®è§£æ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-tainté…ç½®è§£æ&#34;&gt;#&lt;/a&gt; 1. Taint é…ç½®è§£æ&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;#1.Taintè¯­æ³•
# kubectl taint nodes NODE_NAME TAINT_KEY=TAINT_VALUE:EFFECT

#2.åˆ›å»ºTaintç¤ºä¾‹
# kubectl taint nodes k8s-node01 ssd=true:PreferNoSchedule

#3.æŸ¥çœ‹æ±¡ç‚¹
# kubectl describe node k8s-node01 | grep Taints -A 10

#4.åˆ é™¤æ±¡ç‚¹
# kubectl taint nodes k8s-node01 ssd-                   #åŸºäºKeyåˆ é™¤
# kubectl taint nodes k8s-node01 ssd:PreferNoSchedule-  #åŸºäºKey+Effectåˆ é™¤

#5.ä¿®æ”¹æ±¡ç‚¹ï¼ˆKeyå’ŒEffectç›¸åŒï¼‰
# kubectl taint nodes k8s-node01 ssd=true:PreferNoSchedule --overwrite
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;EFFECT æ’æ–¥ç­‰çº§ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NoScheduleï¼šç¦æ­¢è°ƒåº¦åˆ°è¯¥èŠ‚ç‚¹ï¼Œå·²ç»åœ¨è¯¥èŠ‚ç‚¹ä¸Šçš„ Pod ä¸å—å½±å“&lt;/li&gt;
&lt;li&gt;NoExecuteï¼šç¦æ­¢è°ƒåº¦åˆ°è¯¥èŠ‚ç‚¹ï¼Œå¦‚æœä¸ç¬¦åˆè¿™ä¸ªæ±¡ç‚¹ï¼Œä¼šç«‹é©¬è¢«é©±é€ï¼ˆæˆ–åœ¨ä¸€æ®µæ—¶é—´åï¼‰&lt;/li&gt;
&lt;li&gt;PreferNoScheduleï¼šå°½é‡é¿å…å°† Pod è°ƒåº¦åˆ°æŒ‡å®šçš„èŠ‚ç‚¹ä¸Šï¼Œå¦‚æœæ²¡æœ‰æ›´åˆé€‚çš„èŠ‚ç‚¹ï¼Œå¯ä»¥éƒ¨ç½²åˆ°è¯¥èŠ‚ç‚¹&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2tolerationé…ç½®è§£æ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2tolerationé…ç½®è§£æ&#34;&gt;#&lt;/a&gt; 2.Toleration é…ç½®è§£æ&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;#1.å®Œå…¨åŒ¹é…
tolerations:
- key: &amp;quot;taintKey&amp;quot;
  operator: &amp;quot;Equal&amp;quot;
  value: &amp;quot;taintValue&amp;quot;
  effect: &amp;quot;NoSchedule
 
#2.ä¸å®Œå…¨åŒ¹é… 
tolerations:
- key: &amp;quot;taintKey&amp;quot;
  operator: &amp;quot;Exists&amp;quot;
  effect: &amp;quot;NoSchedule&amp;quot;
  
#3.å¤§èŒƒå›´åŒ¹é…ï¼ˆä¸æ¨èkeyä¸ºå†…ç½®Taintï¼Œä¼šå¯¼è‡´èŠ‚ç‚¹æ•…éšœpodæ— æ³•æ¼‚ç§»ï¼‰
tolerations:
- key: &amp;quot;taintKey&amp;quot;
  operator: &amp;quot;Exists
  
#4.å®¹å¿æ—¶é—´é…ç½®
tolerations:
- key: &amp;quot;key1&amp;quot;
  operator: &amp;quot;Equal&amp;quot;
  value: &amp;quot;value1&amp;quot;
  effect: &amp;quot;NoExecute&amp;quot;
  tolerationSeconds: 3600
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;3-taint-tolerationé…ç½®ç¤ºä¾‹&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3-taint-tolerationé…ç½®ç¤ºä¾‹&#34;&gt;#&lt;/a&gt; 3. Taintã€Toleration é…ç½®ç¤ºä¾‹&lt;/h4&gt;
&lt;p&gt;æœ‰ä¸€ä¸ª K8s èŠ‚ç‚¹æ˜¯çº¯ SSD ç¡¬ç›˜çš„èŠ‚ç‚¹ï¼Œç°éœ€è¦åªæœ‰ä¸€äº›éœ€è¦é«˜æ€§èƒ½å­˜å‚¨çš„ Pod æ‰èƒ½è°ƒåº¦åˆ°è¯¥èŠ‚ç‚¹ä¸Šã€‚&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#1.ç»™èŠ‚ç‚¹æ‰“ä¸Šæ±¡ç‚¹å’Œæ ‡ç­¾
# kubectl taint nodes k8s-node01 ssd=true:PreferNoSchedule
# kubectl label node k8s-node01 ssd=true

#2.é…ç½®Tolerationï¼š
# cat nginx-deploy.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deploy
  labels:
    app: nginx-deploy
  namespace: default
spec:
  selector:
    matchLabels:
      app: nginx-deploy
  replicas: 5
  template:
    metadata:
      labels:
        app: nginx-deploy
    spec:
      containers:
        - name: nginx-deploy
          image: nginx
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              memory: 1024Mi
              cpu: 1
            requests:
              memory: 128Mi
              cpu: 100m
      nodeSelector:
        ssd: &#39;true&#39;
      tolerations:
        - key: ssd
          operator: Exists
          effect: NoSchedule
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;4-k8så†…ç½®æ±¡ç‚¹&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4-k8så†…ç½®æ±¡ç‚¹&#34;&gt;#&lt;/a&gt; 4. K8s å†…ç½®æ±¡ç‚¹&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://node.kubernetes.io/not-ready%EF%BC%9A%E8%8A%82%E7%82%B9%E6%9C%AA%E5%87%86%E5%A4%87%E5%A5%BD%EF%BC%8C%E7%9B%B8%E5%BD%93%E4%BA%8E%E8%8A%82%E7%82%B9%E7%8A%B6%E6%80%81Ready%E7%9A%84%E5%80%BC%E4%B8%BAFalse%E3%80%82&#34;&gt;node.kubernetes.io/not-readyï¼šèŠ‚ç‚¹æœªå‡†å¤‡å¥½ï¼Œç›¸å½“äºèŠ‚ç‚¹çŠ¶æ€ Ready çš„å€¼ä¸º Falseã€‚&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://node.kubernetes.io/unreachable%EF%BC%9ANode&#34;&gt;node.kubernetes.io/unreachableï¼šNode&lt;/a&gt; Controller è®¿é—®ä¸åˆ°èŠ‚ç‚¹ï¼Œç›¸å½“äºèŠ‚ç‚¹çŠ¶æ€ Ready çš„å€¼ä¸º Unknownã€‚&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://node.kubernetes.io/out-of-disk%EF%BC%9A%E8%8A%82%E7%82%B9%E7%A3%81%E7%9B%98%E8%80%97%E5%B0%BD%E3%80%82&#34;&gt;node.kubernetes.io/out-of-diskï¼šèŠ‚ç‚¹ç£ç›˜è€—å°½ã€‚&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://node.kubernetes.io/memory-pressure%EF%BC%9A%E8%8A%82%E7%82%B9%E5%AD%98%E5%9C%A8%E5%86%85%E5%AD%98%E5%8E%8B%E5%8A%9B%E3%80%82&#34;&gt;node.kubernetes.io/memory-pressureï¼šèŠ‚ç‚¹å­˜åœ¨å†…å­˜å‹åŠ›ã€‚&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://node.kubernetes.io/disk-pressure%EF%BC%9A%E8%8A%82%E7%82%B9%E5%AD%98%E5%9C%A8%E7%A3%81%E7%9B%98%E5%8E%8B%E5%8A%9B%E3%80%82&#34;&gt;node.kubernetes.io/disk-pressureï¼šèŠ‚ç‚¹å­˜åœ¨ç£ç›˜å‹åŠ›ã€‚&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://node.kubernetes.io/network-unavailable%EF%BC%9A%E8%8A%82%E7%82%B9%E7%BD%91%E7%BB%9C%E4%B8%8D%E5%8F%AF%E8%BE%BE%E3%80%82&#34;&gt;node.kubernetes.io/network-unavailableï¼šèŠ‚ç‚¹ç½‘ç»œä¸å¯è¾¾ã€‚&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://node.kubernetes.io/unschedulable%EF%BC%9A%E8%8A%82%E7%82%B9%E4%B8%8D%E5%8F%AF%E8%B0%83%E5%BA%A6%E3%80%82&#34;&gt;node.kubernetes.io/unschedulableï¼šèŠ‚ç‚¹ä¸å¯è°ƒåº¦ã€‚&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://node.cloudprovider.kubernetes.io/uninitialized%EF%BC%9A%E5%A6%82%E6%9E%9CKubelet%E5%90%AF%E5%8A%A8%E6%97%B6%E6%8C%87%E5%AE%9A%E4%BA%86%E4%B8%80%E4%B8%AA%E5%A4%96%E9%83%A8%E7%9A%84cloudprovider%EF%BC%8C%E5%AE%83%E5%B0%86%E7%BB%99%E5%BD%93%E5%89%8D%E8%8A%82%E7%82%B9%E6%B7%BB%E5%8A%A0%E4%B8%80%E4%B8%AATaint%E5%B0%86%E5%85%B6%E6%A0%87%E8%AE%B0%E4%B8%BA%E4%B8%8D%E5%8F%AF%E7%94%A8%E3%80%82%E5%9C%A8cloud-controller-manager%E7%9A%84%E4%B8%80%E4%B8%AAcontroller%E5%88%9D%E5%A7%8B%E5%8C%96%E8%BF%99%E4%B8%AA%E8%8A%82%E7%82%B9%E5%90%8E%EF%BC%8CKubelet%E5%B0%86%E5%88%A0%E9%99%A4%E8%BF%99%E4%B8%AATaint%E3%80%82&#34;&gt;node.cloudprovider.kubernetes.io/uninitializedï¼šå¦‚æœ Kubelet å¯åŠ¨æ—¶æŒ‡å®šäº†ä¸€ä¸ªå¤–éƒ¨çš„ cloudproviderï¼Œå®ƒå°†ç»™å½“å‰èŠ‚ç‚¹æ·»åŠ ä¸€ä¸ª Taint å°†å…¶æ ‡è®°ä¸ºä¸å¯ç”¨ã€‚åœ¨ cloud-controller-manager çš„ä¸€ä¸ª controller åˆå§‹åŒ–è¿™ä¸ªèŠ‚ç‚¹åï¼ŒKubelet å°†åˆ é™¤è¿™ä¸ª Taintã€‚&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/vO7kURL.png&#34; alt=&#34;1.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Deployment åˆ›å»ºå K8s é»˜è®¤ä¸º Pod æ·»åŠ å®¹å¿ï¼Œå½“ Pod æ‰€åœ¨çš„èŠ‚ç‚¹å®•æœºï¼Œ300 ç§’å pod ä¼šæ¼‚ç§»ï¼Œé»˜è®¤å®¹å¿æ—¶é—´ 300 ç§’ã€‚&lt;/p&gt;
&lt;h4 id=&#34;5èŠ‚ç‚¹å®•æœºå¿«é€Ÿæ¢å¤ä¸šåŠ¡åº”ç”¨&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#5èŠ‚ç‚¹å®•æœºå¿«é€Ÿæ¢å¤ä¸šåŠ¡åº”ç”¨&#34;&gt;#&lt;/a&gt; 5. èŠ‚ç‚¹å®•æœºå¿«é€Ÿæ¢å¤ä¸šåŠ¡åº”ç”¨&lt;/h4&gt;
&lt;p&gt;èŠ‚ç‚¹ä¸å¥åº·ï¼Œ180 ç§’åå†é©±é€ï¼ˆé»˜è®¤æ˜¯ 300 ç§’ï¼‰&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cat nginx-deploy.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deploy
  labels:
    app: nginx-deploy
  namespace: default
spec:
  selector:
    matchLabels:
      app: nginx-deploy
  replicas: 5
  template:
    metadata:
      labels:
        app: nginx-deploy
    spec:
      containers:
        - name: nginx-deploy
          image: nginx
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              memory: 1024Mi
              cpu: 1
            requests:
              memory: 128Mi
              cpu: 100m
      tolerations:
        - key: node.kubernetes.io/unreachable
          operator: Exists
          effect: NoExecute
          tolerationSeconds: 180
        - key: node.kubernetes.io/not-ready
          operator: Exists
          effect: NoExecute
          tolerationSeconds: 180
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;æœ¬æ–‡å‡ºè‡ªäºï¼š&lt;a href=&#34;https://edu.51cto.com/course/23845.html&#34;&gt;https://edu.51cto.com/course/23845.html&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</content>
        <category term="Kubernetes" />
        <updated>2025-04-20T07:51:58.000Z</updated>
    </entry>
    <entry>
        <id>http://ixuyong.cn/posts/3142072607.html</id>
        <title>K8såˆå§‹åŒ–å®¹å™¨ã€ä¸´æ—¶å®¹å™¨</title>
        <link rel="alternate" href="http://ixuyong.cn/posts/3142072607.html"/>
        <content type="html">&lt;h3 id=&#34;k8såˆå§‹åŒ–å®¹å™¨-ä¸´æ—¶å®¹å™¨&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#k8såˆå§‹åŒ–å®¹å™¨-ä¸´æ—¶å®¹å™¨&#34;&gt;#&lt;/a&gt; K8s åˆå§‹åŒ–å®¹å™¨ã€ä¸´æ—¶å®¹å™¨&lt;/h3&gt;
&lt;h4 id=&#34;1-åˆå§‹åŒ–å®¹å™¨&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-åˆå§‹åŒ–å®¹å™¨&#34;&gt;#&lt;/a&gt; 1. åˆå§‹åŒ–å®¹å™¨&lt;/h4&gt;
&lt;h5 id=&#34;1-1-åˆå§‹åŒ–å®¹å™¨çš„ç”¨é€”&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-1-åˆå§‹åŒ–å®¹å™¨çš„ç”¨é€”&#34;&gt;#&lt;/a&gt; 1. 1 åˆå§‹åŒ–å®¹å™¨çš„ç”¨é€”&lt;/h5&gt;
&lt;p&gt;åˆå§‹åŒ–å®¹å™¨ä¸»è¦æ˜¯åœ¨ä¸»åº”ç”¨å¯åŠ¨ä¹‹å‰ï¼Œåšä¸€äº›åˆå§‹åŒ–çš„æ“ä½œï¼Œæ¯”å¦‚åˆ›å»ºæ–‡ä»¶ã€ä¿®æ”¹å†…æ ¸å‚æ•°ã€ç­‰å¾…ä¾èµ–ç¨‹åºå¯åŠ¨æˆ–å…¶ä»–éœ€è¦åœ¨ä¸»ç¨‹åºå¯åŠ¨ä¹‹å‰éœ€è¦åšçš„å·¥ä½œã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Init å®¹å™¨å¯ä»¥åŒ…å«ä¸€äº›å®‰è£…è¿‡ç¨‹ä¸­åº”ç”¨å®¹å™¨ä¸­ä¸å­˜åœ¨çš„å®ç”¨å·¥å…·æˆ–ä¸ªæ€§åŒ–ä»£ç ï¼›&lt;/li&gt;
&lt;li&gt;Init å®¹å™¨å¯ä»¥å®‰å…¨åœ°è¿è¡Œè¿™äº›å·¥å…·ï¼Œé¿å…è¿™äº›å·¥å…·å¯¼è‡´åº”ç”¨é•œåƒçš„å®‰å…¨æ€§é™ä½ï¼›&lt;/li&gt;
&lt;li&gt;Init å®¹å™¨å¯ä»¥ä»¥ root èº«ä»½è¿è¡Œï¼Œæ‰§è¡Œä¸€äº›é«˜æƒé™å‘½ä»¤ï¼›&lt;/li&gt;
&lt;li&gt;Init å®¹å™¨ç›¸å…³æ“ä½œæ‰§è¡Œå®Œæˆä»¥åå³é€€å‡ºï¼Œä¸ä¼šç»™ä¸šåŠ¡å®¹å™¨å¸¦æ¥å®‰å…¨éšæ‚£ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;12-åˆå§‹åŒ–å®¹å™¨å’ŒpoststartåŒºåˆ«&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#12-åˆå§‹åŒ–å®¹å™¨å’ŒpoststartåŒºåˆ«&#34;&gt;#&lt;/a&gt; 1.2 åˆå§‹åŒ–å®¹å™¨å’Œ PostStart åŒºåˆ«&lt;/h5&gt;
&lt;p&gt;PostStartï¼šä¾èµ–ä¸»åº”ç”¨çš„ç¯å¢ƒï¼Œè€Œä¸”å¹¶ä¸ä¸€å®šå…ˆäº Command è¿è¡Œã€‚&lt;/p&gt;
&lt;p&gt;InitContainerï¼šä¸ä¾èµ–ä¸»åº”ç”¨çš„ç¯å¢ƒï¼Œå¯ä»¥æœ‰æ›´é«˜çš„æƒé™å’Œæ›´å¤šçš„å·¥å…·ï¼Œä¸€å®šä¼šåœ¨ä¸»åº”ç”¨å¯åŠ¨ä¹‹å‰å®Œæˆ&lt;/p&gt;
&lt;h5 id=&#34;13-åˆå§‹åŒ–å®¹å™¨å’Œæ™®é€šå®¹å™¨çš„åŒºåˆ«&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#13-åˆå§‹åŒ–å®¹å™¨å’Œæ™®é€šå®¹å™¨çš„åŒºåˆ«&#34;&gt;#&lt;/a&gt; 1.3 åˆå§‹åŒ–å®¹å™¨å’Œæ™®é€šå®¹å™¨çš„åŒºåˆ«&lt;/h5&gt;
&lt;p&gt;Init å®¹å™¨ä¸æ™®é€šçš„å®¹å™¨éå¸¸åƒï¼Œé™¤äº†å¦‚ä¸‹å‡ ç‚¹ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ç¬¬ä¸€ä¸ª Init å®¹å™¨è¿è¡ŒæˆåŠŸåæ‰ä¼šè¿è¡Œä¸‹ä¸€ä¸ª Init å®¹å™¨ï¼›&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;æ‰€æœ‰çš„ Init å®¹å™¨è¿è¡ŒæˆåŠŸåæ‰ä¼šè¿è¡Œä¸»å®¹å™¨ï¼›&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;å¦‚æœ Pod çš„ Init å®¹å™¨å¤±è´¥ï¼ŒKubernetes ä¼šä¸æ–­åœ°é‡å¯è¯¥ Podï¼Œç›´åˆ° Init å®¹å™¨æˆåŠŸä¸ºæ­¢ï¼Œä½†æ˜¯ Pod å¯¹åº”çš„ restartPolicy å€¼ä¸º Neverï¼ŒKubernetes ä¸ä¼šé‡æ–°å¯åŠ¨ Podã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Init å®¹å™¨ä¸æ”¯æŒ lifecycleã€livenessProbeã€readinessProbe å’Œ startupProbe&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;14-åˆå§‹åŒ–å®¹å™¨ç¤ºä¾‹&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#14-åˆå§‹åŒ–å®¹å™¨ç¤ºä¾‹&#34;&gt;#&lt;/a&gt; 1.4 åˆå§‹åŒ–å®¹å™¨ç¤ºä¾‹&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# cat init.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: nginx-deploy
  name: nginx-deploy
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx-deploy
  template:
    metadata:
      labels:
        app: nginx-deploy
    spec:
      initContainers:           # åˆå§‹åŒ–å®¹å™¨è®¾å®š
      - name: fix-permissions
        image: busybox
        command: [&amp;quot;sh&amp;quot;,&amp;quot;-c&amp;quot;,&amp;quot;echo hello kubernetes&amp;gt;/usr/share/nginx/html/index.html&amp;quot;]
        securityContext:
          privileged: true
        volumeMounts:
        - name: share-volume
          mountPath: /usr/share/nginx/html
      containers:
      - image: nginx
        name: nginx
        volumeMounts:
        - name: timezone
          mountPath: /etc/timezone
        - name: tz-config
          mountPath: /usr/share/zoneinfo/Asia/Shanghai
        - name: tz-config
          mountPath: /etc/localtime
        - name: share-volume
          mountPath: /usr/share/nginx/html
      volumes:
      - name: share-volume
        emptyDir: &amp;#123;&amp;#125;
      - name: timezone
        hostPath:
          path: /etc/timezone
          type: File
      - name: tz-config
        hostPath:
          path: /usr/share/zoneinfo/Asia/Shanghai
          type: File

[root@k8s-master01 ~]# kubectl create -f init.yaml

[root@k8s-master01 ~]# curl 172.16.32.145
hello kubernetes
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2-ä¸´æ—¶å®¹å™¨&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-ä¸´æ—¶å®¹å™¨&#34;&gt;#&lt;/a&gt; 2. ä¸´æ—¶å®¹å™¨&lt;/h4&gt;
&lt;h5 id=&#34;21-æ³¨å…¥ä¸´æ—¶å®¹å™¨åˆ°pod&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#21-æ³¨å…¥ä¸´æ—¶å®¹å™¨åˆ°pod&#34;&gt;#&lt;/a&gt; 2.1 æ³¨å…¥ä¸´æ—¶å®¹å™¨åˆ° Pod&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# kubectl get pods
NAME                            READY   STATUS    RESTARTS      AGE
nginx-deploy-7dd6cd4b44-ktw5k   1/1     Running   1             16h
nginx-deploy-7dd6cd4b44-mjcgq   1/1     Running   1 (28m ago)   16h
nginx-deploy-7dd6cd4b44-wdm6p   1/1     Running   1 (28m ago)   16h

#1.è¿›å…¥å®¹å™¨å‘ç°podæ²¡æœ‰pså’Œnetstatå‘½ä»¤
[root@k8s-master01 ~]# kubectl exec -it nginx-deploy-7dd6cd4b44-ktw5k  -- bash
root@nginx-deploy-7dd6cd4b44-ktw5k:/# ps aux
root@nginx-deploy-7dd6cd4b44-ktw5k:/# netstat -lntp

#2.æ³¨å…¥ä¸´æ—¶å®¹å™¨è‡³è¯¥Pod
[root@k8s-master01 ~]# kubectl debug nginx-deploy-7dd6cd4b44-wdm6p -ti --image=registry.cn-hangzhou.aliyuncs.com/old_xu/debug-tools
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;21-æ³¨å…¥ä¸´æ—¶å®¹å™¨åˆ°èŠ‚ç‚¹&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#21-æ³¨å…¥ä¸´æ—¶å®¹å™¨åˆ°èŠ‚ç‚¹&#34;&gt;#&lt;/a&gt; 2.1 æ³¨å…¥ä¸´æ—¶å®¹å™¨åˆ°èŠ‚ç‚¹&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;kubectl debug node k8s-node01 -it --image=registry.cn-hangzhou.aliyuncs.com/old_xu/debug-tools
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;æœ¬æ–‡å‡ºè‡ªäºï¼š&lt;a href=&#34;https://edu.51cto.com/course/23845.html&#34;&gt;https://edu.51cto.com/course/23845.html&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</content>
        <category term="Kubernetes" />
        <updated>2025-04-19T13:07:20.000Z</updated>
    </entry>
    <entry>
        <id>http://ixuyong.cn/posts/3833778957.html</id>
        <title>K8sè®¡åˆ’ä»»åŠ¡Jobã€Cronjob</title>
        <link rel="alternate" href="http://ixuyong.cn/posts/3833778957.html"/>
        <content type="html">&lt;h3 id=&#34;k8sè®¡åˆ’ä»»åŠ¡job-cronjob&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#k8sè®¡åˆ’ä»»åŠ¡job-cronjob&#34;&gt;#&lt;/a&gt; K8s è®¡åˆ’ä»»åŠ¡ Jobã€Cronjob&lt;/h3&gt;
&lt;h4 id=&#34;1-jobé…ç½®å‚æ•°è¯¦è§£&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-jobé…ç½®å‚æ•°è¯¦è§£&#34;&gt;#&lt;/a&gt; 1. Job é…ç½®å‚æ•°è¯¦è§£&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;# cat job.yaml 
apiVersion: batch/v1
kind: Job
metadata:
  labels:
    job-name: echo
  name: echo
  namespace: default
spec:
  #suspend: true # 1.21+
  #ttlSecondsAfterFinished: 100
  backoffLimit: 4
  completions: 1
  parallelism: 1
  template:
    spec:
      containers:
      - name: echo
        image: busybox
        imagePullPolicy: IfNotPresent
        command:
        - sh
        - -c
        - echo &amp;quot;Hello Job&amp;quot;
      restartPolicy: Never
      
[root@k8s-master01 ~]# kubectl get jobs
NAME   STATUS     COMPLETIONS   DURATION   AGE
echo   Complete   1/1           70s        2m5s

[root@k8s-master01 ~]# kubectl get pods
NAME          READY   STATUS      RESTARTS      AGE
echo-564c8    0/1     Completed   0             2m10s

[root@k8s-master01 ~]# kubectl logs echo-564c8
Hello Job
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;backoffLimit:ï¼šå¦‚æœä»»åŠ¡æ‰§è¡Œå¤±è´¥ï¼Œå¤±è´¥å¤šå°‘æ¬¡åä¸å†æ‰§è¡Œ&lt;/li&gt;
&lt;li&gt;completionsï¼šæœ‰å¤šå°‘ä¸ª Pod æ‰§è¡ŒæˆåŠŸï¼Œè®¤ä¸ºä»»åŠ¡æ˜¯æˆåŠŸçš„ï¼Œé»˜è®¤ä¸ºç©ºå’Œ parallelism æ•°å€¼ä¸€æ ·&lt;/li&gt;
&lt;li&gt;parallelismï¼šå¹¶è¡Œæ‰§è¡Œä»»åŠ¡çš„æ•°é‡ï¼Œå¦‚æœ parallelism æ•°å€¼å¤§äº completions æ•°å€¼ï¼Œåªä¼šåˆ›å»º completions çš„æ•°é‡ï¼›å¦‚æœ completions æ˜¯ 4ï¼Œå¹¶å‘æ˜¯ 3ï¼Œç¬¬ä¸€æ¬¡ä¼šåˆ›å»º 3 ä¸ª Pod æ‰§è¡Œä»»åŠ¡ï¼Œç¬¬äºŒæ¬¡åªä¼šåˆ›å»ºä¸€ä¸ª Pod æ‰§è¡Œä»»åŠ¡&lt;/li&gt;
&lt;li&gt;ttlSecondsAfterFinishedï¼šJob åœ¨æ‰§è¡Œç»“æŸä¹‹åï¼ˆçŠ¶æ€ä¸º completed æˆ– Failedï¼‰è‡ªåŠ¨æ¸…ç†ã€‚è®¾ç½®ä¸º 0 è¡¨ç¤ºæ‰§è¡Œç»“æŸç«‹å³åˆ é™¤ï¼Œä¸è®¾ç½®åˆ™ä¸ä¼šæ¸…é™¤ï¼Œéœ€è¦å¼€å¯ TTLAfterFinished ç‰¹æ€§&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2-cronjobé…ç½®å‚æ•°è¯¦è§£&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-cronjobé…ç½®å‚æ•°è¯¦è§£&#34;&gt;#&lt;/a&gt; 2. CronJob é…ç½®å‚æ•°è¯¦è§£&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;# cat cronjob.yaml 
apiVersion: batch/v1
kind: CronJob
metadata:
  name: hello
spec:
  schedule: &amp;quot;*/1 * * * *&amp;quot;
  concurrencyPolicy: Allow   #å…è®¸åŒæ—¶è¿è¡Œå¤šä¸ªä»»åŠ¡
  failedJobsHistoryLimit: 10  #ä¿ç•™å¤šå°‘å¤±è´¥çš„ä»»åŠ¡
  successfulJobsHistoryLimit: 10  #ä¿ç•™å¤šå°‘å·²å®Œæˆçš„ä»»åŠ¡
  #suspend: true             #å¦‚æœtrueåˆ™å–æ¶ˆå‘¨æœŸæ€§æ‰§è¡Œä»»åŠ¡
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: hello
            image: busybox
            command:
            - sh
            - -c
            - date; echo Hello from the Kubernetes cluster
          restartPolicy: OnFailure 
          
[root@k8s-master01 ~]# kubectl get  cj
NAME    SCHEDULE      TIMEZONE   SUSPEND   ACTIVE   LAST SCHEDULE   AGE
hello   */1 * * * *   &amp;lt;none&amp;gt;     False     0        6s              81s

[root@k8s-master01 ~]# kubectl get  jobs
NAME             STATUS     COMPLETIONS   DURATION   AGE
hello-29084454   Complete   1/1           4s         72s
hello-29084455   Complete   1/1           5s         12s

[root@k8s-master01 ~]# kubectl get  pods
NAME                   READY   STATUS      RESTARTS   AGE
hello-29084454-hwv7p   0/1     Completed   0          78s
hello-29084455-vf99w   0/1     Completed   0          18s

[root@k8s-master01 ~]# kubectl logs -f hello-29084455-vf99w
Sat Apr 19 12:55:02 UTC 2025
Hello from the Kubernetes cluster
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;apiVersion: batch/v1beta1   #1.21+ batch/v1&lt;/li&gt;
&lt;li&gt;scheduleï¼šè°ƒåº¦å‘¨æœŸï¼Œå’Œ Linux ä¸€è‡´ï¼Œåˆ†åˆ«æ˜¯åˆ†æ—¶æ—¥æœˆå‘¨ã€‚&lt;/li&gt;
&lt;li&gt;restartPolicyï¼šé‡å¯ç­–ç•¥ï¼Œå’Œ Pod ä¸€è‡´ã€‚&lt;/li&gt;
&lt;li&gt;concurrencyPolicyï¼šå¹¶å‘è°ƒåº¦ç­–ç•¥ã€‚å¯é€‰å‚æ•°å¦‚ä¸‹ï¼š
&lt;ul&gt;
&lt;li&gt;Allowï¼šå…è®¸åŒæ—¶è¿è¡Œå¤šä¸ªä»»åŠ¡ã€‚&lt;/li&gt;
&lt;li&gt;Forbidï¼šä¸å…è®¸å¹¶å‘è¿è¡Œï¼Œå¦‚æœä¹‹å‰çš„ä»»åŠ¡å°šæœªå®Œæˆï¼Œæ–°çš„ä»»åŠ¡ä¸ä¼šè¢«åˆ›å»ºã€‚&lt;/li&gt;
&lt;li&gt;Replaceï¼šå¦‚æœä¹‹å‰çš„ä»»åŠ¡å°šæœªå®Œæˆï¼Œæ–°çš„ä»»åŠ¡ä¼šæ›¿æ¢çš„ä¹‹å‰çš„ä»»åŠ¡ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;suspendï¼šå¦‚æœè®¾ç½®ä¸º trueï¼Œåˆ™æš‚åœåç»­çš„ä»»åŠ¡ï¼Œé»˜è®¤ä¸º falseã€‚&lt;/li&gt;
&lt;li&gt;successfulJobsHistoryLimitï¼šä¿ç•™å¤šå°‘å·²å®Œæˆçš„ä»»åŠ¡ï¼ŒæŒ‰éœ€é…ç½®ã€‚&lt;/li&gt;
&lt;li&gt;failedJobsHistoryLimitï¼šä¿ç•™å¤šå°‘å¤±è´¥çš„ä»»åŠ¡ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;æœ¬æ–‡å‡ºè‡ªäºï¼š&lt;a href=&#34;https://edu.51cto.com/course/23845.html&#34;&gt;https://edu.51cto.com/course/23845.html&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</content>
        <category term="Kubernetes" />
        <updated>2025-04-19T13:00:21.000Z</updated>
    </entry>
    <entry>
        <id>http://ixuyong.cn/posts/169153047.html</id>
        <title>K8sæŒä¹…åŒ–å­˜å‚¨</title>
        <link rel="alternate" href="http://ixuyong.cn/posts/169153047.html"/>
        <content type="html">&lt;h3 id=&#34;k8sæŒä¹…åŒ–å­˜å‚¨&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#k8sæŒä¹…åŒ–å­˜å‚¨&#34;&gt;#&lt;/a&gt; K8s æŒä¹…åŒ–å­˜å‚¨&lt;/h3&gt;
&lt;h4 id=&#34;1-volume&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-volume&#34;&gt;#&lt;/a&gt; 1. Volume&lt;/h4&gt;
&lt;p&gt;Containerï¼ˆå®¹å™¨ï¼‰ä¸­çš„ç£ç›˜æ–‡ä»¶æ˜¯çŸ­æš‚çš„ï¼Œå½“å®¹å™¨å´©æºƒæ—¶ï¼Œkubelet ä¼šé‡æ–°å¯åŠ¨å®¹å™¨ï¼ŒContainer ä¼šä»¥æœ€å¹²å‡€çš„çŠ¶æ€å¯åŠ¨ï¼Œæœ€åˆçš„æ–‡ä»¶å°†ä¸¢å¤±ã€‚å¦å¤–ï¼Œå½“ä¸€ä¸ª Pod è¿è¡Œå¤šä¸ª Container æ—¶ï¼Œå„ä¸ªå®¹å™¨å¯èƒ½éœ€è¦å…±äº«ä¸€äº›æ–‡ä»¶ã€‚Kubernetes Volume å¯ä»¥è§£å†³è¿™ä¸¤ä¸ªé—®é¢˜ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ä¸€äº›éœ€è¦æŒä¹…åŒ–æ•°æ®çš„ç¨‹åºæ‰ä¼šç”¨åˆ° Volumesï¼Œæˆ–è€…ä¸€äº›éœ€è¦å…±äº«æ•°æ®çš„å®¹å™¨éœ€è¦ volumesã€‚&lt;/li&gt;
&lt;li&gt;æ—¥å¿—æ”¶é›†çš„éœ€æ±‚éœ€è¦åœ¨åº”ç”¨ç¨‹åºçš„å®¹å™¨é‡Œé¢åŠ ä¸€ä¸ª sidecarï¼Œè¿™ä¸ªå®¹å™¨æ˜¯ä¸€ä¸ªæ”¶é›†æ—¥å¿—çš„å®¹å™¨ï¼Œæ¯”å¦‚ filebeatï¼Œå®ƒé€šè¿‡ volumes å…±äº«åº”ç”¨ç¨‹åºçš„æ—¥å¿—æ–‡ä»¶ç›®å½•ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;11-emptydirå®ç°æ•°æ®å…±äº«&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#11-emptydirå®ç°æ•°æ®å…±äº«&#34;&gt;#&lt;/a&gt; 1.1 EmptyDir å®ç°æ•°æ®å…±äº«&lt;/h5&gt;
&lt;p&gt;å’Œä¸Šè¿° volume ä¸åŒçš„æ˜¯ï¼Œå¦‚æœåˆ é™¤ Podï¼ŒemptyDir å·ä¸­çš„æ•°æ®ä¹Ÿå°†è¢«åˆ é™¤ï¼Œä¸€èˆ¬ emptyDir å·ç”¨äº Pod ä¸­çš„ä¸åŒ Container å…±äº«æ•°æ®ã€‚&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cat nginx-deploy.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deploy
  labels:
    app: nginx-deploy
  namespace: default
spec:
  selector:
    matchLabels:
      app: nginx-deploy
  replicas: 1
  template:
    metadata:
      labels:
        app: nginx-deploy
    spec:
      restartPolicy: Always
      volumes:
        - name: share-volume
          emptyDir: &amp;#123;&amp;#125;
      containers:
        - name: nginx
          image: nginx:latest
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              memory: 1024Mi
              cpu: 1
            requests:
              memory: 128Mi
              cpu: 100m
          volumeMounts:
            - name: share-volume
              mountPath: /opt
        - name: nginx2
          image: nginx:latest
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              memory: 1024Mi
              cpu: 1
            requests:
              memory: 128Mi
              cpu: 100m
          command:
            - sh
            - &#39;-c&#39;
            - sleep 3600
          volumeMounts:
            - name: share-volume
              mountPath: /mnt
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;12-volumes-hostpathæŒ‚è½½å®¿ä¸»æœºè·¯å¾„&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#12-volumes-hostpathæŒ‚è½½å®¿ä¸»æœºè·¯å¾„&#34;&gt;#&lt;/a&gt; 1.2 Volumes HostPath æŒ‚è½½å®¿ä¸»æœºè·¯å¾„&lt;/h5&gt;
&lt;p&gt;hostPath å·å¯å°†èŠ‚ç‚¹ä¸Šçš„æ–‡ä»¶æˆ–ç›®å½•æŒ‚è½½åˆ° Pod ä¸Šï¼Œç”¨äº Pod è‡ªå®šä¹‰æ—¥å¿—è¾“å‡ºæˆ–è®¿é—® Docker å†…éƒ¨çš„å®¹å™¨ç­‰ã€‚&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# cat nginx-deploy.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deploy
  labels:
    app: nginx-deploy
  namespace: default
spec:
  selector:
    matchLabels:
      app: nginx-deploy
  replicas: 1
  template:
    metadata:
      labels:
        app: nginx-deploy
    spec:
      restartPolicy: Always
      volumes:
      - name: share-volume
        emptyDir: &amp;#123;&amp;#125;
      - name: tz-config
        hostPath:
          path: /usr/share/zoneinfo/Asia/Shanghai
          type: &amp;quot;&amp;quot;
      - name: timezone
        hostPath:
          path: /etc/timezone
          type: &amp;quot;&amp;quot;
      containers:
        - name: nginx
          image: nginx:latest
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              memory: 1024Mi
              cpu: 1
            requests:
              memory: 128Mi
              cpu: 100m
          volumeMounts:
          - name: share-volume
            mountPath: /opt
          - name: tz-config
            mountPath: /usr/share/zoneinfo/Asia/Shanghai
          - name: tz-config
            mountPath: /etc/localtime
          - name: timezone
            mountPath: /etc/timezone
        - name: nginx2
          image: nginx:latest
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              memory: 1024Mi
              cpu: 1
            requests:
              memory: 128Mi
              cpu: 100m
          command:
            - sh
            - &#39;-c&#39;
            - sleep 3600
          volumeMounts:
          - name: share-volume
            mountPath: /mnt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;hostPath å·å¸¸ç”¨çš„ typeï¼ˆç±»å‹ï¼‰å¦‚ä¸‹ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;type ä¸ºç©ºå­—ç¬¦ä¸²ï¼šé»˜è®¤é€‰é¡¹ï¼Œæ„å‘³ç€æŒ‚è½½ hostPath å·ä¹‹å‰ä¸ä¼šæ‰§è¡Œä»»ä½•æ£€æŸ¥ã€‚&lt;/li&gt;
&lt;li&gt;DirectoryOrCreateï¼šå¦‚æœç»™å®šçš„ path ä¸å­˜åœ¨ä»»ä½•ä¸œè¥¿ï¼Œé‚£ä¹ˆå°†æ ¹æ®éœ€è¦åˆ›å»ºä¸€ä¸ªæƒé™ä¸º 0755 çš„ç©ºç›®å½•ï¼Œå’Œ Kubelet å…·æœ‰ç›¸åŒçš„ç»„å’Œæƒé™ã€‚&lt;/li&gt;
&lt;li&gt;Directoryï¼šç›®å½•å¿…é¡»å­˜åœ¨äºç»™å®šçš„è·¯å¾„ä¸‹ã€‚&lt;/li&gt;
&lt;li&gt;FileOrCreateï¼šå¦‚æœç»™å®šçš„è·¯å¾„ä¸å­˜å‚¨ä»»ä½•å†…å®¹ï¼Œåˆ™ä¼šæ ¹æ®éœ€è¦åˆ›å»ºä¸€ä¸ªç©ºæ–‡ä»¶ï¼Œæƒé™è®¾ç½®ä¸º 0644ï¼Œå’Œ Kubelet å…·æœ‰ç›¸åŒçš„ç»„å’Œæ‰€æœ‰æƒã€‚&lt;/li&gt;
&lt;li&gt;Fileï¼šæ–‡ä»¶ï¼Œå¿…é¡»å­˜åœ¨äºç»™å®šè·¯å¾„ä¸­ã€‚&lt;/li&gt;
&lt;li&gt;Socketï¼šUNIX å¥—æ¥å­—ï¼Œå¿…é¡»å­˜åœ¨äºç»™å®šè·¯å¾„ä¸­ã€‚&lt;/li&gt;
&lt;li&gt;CharDeviceï¼šå­—ç¬¦è®¾å¤‡ï¼Œå¿…é¡»å­˜åœ¨äºç»™å®šè·¯å¾„ä¸­ã€‚&lt;/li&gt;
&lt;li&gt;BlockDeviceï¼šå—è®¾å¤‡ï¼Œå¿…é¡»å­˜åœ¨äºç»™å®šè·¯å¾„ä¸­ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;13-æŒ‚è½½nfsè‡³å®¹å™¨&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#13-æŒ‚è½½nfsè‡³å®¹å™¨&#34;&gt;#&lt;/a&gt; 1.3 æŒ‚è½½ NFS è‡³å®¹å™¨&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;#1.å®‰è£…nfs
# yum install nfs-utils -y       
# mkdir /data/nfs -p
# vim /etc/exports 
/data 192.168.1.0/24(rw,no_root_squash)
# exportfs -arv   
# systemctl start nfs-server &amp;amp;&amp;amp; systemctl enable nfs-server &amp;amp;&amp;amp; systemctl status nfs-server 

#2.æµ‹è¯•å®¢æˆ·ç«¯æŒ‚è½½
# showmount -e 192.168.1.75
# mount -t nfs 192.168.1.75:/data/nfs /mnt

#3.DeployæŒ‚è½½NFS
[root@k8s-master01 ~]# cat nginx-deploy-nfs.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deploy
  labels:
    app: nginx-deploy
  annotations:
    app: nginx-deploy
  namespace: default
spec:
  selector:
    matchLabels:
      app: nginx-deploy
  replicas: 1
  template:
    metadata:
      labels:
        app: nginx-deploy
      annotations:
        app: nginx-deploy
    spec:
      restartPolicy: Always
      volumes:
      - name: nfs-volume
        nfs:
          server: 192.168.1.75
          path: /data/nfs
      - name: tz-config
        hostPath:
          path: /usr/share/zoneinfo/Asia/Shanghai
          type: &amp;quot;&amp;quot;
      - name: timezone
        hostPath:
          path: /etc/timezone
          type: &amp;quot;&amp;quot;
      containers:
        - name: nginx-deploy
          image: nginx:latest
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              memory: 1024Mi
              cpu: 1
            requests:
              memory: 128Mi
              cpu: 100m
          volumeMounts:
          - name: nfs-volume
            mountPath: /usr/share/nginx/html
          - name: tz-config
            mountPath: /usr/share/zoneinfo/Asia/Shanghai
          - name: tz-config
            mountPath: /etc/localtime
          - name: timezone
            mountPath: /etc/timezone
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2-pv-pvc&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-pv-pvc&#34;&gt;#&lt;/a&gt; 2. PVã€PVC&lt;/h4&gt;
&lt;p&gt;PersistentVolumeï¼šç®€ç§° PVï¼Œæ˜¯ç”± Kubernetes ç®¡ç†å‘˜è®¾ç½®çš„å­˜å‚¨ï¼Œå¯ä»¥é…ç½® Cephã€NFSã€GlusterFS ç­‰å¸¸ç”¨å­˜å‚¨é…ç½®ï¼Œç›¸å¯¹äº Volume é…ç½®ï¼Œæä¾›äº†æ›´å¤šçš„åŠŸèƒ½ï¼Œæ¯”å¦‚ç”Ÿå‘½å‘¨æœŸçš„ç®¡ç†ã€å¤§å°çš„é™åˆ¶ã€‚PV åˆ†ä¸ºé™æ€å’ŒåŠ¨æ€ã€‚&lt;/p&gt;
&lt;p&gt;PersistentVolumeClaimï¼šç®€ç§° PVCï¼Œæ˜¯å¯¹å­˜å‚¨ PV çš„è¯·æ±‚ï¼Œè¡¨ç¤ºéœ€è¦ä»€ä¹ˆç±»å‹çš„ PVï¼Œéœ€è¦å­˜å‚¨çš„æŠ€æœ¯äººå‘˜åªéœ€è¦é…ç½® PVC å³å¯ä½¿ç”¨å­˜å‚¨ï¼Œæˆ–è€… Volume é…ç½® PVC çš„åç§°å³å¯ã€‚&lt;/p&gt;
&lt;h5 id=&#34;21-pvå›æ”¶ç­–ç•¥&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#21-pvå›æ”¶ç­–ç•¥&#34;&gt;#&lt;/a&gt; 2.1 PV å›æ”¶ç­–ç•¥&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Retainï¼šä¿ç•™ï¼Œè¯¥ç­–ç•¥å…è®¸æ‰‹åŠ¨å›æ”¶èµ„æºï¼Œå½“åˆ é™¤ PVC æ—¶ï¼ŒPV ä»ç„¶å­˜åœ¨ï¼ŒPV è¢«è§†ä¸ºå·²é‡Šæ”¾ï¼Œç®¡ç†å‘˜å¯ä»¥æ‰‹åŠ¨å›æ”¶å·ã€‚&lt;/li&gt;
&lt;li&gt;Recycleï¼šå›æ”¶ï¼Œå¦‚æœ Volume æ’ä»¶æ”¯æŒï¼ŒRecycle ç­–ç•¥ä¼šå¯¹å·æ‰§è¡Œ rm -rf æ¸…ç†è¯¥ PVï¼Œå¹¶ä½¿å…¶å¯ç”¨äºä¸‹ä¸€ä¸ªæ–°çš„ PVCï¼Œä½†æ˜¯æœ¬ç­–ç•¥å°†æ¥ä¼šè¢«å¼ƒç”¨ï¼Œç›®å‰åªæœ‰ NFS å’Œ HostPath æ”¯æŒè¯¥ç­–ç•¥ã€‚&lt;/li&gt;
&lt;li&gt;Deleteï¼šåˆ é™¤ï¼Œå¦‚æœ Volume æ’ä»¶æ”¯æŒï¼Œåˆ é™¤ PVC æ—¶ä¼šåŒæ—¶åˆ é™¤ PVï¼ŒåŠ¨æ€å·é»˜è®¤ä¸º Deleteï¼Œç›®å‰æ”¯æŒ Delete çš„å­˜å‚¨åç«¯åŒ…æ‹¬ AWS EBS, GCE PD, Azure Disk, or OpenStack Cinder ç­‰ã€‚&lt;/li&gt;
&lt;li&gt;å¯ä»¥é€šè¿‡ persistentVolumeReclaimPolicy: Recycle å­—æ®µé…ç½®&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;22-pvè®¿é—®ç­–ç•¥&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#22-pvè®¿é—®ç­–ç•¥&#34;&gt;#&lt;/a&gt; 2.2 PV è®¿é—®ç­–ç•¥&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;ReadWriteOnceï¼šå¯ä»¥è¢«å•èŠ‚ç‚¹ä»¥è¯»å†™æ¨¡å¼æŒ‚è½½ï¼Œå‘½ä»¤è¡Œä¸­å¯ä»¥è¢«ç¼©å†™ä¸º RWOã€‚&lt;/li&gt;
&lt;li&gt;ReadOnlyManyï¼šå¯ä»¥è¢«å¤šä¸ªèŠ‚ç‚¹ä»¥åªè¯»æ¨¡å¼æŒ‚è½½ï¼Œå‘½ä»¤è¡Œä¸­å¯ä»¥è¢«ç¼©å†™ä¸º ROXã€‚&lt;/li&gt;
&lt;li&gt;ReadWriteManyï¼šå¯ä»¥è¢«å¤šä¸ªèŠ‚ç‚¹ä»¥è¯»å†™æ¨¡å¼æŒ‚è½½ï¼Œå‘½ä»¤è¡Œä¸­å¯ä»¥è¢«ç¼©å†™ä¸º RWXã€‚&lt;/li&gt;
&lt;li&gt;ReadWriteOncePod ï¼šåªå…è®¸è¢«å•ä¸ª Pod è®¿é—®ï¼Œéœ€è¦ K8s 1.22 + ä»¥ä¸Šç‰ˆæœ¬ï¼Œå¹¶ä¸”æ˜¯ CSI åˆ›å»ºçš„ PV æ‰å¯ä½¿ç”¨ï¼Œç¼©å†™ä¸º RWOP&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Volume Plugin&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;ReadWriteOnce&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;ReadOnlyMany&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;ReadWriteMany&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;ReadWriteOncePod&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;AzureFile&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;âœ“&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;âœ“&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;âœ“&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;CephFS&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;âœ“&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;âœ“&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;âœ“&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;CSI&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;depends on the driver&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;depends on the driver&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;depends on the driver&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;depends on the driver&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;FC&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;âœ“&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;âœ“&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;FlexVolume&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;âœ“&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;âœ“&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;depends on the driver&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;HostPath&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;âœ“&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;iSCSI&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;âœ“&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;âœ“&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;NFS&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;âœ“&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;âœ“&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;âœ“&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;RBD&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;âœ“&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;âœ“&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;VsphereVolume&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;âœ“&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;- (works when Pods are collocated)&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;PortworxVolume&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;âœ“&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;âœ“&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h5 id=&#34;23-å­˜å‚¨åˆ†ç±»&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#23-å­˜å‚¨åˆ†ç±»&#34;&gt;#&lt;/a&gt; 2.3 å­˜å‚¨åˆ†ç±»&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;æ–‡ä»¶å­˜å‚¨ï¼šä¸€äº›æ•°æ®å¯èƒ½éœ€è¦è¢«å¤šä¸ªèŠ‚ç‚¹ä½¿ç”¨ï¼Œæ¯”å¦‚ç”¨æˆ·çš„å¤´åƒã€ç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶ç­‰ï¼Œå®ç°æ–¹å¼ï¼šNFSã€NASã€FTPã€CephFS ç­‰ã€‚&lt;/li&gt;
&lt;li&gt;å—å­˜å‚¨ï¼šä¸€äº›æ•°æ®åªèƒ½è¢«ä¸€ä¸ªèŠ‚ç‚¹ä½¿ç”¨ï¼Œæˆ–è€…æ˜¯éœ€è¦å°†ä¸€å—è£¸ç›˜æ•´ä¸ªæŒ‚è½½ä½¿ç”¨ï¼Œæ¯”å¦‚æ•°æ®åº“ã€Redis ç­‰ï¼Œå®ç°æ–¹å¼ï¼šCephã€GlusterFSã€å…¬æœ‰äº‘ã€‚&lt;/li&gt;
&lt;li&gt;å¯¹è±¡å­˜å‚¨ï¼šç”±ç¨‹åºä»£ç ç›´æ¥å®ç°çš„ä¸€ç§å­˜å‚¨æ–¹å¼ï¼Œäº‘åŸç”Ÿåº”ç”¨æ— çŠ¶æ€åŒ–å¸¸ç”¨çš„å®ç°æ–¹å¼ï¼Œå®ç°æ–¹å¼ï¼šä¸€èˆ¬æ˜¯ç¬¦åˆ S3 åè®®çš„äº‘å­˜å‚¨ï¼Œæ¯”å¦‚ AWS çš„ S3 å­˜å‚¨ã€Minioã€ä¸ƒç‰›äº‘ç­‰ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;24-pvé…ç½®ç¤ºä¾‹nfs&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#24-pvé…ç½®ç¤ºä¾‹nfs&#34;&gt;#&lt;/a&gt; 2.4 PV é…ç½®ç¤ºä¾‹ NFS&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfs-pv1
spec:
  capacity:
    storage: 5Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: nfs-slow
  nfs:
    path: /data/pv1
    server: 192.168.1.75
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;capacityï¼šå®¹é‡é…ç½®&lt;/p&gt;
&lt;p&gt;volumeModeï¼šå·çš„æ¨¡å¼ï¼Œç›®å‰æ”¯æŒ Filesystemï¼ˆæ–‡ä»¶ç³»ç»Ÿï¼‰ å’Œ Blockï¼ˆå—ï¼‰ï¼Œå…¶ä¸­ Block ç±»å‹éœ€è¦åç«¯å­˜å‚¨æ”¯æŒï¼Œé»˜è®¤ä¸ºæ–‡ä»¶ç³»ç»Ÿ&lt;/p&gt;
&lt;p&gt;accessModesï¼šè¯¥ PV çš„è®¿é—®æ¨¡å¼&lt;/p&gt;
&lt;p&gt;storageClassNameï¼šPV çš„ç±»ï¼Œä¸€ä¸ªç‰¹å®šç±»å‹çš„ PV åªèƒ½ç»‘å®šåˆ°ç‰¹å®šç±»åˆ«çš„ PVCï¼›&lt;/p&gt;
&lt;p&gt;persistentVolumeReclaimPolicyï¼šå›æ”¶ç­–ç•¥&lt;/p&gt;
&lt;p&gt;mountOptionsï¼šéå¿…é¡»ï¼Œæ–°ç‰ˆæœ¬ä¸­å·²å¼ƒç”¨&lt;/p&gt;
&lt;p&gt;nfsï¼šNFS æœåŠ¡é…ç½®ï¼ŒåŒ…æ‹¬ä»¥ä¸‹ä¸¤ä¸ªé€‰é¡¹&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;pathï¼šNFS ä¸Šçš„å…±äº«ç›®å½•&lt;/li&gt;
&lt;li&gt;serverï¼šNFS çš„ IP åœ°å€&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;25-pvé…ç½®ç¤ºä¾‹hostpath&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#25-pvé…ç½®ç¤ºä¾‹hostpath&#34;&gt;#&lt;/a&gt; 2.5 PV é…ç½®ç¤ºä¾‹ HostPath&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: PersistentVolume
metadata:
  name: hostpath
spec:
  capacity:
    storage: 5Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: hostpath
  hostPath:
    path: &amp;quot;/mnt/data&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;hostPathï¼šhostPath æœåŠ¡é…ç½®&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;pathï¼šå®¿ä¸»æœºè·¯å¾„&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;26-pvçš„çŠ¶æ€&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#26-pvçš„çŠ¶æ€&#34;&gt;#&lt;/a&gt; 2.6 PV çš„çŠ¶æ€&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Availableï¼šå¯ç”¨ï¼Œæ²¡æœ‰è¢« PVC ç»‘å®šçš„ç©ºé—²èµ„æºã€‚&lt;/li&gt;
&lt;li&gt;Boundï¼šå·²ç»‘å®šï¼Œå·²ç»è¢« PVC ç»‘å®šã€‚&lt;/li&gt;
&lt;li&gt;Releasedï¼šå·²é‡Šæ”¾ï¼ŒPVC è¢«åˆ é™¤ï¼Œä½†æ˜¯èµ„æºè¿˜æœªè¢«é‡æ–°ä½¿ç”¨ã€‚&lt;/li&gt;
&lt;li&gt;Failedï¼šå¤±è´¥ï¼Œè‡ªåŠ¨å›æ”¶å¤±è´¥ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;27-pvcç»‘å®špv&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#27-pvcç»‘å®špv&#34;&gt;#&lt;/a&gt; 2.7 PVC ç»‘å®š PV&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nfs-pvc
spec:
  storageClassName: nfs-slow
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi      
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;PVC çš„ç©ºé—´ç”³è¯·å¤§å°â‰¤PV çš„å¤§å°&lt;/li&gt;
&lt;li&gt;PVC çš„ StorageClassName å’Œ PV çš„ä¸€è‡´&lt;/li&gt;
&lt;li&gt;PVC çš„ accessModes å’Œ PV çš„ä¸€è‡´&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;28-depoymentæŒ‚è½½pvc&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#28-depoymentæŒ‚è½½pvc&#34;&gt;#&lt;/a&gt; 2.8 Depoyment æŒ‚è½½ PVC&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: nginx-deploy
  name: nginx-deploy
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx-deploy
  template:
    metadata:
      labels:
        app: nginx-deploy
    spec:
      volumes:
      - name: nfs-pvc-storage  #volumeåç§°
        persistentVolumeClaim:
          claimName: nfs-pvc   #PVCåç§°
      containers:
      - image: nginx
        name: nginx
        volumeMounts:
         - name: nfs-pvc-storage
          mountPath: /usr/share/nginx/html
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æŒ‚è½½ PVC çš„ Pod ä¸€ç›´å¤„äº Pendingï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PVC æ²¡æœ‰åˆ›å»ºæˆåŠŸæˆ– PVC ä¸å­˜åœ¨&lt;/li&gt;
&lt;li&gt;PVC å’Œ Pod ä¸åœ¨åŒä¸€ä¸ª Namespace&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;æœ¬æ–‡å‡ºè‡ªäºï¼š&lt;a href=&#34;https://edu.51cto.com/course/23845.html&#34;&gt;https://edu.51cto.com/course/23845.html&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</content>
        <category term="Kubernetes" />
        <updated>2025-04-18T14:25:17.000Z</updated>
    </entry>
    <entry>
        <id>http://ixuyong.cn/posts/3992668367.html</id>
        <title>K8sé…ç½®ç®¡ç†Configmap</title>
        <link rel="alternate" href="http://ixuyong.cn/posts/3992668367.html"/>
        <content type="html">&lt;h3 id=&#34;k8sé…ç½®ç®¡ç†configmap&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#k8sé…ç½®ç®¡ç†configmap&#34;&gt;#&lt;/a&gt; K8s é…ç½®ç®¡ç† Configmap&lt;/h3&gt;
&lt;h4 id=&#34;1-configmap&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-configmap&#34;&gt;#&lt;/a&gt; 1. Configmap&lt;/h4&gt;
&lt;h5 id=&#34;1-1-åŸºäºfrom-env-fileåˆ›å»ºconfigmap&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-1-åŸºäºfrom-env-fileåˆ›å»ºconfigmap&#34;&gt;#&lt;/a&gt; 1. 1 åŸºäº from-env-file åˆ›å»º Configmap&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;# cat cm_env.conf 
podname=nf-flms-system
podip=192.168.1.100
env=prod
nacosaddr=nacos.svc.cluster.local

#kubectl create cm cmenv --from-env-file=./cm_env.conf 
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;12-åŸºäºfrom-literalåˆ›å»ºconfigmap&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#12-åŸºäºfrom-literalåˆ›å»ºconfigmap&#34;&gt;#&lt;/a&gt; 1.2 åŸºäº from-literal åˆ›å»º Configmap&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;# kubectl create cm cmliteral --from-literal=level=INFO --from-literal=passwd=Superman*2023
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;13-åŸºäºfrom-fileåˆ›å»ºconfigmap&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#13-åŸºäºfrom-fileåˆ›å»ºconfigmap&#34;&gt;#&lt;/a&gt; 1.3 åŸºäº from-file åˆ›å»º Configmap&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;# cat s.hmallleasing.com.conf 
server &amp;#123;
    listen 80;
    server_name s.hmallleasing.com;
    client_max_body_size 1G; 
    location / &amp;#123;
        proxy_pass http://192.168.1.134;
        proxy_set_header Host $http_host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        
        proxy_connect_timeout 30;
        proxy_send_timeout 60;
        proxy_read_timeout 60;
        
        proxy_buffering on;
        proxy_buffer_size 32k;
        proxy_buffers 4 128k;
        proxy_temp_file_write_size 10240k;		
        proxy_max_temp_file_size 10240k;
    &amp;#125;
&amp;#125;

server &amp;#123;
    listen 80;
    server_name s.hmallleasing.com;
    return 302 https://$server_name$request_uri;
&amp;#125;

# kubectl create cm nginxconfig --from-file=./s.hmallleasing.com.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;14-deploymentæŒ‚è½½configmapç¤ºä¾‹&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#14-deploymentæŒ‚è½½configmapç¤ºä¾‹&#34;&gt;#&lt;/a&gt; 1.4 Deployment æŒ‚è½½ configmap ç¤ºä¾‹&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 cm]# cat deploy.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: nginx-deploy
  name: nginx-deploy
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx-deploy
  template:
    metadata:
      labels:
        app: nginx-deploy
    spec:
      imagePullSecrets:        
      - name: harboradmin
      containers:
      - image: nginx
        name: nginx
        ports:
        - name: http
          containerPort: 80
          protocol: TCP
        envFrom:         # 1.æ‰¹é‡æŒ‚è½½ConfigMapç”Ÿæˆç¯å¢ƒå˜é‡
        - configMapRef:
            name: cmenv
        env:
        - name: MYSQL_ADDR     # 2.è‡ªå®šä¹‰ç¯å¢ƒå˜é‡
          value: &amp;quot;192.168.40.150&amp;quot;
        - name: MYSQL_PASSWD
          value: Superman*2022
        - name: LOG_LEVEL           # 3.æŒ‚è½½å•ä¸ªConfigMapç”Ÿæˆç¯å¢ƒå˜é‡ï¼Œè¿™é‡Œå’ŒConfigMapä¸­çš„é”®åæ˜¯ä¸ä¸€æ ·çš„     
          valueFrom:
            configMapKeyRef:
              name: cmliteral       # è¿™ä¸ªå€¼æ¥è‡ªConfigMap
              key: level            # æ¥è‡ªConfigMapçš„key
        volumeMounts:              
        - name: nginx-config
          mountPath: &amp;quot;/etc/nginx/conf.d&amp;quot;
          readOnly: true
      volumes:
      - name: nginx-config
        configMap:
          name: nginxconfig      # æä¾›ä½ æƒ³è¦æŒ‚è½½çš„ ConfigMap çš„åå­—
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;15-é‡å‘½åæŒ‚è½½çš„configmaq-keyçš„åç§°&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#15-é‡å‘½åæŒ‚è½½çš„configmaq-keyçš„åç§°&#34;&gt;#&lt;/a&gt; 1.5 é‡å‘½åæŒ‚è½½çš„ configmaq key çš„åç§°&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 cm]# cat deploy.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: nginx-deploy
  name: nginx-deploy
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx-deploy
  template:
    metadata:
      labels:
        app: nginx-deploy
    spec:
      imagePullSecrets:        
      - name: harboradmin
      containers:
      - image: nginx
        name: nginx
        ports:
        - name: http
          containerPort: 80
          protocol: TCP
        envFrom:         # 1.æ‰¹é‡æŒ‚è½½ConfigMapç”Ÿæˆç¯å¢ƒå˜é‡
        - configMapRef:
            name: cmenv
        env:
        - name: MYSQL_ADDR     # 2.è‡ªå®šä¹‰ç¯å¢ƒå˜é‡
          value: &amp;quot;192.168.40.150&amp;quot;
        - name: MYSQL_PASSWD
          value: Superman*2022
        - name: LOG_LEVEL           # 3.æŒ‚è½½å•ä¸ªConfigMapç”Ÿæˆç¯å¢ƒå˜é‡ï¼Œè¿™é‡Œå’ŒConfigMapä¸­çš„é”®åæ˜¯ä¸ä¸€æ ·çš„     
          valueFrom:
            configMapKeyRef:
              name: cmliteral       # è¿™ä¸ªå€¼æ¥è‡ªConfigMap
              key: level            # æ¥è‡ªConfigMapçš„key
        volumeMounts:              
        - name: nginx-config
          mountPath: &amp;quot;/etc/nginx/conf.d&amp;quot;
          readOnly: true
      volumes:
      - name: nginx-config
        configMap:
          name: nginxconfig      # æä¾›ä½ æƒ³è¦æŒ‚è½½çš„ ConfigMap çš„åå­—
          items:                # é‡å‘½åæŒ‚è½½çš„configmaq keyçš„åç§°ä¸ºnginx.conf
          - key: s.hmallleasing.com.conf  
            path: nginx.conf
 
#æŸ¥çœ‹æŒ‚è½½çš„configmaq keyçš„åç§°é‡å‘½åä¸ºnginx.conf
[root@k8s-master01 cm]# kubectl get pods
NAME                           READY   STATUS    RESTARTS   AGE
nginx-deploy-bc476bc56-flln4   1/1     Running   0          10h
nginx-deploy-bc476bc56-jhsh6   1/1     Running   0          10h
nginx-deploy-bc476bc56-splv9   1/1     Running   0          10h
[root@k8s-master01 cm]# kubectl exec -it nginx-deploy-bc476bc56-flln4 -- bash
root@nginx-deploy-bc476bc56-flln4:/# ls /etc/nginx/conf.d/
nginx.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;16-ä¿®æ”¹æŒ‚è½½çš„configmaq-æƒé™&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#16-ä¿®æ”¹æŒ‚è½½çš„configmaq-æƒé™&#34;&gt;#&lt;/a&gt; 1.6 ä¿®æ”¹æŒ‚è½½çš„ configmaq æƒé™&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 cm]# cat deploy.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: nginx-deploy
  name: nginx-deploy
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx-deploy
  template:
    metadata:
      labels:
        app: nginx-deploy
    spec:
      imagePullSecrets:        
      - name: harboradmin
      containers:
      - image: nginx
        name: nginx
        ports:
        - name: http
          containerPort: 80
          protocol: TCP
        envFrom:         # 1.æ‰¹é‡æŒ‚è½½ConfigMapç”Ÿæˆç¯å¢ƒå˜é‡
        - configMapRef:
            name: cmenv
        env:
        - name: MYSQL_ADDR     # 2.è‡ªå®šä¹‰ç¯å¢ƒå˜é‡
          value: &amp;quot;192.168.40.150&amp;quot;
        - name: MYSQL_PASSWD
          value: Superman*2022
        - name: LOG_LEVEL           # 3.æŒ‚è½½å•ä¸ªConfigMapç”Ÿæˆç¯å¢ƒå˜é‡ï¼Œè¿™é‡Œå’ŒConfigMapä¸­çš„é”®åæ˜¯ä¸ä¸€æ ·çš„     
          valueFrom:
            configMapKeyRef:
              name: cmliteral       # è¿™ä¸ªå€¼æ¥è‡ªConfigMap
              key: level            # æ¥è‡ªConfigMapçš„key
        volumeMounts:              
        - name: nginx-config
          mountPath: &amp;quot;/etc/nginx/conf.d&amp;quot;
          readOnly: true
      volumes:
      - name: nginx-config
        configMap:
          name: nginxconfig      # æä¾›ä½ æƒ³è¦æŒ‚è½½çš„ ConfigMap çš„åå­—
          items:                # é‡å‘½åæŒ‚è½½çš„configmaq keyçš„åç§°ä¸ºnginx.conf
          - key: s.hmallleasing.com.conf  
            path: nginx.conf
            mode: 0644        # é…ç½®æŒ‚è½½æƒé™ï¼Œé’ˆå¯¹å•ä¸ªkeyç”Ÿæ•ˆ
          defaultMode: 0666   # é…ç½®æŒ‚è½½æƒé™ï¼Œé’ˆå¯¹æ•´ä¸ªkeyç”Ÿæ•ˆ
    
#æŸ¥çœ‹æŒ‚è½½æƒé™
root@nginx-deploy-7657fbffc7-k75l5:/# ls -l /etc/nginx/conf.d/nginx.conf 
lrwxrwxrwx 1 root root 17 Apr 16 13:37 /etc/nginx/conf.d/nginx.conf -&amp;gt; ..data/nginx.conf
root@nginx-deploy-7657fbffc7-k75l5:/# ls -l /etc/nginx/conf.d/..data/nginx.conf 
-rw-rw-rw- 1 root root 722 Apr 16 13:37 /etc/nginx/conf.d/..data/nginx.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;17-subpathè§£å†³æŒ‚è½½è¦†ç›–é—®é¢˜&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#17-subpathè§£å†³æŒ‚è½½è¦†ç›–é—®é¢˜&#34;&gt;#&lt;/a&gt; 1.7 subpath è§£å†³æŒ‚è½½è¦†ç›–é—®é¢˜&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;#1.åˆ›å»ºconfigmap
[root@k8s-master01 cm]# cat nginx.conf 

user  nginx;
worker_processes  1;

error_log  /var/log/nginx/error.log warn;
pid        /var/run/nginx.pid;


events &amp;#123;
    worker_connections  512;
&amp;#125;


http &amp;#123;
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format  main  &#39;$remote_addr - $remote_user [$time_local] &amp;quot;$request&amp;quot; &#39;
                      &#39;$status $body_bytes_sent &amp;quot;$http_referer&amp;quot; &#39;
                      &#39;&amp;quot;$http_user_agent&amp;quot; &amp;quot;$http_x_forwarded_for&amp;quot;&#39;;

    access_log  /var/log/nginx/access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    keepalive_timeout  65;

    #gzip  on;

    include /etc/nginx/conf.d/*.conf;
&amp;#125;

[root@k8s-master01 cm]# kubectl create cm nginx-config --from-file=./nginx.conf

#subpathè§£å†³æŒ‚è½½è¦†ç›–é—®é¢˜
[root@k8s-master01 study]# cat cm-deploy.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: nginx-deploy
  name: nginx-deploy
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx-deploy
  template:
    metadata:
      labels:
        app: nginx-deploy
    spec:
      imagePullSecrets:        
      - name: harboradmin
      containers:
      - image: nginx
        name: nginx
        ports:
        - name: http
          containerPort: 80
          protocol: TCP
        envFrom:         # â‘ æ‰¹é‡æŒ‚è½½ConfigMapç”Ÿæˆç¯å¢ƒå˜é‡
        - configMapRef:
            name: cmenv
        env:
        - name: MYSQL_ADDR     # â‘¡è‡ªå®šä¹‰ç¯å¢ƒå˜é‡
          value: &amp;quot;192.168.40.150&amp;quot;
        - name: MYSQL_PASSWD
          value: Superman*2022
        - name: LOG_LEVEL           # â‘¢æŒ‚è½½å•ä¸ªConfigMapç”Ÿæˆç¯å¢ƒå˜é‡ï¼Œè¿™é‡Œå’ŒConfigMapä¸­çš„é”®åæ˜¯ä¸ä¸€æ ·çš„     
          valueFrom:
            configMapKeyRef:
              name: cmliteral       # è¿™ä¸ªå€¼æ¥è‡ªConfigMap
              key: level            # æ¥è‡ªConfigMapçš„key
        volumeMounts:
        - name: config
          mountPath: &amp;quot;/etc/nginx/nginx.conf&amp;quot;   #åªæŒ‚åœ¨nginx.confä¸€ä¸ªæ–‡ä»¶,ä¸è¦†ç›–ç›®å½•
          subPath: nginx.conf      
      volumes:
      - name: config
        configMap:
          name: nginx-config      # æä¾›ä½ æƒ³è¦æŒ‚è½½çš„ConfigMapçš„åå­—
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2-secret&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-secret&#34;&gt;#&lt;/a&gt; 2. Secret&lt;/h4&gt;
&lt;h5 id=&#34;21-secretæ‹‰å–ç§æœ‰ä»“åº“é•œåƒ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#21-secretæ‹‰å–ç§æœ‰ä»“åº“é•œåƒ&#34;&gt;#&lt;/a&gt; 2.1 Secret æ‹‰å–ç§æœ‰ä»“åº“é•œåƒ&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;# kubectl create secret docker-registry harboradmin \
--docker-server=s.hmallleasing.com \
--docker-username=admin \
--docker-password=Superman*2023 
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;22-åˆ›å»ºssl-secret&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#22-åˆ›å»ºssl-secret&#34;&gt;#&lt;/a&gt; 2.2 åˆ›å»º ssl Secret&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;# kubectl create secret tls dev.hmallleasig.com --key *.hmallleasing.com_key.key --cert *.hmallleasing.com_chain.crt -n dev
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;23-åŸºäºå‘½ä»¤åˆ›å»ºgeneric-secret&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#23-åŸºäºå‘½ä»¤åˆ›å»ºgeneric-secret&#34;&gt;#&lt;/a&gt; 2.3 åŸºäºå‘½ä»¤åˆ›å»º generic Secret&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;#1.é€šè¿‡from-env-fileåˆ›å»º
# cat db.conf 
username=xuyong
passwd=Superman*2023

# kubectl create secret generic dbconf --from-env-file=./db.conf

#2.é€šè¿‡from-literalåˆ›å»º
kubectl create secret generic db-user-pass \
    --from-literal=username=admin \
    --from-literal=password=&#39;S!B\*d$zDsb=&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;24-secretåŠ å¯†-è§£å¯†&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#24-secretåŠ å¯†-è§£å¯†&#34;&gt;#&lt;/a&gt; 2.4 Secret åŠ å¯†ã€è§£å¯†&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;1.åŠ å¯†
# echo -n &amp;quot;Superman*2023&amp;quot; | base64
U3VwZXJtYW4qMjAyMw==

2.è§£å¯†
# echo &amp;quot;U3VwZXJtYW4qMjAyMw==&amp;quot; | base64 --decode
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;25-åŸºäºæ–‡ä»¶åˆ›å»ºéåŠ å¯†generic-secret&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#25-åŸºäºæ–‡ä»¶åˆ›å»ºéåŠ å¯†generic-secret&#34;&gt;#&lt;/a&gt; 2.5 åŸºäºæ–‡ä»¶åˆ›å»ºéåŠ å¯† generic Secret&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;# kubectl get secret dbconf -oyaml
apiVersion: v1
data:
  passwd: U3VwZXJtYW4qMjAyMw==
  username: eHV5b25n
kind: Secret
metadata:
  name: dbconf
  namespace: default
type: Opaque
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;2-6-åŸºäºyamlåˆ›å»ºåŠ å¯†generic-secret&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-6-åŸºäºyamlåˆ›å»ºåŠ å¯†generic-secret&#34;&gt;#&lt;/a&gt; 2. 6 åŸºäº yaml åˆ›å»ºåŠ å¯† generic Secret&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;# cat mysql-secret.yaml 
apiVersion: v1
kind: Secret
metadata:
  name: mysql-secret
  namespace: dev
stringData:
  MYSQL_ROOT_PASSWORD: Superman*2023
type: Opaque
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;27-deploymentæŒ‚è½½secretç¤ºä¾‹&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#27-deploymentæŒ‚è½½secretç¤ºä¾‹&#34;&gt;#&lt;/a&gt; 2.7 Deployment æŒ‚è½½ Secret ç¤ºä¾‹&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 study]# cat cm-deploy.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: nginx-deploy
  name: nginx-deploy
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx-deploy
  template:
    metadata:
      labels:
        app: nginx-deploy
    spec:
      imagePullSecrets:        
      - name: harboradmin
      containers:
      - image: nginx
        name: nginx
        ports:
        - name: http
          containerPort: 80
          protocol: TCP
        - name: MYSQL_ROOT_PASSWORD  
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: MYSQL_ROOT_PASSWORD
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;3-configmapsecretçƒ­æ›´æ–°&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3-configmapsecretçƒ­æ›´æ–°&#34;&gt;#&lt;/a&gt; 3. ConfigMap&amp;amp;Secret çƒ­æ›´æ–°&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;# kubectl create cm nginxconfig --from-file=nginx.conf --dry-run=client -oyaml | kubectl replace -f -
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;æœ¬æ–‡å‡ºè‡ªäºï¼š&lt;a href=&#34;https://edu.51cto.com/course/23845.html&#34;&gt;https://edu.51cto.com/course/23845.html&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</content>
        <category term="Kubernetes" />
        <updated>2025-04-14T13:47:47.000Z</updated>
    </entry>
    <entry>
        <id>http://ixuyong.cn/posts/858611107.html</id>
        <title>K8sæœåŠ¡å‘å¸ƒService</title>
        <link rel="alternate" href="http://ixuyong.cn/posts/858611107.html"/>
        <content type="html">&lt;h3 id=&#34;k8sæœåŠ¡å‘å¸ƒservice&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#k8sæœåŠ¡å‘å¸ƒservice&#34;&gt;#&lt;/a&gt; K8s æœåŠ¡å‘å¸ƒ Service&lt;/h3&gt;
&lt;h4 id=&#34;1-serviceç±»å‹&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-serviceç±»å‹&#34;&gt;#&lt;/a&gt; 1. Service ç±»å‹&lt;/h4&gt;
&lt;p&gt;Kubernetes Service Typeï¼ˆæœåŠ¡ç±»å‹ï¼‰ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ç§ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ClusterIPï¼šåœ¨é›†ç¾¤å†…éƒ¨ä½¿ç”¨ï¼Œé»˜è®¤å€¼ï¼Œåªèƒ½ä»é›†ç¾¤ä¸­è®¿é—®ã€‚&lt;/li&gt;
&lt;li&gt;NodePortï¼šåœ¨æ‰€æœ‰å®‰è£…äº† Kube-Proxy çš„èŠ‚ç‚¹ä¸Šæ‰“å¼€ä¸€ä¸ªç«¯å£ï¼Œæ­¤ç«¯å£å¯ä»¥ä»£ç†è‡³åç«¯ Podï¼Œå¯ä»¥é€šè¿‡ NodePort ä»é›†ç¾¤å¤–éƒ¨è®¿é—®é›†ç¾¤å†…çš„æœåŠ¡ï¼Œæ ¼å¼ä¸º NodeIP:NodePortã€‚&lt;/li&gt;
&lt;li&gt;LoadBalancerï¼šä½¿ç”¨äº‘æä¾›å•†çš„è´Ÿè½½å‡è¡¡å™¨å…¬å¼€æœåŠ¡ï¼Œæˆæœ¬è¾ƒé«˜ã€‚&lt;/li&gt;
&lt;li&gt;ExternalNameï¼šé€šè¿‡è¿”å›å®šä¹‰çš„ CNAME åˆ«åï¼Œæ²¡æœ‰è®¾ç½®ä»»ä½•ç±»å‹çš„ä»£ç†ï¼Œéœ€è¦ 1.7 æˆ–æ›´é«˜ç‰ˆæœ¬ kube-dns æ”¯æŒã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;11-nodeportç±»å‹&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#11-nodeportç±»å‹&#34;&gt;#&lt;/a&gt; 1.1 NodePort ç±»å‹&lt;/h5&gt;
&lt;p&gt;å¦‚æœå°† Service çš„ type å­—æ®µè®¾ç½®ä¸º NodePortï¼Œåˆ™ Kubernetes å°†ä» --service-node-port-range å‚æ•°æŒ‡å®šçš„èŒƒå›´ï¼ˆé»˜è®¤ä¸º 30000-32767ï¼‰ä¸­è‡ªåŠ¨åˆ†é…ç«¯å£ï¼Œä¹Ÿå¯ä»¥æ‰‹åŠ¨æŒ‡å®š NodePortï¼Œåˆ›å»ºè¯¥ Service åï¼Œé›†ç¾¤æ¯ä¸ªèŠ‚ç‚¹éƒ½å°†æš´éœ²ä¸€ä¸ªç«¯å£ï¼Œé€šè¿‡æŸä¸ªå®¿ä¸»æœºçš„ IP + ç«¯å£å³å¯è®¿é—®åˆ°åç«¯çš„åº”ç”¨ã€‚&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Service
metadata:
  name: nginx-svc
  namespace: default
  labels:
    app: nginx-svc
spec:
  ports:
    - port: 80
      targetPort: 80
      protocol: TCP
      name: http
  selector:
    app: nginx
  type: NodePort
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;12-clusteripç±»å‹&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#12-clusteripç±»å‹&#34;&gt;#&lt;/a&gt; 1.2 ClusterIP ç±»å‹&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Service
metadata:
  name: nginx-svc
  namespace: default
  labels:
    app: nginx-svc
spec:
  ports:
    - port: 80
      targetPort: 80
      protocol: TCP
      name: http
  selector:
    app: nginx
  type: ClusterIP
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;13-ä½¿ç”¨serviceä»£ç†k8så¤–éƒ¨æœåŠ¡&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#13-ä½¿ç”¨serviceä»£ç†k8så¤–éƒ¨æœåŠ¡&#34;&gt;#&lt;/a&gt; 1.3 ä½¿ç”¨ Service ä»£ç† K8s å¤–éƒ¨æœåŠ¡&lt;/h5&gt;
&lt;p&gt;ä½¿ç”¨åœºæ™¯ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å¸Œæœ›åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨æŸä¸ªå›ºå®šçš„åç§°è€Œé IP åœ°å€è®¿é—®å¤–éƒ¨çš„ä¸­é—´ä»¶æœåŠ¡ï¼›&lt;/li&gt;
&lt;li&gt;å¸Œæœ› Service æŒ‡å‘å¦ä¸€ä¸ª Namespace ä¸­æˆ–å…¶ä»–é›†ç¾¤ä¸­çš„æœåŠ¡ï¼›&lt;/li&gt;
&lt;li&gt;æ­£åœ¨å°†å·¥ä½œè´Ÿè½½è½¬ç§»åˆ° Kubernetes é›†ç¾¤ï¼Œä½†æ˜¯ä¸€éƒ¨åˆ†æœåŠ¡ä»è¿è¡Œåœ¨ Kubernetes é›†ç¾¤ä¹‹å¤–çš„ backendã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Service
metadata:
  labels:
    app: mysql-svc-external
  name: mysql-svc-external
spec:
  clusterIP: None
  ports:
  - name: mysql
    port: 3306 
    protocol: TCP
    targetPort: 3306
  type: ClusterIP
---
apiVersion: v1
kind: Endpoints
metadata:
  labels:
    app: mysql-svc-external
  name: mysql-svc-external
subsets:
- addresses:
  - ip: 192.168.40.150
  ports:
  - name: mysql
    port: 3306
    protocol: TCP
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;14-externalname-service&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#14-externalname-service&#34;&gt;#&lt;/a&gt; 1.4 ExternalName Service&lt;/h5&gt;
&lt;p&gt;ExternalName Service æ˜¯ Service çš„ç‰¹ä¾‹ï¼Œå®ƒæ²¡æœ‰ Selectorï¼Œä¹Ÿæ²¡æœ‰å®šä¹‰ä»»ä½•ç«¯å£å’Œ Endpointï¼Œå®ƒé€šè¿‡è¿”å›è¯¥å¤–éƒ¨æœåŠ¡çš„åˆ«åæ¥æä¾›æœåŠ¡ã€‚&lt;/p&gt;
&lt;p&gt;æ¯”å¦‚å¯ä»¥å®šä¹‰ä¸€ä¸ª Serviceï¼Œåç«¯è®¾ç½®ä¸ºä¸€ä¸ªå¤–éƒ¨åŸŸåï¼Œè¿™æ ·é€šè¿‡ Service çš„åç§°å³å¯è®¿é—®åˆ°è¯¥åŸŸåã€‚ä½¿ç”¨ nslookup è§£æä»¥ä¸‹æ–‡ä»¶å®šä¹‰çš„ Serviceï¼Œé›†ç¾¤çš„ DNS &lt;a href=&#34;http://xn--my-uu2cmg2cx7mswf9rko5lsx1a5n3h.database.example.com&#34;&gt;æœåŠ¡å°†è¿”å›ä¸€ä¸ªå€¼ä¸º my.database.example.com&lt;/a&gt; çš„ CNAME è®°å½•ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kind: Service
apiVersion: v1
metadata:
  name: my-service
  namespace: prod
spec:
  type: ExternalName
  externalName: my.database.example.com
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;15-å¤šç«¯å£-service&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#15-å¤šç«¯å£-service&#34;&gt;#&lt;/a&gt; 1.5 å¤šç«¯å£ Service&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Service
metadata:
  name: nginx-svc
  namespace: default
  labels:
    app: nginx-svc
spec:
  ports:
    - port: 80
      targetPort: 80
      protocol: TCP
      name: http
    - port: 443
      targetPort: 443
      protocol: TCP
      name: https
  selector:
    app: nginx
  type: ClusterIP
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;æœ¬æ–‡å‡ºè‡ªäºï¼š&lt;a href=&#34;https://edu.51cto.com/course/23845.html&#34;&gt;https://edu.51cto.com/course/23845.html&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</content>
        <category term="Kubernetes" />
        <updated>2025-04-14T11:25:51.000Z</updated>
    </entry>
    <entry>
        <id>http://ixuyong.cn/posts/108692210.html</id>
        <title>K8sèµ„æºè°ƒåº¦deploymentã€statefulsetã€daemonset</title>
        <link rel="alternate" href="http://ixuyong.cn/posts/108692210.html"/>
        <content type="html">&lt;h3 id=&#34;k8sèµ„æºè°ƒåº¦deployment-statefulset-daemonset&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#k8sèµ„æºè°ƒåº¦deployment-statefulset-daemonset&#34;&gt;#&lt;/a&gt; K8s èµ„æºè°ƒåº¦ deploymentã€statefulsetã€daemonset&lt;/h3&gt;
&lt;h4 id=&#34;1-æ— çŠ¶æ€åº”ç”¨ç®¡ç†-deployment&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-æ— çŠ¶æ€åº”ç”¨ç®¡ç†-deployment&#34;&gt;#&lt;/a&gt; 1. æ— çŠ¶æ€åº”ç”¨ç®¡ç† Deployment&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# cat nginx-deploy.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deploy
  labels:
    app: nginx-deploy
  annotations:
    app: nginx-deploy
  namespace: default
spec:
  selector:
    matchLabels:
      app: nginx-deploy
  replicas: 3
  template:
    metadata:
      labels:
        app: nginx-deploy
    spec:
      containers:
        - name: nginx-deploy
          image: nginx:1.21.0
          imagePullPolicy: IfNotPresent
      restartPolicy: Always
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ç¤ºä¾‹è§£æï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;nginx-deployï¼šDeployment çš„åç§°ï¼›&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;replicasï¼š åˆ›å»º Pod çš„å‰¯æœ¬æ•°ï¼›&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;selectorï¼šå®šä¹‰ Deployment å¦‚ä½•æ‰¾åˆ°è¦ç®¡ç†çš„ Podï¼Œä¸ template çš„ labelï¼ˆæ ‡ç­¾ï¼‰å¯¹åº”ï¼ŒapiVersion ä¸º apps/v1 å¿…é¡»æŒ‡å®šè¯¥å­—æ®µï¼›&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;template å­—æ®µåŒ…å«ä»¥ä¸‹å­—æ®µï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;app: nginx-deploy ä½¿ç”¨ labelï¼ˆæ ‡ç­¾ï¼‰æ ‡è®° Podï¼›&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;specï¼šè¡¨ç¤º Pod è¿è¡Œä¸€ä¸ªåå­—ä¸º nginx çš„å®¹å™¨ï¼›&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;imageï¼šè¿è¡Œæ­¤ Pod ä½¿ç”¨çš„é•œåƒï¼›&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Portï¼šå®¹å™¨ç”¨äºå‘é€å’Œæ¥æ”¶æµé‡çš„ç«¯å£ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;11-æ›´æ–°-deployment&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#11-æ›´æ–°-deployment&#34;&gt;#&lt;/a&gt; 1.1 æ›´æ–° Deployment&lt;/h5&gt;
&lt;p&gt;å‡å¦‚æ›´æ–° Nginx Pod çš„ image ä½¿ç”¨ nginx:latestï¼Œå¹¶ä½¿ç”¨ --record è®°å½•å½“å‰æ›´æ”¹çš„å‚æ•°ï¼ŒåæœŸå›æ»šæ—¶å¯ä»¥æŸ¥çœ‹åˆ°å¯¹åº”çš„ä¿¡æ¯ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# kubectl set image deployment nginx-deploy nginx-deploy=nginx:latest --record
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æ›´æ–°è¿‡ç¨‹ä¸ºæ–°æ—§äº¤æ›¿æ›´æ–°ï¼Œé¦–å…ˆæ–°å»ºä¸€ä¸ª Podï¼Œå½“ Pod çŠ¶æ€ä¸º Running æ—¶ï¼Œåˆ é™¤ä¸€ä¸ªæ—§çš„ Podï¼ŒåŒæ—¶å†åˆ›å»ºä¸€ä¸ªæ–°çš„ Podã€‚å½“è§¦å‘ä¸€ä¸ªæ›´æ–°åï¼Œä¼šæœ‰æ–°çš„ ReplicaSet äº§ç”Ÿï¼Œæ—§çš„ ReplicaSet ä¼šè¢«ä¿å­˜ï¼ŒæŸ¥çœ‹æ­¤æ—¶ ReplicaSetï¼Œå¯ä»¥ä» AGE æˆ– READY çœ‹å‡ºæ¥æ–°æ—§ ReplicaSetï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# kubectl get rs
NAME                      DESIRED   CURRENT   READY   AGE
nginx-deploy-65bfb77869   0         0         0       50s
nginx-deploy-85b94dddb4   3         3         3       8s
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;é€šè¿‡ describe æŸ¥çœ‹ Deployment çš„è¯¦ç»†ä¿¡æ¯ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]#  kubectl describe deploy nginx-deploy
Name:                   nginx-deploy
Namespace:              default
CreationTimestamp:      Mon, 14 Apr 2025 11:28:03 +0800
Labels:                 app=nginx-deploy
Annotations:            app: nginx-deploy
                        deployment.kubernetes.io/revision: 2
                        kubernetes.io/change-cause: kubectl set image deployment nginx-deploy nginx-deploy=nginx:latest --record=true
Selector:               app=nginx-deploy
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=nginx-deploy
  Containers:
   nginx-deploy:
    Image:         nginx:latest
    Port:          &amp;lt;none&amp;gt;
    Host Port:     &amp;lt;none&amp;gt;
    Environment:   &amp;lt;none&amp;gt;
    Mounts:        &amp;lt;none&amp;gt;
  Volumes:         &amp;lt;none&amp;gt;
  Node-Selectors:  &amp;lt;none&amp;gt;
  Tolerations:     &amp;lt;none&amp;gt;
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  nginx-deploy-65bfb77869 (0/0 replicas created)
NewReplicaSet:   nginx-deploy-85b94dddb4 (3/3 replicas created)
Events:
  Type    Reason             Age   From                   Message
  ----    ------             ----  ----                   -------
  Normal  ScalingReplicaSet  71s   deployment-controller  Scaled up replica set nginx-deploy-65bfb77869 from 0 to 3
  Normal  ScalingReplicaSet  29s   deployment-controller  Scaled up replica set nginx-deploy-85b94dddb4 from 0 to 1
  Normal  ScalingReplicaSet  28s   deployment-controller  Scaled down replica set nginx-deploy-65bfb77869 from 3 to 2
  Normal  ScalingReplicaSet  28s   deployment-controller  Scaled up replica set nginx-deploy-85b94dddb4 from 1 to 2
  Normal  ScalingReplicaSet  27s   deployment-controller  Scaled down replica set nginx-deploy-65bfb77869 from 2 to 1
  Normal  ScalingReplicaSet  27s   deployment-controller  Scaled up replica set nginx-deploy-85b94dddb4 from 2 to 3
  Normal  ScalingReplicaSet  26s   deployment-controller  Scaled down replica set nginx-deploy-65bfb77869 from 1 to 0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;åœ¨ describe ä¸­å¯ä»¥çœ‹å‡ºï¼Œç¬¬ä¸€æ¬¡åˆ›å»ºæ—¶ï¼Œå®ƒåˆ›å»ºäº†ä¸€ä¸ªåä¸º nginx-deploy-65bfb77869 çš„ ReplicaSetï¼Œå¹¶ç›´æ¥å°†å…¶æ‰©å±•ä¸º 3 ä¸ªå‰¯æœ¬ã€‚æ›´æ–°éƒ¨ç½²æ—¶ï¼Œå®ƒåˆ›å»ºäº†ä¸€ä¸ªæ–°çš„ ReplicaSetï¼Œå‘½åä¸º nginx-deploy-85b94dddb4ï¼Œå¹¶å°†å…¶å‰¯æœ¬æ•°æ‰©å±•ä¸º 1ï¼Œç„¶åå°†æ—§çš„ ReplicaSet ç¼©å°ä¸º 2ï¼Œè¿™æ ·è‡³å°‘å¯ä»¥æœ‰ 2 ä¸ª Pod å¯ç”¨ï¼Œæœ€å¤šåˆ›å»ºäº† 4 ä¸ª Podã€‚ä»¥æ­¤ç±»æ¨ï¼Œä½¿ç”¨ç›¸åŒçš„æ»šåŠ¨æ›´æ–°ç­–ç•¥å‘ä¸Šå’Œå‘ä¸‹æ‰©å±•æ–°æ—§ ReplicaSetï¼Œæœ€ç»ˆæ–°çš„ ReplicaSet å¯ä»¥æ‹¥æœ‰ 3 ä¸ªå‰¯æœ¬ï¼Œå¹¶å°†æ—§çš„ ReplicaSet ç¼©å°ä¸º 0ã€‚&lt;/p&gt;
&lt;h5 id=&#34;12-å›æ»š-deployment&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#12-å›æ»š-deployment&#34;&gt;#&lt;/a&gt; 1.2 å›æ»š Deployment&lt;/h5&gt;
&lt;p&gt;å½“æ›´æ–°äº†ç‰ˆæœ¬ä¸ç¨³å®šæˆ–é…ç½®ä¸åˆç†æ—¶ï¼Œå¯ä»¥å¯¹å…¶è¿›è¡Œå›æ»šæ“ä½œï¼Œå‡è®¾æˆ‘ä»¬åˆè¿›è¡Œäº†å‡ æ¬¡æ›´æ–°ï¼ˆæ­¤å¤„ä»¥æ›´æ–°é•œåƒç‰ˆæœ¬è§¦å‘æ›´æ–°ï¼Œæ›´æ”¹é…ç½®æ•ˆæœç±»ä¼¼ï¼‰ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# kubectl set image deployment nginx-deploy nginx-deploy=nginx:1.21.1 --record
# kubectl set image deployment nginx-deploy nginx-deploy=nginx:1.21.2 --record
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ä½¿ç”¨ kubectl rollout history æŸ¥çœ‹æ›´æ–°å†å²ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# kubectl rollout history deployment nginx-deploy
deployment.apps/nginx-deploy 
REVISION  CHANGE-CAUSE
1         &amp;lt;none&amp;gt;
2         kubectl set image deployment nginx-deploy nginx-deploy=nginx:latest --record=true
3         kubectl set image deployment nginx-deploy nginx-deploy=nginx:1.21.1 --record=true
4         kubectl set image deployment nginx-deploy nginx-deploy=nginx:1.21.2 --record=true
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æŸ¥çœ‹ Deployment æŸæ¬¡æ›´æ–°çš„è¯¦ç»†ä¿¡æ¯ï¼Œä½¿ç”¨ --revision æŒ‡å®šæŸæ¬¡æ›´æ–°ç‰ˆæœ¬å·ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# kubectl rollout history deployment nginx-deploy --revision=4
deployment.apps/nginx-deploy with revision #4
Pod Template:
  Labels:	app=nginx-deploy
	pod-template-hash=65b576b795
  Annotations:	kubernetes.io/change-cause: kubectl set image deployment nginx-deploy nginx-deploy=nginx:1.21.2 --record=true
  Containers:
   nginx-deploy:
    Image:	nginx:1.21.2
    Port:	&amp;lt;none&amp;gt;
    Host Port:	&amp;lt;none&amp;gt;
    Environment:	&amp;lt;none&amp;gt;
    Mounts:	&amp;lt;none&amp;gt;
  Volumes:	&amp;lt;none&amp;gt;
  Node-Selectors:	&amp;lt;none&amp;gt;
  Tolerations:	&amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å¦‚æœåªéœ€è¦å›æ»šåˆ°ä¸Šä¸€ä¸ªç¨³å®šç‰ˆæœ¬ï¼Œä½¿ç”¨ kubectl rollout undo å³å¯ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# kubectl rollout undo deployment nginx-deploy
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å†æ¬¡æŸ¥çœ‹æ›´æ–°å†å²ï¼Œå‘ç° REVISION3 å›åˆ°äº† nginx:1.21.1ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# kubectl rollout history deployment nginx-deploy
deployment.apps/nginx-deploy 
REVISION  CHANGE-CAUSE
1         &amp;lt;none&amp;gt;
2         kubectl set image deployment nginx-deploy nginx-deploy=nginx:latest --record=true
4         kubectl set image deployment nginx-deploy nginx-deploy=nginx:1.21.2 --record=true
5         kubectl set image deployment nginx-deploy nginx-deploy=nginx:1.21.1 --record=true
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å¦‚æœè¦å›æ»šåˆ°æŒ‡å®šç‰ˆæœ¬ï¼Œä½¿ç”¨ --to-revision å‚æ•°ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# kubectl rollout undo deployment nginx-deploy --to-revision=2
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;13-æ‰©å®¹-deployment&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#13-æ‰©å®¹-deployment&#34;&gt;#&lt;/a&gt; 1.3 æ‰©å®¹ Deployment&lt;/h5&gt;
&lt;p&gt;å½“å…¬å¸è®¿é—®é‡å˜å¤§ï¼Œæˆ–è€…æœ‰é¢„æœŸå†…çš„æ´»åŠ¨æ—¶ï¼Œä¸‰ä¸ª Pod å¯èƒ½å·²æ— æ³•æ”¯æ’‘ä¸šåŠ¡æ—¶ï¼Œå¯ä»¥æå‰å¯¹å…¶è¿›è¡Œæ‰©å±•ã€‚&lt;/p&gt;
&lt;p&gt;ä½¿ç”¨ kubectl scale åŠ¨æ€è°ƒæ•´ Pod çš„å‰¯æœ¬æ•°ï¼Œæ¯”å¦‚å¢åŠ  Pod ä¸º 5 ä¸ªï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# kubectl scale deployment nginx-deploy --replicas=5
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æŸ¥çœ‹ Podï¼Œæ­¤æ—¶ Pod å·²ç»å˜æˆäº† 5 ä¸ªï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# kubectl get pods
NAME                            READY   STATUS    RESTARTS   AGE
nginx-deploy-85b94dddb4-2qrh6   1/1     Running   0          2m9s
nginx-deploy-85b94dddb4-gvkqj   1/1     Running   0          2m10s
nginx-deploy-85b94dddb4-mdfjs   1/1     Running   0          22s
nginx-deploy-85b94dddb4-rhgpr   1/1     Running   0          2m8s
nginx-deploy-85b94dddb4-vwjhl   1/1     Running   0          22s
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;14-æš‚åœå’Œæ¢å¤-deployment-æ›´æ–°&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#14-æš‚åœå’Œæ¢å¤-deployment-æ›´æ–°&#34;&gt;#&lt;/a&gt; 1.4 æš‚åœå’Œæ¢å¤ Deployment æ›´æ–°&lt;/h5&gt;
&lt;p&gt;ä¸Šè¿°æ¼”ç¤ºçš„å‡ä¸ºæ›´æ”¹æŸä¸€å¤„çš„é…ç½®ï¼Œæ›´æ”¹åç«‹å³è§¦å‘æ›´æ–°ï¼Œå¤§å¤šæ•°æƒ…å†µä¸‹å¯èƒ½éœ€è¦é’ˆå¯¹ä¸€ä¸ªèµ„æºæ–‡ä»¶æ›´æ”¹å¤šå¤„åœ°æ–¹ï¼Œè€Œå¹¶ä¸éœ€è¦å¤šæ¬¡è§¦å‘æ›´æ–°ï¼Œæ­¤æ—¶å¯ä»¥ä½¿ç”¨ Deployment æš‚åœåŠŸèƒ½ï¼Œä¸´æ—¶ç¦ç”¨æ›´æ–°æ“ä½œï¼Œå¯¹ Deployment è¿›è¡Œå¤šæ¬¡ä¿®æ”¹ååœ¨è¿›è¡Œæ›´æ–°ã€‚&lt;/p&gt;
&lt;p&gt;ä½¿ç”¨ kubectl rollout pause å‘½ä»¤å³å¯æš‚åœ Deployment æ›´æ–°ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# kubectl rollout pause deployment nginx-deploy
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ç„¶åå¯¹ Deployment è¿›è¡Œç›¸å…³æ›´æ–°æ“ä½œï¼Œæ¯”å¦‚å…ˆæ›´æ–°é•œåƒï¼Œç„¶åå¯¹å…¶èµ„æºè¿›è¡Œé™åˆ¶ï¼ˆå¦‚æœä½¿ç”¨çš„æ˜¯ kubectl edit å‘½ä»¤ï¼Œå¯ä»¥ç›´æ¥è¿›è¡Œå¤šæ¬¡ä¿®æ”¹ï¼Œæ— éœ€æš‚åœæ›´æ–°ï¼Œkubectlset å‘½ä»¤ä¸€èˆ¬ä¼šé›†æˆåœ¨ CICD æµæ°´çº¿ä¸­ï¼‰ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# kubectl set image deployment nginx-deploy nginx-deploy=nginx:1.21.3
# kubectl set resources deployment nginx-deploy -c=nginx-deploy --limits=cpu=200m,memory=512Mi
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;é€šè¿‡ rollout history å¯ä»¥çœ‹åˆ°æ²¡æœ‰æ–°çš„æ›´æ–°ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#  kubectl rollout history deployment nginx-deploy
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;è¿›è¡Œå®Œæœ€åä¸€å¤„é…ç½®æ›´æ”¹åï¼Œä½¿ç”¨ kubectl rollout resume æ¢å¤ Deployment æ›´æ–°ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# kubectl rollout resume deployment nginx-deploy
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å¯ä»¥æŸ¥çœ‹åˆ°æ¢å¤æ›´æ–°çš„ Deployment åˆ›å»ºäº†ä¸€ä¸ªæ–°çš„ RSï¼ˆReplicaSet ç¼©å†™ï¼‰ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# kubectl get rs
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å¯ä»¥æŸ¥çœ‹ Deployment çš„ imageï¼ˆé•œåƒï¼‰å·²ç»å˜ä¸º nginx:1.21.3&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# kubectl get pods -oyaml|grep image
    - image: nginx:1.21.3
      imagePullPolicy: IfNotPresent
      image: docker.io/library/nginx:1.21.3
      imageID: docker.io/library/nginx@sha256:644a70516a26004c97d0d85c7fe1d0c3a67ea8ab7ddf4aff193d9f301670cf36
    - image: nginx:1.21.3
      imagePullPolicy: IfNotPresent
      image: docker.io/library/nginx:1.21.3
      imageID: docker.io/library/nginx@sha256:644a70516a26004c97d0d85c7fe1d0c3a67ea8ab7ddf4aff193d9f301670cf36
    - image: nginx:1.21.3
      imagePullPolicy: IfNotPresent
      image: docker.io/library/nginx:1.21.3
      imageID: docker.io/library/nginx@sha256:644a70516a26004c97d0d85c7fe1d0c3a67ea8ab7ddf4aff193d9f301670cf36
    - image: nginx:1.21.3
      imagePullPolicy: IfNotPresent
      image: docker.io/library/nginx:1.21.3
      imageID: docker.io/library/nginx@sha256:644a70516a26004c97d0d85c7fe1d0c3a67ea8ab7ddf4aff193d9f301670cf36
    - image: nginx:1.21.3
      imagePullPolicy: IfNotPresent
      image: docker.io/library/nginx:1.21.3
      imageID: docker.io/library/nginx@sha256:644a70516a26004c97d0d85c7fe1d0c3a67ea8ab7ddf4aff193d9f301670cf36
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;15-æ›´æ–°-deployment-çš„æ³¨æ„äº‹é¡¹&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#15-æ›´æ–°-deployment-çš„æ³¨æ„äº‹é¡¹&#34;&gt;#&lt;/a&gt; 1.5 æ›´æ–° Deployment çš„æ³¨æ„äº‹é¡¹&lt;/h5&gt;
&lt;p&gt;åœ¨é»˜è®¤æƒ…å†µä¸‹ï¼Œrevision ä¿ç•™ 10 ä¸ªæ—§çš„ ReplicaSetï¼Œå…¶ä½™çš„å°†åœ¨åå°è¿›è¡Œåƒåœ¾å›æ”¶ï¼Œå¯ä»¥åœ¨.spec.revisionHistoryLimit è®¾ç½®ä¿ç•™ ReplicaSet çš„ä¸ªæ•°ã€‚å½“è®¾ç½®ä¸º 0 æ—¶ï¼Œä¸ä¿ç•™å†å²è®°å½•ã€‚&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deploy
  namespace: default
  labels:
    app: nginx-deploy
spec:
  replicas: 5
  selector:
    matchLabels:
      app: nginx-deploy
  template:
    metadata:
      labels:
        app: nginx-deploy
    spec:
      containers:
        - name: nginx-deploy
          image: nginx:1.21.3
          resources:
            limits:
              cpu: 200m
              memory: 512Mi
          imagePullPolicy: IfNotPresent
      restartPolicy: Always
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 25%
      maxSurge: 25%
  revisionHistoryLimit: 10
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æ›´æ–°ç­–ç•¥ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;spec.strategy.type==Recreateï¼Œè¡¨ç¤ºé‡å»ºï¼Œå…ˆåˆ æ‰æ—§çš„ Pod å†åˆ›å»ºæ–°çš„ Podï¼›&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;  strategy:
    type: Recreate
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;spec.strategy.type==RollingUpdateï¼Œè¡¨ç¤ºæ»šåŠ¨æ›´æ–°ï¼Œå¯ä»¥æŒ‡å®š maxUnavailable å’Œ maxSurge æ¥æ§åˆ¶æ»šåŠ¨æ›´æ–°è¿‡ç¨‹ï¼›&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;spec.strategy.rollingUpdate.maxUnavailableï¼ŒæŒ‡å®šåœ¨å›æ»šæ›´æ–°æ—¶æœ€å¤§ä¸å¯ç”¨çš„ Pod æ•°é‡ï¼Œå¯é€‰å­—æ®µï¼Œé»˜è®¤ä¸º 25%ï¼Œå¯ä»¥è®¾ç½®ä¸ºæ•°å­—æˆ–ç™¾åˆ†æ¯”ï¼Œå¦‚æœ maxSurge ä¸º 0ï¼Œåˆ™è¯¥å€¼ä¸èƒ½ä¸º 0ï¼›&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;spec.strategy.rollingUpdate.maxSurge å¯ä»¥è¶…è¿‡æœŸæœ›å€¼çš„æœ€å¤§ Pod æ•°ï¼Œå¯é€‰å­—æ®µï¼Œé»˜è®¤ä¸º 25%ï¼Œå¯ä»¥è®¾ç½®æˆæ•°å­—æˆ–ç™¾åˆ†æ¯”ï¼Œå¦‚æœ maxUnavailable ä¸º 0ï¼Œåˆ™è¯¥å€¼ä¸èƒ½ä¸º 0ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 25%
      maxSurge: 25%
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2-æœ‰çŠ¶æ€åº”ç”¨ç®¡ç†-statefulset&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-æœ‰çŠ¶æ€åº”ç”¨ç®¡ç†-statefulset&#34;&gt;#&lt;/a&gt; 2. æœ‰çŠ¶æ€åº”ç”¨ç®¡ç† StatefulSet&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Service
metadata:
  name: web
  namespace: default
spec:
  ports:
    - port: 80
      targetPort: 80
      protocol: TCP
      name: http
  selector:
    app: nginx
  type: ClusterIP
  clusterIP: None
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: nginx
  namespace: default
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
        - name: nginx
          image: nginx:latest
          resources:
            limits:
              cpu: &#39;1&#39;
              memory: 1Gi
            requests:
              cpu: 100m
              memory: 128Mi
      restartPolicy: Always
  serviceName: web
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;kind: Service å®šä¹‰äº†ä¸€ä¸ªåå­—ä¸º web çš„ Headless Serviceï¼Œåˆ›å»ºçš„ Service æ ¼å¼ä¸º nginx-0.web.default.svc.cluster.localï¼Œå…¶ä»–çš„ç±»ä¼¼ï¼Œå› ä¸ºæ²¡æœ‰æŒ‡å®š Namespaceï¼ˆå‘½åç©ºé—´ï¼‰ï¼Œæ‰€ä»¥é»˜è®¤éƒ¨ç½²åœ¨ defaultï¼›&lt;/li&gt;
&lt;li&gt;kind: StatefulSet å®šä¹‰äº†ä¸€ä¸ªåå­—ä¸º nginx çš„ StatefulSetï¼Œreplicas è¡¨ç¤ºéƒ¨ç½² Pod çš„å‰¯æœ¬æ•°ï¼Œæœ¬å®ä¾‹ä¸º 3ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;21-åˆ›å»º-statefulset&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#21-åˆ›å»º-statefulset&#34;&gt;#&lt;/a&gt; 2.1 åˆ›å»º StatefulSet&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# kubectl get pods
NAME      READY   STATUS    RESTARTS   AGE
nginx-0   1/1     Running   0          8m51s
nginx-1   1/1     Running   0          8m50s
nginx-2   1/1     Running   0          8m48s
[root@k8s-master01 ~]# kubectl get svc
NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.96.0.1    &amp;lt;none&amp;gt;        443/TCP   6d1h
web          ClusterIP   None         &amp;lt;none&amp;gt;        80/TCP    9m28s
[root@k8s-master01 ~]# kubectl get sts
NAME    READY   AGE
nginx   3/3     8m58s
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;22-statefulsetåˆ›å»ºpodæµç¨‹&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#22-statefulsetåˆ›å»ºpodæµç¨‹&#34;&gt;#&lt;/a&gt; 2.2 StatefulSet åˆ›å»º Pod æµç¨‹&lt;/h5&gt;
&lt;p&gt;StatefulSet ç®¡ç†çš„ Pod éƒ¨ç½²å’Œæ‰©å±•è§„åˆ™å¦‚ä¸‹ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å¯¹äºå…·æœ‰ N ä¸ªå‰¯æœ¬çš„ StatefulSetï¼Œå°†æŒ‰é¡ºåºä» 0 åˆ° N-1 å¼€å§‹åˆ›å»º Podï¼›&lt;/li&gt;
&lt;li&gt;å½“åˆ é™¤ Pod æ—¶ï¼Œå°†æŒ‰ç…§ N-1 åˆ° 0 çš„åé¡ºåºç»ˆæ­¢ï¼›&lt;/li&gt;
&lt;li&gt;åœ¨ç¼©æ”¾ Pod ä¹‹å‰ï¼Œå¿…é¡»ä¿è¯å½“å‰çš„ Pod æ˜¯ Runningï¼ˆè¿è¡Œä¸­ï¼‰æˆ–è€… Readyï¼ˆå°±ç»ªï¼‰ï¼›&lt;/li&gt;
&lt;li&gt;åœ¨ç»ˆæ­¢ Pod ä¹‹å‰ï¼Œå®ƒæ‰€æœ‰çš„ç»§ä»»è€…å¿…é¡»æ˜¯å®Œå…¨å…³é—­çŠ¶æ€ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;StatefulSet çš„ pod.Spec.TerminationGracePeriodSecondsï¼ˆç»ˆæ­¢ Pod çš„ç­‰å¾…æ—¶é—´ï¼‰ä¸åº”è¯¥æŒ‡å®šä¸º 0ï¼Œè®¾ç½®ä¸º 0 å¯¹ StatefulSet çš„ Pod æ˜¯æå…¶ä¸å®‰å…¨çš„åšæ³•ï¼Œä¼˜é›…åœ°åˆ é™¤ StatefulSet çš„ Pod æ˜¯éå¸¸æœ‰å¿…è¦çš„ï¼Œè€Œä¸”æ˜¯å®‰å…¨çš„ï¼Œå› ä¸ºå®ƒå¯ä»¥ç¡®ä¿åœ¨ Kubelet ä» APIServer åˆ é™¤ä¹‹å‰ï¼Œè®© Pod æ­£å¸¸å…³é—­ã€‚&lt;/p&gt;
&lt;p&gt;å½“åˆ›å»ºä¸Šé¢çš„ Nginx å®ä¾‹æ—¶ï¼ŒPod å°†æŒ‰ nginx-0ã€nginx-1ã€nginx-2 çš„é¡ºåºéƒ¨ç½² 3 ä¸ª Podã€‚åœ¨ nginx-0 å¤„äº Running æˆ–è€… Ready ä¹‹å‰ï¼Œnginx-1 ä¸ä¼šè¢«éƒ¨ç½²ï¼Œç›¸åŒçš„ï¼Œnginx-2 åœ¨ web-1 æœªå¤„äº Running å’Œ Ready ä¹‹å‰ä¹Ÿä¸ä¼šè¢«éƒ¨ç½²ã€‚å¦‚æœåœ¨ nginx-1 å¤„äº Running å’Œ Ready çŠ¶æ€æ—¶ï¼Œnginx-0 å˜æˆ Failed å¤±è´¥ï¼‰çŠ¶æ€ï¼Œé‚£ä¹ˆ nginx-2 å°†ä¸ä¼šè¢«å¯åŠ¨ï¼Œç›´åˆ° nginx-0 æ¢å¤ä¸º Running å’Œ Ready çŠ¶æ€ã€‚&lt;/p&gt;
&lt;p&gt;å¦‚æœç”¨æˆ·å°† StatefulSet çš„ replicas è®¾ç½®ä¸º 1ï¼Œé‚£ä¹ˆ nginx-2 å°†é¦–å…ˆè¢«ç»ˆæ­¢ï¼Œåœ¨å®Œå…¨å…³é—­å¹¶åˆ é™¤ nginx-2 ä¹‹å‰ï¼Œä¸ä¼šåˆ é™¤ nginx-1ã€‚å¦‚æœ nginx-2 ç»ˆæ­¢å¹¶ä¸”å®Œå…¨å…³é—­åï¼Œnginx-0 çªç„¶å¤±è´¥ï¼Œé‚£ä¹ˆåœ¨ nginx-0 æœªæ¢å¤æˆ Running æˆ–è€… Ready æ—¶ï¼Œnginx-1 ä¸ä¼šè¢«åˆ é™¤ã€‚&lt;/p&gt;
&lt;h5 id=&#34;23-tatefulset-æ‰©å®¹å’Œç¼©å®¹&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#23-tatefulset-æ‰©å®¹å’Œç¼©å®¹&#34;&gt;#&lt;/a&gt; 2.3 tatefulSet æ‰©å®¹å’Œç¼©å®¹&lt;/h5&gt;
&lt;p&gt;å’Œ Deployment ç±»ä¼¼ï¼Œå¯ä»¥é€šè¿‡æ›´æ–° replicas å­—æ®µæ‰©å®¹ / ç¼©å®¹ StatefulSetï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ kubectlscaleã€kubectl edit å’Œ kubectl patch æ¥æ‰©å®¹ / ç¼©å®¹ä¸€ä¸ª StatefulSetã€‚&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# kubectl scale sts nginx --replicas=5
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;24-statefulset-æ›´æ–°ç­–ç•¥&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#24-statefulset-æ›´æ–°ç­–ç•¥&#34;&gt;#&lt;/a&gt; 2.4 StatefulSet æ›´æ–°ç­–ç•¥&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;On Delete ç­–ç•¥&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;OnDelete æ›´æ–°ç­–ç•¥å®ç°äº†ä¼ ç»Ÿï¼ˆ1.7 ç‰ˆæœ¬ä¹‹å‰ï¼‰çš„è¡Œä¸ºï¼Œå®ƒä¹Ÿæ˜¯é»˜è®¤çš„æ›´æ–°ç­–ç•¥ã€‚å½“æˆ‘ä»¬é€‰æ‹©è¿™ä¸ªæ›´æ–°ç­–ç•¥å¹¶ä¿®æ”¹ StatefulSet çš„.spec.template å­—æ®µæ—¶ï¼ŒStatefulSet æ§åˆ¶å™¨ä¸ä¼šè‡ªåŠ¨æ›´æ–° Podï¼Œå¿…é¡»æ‰‹åŠ¨åˆ é™¤ Pod æ‰èƒ½ä½¿æ§åˆ¶å™¨åˆ›å»ºæ–°çš„ Podã€‚&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  updateStrategy:
    type: OnDelete
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;RollingUpdate ç­–ç•¥&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;RollingUpdateï¼ˆæ»šåŠ¨æ›´æ–°ï¼‰æ›´æ–°ç­–ç•¥ä¼šè‡ªåŠ¨æ›´æ–°ä¸€ä¸ª StatefulSet ä¸­æ‰€æœ‰çš„ Podï¼Œé‡‡ç”¨ä¸åºå·ç´¢å¼•ç›¸åçš„é¡ºåºè¿›è¡Œæ»šåŠ¨æ›´æ–°ã€‚&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      partition: 0
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;25-åˆ†æ®µæ›´æ–°&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#25-åˆ†æ®µæ›´æ–°&#34;&gt;#&lt;/a&gt; 2.5 åˆ†æ®µæ›´æ–°&lt;/h5&gt;
&lt;p&gt;å°†åˆ†åŒºæ”¹ä¸º 2ï¼Œæ­¤æ—¶ä¼šè‡ªåŠ¨æ›´æ–° nginx-2ã€nginx-3ã€nginx-4ï¼ˆå› ä¸ºä¹‹å‰æ›´æ”¹äº†æ›´æ–°ç­–ç•¥ï¼‰ï¼Œä½†æ˜¯ä¸ä¼šæ›´æ–° nginx-0 å’Œ nginx-1ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      partition: 2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å°† sts é•œåƒä¸º nginx:1.21.1&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# kubectl set image sts nginx nginx=nginx:1.21.1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æŒ‰ç…§ä¸Šè¿°æ–¹å¼ï¼Œå¯ä»¥å®ç°åˆ†é˜¶æ®µæ›´æ–°ï¼Œç±»ä¼¼äºç°åº¦ / é‡‘ä¸é›€å‘å¸ƒã€‚æŸ¥çœ‹æœ€ç»ˆçš„ç»“æœå¦‚ä¸‹ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# kubectl get pods -oyaml|grep image
    - image: nginx:latest
      imagePullPolicy: IfNotPresent
      image: docker.io/library/nginx:latest
      imageID: docker.io/library/nginx@sha256:fad8e1cd52e24bce7b72cd7cb674a2efad671647b917055f5bd8a1f7ac9b1af8
    - image: nginx:latest
      imagePullPolicy: IfNotPresent
      image: docker.io/library/nginx:latest
      imageID: docker.io/library/nginx@sha256:fad8e1cd52e24bce7b72cd7cb674a2efad671647b917055f5bd8a1f7ac9b1af8
    - image: nginx:1.21.1
      imagePullPolicy: IfNotPresent
      image: docker.io/library/nginx:1.21.1
      imageID: docker.io/library/nginx@sha256:a05b0cdd4fc1be3b224ba9662ebdf98fe44c09c0c9215b45f84344c12867002e
    - image: nginx:1.21.1
      imagePullPolicy: IfNotPresent
      image: docker.io/library/nginx:1.21.1
      imageID: docker.io/library/nginx@sha256:a05b0cdd4fc1be3b224ba9662ebdf98fe44c09c0c9215b45f84344c12867002e
    - image: nginx:1.21.1
      imagePullPolicy: IfNotPresent
      image: docker.io/library/nginx:1.21.1
      imageID: docker.io/library/nginx@sha256:a05b0cdd4fc1be3b224ba9662ebdf98fe44c09c0c9215b45f84344c12867002e
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;26-statefulset-æŒ‚è½½åŠ¨æ€å­˜å‚¨&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#26-statefulset-æŒ‚è½½åŠ¨æ€å­˜å‚¨&#34;&gt;#&lt;/a&gt; 2.6 StatefulSet æŒ‚è½½åŠ¨æ€å­˜å‚¨&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Service
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  ports:
  - port: 80
    name: web
  clusterIP: None
  selector:
    app: nginx
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: web
spec:
  selector:
    matchLabels:
      app: nginx 
  serviceName: &amp;quot;nginx&amp;quot;
  replicas: 3 1
  template:
    metadata:
      labels:
        app: nginx 
    spec:
      containers:
      - name: nginx
        image: nginx:1.20
        ports:
        - containerPort: 80
          name: web
        volumeMounts:
        - name: www
          mountPath: /usr/share/nginx/html
  volumeClaimTemplates:
  - metadata:
      name: www
    spec:
      accessModes: [ &amp;quot;ReadWriteOnce&amp;quot; ]
      storageClassName: &amp;quot;rook-ceph-block&amp;quot;
      resources:
        requests:
          storage: 10Gi
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;3å®ˆæŠ¤è¿›ç¨‹é›†-daemonset&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3å®ˆæŠ¤è¿›ç¨‹é›†-daemonset&#34;&gt;#&lt;/a&gt; 3. å®ˆæŠ¤è¿›ç¨‹é›† DaemonSet&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nginx-ds
  labels:
    app: nginx-ds
  namespace: default
spec:
  selector:
    matchLabels:
      app: nginx-ds
  template:
    metadata:
      labels:
        app: nginx-ds
    spec:
      containers:
        - name: nginx-ds
          image: nginx:latest
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              memory: 1024Mi
              cpu: 1
            requests:
              memory: 128Mi
              cpu: 100m
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æ­¤æ—¶ä¼šåœ¨æ¯ä¸ªèŠ‚ç‚¹åˆ›å»ºä¸€ä¸ª Podï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# kubectl get pods -o wide
NAME             READY   STATUS    RESTARTS   AGE   IP               NODE           NOMINATED NODE   READINESS GATES
nginx-ds-47dxc   1/1     Running   0          56s   172.16.85.213    k8s-node01     &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-ds-4m89f   1/1     Running   0          56s   172.16.32.143    k8s-master01   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-ds-mtpc2   1/1     Running   0          56s   172.16.195.12    k8s-master03   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-ds-t5rxc   1/1     Running   0          56s   172.16.122.142   k8s-master02   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
nginx-ds-x86kc   1/1     Running   0          56s   172.16.58.222    k8s-node02     &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æŒ‡å®šèŠ‚ç‚¹éƒ¨ç½² Pod&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;      nodeSelector:
        ingress: &#39;true&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æ›´æ–°å’Œå›æ»š DaemonSet&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# kubectl set image ds nginx-ds nginx-ds=1.21.0 --record=true
# kubectl rollout undo daemonset &amp;lt;daemonset-name&amp;gt; --to-revision=&amp;lt;revision&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;DaemonSet çš„æ›´æ–°å’Œå›æ»šä¸ Deployment ç±»ä¼¼ï¼Œæ­¤å¤„ä¸å†æ¼”ç¤ºã€‚&lt;/p&gt;
&lt;h4 id=&#34;4-hpa&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4-hpa&#34;&gt;#&lt;/a&gt; 4. HPA&lt;/h4&gt;
&lt;p&gt;åˆ›å»º deploymentã€service&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: Service
metadata:
  name: nginx-hpa-svc
  namespace: default
spec:
  ports:
    - port: 80
      targetPort: 80
      protocol: TCP
      name: http
  selector:
    app: nginx-hpa
  type: ClusterIP

---

apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-hpa
  labels:
    app: nginx-hpa
  namespace: default
spec:
  selector:
    matchLabels:
      app: nginx-hpa
  replicas: 1
  template:
    metadata:
      labels:
        app: nginx-hpa
    spec:
      restartPolicy: Always
      containers:
        - name: nginx-hpa
          image: nginx:latest
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              memory: 1024Mi
              cpu: 1
            requests:
              memory: 128Mi
              cpu: 100m
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;åˆ›å»º HPA&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# kubectl autoscale deployment nginx-hpa --cpu-percent=10 --min=1 --max=10
# kubectl get hpa
NAME        REFERENCE              TARGETS       MINPODS   MAXPODS   REPLICAS   AGE
nginx-hpa   Deployment/nginx-hpa   cpu: 0%/10%   1         10        1          16s

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æµ‹è¯•è‡ªåŠ¨æ‰©ç¼©å®¹&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;while true; do wget -q -O- http://10.96.18.221 &amp;gt; /dev/null; done
[root@k8s-master01 ~]# kubectl get pods
NAME                        READY   STATUS    RESTARTS   AGE
nginx-hpa-d8bcbdf7d-4mkxp   1/1     Running   0          66s
nginx-hpa-d8bcbdf7d-974q5   1/1     Running   0          6m36s
nginx-hpa-d8bcbdf7d-g6p2h   1/1     Running   0          66s
nginx-hpa-d8bcbdf7d-lvvsq   1/1     Running   0          111s
nginx-hpa-d8bcbdf7d-tgqmr   1/1     Running   0          111s
nginx-hpa-d8bcbdf7d-tzfbs   1/1     Running   0          21s
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;æœ¬æ–‡å‡ºè‡ªäºï¼š&lt;a href=&#34;https://edu.51cto.com/course/23845.html&#34;&gt;https://edu.51cto.com/course/23845.html&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</content>
        <category term="Kubernetes" />
        <updated>2025-04-14T11:25:00.000Z</updated>
    </entry>
    <entry>
        <id>http://ixuyong.cn/posts/1771242682.html</id>
        <title>K8sé›¶å®•æœºæœåŠ¡å‘å¸ƒ-æ¢é’ˆ</title>
        <link rel="alternate" href="http://ixuyong.cn/posts/1771242682.html"/>
        <content type="html">&lt;h3 id=&#34;k8sé›¶å®•æœºæœåŠ¡å‘å¸ƒ-æ¢é’ˆ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#k8sé›¶å®•æœºæœåŠ¡å‘å¸ƒ-æ¢é’ˆ&#34;&gt;#&lt;/a&gt; K8s é›¶å®•æœºæœåŠ¡å‘å¸ƒ - æ¢é’ˆ&lt;/h3&gt;
&lt;h4 id=&#34;1-podçŠ¶æ€åŠ-pod-æ•…éšœæ’æŸ¥å‘½ä»¤&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-podçŠ¶æ€åŠ-pod-æ•…éšœæ’æŸ¥å‘½ä»¤&#34;&gt;#&lt;/a&gt; 1. Pod çŠ¶æ€åŠ Pod æ•…éšœæ’æŸ¥å‘½ä»¤&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;çŠ¶æ€&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;è¯´æ˜&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Pendingï¼ˆæŒ‚èµ·ï¼‰&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Pod å·²è¢« Kubernetes ç³»ç»Ÿæ¥æ”¶ï¼Œä½†ä»æœ‰ä¸€ä¸ªæˆ–å¤šä¸ªå®¹å™¨æœªè¢«åˆ›å»ºï¼Œå¯ä»¥é€šè¿‡ kubectl describe æŸ¥çœ‹å¤„äº Pending çŠ¶æ€çš„åŸå› &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Runningï¼ˆè¿è¡Œä¸­ï¼‰&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Pod å·²ç»è¢«ç»‘å®šåˆ°ä¸€ä¸ªèŠ‚ç‚¹ä¸Šï¼Œå¹¶ä¸”æ‰€æœ‰çš„å®¹å™¨éƒ½å·²ç»è¢«åˆ›å»ºï¼Œè€Œä¸”è‡³å°‘æœ‰ä¸€ä¸ªæ˜¯è¿è¡ŒçŠ¶æ€ï¼Œæˆ–è€…æ˜¯æ­£åœ¨å¯åŠ¨æˆ–è€…é‡å¯ï¼Œå¯ä»¥é€šè¿‡ kubectl logs æŸ¥çœ‹ Pod çš„æ—¥å¿—&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Succeededï¼ˆæˆåŠŸï¼‰&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;æ‰€æœ‰å®¹å™¨æ‰§è¡ŒæˆåŠŸå¹¶ç»ˆæ­¢ï¼Œå¹¶ä¸”ä¸ä¼šå†æ¬¡é‡å¯ï¼Œå¯ä»¥é€šè¿‡ kubectl logs æŸ¥çœ‹ Pod æ—¥å¿—&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Failedï¼ˆå¤±è´¥ï¼‰&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;æ‰€æœ‰å®¹å™¨éƒ½å·²ç»ˆæ­¢ï¼Œå¹¶ä¸”è‡³å°‘æœ‰ä¸€ä¸ªå®¹å™¨ä»¥å¤±è´¥çš„æ–¹å¼ç»ˆæ­¢ï¼Œä¹Ÿå°±æ˜¯è¯´è¿™ä¸ªå®¹å™¨è¦ä¹ˆä»¥éé›¶çŠ¶æ€é€€å‡ºï¼Œè¦ä¹ˆè¢«ç³»ç»Ÿç»ˆæ­¢ï¼Œå¯ä»¥é€šè¿‡ logs å’Œ describe æŸ¥çœ‹ Pod æ—¥å¿—å’ŒçŠ¶æ€&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Unknownï¼ˆæœªçŸ¥ï¼‰&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;é€šå¸¸æ˜¯ç”±äºé€šä¿¡é—®é¢˜é€ æˆçš„æ— æ³•è·å¾— Pod çš„çŠ¶æ€&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;ImagePullBackOff ErrImagePull&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;é•œåƒæ‹‰å–å¤±è´¥ï¼Œä¸€èˆ¬æ˜¯ç”±äºé•œåƒä¸å­˜åœ¨ã€ç½‘ç»œä¸é€šæˆ–è€…éœ€è¦ç™»å½•è®¤è¯å¼•èµ·çš„ï¼Œå¯ä»¥ä½¿ç”¨ describe å‘½ä»¤æŸ¥çœ‹å…·ä½“åŸå› &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;CrashLoopBackOff&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;å®¹å™¨å¯åŠ¨å¤±è´¥ï¼Œå¯ä»¥é€šè¿‡ logs å‘½ä»¤æŸ¥çœ‹å…·ä½“åŸå› ï¼Œä¸€èˆ¬ä¸ºå¯åŠ¨å‘½ä»¤ä¸æ­£ç¡®ï¼Œå¥åº·æ£€æŸ¥ä¸é€šè¿‡ç­‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;OOMKilled&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;å®¹å™¨å†…å­˜æº¢å‡ºï¼Œä¸€èˆ¬æ˜¯å®¹å™¨çš„å†…å­˜ Limit è®¾ç½®çš„è¿‡å°ï¼Œæˆ–è€…ç¨‹åºæœ¬èº«æœ‰å†…å­˜æº¢å‡ºï¼Œå¯ä»¥é€šè¿‡ logs æŸ¥çœ‹ç¨‹åºå¯åŠ¨æ—¥å¿—&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Terminating&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Pod æ­£åœ¨è¢«åˆ é™¤ï¼Œå¯ä»¥é€šè¿‡ describe æŸ¥çœ‹çŠ¶æ€&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;SysctlForbidden&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Pod è‡ªå®šä¹‰äº†å†…æ ¸é…ç½®ï¼Œä½† kubelet æ²¡æœ‰æ·»åŠ å†…æ ¸é…ç½®æˆ–é…ç½®çš„å†…æ ¸å‚æ•°ä¸æ”¯æŒï¼Œå¯ä»¥é€šè¿‡ describe æŸ¥çœ‹å…·ä½“åŸå› &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Completed&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;å®¹å™¨å†…éƒ¨ä¸»è¿›ç¨‹é€€å‡ºï¼Œä¸€èˆ¬è®¡åˆ’ä»»åŠ¡æ‰§è¡Œç»“æŸä¼šæ˜¾ç¤ºè¯¥çŠ¶æ€ï¼Œæ­¤æ—¶å¯ä»¥é€šè¿‡ logs æŸ¥çœ‹å®¹å™¨æ—¥å¿—&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;ContainerCreating&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Pod æ­£åœ¨åˆ›å»ºï¼Œä¸€èˆ¬ä¸ºæ­£åœ¨ä¸‹è½½é•œåƒï¼Œæˆ–è€…æœ‰é…ç½®ä¸å½“çš„åœ°æ–¹ï¼Œå¯ä»¥é€šè¿‡ describe æŸ¥çœ‹å…·ä½“åŸå› &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;2-podé•œåƒæ‹‰å–ç­–ç•¥&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-podé•œåƒæ‹‰å–ç­–ç•¥&#34;&gt;#&lt;/a&gt; 2. Pod é•œåƒæ‹‰å–ç­–ç•¥&lt;/h4&gt;
&lt;p&gt;é€šè¿‡ spec.containers [].imagePullPolicy å‚æ•°å¯ä»¥æŒ‡å®šé•œåƒçš„æ‹‰å–ç­–ç•¥ï¼Œç›®å‰æ”¯æŒçš„ç­–ç•¥å¦‚ä¸‹ï¼š&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;æ“ä½œæ–¹å¼&lt;/th&gt;
&lt;th&gt;è¯´æ˜&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Always&lt;/td&gt;
&lt;td&gt;æ€»æ˜¯æ‹‰å–ï¼Œå½“é•œåƒ tag ä¸º latest æ—¶ï¼Œä¸” imagePullPolicy æœªé…ç½®ï¼Œé»˜è®¤ä¸º Always&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Never&lt;/td&gt;
&lt;td&gt;ä¸ç®¡æ˜¯å¦å­˜åœ¨éƒ½ä¸ä¼šæ‹‰å–&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;IfNotPresent&lt;/td&gt;
&lt;td&gt;é•œåƒä¸å­˜åœ¨æ—¶æ‹‰å–é•œåƒï¼Œå¦‚æœ tag ä¸ºé latestï¼Œä¸” imagePullPolicy æœªé…ç½®ï¼Œé»˜è®¤ä¸º IfNotPresent&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;æ›´æ”¹é•œåƒæ‹‰å–ç­–ç•¥ä¸º IfNotPresentï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deploy
  labels:
    app: nginx-deploy
  annotations:
    app: nginx-deploy
  namespace: default
spec:
  selector:
    matchLabels:
      app: nginx-deploy
  replicas: 3
  template:
    metadata:
      labels:
        app: nginx-deploy
    spec:
      containers:
        - name: nginx-deploy
          image: nginx:latest
          imagePullPolicy: IfNotPresent
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;3-pod-é‡å¯ç­–ç•¥&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3-pod-é‡å¯ç­–ç•¥&#34;&gt;#&lt;/a&gt; 3. &lt;strong&gt;Pod&lt;/strong&gt; é‡å¯ç­–ç•¥&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;æ“ä½œæ–¹å¼&lt;/th&gt;
&lt;th&gt;è¯´æ˜&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Always&lt;/td&gt;
&lt;td&gt;é»˜è®¤ç­–ç•¥ã€‚å®¹å™¨å¤±æ•ˆæ—¶ï¼Œè‡ªåŠ¨é‡å¯è¯¥å®¹å™¨&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OnFailure&lt;/td&gt;
&lt;td&gt;å®¹å™¨ä»¥ä¸ä¸º 0 çš„çŠ¶æ€ç ç»ˆæ­¢ï¼Œè‡ªåŠ¨é‡å¯è¯¥å®¹å™¨&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Never&lt;/td&gt;
&lt;td&gt;æ— è®ºä½•ç§çŠ¶æ€ï¼Œéƒ½ä¸ä¼šé‡å¯&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;æŒ‡å®šé‡å¯ç­–ç•¥ä¸º Always ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deploy
  labels:
    app: nginx-deploy
  annotations:
    app: nginx-deploy
  namespace: default
spec:
  selector:
    matchLabels:
      app: nginx-deploy
  replicas: 3
  template:
    metadata:
      labels:
        app: nginx-deploy
    spec:
      containers:
        - name: nginx-deploy
          image: nginx:latest
          imagePullPolicy: IfNotPresent
      restartPolicy: Always
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;4-podçš„ä¸‰ç§æ¢é’ˆ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4-podçš„ä¸‰ç§æ¢é’ˆ&#34;&gt;#&lt;/a&gt; 4. Pod çš„ä¸‰ç§æ¢é’ˆ&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;ç§ç±»&lt;/th&gt;
&lt;th&gt;è¯´æ˜&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;startupProbe&lt;/td&gt;
&lt;td&gt;Kubernetes1.16 æ–°åŠ çš„æ¢æµ‹æ–¹å¼ï¼Œç”¨äºåˆ¤æ–­å®¹å™¨å†…çš„åº”ç”¨ç¨‹åºæ˜¯å¦å·²ç»å¯åŠ¨ã€‚å¦‚æœé…ç½®äº† startupProbeï¼Œå°±ä¼šå…ˆç¦ç”¨å…¶ä»–æ¢æµ‹ï¼Œç›´åˆ°å®ƒæˆåŠŸä¸ºæ­¢ã€‚å¦‚æœæ¢æµ‹å¤±è´¥ï¼ŒKubelet ä¼šæ€æ­»å®¹å™¨ï¼Œä¹‹åæ ¹æ®é‡å¯ç­–ç•¥è¿›è¡Œå¤„ç†ï¼Œå¦‚æœæ¢æµ‹æˆåŠŸï¼Œæˆ–æ²¡æœ‰é…ç½® startupProbeï¼Œåˆ™çŠ¶æ€ä¸ºæˆåŠŸï¼Œä¹‹åå°±ä¸å†æ¢æµ‹ã€‚&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;livenessProbe&lt;/td&gt;
&lt;td&gt;ç”¨äºæ¢æµ‹å®¹å™¨æ˜¯å¦åœ¨è¿è¡Œï¼Œå¦‚æœæ¢æµ‹å¤±è´¥ï¼Œkubelet ä¼š â€œæ€æ­»â€ å®¹å™¨å¹¶æ ¹æ®é‡å¯ç­–ç•¥è¿›è¡Œç›¸åº”çš„å¤„ç†ã€‚å¦‚æœæœªæŒ‡å®šè¯¥æ¢é’ˆï¼Œå°†é»˜è®¤ä¸º Success&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;readinessProbe&lt;/td&gt;
&lt;td&gt;ä¸€èˆ¬ç”¨äºæ¢æµ‹å®¹å™¨å†…çš„ç¨‹åºæ˜¯å¦å¥åº·ï¼Œå³åˆ¤æ–­å®¹å™¨æ˜¯å¦ä¸ºå°±ç»ªï¼ˆReadyï¼‰çŠ¶æ€ã€‚å¦‚æœæ˜¯ï¼Œåˆ™å¯ä»¥å¤„ç†è¯·æ±‚ï¼Œåä¹‹ Endpoints Controller å°†ä»æ‰€æœ‰çš„ Service çš„ Endpoints ä¸­åˆ é™¤æ­¤å®¹å™¨æ‰€åœ¨ Pod çš„ IP åœ°å€ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†é»˜è®¤ä¸º Success&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;5-podæ¢é’ˆçš„å®ç°æ–¹å¼&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#5-podæ¢é’ˆçš„å®ç°æ–¹å¼&#34;&gt;#&lt;/a&gt; 5. Pod æ¢é’ˆçš„å®ç°æ–¹å¼&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;å®ç°æ–¹å¼&lt;/th&gt;
&lt;th&gt;è¯´æ˜&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;ExecAction&lt;/td&gt;
&lt;td&gt;åœ¨å®¹å™¨å†…æ‰§è¡Œä¸€ä¸ªæŒ‡å®šçš„å‘½ä»¤ï¼Œå¦‚æœå‘½ä»¤è¿”å›å€¼ä¸º 0ï¼Œåˆ™è®¤ä¸ºå®¹å™¨å¥åº·&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TCPSocketAction&lt;/td&gt;
&lt;td&gt;é€šè¿‡ TCP è¿æ¥æ£€æŸ¥å®¹å™¨æŒ‡å®šçš„ç«¯å£ï¼Œå¦‚æœç«¯å£å¼€æ”¾ï¼Œåˆ™è®¤ä¸ºå®¹å™¨å¥åº·&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;HTTPGetAction&lt;/td&gt;
&lt;td&gt;å¯¹æŒ‡å®šçš„ URL è¿›è¡Œ Get è¯·æ±‚ï¼Œå¦‚æœçŠ¶æ€ç åœ¨ 200~400 ä¹‹é—´ï¼Œåˆ™è®¤ä¸ºå®¹å™¨å¥åº·&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;6-å¥åº·æ£€æŸ¥é…ç½®&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#6-å¥åº·æ£€æŸ¥é…ç½®&#34;&gt;#&lt;/a&gt; 6. å¥åº·æ£€æŸ¥é…ç½®&lt;/h4&gt;
&lt;p&gt;é…ç½®å¥åº·æ£€æŸ¥ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deploy
  labels:
    app: nginx-deploy
  annotations:
    app: nginx-deploy
  namespace: default
spec:
  selector:
    matchLabels:
      app: nginx-deploy
  replicas: 3
  template:
    metadata:
      labels:
        app: nginx-deploy
    spec:
      containers:
        - name: nginx-deploy
          image: nginx:latest
          imagePullPolicy: IfNotPresent
          startupProbe:
            initialDelaySeconds: 30
            timeoutSeconds: 2
            periodSeconds: 30
            successThreshold: 1
            failureThreshold: 2
            tcpSocket:
              port: 80
          livenessProbe:
            initialDelaySeconds: 30
            timeoutSeconds: 2
            periodSeconds: 30
            successThreshold: 1
            failureThreshold: 2
            tcpSocket:
              port: 80
          readinessProbe:
            initialDelaySeconds: 30
            timeoutSeconds: 2
            periodSeconds: 30
            successThreshold: 1
            failureThreshold: 2
            httpGet:
              path: /index.html
              port: 80
              scheme: HTTP
      restartPolicy: Always
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;7-prestopå’Œ-poststarté…ç½®&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#7-prestopå’Œ-poststarté…ç½®&#34;&gt;#&lt;/a&gt; 7. PreStop å’Œ PostStart é…ç½®&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# cat nginx-deploy.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deploy
  labels:
    app: nginx-deploy
  annotations:
    app: nginx-deploy
  namespace: default
spec:
  selector:
    matchLabels:
      app: nginx-deploy
  replicas: 3
  template:
    metadata:
      labels:
        app: nginx-deploy
    spec:
      containers:
        - name: nginx-deploy
          image: nginx:latest
          imagePullPolicy: IfNotPresent
          startupProbe:
            initialDelaySeconds: 30
            timeoutSeconds: 2
            periodSeconds: 30
            successThreshold: 1
            failureThreshold: 2
            tcpSocket:
              port: 80
          livenessProbe:
            initialDelaySeconds: 30
            timeoutSeconds: 2
            periodSeconds: 30
            successThreshold: 1
            failureThreshold: 2
            tcpSocket:
              port: 80
          readinessProbe:
            initialDelaySeconds: 30
            timeoutSeconds: 2
            periodSeconds: 30
            successThreshold: 1
            failureThreshold: 2
            httpGet:
              path: /index.html
              port: 80
              scheme: HTTP
          lifecycle:
            postStart:
              exec:
                command:
                  - sh
                  - &#39;-c&#39;
                  - mkdir /data
            preStop:
              exec:
                command:
                  - sh
                  - &#39;-c&#39;
                  - sleep 30
      restartPolicy: Always
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;æœ¬æ–‡å‡ºè‡ªäºï¼š&lt;a href=&#34;https://edu.51cto.com/course/23845.html&#34;&gt;https://edu.51cto.com/course/23845.html&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</content>
        <category term="Kubernetes" />
        <updated>2025-04-14T11:23:48.000Z</updated>
    </entry>
    <entry>
        <id>http://ixuyong.cn/posts/3071070979.html</id>
        <title>ä¸€é”®æ°¸ä¹…æ¿€æ´»Windowã€officeæ•™ç¨‹</title>
        <link rel="alternate" href="http://ixuyong.cn/posts/3071070979.html"/>
        <content type="html">&lt;h3 id=&#34;ä¸€é”®æ°¸ä¹…æ¿€æ´»window-officeæ•™ç¨‹&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#ä¸€é”®æ°¸ä¹…æ¿€æ´»window-officeæ•™ç¨‹&#34;&gt;#&lt;/a&gt; ä¸€é”®æ°¸ä¹…æ¿€æ´» Windowã€office æ•™ç¨‹&lt;/h3&gt;
&lt;p&gt;1ã€æŒ‰ä¸‹ Win é”® + Rï¼Œè°ƒå‡ºè¿è¡Œå¯¹è¯æ¡†ï¼Œè¾“å…¥ powershell å¹¶å›è½¦ï¼Œå¯åŠ¨å‘½ä»¤æç¤ºç¬¦çª—å£ã€‚æ¥ç€è¾“å…¥ä»¥ä¸‹æŒ‡ä»¤æ‰§è¡Œæ¿€æ´»ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;irmÂ https://get.activated.win | iex
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/ilMT403.png&#34; alt=&#34;1.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;è¯¥è„šæœ¬åŒ…å«å››ä¸ªåŠŸèƒ½ï¼šé¦–ä¸ªå‘½ä»¤ç”¨äº Windows ç³»ç»Ÿæ°¸ä¹…æ¿€æ´»ï¼Œç¬¬äºŒä¸ªç”¨äº Office æ°¸ä¹…æ¿€æ´»ï¼Œç¬¬ä¸‰ä¸ªå°†ç³»ç»Ÿæœ‰æ•ˆæœŸå»¶é•¿è‡³ 2038 å¹´ï¼Œç¬¬å››ä¸ªåˆ™å®ç°æ¯ 180 å¤©è‡ªåŠ¨å¾ªç¯æ¿€æ´»ã€‚&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/taJbKQr.png&#34; alt=&#34;2.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;2. æˆ‘ä»¬å†æ¬¡ä½¿ç”¨ Windows å¾½æ ‡ + R å¿«æ·é”®æ‰“å¼€è¿è¡Œæ¡†ï¼Œè¾“å…¥ slmgr.vbs/xpr å°±å¯ä»¥çœ‹åˆ°ç³»ç»Ÿå·²ç»æ°¸ä¹…æ¿€æ´»äº†ã€‚&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;slmgr.vbs /xpr
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/JMWlUpc.png&#34; alt=&#34;3.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;ä»¥ä¸Šï¼Œæ—¢ç„¶çœ‹åˆ°è¿™é‡Œäº†ï¼Œå¦‚æœè§‰å¾—ä¸é”™ï¼Œéšæ‰‹ç‚¹ä¸ªèµã€æ‰“èµä¸€ä¸‹å§ï¼Œâ­ï½è°¢è°¢ä½ çœ‹æˆ‘çš„æ–‡ç« ï¼Œæˆ‘ä»¬ä¸‹æ¬¡å†è§ã€‚&lt;/p&gt;
</content>
        <category term="Windows" />
        <updated>2025-04-10T13:32:09.000Z</updated>
    </entry>
    <entry>
        <id>http://ixuyong.cn/posts/985149017.html</id>
        <title>äºŒè¿›åˆ¶é«˜å¯ç”¨å®‰è£…K8Sé›†ç¾¤</title>
        <link rel="alternate" href="http://ixuyong.cn/posts/985149017.html"/>
        <content type="html">&lt;h2 id=&#34;äºŒè¿›åˆ¶é«˜å¯ç”¨å®‰è£…k8sé›†ç¾¤&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#äºŒè¿›åˆ¶é«˜å¯ç”¨å®‰è£…k8sé›†ç¾¤&#34;&gt;#&lt;/a&gt; äºŒè¿›åˆ¶é«˜å¯ç”¨å®‰è£… K8s é›†ç¾¤&lt;/h2&gt;
&lt;h4 id=&#34;1-åŸºæœ¬é…ç½®&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-åŸºæœ¬é…ç½®&#34;&gt;#&lt;/a&gt; 1. åŸºæœ¬é…ç½®&lt;/h4&gt;
&lt;h5 id=&#34;11-åŸºæœ¬ç¯å¢ƒé…ç½®&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#11-åŸºæœ¬ç¯å¢ƒé…ç½®&#34;&gt;#&lt;/a&gt; 1.1 åŸºæœ¬ç¯å¢ƒé…ç½®&lt;/h5&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;ä¸»æœºå&lt;/th&gt;
&lt;th&gt;IP åœ°å€&lt;/th&gt;
&lt;th&gt;è¯´æ˜&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;k8s-master01 ~ 03&lt;/td&gt;
&lt;td&gt;192.168.1.71 ~ 73&lt;/td&gt;
&lt;td&gt;master èŠ‚ç‚¹ * 3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;/&lt;/td&gt;
&lt;td&gt;192.168.1.70&lt;/td&gt;
&lt;td&gt;keepalived è™šæ‹Ÿ IPï¼ˆä¸å ç”¨æœºå™¨ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;k8s-node01 ~ 02&lt;/td&gt;
&lt;td&gt;192.168.1.74/75&lt;/td&gt;
&lt;td&gt;worker èŠ‚ç‚¹ * 2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;em&gt;è¯·ç»Ÿä¸€æ›¿æ¢è¿™äº›ç½‘æ®µï¼ŒPod ç½‘æ®µå’Œ service å’Œå®¿ä¸»æœºç½‘æ®µä¸è¦é‡å¤ï¼ï¼ï¼&lt;/em&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;em&gt;&lt;strong&gt;* é…ç½®ä¿¡æ¯ *&lt;/strong&gt;&lt;/em&gt;&lt;/th&gt;
&lt;th&gt;å¤‡æ³¨&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;ç³»ç»Ÿç‰ˆæœ¬&lt;/td&gt;
&lt;td&gt;Rocky Linux 8/9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Containerd&lt;/td&gt;
&lt;td&gt;latest&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Pod ç½‘æ®µ&lt;/td&gt;
&lt;td&gt;172.16.0.0/16&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Service ç½‘æ®µ&lt;/td&gt;
&lt;td&gt;10.96.0.0/16&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;æ›´æ”¹ä¸»æœºåï¼ˆå…¶å®ƒèŠ‚ç‚¹æŒ‰éœ€ä¿®æ”¹ï¼‰ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;hostnamectl set-hostname k8s-master01 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;é…ç½® hostsï¼Œä¿®æ”¹ /etc/hosts å¦‚ä¸‹ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# cat /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
192.168.1.71 k8s-master01
192.168.1.72 k8s-master02
192.168.1.73 k8s-master03
192.168.1.74 k8s-node01
192.168.1.75 k8s-node02
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;é…ç½® yum æºï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# é…ç½®åŸºç¡€æº
sed -e &#39;s|^mirrorlist=|#mirrorlist=|g&#39; \
    -e &#39;s|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g&#39; \
    -i.bak \
    /etc/yum.repos.d/*.repo

yum makecache
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;å¿…å¤‡å·¥å…·å®‰è£…ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yum install wget jq psmisc vim net-tools telnet yum-utils device-mapper-persistent-data lvm2 git rsyslog -y
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;å…³é—­é˜²ç«å¢™ã€selinuxã€dnsmasqã€swapã€å¼€å¯ rsyslogã€‚æœåŠ¡å™¨é…ç½®å¦‚ä¸‹ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;systemctl disable --now firewalld 
systemctl disable --now dnsmasq
setenforce 0
sed -i &#39;s#SELINUX=enforcing#SELINUX=disabled#g&#39; /etc/sysconfig/selinux
sed -i &#39;s#SELINUX=enforcing#SELINUX=disabled#g&#39; /etc/selinux/config
systemctl enable --now rsyslog
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;å…³é—­ swap åˆ†åŒºï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;swapoff -a &amp;amp;&amp;amp; sysctl -w vm.swappiness=0
sed -ri &#39;/^[^#]*swap/s@^@#@&#39; /etc/fstab
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;å®‰è£… ntpdateï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo dnf install epel-release -y
sudo dnf config-manager --set-enabled epel
sudo dnf install ntpsec
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;åŒæ­¥æ—¶é—´å¹¶é…ç½®ä¸Šæµ·æ—¶åŒºï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
echo &#39;Asia/Shanghai&#39; &amp;gt;/etc/timezone
ntpdate time2.aliyun.com
# åŠ å…¥åˆ°crontab
crontab -e
*/5 * * * * /usr/sbin/ntpdate time2.aliyun.com
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;é…ç½® limitï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ulimit -SHn 65535
vim /etc/security/limits.conf
# æœ«å°¾æ·»åŠ å¦‚ä¸‹å†…å®¹
* soft nofile 65536
* hard nofile 131072
* soft nproc 65535
* hard nproc 655350
* soft memlock unlimited
* hard memlock unlimited
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;å‡çº§ç³»ç»Ÿï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yum update -y
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;Master01 èŠ‚ç‚¹&lt;/mark&gt;å…å¯†é’¥ç™»å½•å…¶ä»–èŠ‚ç‚¹ï¼Œå®‰è£…è¿‡ç¨‹ä¸­ç”Ÿæˆé…ç½®æ–‡ä»¶å’Œè¯ä¹¦å‡åœ¨ Master01 ä¸Šæ“ä½œï¼Œé›†ç¾¤ç®¡ç†ä¹Ÿåœ¨ Master01 ä¸Šæ“ä½œï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ssh-keygen -t rsa
for i in k8s-master01 k8s-master02 k8s-master03 k8s-node01 k8s-node02;do ssh-copy-id -i .ssh/id_rsa.pub $i;done
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;æ³¨æ„ï¼šå…¬æœ‰äº‘ç¯å¢ƒï¼Œå¯èƒ½éœ€è¦æŠŠ kubectl æ”¾åœ¨ä¸€ä¸ªé Master èŠ‚ç‚¹ä¸Š&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;mark&gt;Master01 èŠ‚ç‚¹&lt;/mark&gt;ä¸‹è½½å®‰è£…æ‰€æœ‰çš„æºç æ–‡ä»¶ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd /root/ ; git clone https://gitee.com/chinagei/k8s-ha-install
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;12-å†…æ ¸é…ç½®&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#12-å†…æ ¸é…ç½®&#34;&gt;#&lt;/a&gt; 1.2 å†…æ ¸é…ç½®&lt;/h5&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;å®‰è£… ipvsadmï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yum install ipvsadm ipset sysstat conntrack libseccomp -y
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;é…ç½® ipvs æ¨¡å—ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;modprobe -- ip_vs
modprobe -- ip_vs_rr
modprobe -- ip_vs_wrr
modprobe -- ip_vs_sh
modprobe -- nf_conntrack
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;åˆ›å»º ipvs.confï¼Œå¹¶é…ç½®å¼€æœºè‡ªåŠ¨åŠ è½½ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vim /etc/modules-load.d/ipvs.conf 
# åŠ å…¥ä»¥ä¸‹å†…å®¹
ip_vs
ip_vs_lc
ip_vs_wlc
ip_vs_rr
ip_vs_wrr
ip_vs_lblc
ip_vs_lblcr
ip_vs_dh
ip_vs_sh
ip_vs_fo
ip_vs_nq
ip_vs_sed
ip_vs_ftp
ip_vs_sh
nf_conntrack
ip_tables
ip_set
xt_set
ipt_set
ipt_rpfilter
ipt_REJECT
ipip
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;ç„¶åæ‰§è¡Œ systemctl enable --now systemd-modules-load.service å³å¯ï¼ˆæŠ¥é”™ä¸ç”¨ç®¡ï¼‰&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;systemctl enable --now systemd-modules-load.service
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;å†…æ ¸ä¼˜åŒ–é…ç½®ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt;EOF &amp;gt; /etc/sysctl.d/k8s.conf
net.ipv4.ip_forward = 1
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-ip6tables = 1
fs.may_detach_mounts = 1
net.ipv4.conf.all.route_localnet = 1
vm.overcommit_memory=1
vm.panic_on_oom=0
fs.inotify.max_user_watches=89100
fs.file-max=52706963
fs.nr_open=52706963
net.netfilter.nf_conntrack_max=2310720

net.ipv4.tcp_keepalive_time = 600
net.ipv4.tcp_keepalive_probes = 3
net.ipv4.tcp_keepalive_intvl =15
net.ipv4.tcp_max_tw_buckets = 36000
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_max_orphans = 327680
net.ipv4.tcp_orphan_retries = 3
net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_max_syn_backlog = 16384
net.ipv4.ip_conntrack_max = 65536
net.ipv4.tcp_max_syn_backlog = 16384
net.ipv4.tcp_timestamps = 0
net.core.somaxconn = 16384
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;åº”ç”¨é…ç½®ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sysctl --system
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;é…ç½®å®Œå†…æ ¸åï¼Œé‡å¯æœºå™¨ï¼Œä¹‹åæŸ¥çœ‹å†…æ ¸æ¨¡å—æ˜¯å¦å·²è‡ªåŠ¨åŠ è½½ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;reboot
lsmod | grep --color=auto -e ip_vs -e nf_conntrack
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2-é«˜å¯ç”¨ç»„ä»¶å®‰è£…&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-é«˜å¯ç”¨ç»„ä»¶å®‰è£…&#34;&gt;#&lt;/a&gt; 2. é«˜å¯ç”¨ç»„ä»¶å®‰è£…&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;æ³¨æ„ï¼šå¦‚æœå®‰è£…çš„ä¸æ˜¯é«˜å¯ç”¨é›†ç¾¤ï¼Œhaproxy å’Œ keepalived æ— éœ€å®‰è£…&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;æ³¨æ„ï¼šå…¬æœ‰äº‘è¦ç”¨å…¬æœ‰äº‘è‡ªå¸¦çš„è´Ÿè½½å‡è¡¡ï¼Œæ¯”å¦‚é˜¿é‡Œäº‘çš„ SLBã€NLBï¼Œè…¾è®¯äº‘çš„ ELBï¼Œç”¨æ¥æ›¿ä»£ haproxy å’Œ keepalivedï¼Œå› ä¸ºå…¬æœ‰äº‘å¤§éƒ¨åˆ†éƒ½æ˜¯ä¸æ”¯æŒ keepalived çš„ã€‚&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰ Master èŠ‚ç‚¹&lt;/mark&gt;é€šè¿‡ yum å®‰è£… HAProxy å’Œ KeepAlivedï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yum install keepalived haproxy -y
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰ Master èŠ‚ç‚¹&lt;/mark&gt;é…ç½® HAProxyï¼Œéœ€è¦æ³¨æ„é»„è‰²éƒ¨åˆ†çš„ IPï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 etc]# mkdir /etc/haproxy
[root@k8s-master01 etc]# vim /etc/haproxy/haproxy.cfg 
global
  maxconn  2000
  ulimit-n  16384
  log  127.0.0.1 local0 err
  stats timeout 30s

defaults
  log global
  mode  http
  option  httplog
  timeout connect 5000
  timeout client  50000
  timeout server  50000
  timeout http-request 15s
  timeout http-keep-alive 15s

frontend monitor-in
  bind *:33305
  mode http
  option httplog
  monitor-uri /monitor

frontend k8s-master
  bind 0.0.0.0:8443       #HAProxyç›‘å¬ç«¯å£
  bind 127.0.0.1:8443     #HAProxyç›‘å¬ç«¯å£
  mode tcp
  option tcplog
  tcp-request inspect-delay 5s
  default_backend k8s-master

backend k8s-master
  mode tcp
  option tcplog
  option tcp-check
  balance roundrobin
  default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100
  server k8s-master01	192.168.1.71:6443  check       #API Server IPåœ°å€
  server k8s-master02	192.168.1.72:6443  check       #API Server IPåœ°å€
  server k8s-master03	192.168.1.73:6443  check       #API Server IPåœ°å€
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰ Master èŠ‚ç‚¹&lt;/mark&gt;é…ç½® KeepAlivedï¼Œéœ€è¦æ³¨æ„é»„è‰²éƒ¨åˆ†çš„é…ç½®ã€‚&lt;/p&gt;
&lt;p&gt;&lt;mark&gt;Master01 èŠ‚ç‚¹&lt;/mark&gt;çš„é…ç½®ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 etc]# mkdir /etc/keepalived

[root@k8s-master01 ~]# vim /etc/keepalived/keepalived.conf 
! Configuration File for keepalived
global_defs &amp;#123;
    router_id LVS_DEVEL
script_user root
    enable_script_security
&amp;#125;
vrrp_script chk_apiserver &amp;#123;
    script &amp;quot;/etc/keepalived/check_apiserver.sh&amp;quot;
    interval 5
    weight -5
    fall 2  
rise 1
&amp;#125;
vrrp_instance VI_1 &amp;#123;
    state MASTER
    interface ens160               #ç½‘å¡åç§°
    mcast_src_ip 192.168.1.71      #K8s-master01 IPåœ°å€
    virtual_router_id 51
    priority 101
    advert_int 2
    authentication &amp;#123;
        auth_type PASS
        auth_pass K8SHA_KA_AUTH
    &amp;#125;
    virtual_ipaddress &amp;#123;
        192.168.1.70        #VIPåœ°å€
    &amp;#125;
    track_script &amp;#123;
       chk_apiserver
    &amp;#125;
&amp;#125;	
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;Master02 èŠ‚ç‚¹&lt;/mark&gt;çš„é…ç½®ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# vim /etc/keepalived/keepalived.conf 

! Configuration File for keepalived
global_defs &amp;#123;
    router_id LVS_DEVEL
script_user root
    enable_script_security
&amp;#125;
vrrp_script chk_apiserver &amp;#123;
    script &amp;quot;/etc/keepalived/check_apiserver.sh&amp;quot;
   interval 5
    weight -5
    fall 2  
rise 1
&amp;#125;
vrrp_instance VI_1 &amp;#123;
    state BACKUP
    interface ens160                #ç½‘å¡åç§°
    mcast_src_ip 192.168.1.72       #K8s-master02 IPåœ°å€
    virtual_router_id 51
    priority 100
    advert_int 2
    authentication &amp;#123;
        auth_type PASS
        auth_pass K8SHA_KA_AUTH
    &amp;#125;
    virtual_ipaddress &amp;#123;
        192.168.1.70              #VIPåœ°å€
    &amp;#125;
    track_script &amp;#123;
       chk_apiserver
    &amp;#125;
&amp;#125;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;Master03 èŠ‚ç‚¹&lt;/mark&gt;çš„é…ç½®ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# vim /etc/keepalived/keepalived.conf 

! Configuration File for keepalived
global_defs &amp;#123;
    router_id LVS_DEVEL
script_user root
    enable_script_security
&amp;#125;
vrrp_script chk_apiserver &amp;#123;
    script &amp;quot;/etc/keepalived/check_apiserver.sh&amp;quot;
 interval 5
    weight -5
    fall 2  
rise 1
&amp;#125;
vrrp_instance VI_1 &amp;#123;
    state BACKUP
    interface ens160                 #ç½‘å¡åç§°
    mcast_src_ip 192.168.1.73        #K8s-master03 IPåœ°å€
    virtual_router_id 51
    priority 100
    advert_int 2
    authentication &amp;#123;
        auth_type PASS
        auth_pass K8SHA_KA_AUTH
    &amp;#125;
    virtual_ipaddress &amp;#123;
        192.168.1.70          #VIPåœ°å€
    &amp;#125;
    track_script &amp;#123;
       chk_apiserver
    &amp;#125;
&amp;#125;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰ master èŠ‚ç‚¹&lt;/mark&gt;é…ç½® KeepAlived å¥åº·æ£€æŸ¥æ–‡ä»¶ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 keepalived]# vim /etc/keepalived/check_apiserver.sh 
#!/bin/bash

err=0
for k in $(seq 1 3)
do
    check_code=$(pgrep haproxy)
    if [[ $check_code == &amp;quot;&amp;quot; ]]; then
        err=$(expr $err + 1)
        sleep 1
        continue
    else
        err=0
        break
    fi
done

if [[ $err != &amp;quot;0&amp;quot; ]]; then
    echo &amp;quot;systemctl stop keepalived&amp;quot;
    /usr/bin/systemctl stop keepalived
    exit 1
else
    exit 0
fi
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰ master èŠ‚ç‚¹&lt;/mark&gt;é…ç½®å¥åº·æ£€æŸ¥æ–‡ä»¶æ·»åŠ æ‰§è¡Œæƒé™ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;chmod +x /etc/keepalived/check_apiserver.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰ master èŠ‚ç‚¹&lt;/mark&gt;å¯åŠ¨ haproxy å’Œ keepalivedï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 keepalived]# systemctl daemon-reload
[root@k8s-master01 keepalived]# systemctl enable --now haproxy
[root@k8s-master01 keepalived]# systemctl enable --now keepalived
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;é‡è¦ï¼šå¦‚æœå®‰è£…äº† keepalived å’Œ haproxyï¼Œéœ€è¦æµ‹è¯• keepalived æ˜¯å¦æ˜¯æ­£å¸¸çš„&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;æ‰€æœ‰èŠ‚ç‚¹æµ‹è¯•VIP
[root@k8s-master01 ~]# ping 192.168.1.70 -c 4
PING 192.168.1.70 (192.168.1.70) 56(84) bytes of data.
64 bytes from 192.168.1.70: icmp_seq=1 ttl=64 time=0.464 ms
64 bytes from 192.168.1.70: icmp_seq=2 ttl=64 time=0.063 ms
64 bytes from 192.168.1.70: icmp_seq=3 ttl=64 time=0.062 ms
64 bytes from 192.168.1.70: icmp_seq=4 ttl=64 time=0.063 ms

[root@k8s-master01 ~]# telnet 192.168.1.70 16443
Trying 192.168.1.70...
Connected to 192.168.1.70.
Escape character is &#39;^]&#39;.
Connection closed by foreign host.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å¦‚æœ ping ä¸é€šä¸” telnet æ²¡æœ‰å‡ºç° ] ï¼Œåˆ™è®¤ä¸º VIP ä¸å¯ä»¥ï¼Œä¸å¯åœ¨ç»§ç»­å¾€ä¸‹æ‰§è¡Œï¼Œéœ€è¦æ’æŸ¥ keepalived çš„é—®é¢˜ï¼Œæ¯”å¦‚é˜²ç«å¢™å’Œ selinuxï¼Œhaproxy å’Œ keepalived çš„çŠ¶æ€ï¼Œç›‘å¬ç«¯å£ç­‰&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;æ‰€æœ‰èŠ‚ç‚¹æŸ¥çœ‹é˜²ç«å¢™çŠ¶æ€å¿…é¡»ä¸º disable å’Œ inactiveï¼šsystemctl status firewalld&lt;/li&gt;
&lt;li&gt;æ‰€æœ‰èŠ‚ç‚¹æŸ¥çœ‹ selinux çŠ¶æ€ï¼Œå¿…é¡»ä¸º disableï¼šgetenforce&lt;/li&gt;
&lt;li&gt;master èŠ‚ç‚¹æŸ¥çœ‹ haproxy å’Œ keepalived çŠ¶æ€ï¼šsystemctl status keepalived haproxy&lt;/li&gt;
&lt;li&gt;master èŠ‚ç‚¹æŸ¥çœ‹ç›‘å¬ç«¯å£ï¼šnetstat -lntp&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;å¦‚æœä»¥ä¸Šéƒ½æ²¡æœ‰é—®é¢˜ï¼Œéœ€è¦ç¡®è®¤ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;æ˜¯å¦æ˜¯å…¬æœ‰äº‘æœºå™¨&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;æ˜¯å¦æ˜¯ç§æœ‰äº‘æœºå™¨ï¼ˆç±»ä¼¼ OpenStackï¼‰&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ä¸Šè¿°å…¬æœ‰äº‘ä¸€èˆ¬éƒ½æ˜¯ä¸æ”¯æŒ keepalivedï¼Œç§æœ‰äº‘å¯èƒ½ä¹Ÿæœ‰é™åˆ¶ï¼Œéœ€è¦å’Œè‡ªå·±çš„ç§æœ‰äº‘ç®¡ç†å‘˜å’¨è¯¢&lt;/p&gt;
&lt;h4 id=&#34;3-runtimeå®‰è£…&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3-runtimeå®‰è£…&#34;&gt;#&lt;/a&gt; 3. Runtime å®‰è£…&lt;/h4&gt;
&lt;p&gt;å¦‚æœå®‰è£…çš„ç‰ˆæœ¬ä½äº 1.24ï¼Œé€‰æ‹© Docker å’Œ Containerd å‡å¯ï¼Œé«˜äº 1.24 å»ºè®®é€‰æ‹© Containerd ä½œä¸º Runtimeï¼Œä¸å†æ¨èä½¿ç”¨ Docker ä½œä¸º Runtimeã€‚&lt;/p&gt;
&lt;h5 id=&#34;31-å®‰è£…containerd&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#31-å®‰è£…containerd&#34;&gt;#&lt;/a&gt; 3.1 å®‰è£… Containerd&lt;/h5&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;é…ç½®å®‰è£…æºï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yum install wget jq psmisc vim net-tools telnet yum-utils device-mapper-persistent-data lvm2 git -y
yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;å®‰è£… docker-ceï¼ˆå¦‚æœåœ¨ä»¥å‰å·²ç»å®‰è£…è¿‡ï¼Œéœ€è¦é‡æ–°å®‰è£…æ›´æ–°ä¸€ä¸‹ï¼‰ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# yum install docker-ce containerd -y
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;å¯ä»¥æ— éœ€å¯åŠ¨ Dockerï¼Œåªéœ€è¦é…ç½®å’Œå¯åŠ¨ Containerd å³å¯ã€‚&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;é¦–å…ˆé…ç½® Containerd æ‰€éœ€çš„æ¨¡å—ï¼ˆ&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;ï¼‰ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cat &amp;lt;&amp;lt;EOF | sudo tee /etc/modules-load.d/containerd.conf
overlay
br_netfilter
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;åŠ è½½æ¨¡å—ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# modprobe -- overlay
# modprobe -- br_netfilter
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;ï¼Œé…ç½® Containerd æ‰€éœ€çš„å†…æ ¸ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cat &amp;lt;&amp;lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
net.bridge.bridge-nf-call-iptables  = 1
net.ipv4.ip_forward                 = 1
net.bridge.bridge-nf-call-ip6tables = 1
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;åŠ è½½å†…æ ¸ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# sysctl --system
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;ç”Ÿæˆ Containerd çš„é…ç½®æ–‡ä»¶ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# mkdir -p /etc/containerd
# containerd config default | tee /etc/containerd/config.toml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;æ›´æ”¹ Containerd çš„ Cgroup å’Œ Pause é•œåƒé…ç½®ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sed -i &#39;s#SystemdCgroup = false#SystemdCgroup = true#g&#39; /etc/containerd/config.toml
sed -i &#39;s#k8s.gcr.io/pause#registry.cn-hangzhou.aliyuncs.com/google_containers/pause#g&#39;  /etc/containerd/config.toml
sed -i &#39;s#registry.gcr.io/pause#registry.cn-hangzhou.aliyuncs.com/google_containers/pause#g&#39;  /etc/containerd/config.toml
sed -i &#39;s#registry.k8s.io/pause#registry.cn-hangzhou.aliyuncs.com/google_containers/pause#g&#39;  /etc/containerd/config.toml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;å¯åŠ¨ Containerdï¼Œå¹¶é…ç½®å¼€æœºè‡ªå¯åŠ¨ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# systemctl daemon-reload
# systemctl enable --now containerd
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;é…ç½® crictl å®¢æˆ·ç«¯è¿æ¥çš„è¿è¡Œæ—¶ä½ç½®ï¼ˆå¯é€‰ï¼‰ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cat &amp;gt; /etc/crictl.yaml &amp;lt;&amp;lt;EOF
runtime-endpoint: unix:///run/containerd/containerd.sock
image-endpoint: unix:///run/containerd/containerd.sock
timeout: 10
debug: false
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;4-k8såŠetcdå®‰è£…&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4-k8såŠetcdå®‰è£…&#34;&gt;#&lt;/a&gt; 4 . K8S åŠ etcd å®‰è£…&lt;/h4&gt;
&lt;p&gt;&lt;mark&gt;Master01&lt;/mark&gt; ä¸‹è½½ kubernetes å®‰è£…åŒ…ï¼ˆ1.32.3 éœ€è¦æ›´æ”¹ä¸ºä½ çœ‹åˆ°çš„æœ€æ–°ç‰ˆæœ¬ï¼‰ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# wget https://dl.k8s.io/v1.32.0/kubernetes-server-linux-amd64.tar.gz
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æœ€æ–°ç‰ˆè·å–åœ°å€ï¼š&lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.31.md&#34;&gt;https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;mark&gt;ä»¥ä¸‹æ“ä½œéƒ½åœ¨ master01 æ‰§è¡Œ&lt;/mark&gt;&lt;/p&gt;
&lt;p&gt;ä¸‹è½½ etcd å®‰è£…åŒ…ï¼š&lt;a href=&#34;https://github.com/etcd-io/etcd/releases/&#34;&gt;https://github.com/etcd-io/etcd/releases/&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# wget https://github.com/etcd-io/etcd/releases/download/v3.5.16/etcd-v3.5.16-linux-amd64.tar.gz
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;è§£å‹ kubernetes å®‰è£…æ–‡ä»¶ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# tar -xf kubernetes-server-linux-amd64.tar.gz  --strip-components=3 -C /usr/local/bin kubernetes/server/bin/kube&amp;#123;let,ctl,-apiserver,-controller-manager,-scheduler,-proxy&amp;#125;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;è§£å‹ etcd å®‰è£…æ–‡ä»¶ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]#  tar -zxvf etcd-v3.5.16-linux-amd64.tar.gz --strip-components=1 -C /usr/local/bin etcd-v3.5.16-linux-amd64/etcd&amp;#123;,ctl&amp;#125;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ç‰ˆæœ¬æŸ¥çœ‹ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# kubelet --version
Kubernetes v1.32.3
[root@k8s-master01 ~]# etcdctl version
etcdctl version: 3.5.16
API version: 3.5
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å°†ç»„ä»¶å‘é€åˆ°å…¶ä»–èŠ‚ç‚¹&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;MasterNodes=&#39;k8s-master02 k8s-master03&#39;
WorkNodes=&#39;k8s-node01 k8s-node02&#39;
for NODE in $MasterNodes; do echo $NODE; scp /usr/local/bin/kube&amp;#123;let,ctl,-apiserver,-controller-manager,-scheduler,-proxy&amp;#125; $NODE:/usr/local/bin/; scp /usr/local/bin/etcd* $NODE:/usr/local/bin/; done
for NODE in $WorkNodes; do     scp /usr/local/bin/kube&amp;#123;let,-proxy&amp;#125; $NODE:/usr/local/bin/ ; done
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;Master01 èŠ‚ç‚¹&lt;/mark&gt;åˆ‡æ¢åˆ° 1.32.x åˆ†æ”¯ï¼ˆå…¶ä»–ç‰ˆæœ¬å¯ä»¥åˆ‡æ¢åˆ°å…¶ä»–åˆ†æ”¯ï¼Œ.x å³å¯ï¼Œä¸éœ€è¦æ›´æ”¹ä¸ºå…·ä½“çš„å°ç‰ˆæœ¬ï¼‰ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd /root/k8s-ha-install &amp;amp;&amp;amp; git checkout manual-installation-v1.32.x
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;5-ç”Ÿæˆè¯ä¹¦&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#5-ç”Ÿæˆè¯ä¹¦&#34;&gt;#&lt;/a&gt; 5 . ç”Ÿæˆè¯ä¹¦&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;&lt;mark&gt;äºŒè¿›åˆ¶å®‰è£…æœ€å…³é”®æ­¥éª¤ï¼Œä¸€æ­¥é”™è¯¯å…¨ç›˜çš†è¾“ï¼Œä¸€å®šè¦æ³¨æ„æ¯ä¸ªæ­¥éª¤éƒ½è¦æ˜¯æ­£ç¡®çš„&lt;/mark&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;mark&gt;Master01&lt;/mark&gt; ä¸‹è½½ç”Ÿæˆè¯ä¹¦å·¥å…·ï¼ˆä¸‹è½½ä¸æˆåŠŸå¯ä»¥å»ç™¾åº¦ç½‘ç›˜ï¼‰&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wget &amp;quot;https://pkg.cfssl.org/R1.2/cfssl_linux-amd64&amp;quot; -O /usr/local/bin/cfssl
wget &amp;quot;https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64&amp;quot; -O /usr/local/bin/cfssljson
chmod +x /usr/local/bin/cfssl /usr/local/bin/cfssljson
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;51-etcdè¯ä¹¦&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#51-etcdè¯ä¹¦&#34;&gt;#&lt;/a&gt; 5.1 Etcd è¯ä¹¦&lt;/h5&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰ Master èŠ‚ç‚¹&lt;/mark&gt;åˆ›å»º etcd è¯ä¹¦ç›®å½•ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mkdir /etc/etcd/ssl -p
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;åˆ›å»º kubernetes ç›¸å…³ç›®å½•ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mkdir -p /etc/kubernetes/pki
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;Master01 èŠ‚ç‚¹&lt;/mark&gt;ç”Ÿæˆ etcd è¯ä¹¦&lt;/p&gt;
&lt;p&gt;ç”Ÿæˆè¯ä¹¦çš„ CSRï¼ˆè¯ä¹¦ç­¾åè¯·æ±‚æ–‡ä»¶ï¼Œé…ç½®äº†ä¸€äº›åŸŸåã€å…¬å¸ã€å•ä½ï¼‰æ–‡ä»¶ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 pki]# cd /root/k8s-ha-install/pki

# ç”Ÿæˆetcd CAè¯ä¹¦å’ŒCAè¯ä¹¦çš„key
cfssl gencert -initca etcd-ca-csr.json | cfssljson -bare /etc/etcd/ssl/etcd-ca


cfssl gencert \
   -ca=/etc/etcd/ssl/etcd-ca.pem \
   -ca-key=/etc/etcd/ssl/etcd-ca-key.pem \
   -config=ca-config.json \
   -hostname=127.0.0.1,k8s-master01,k8s-master02,k8s-master03,192.168.1.71,192.168.1.72,192.168.1.73 \
   -profile=kubernetes \
   etcd-csr.json | cfssljson -bare /etc/etcd/ssl/etcd

æ‰§è¡Œç»“æœ
[INFO] generate received request
 	[INFO] received CSR
     [INFO] generating key: rsa-2048
     [INFO] encoded CSR
     [INFO] signed certificate with serial number     250230878926052708909595617022917808304837732033
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å°†è¯ä¹¦å¤åˆ¶åˆ°å…¶ä»– master èŠ‚ç‚¹&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;MasterNodes=&#39;k8s-master02 k8s-master03&#39;

for NODE in $MasterNodes; do
     ssh $NODE &amp;quot;mkdir -p /etc/etcd/ssl&amp;quot;
     for FILE in etcd-ca-key.pem  etcd-ca.pem  etcd-key.pem  etcd.pem; do
       scp /etc/etcd/ssl/$&amp;#123;FILE&amp;#125; $NODE:/etc/etcd/ssl/$&amp;#123;FILE&amp;#125;
     done
 done
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;52-k8sç»„ä»¶è¯ä¹¦&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#52-k8sç»„ä»¶è¯ä¹¦&#34;&gt;#&lt;/a&gt; 5.2 K8s ç»„ä»¶è¯ä¹¦&lt;/h5&gt;
&lt;p&gt;&lt;mark&gt;Master01&lt;/mark&gt; ç”Ÿæˆ kubernetes CA è¯ä¹¦ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 pki]# cd /root/k8s-ha-install/pki

cfssl gencert -initca ca-csr.json | cfssljson -bare /etc/kubernetes/pki/ca
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;521-apiserverè¯ä¹¦&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#521-apiserverè¯ä¹¦&#34;&gt;#&lt;/a&gt; 5.2.1 APIServer è¯ä¹¦&lt;/h6&gt;
&lt;p&gt;æ³¨æ„ï¼š10.96.0. æ˜¯ k8s service çš„ç½‘æ®µï¼Œå¦‚æœè¯´éœ€è¦æ›´æ”¹ k8s service ç½‘æ®µï¼Œé‚£å°±éœ€è¦æ›´æ”¹ 10.96.0.1&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cfssl gencert   -ca=/etc/kubernetes/pki/ca.pem   -ca-key=/etc/kubernetes/pki/ca-key.pem   -config=ca-config.json   -hostname=10.96.0.1,192.168.1.70,127.0.0.1,kubernetes,kubernetes.default,kubernetes.default.svc,kubernetes.default.svc.cluster,kubernetes.default.svc.cluster.local,192.168.1.71,192.168.1.72,192.168.1.73   -profile=kubernetes   apiserver-csr.json | cfssljson -bare /etc/kubernetes/pki/apiserver
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ç”Ÿæˆ apiserver çš„èšåˆè¯ä¹¦ï¼šï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cfssl gencert   -initca front-proxy-ca-csr.json | cfssljson -bare /etc/kubernetes/pki/front-proxy-ca 

cfssl gencert   -ca=/etc/kubernetes/pki/front-proxy-ca.pem   -ca-key=/etc/kubernetes/pki/front-proxy-ca-key.pem   -config=ca-config.json   -profile=kubernetes   front-proxy-client-csr.json | cfssljson -bare /etc/kubernetes/pki/front-proxy-client
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;è¿”å›ç»“æœï¼ˆå¿½ç•¥è­¦å‘Šï¼‰ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;2020/12/11 18:15:28 [INFO] generate received request
2020/12/11 18:15:28 [INFO] received CSR
2020/12/11 18:15:28 [INFO] generating key: rsa-2048

2020/12/11 18:15:28 [INFO] encoded CSR
2020/12/11 18:15:28 [INFO] signed certificate with serial number 597484897564859295955894546063479154194995827845
2020/12/11 18:15:28 [WARNING] This certificate lacks a &amp;quot;hosts&amp;quot; field. This makes it unsuitable for
websites. For more information see the Baseline Requirements for the Issuance and Management
of Publicly-Trusted Certificates, v.1.1.6, from the CA/Browser Forum (https://cabforum.org);
specifically, section 10.2.3 (&amp;quot;Information Requirements&amp;quot;).
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;522-controllermanager&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#522-controllermanager&#34;&gt;#&lt;/a&gt; 5.2.2 ControllerManager&lt;/h6&gt;
&lt;p&gt;ç”Ÿæˆ controller-manage çš„è¯ä¹¦ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-\&#34;&gt;cfssl gencert \
   -ca=/etc/kubernetes/pki/ca.pem \
   -ca-key=/etc/kubernetes/pki/ca-key.pem \
   -config=ca-config.json \
   -profile=kubernetes \
   manager-csr.json | cfssljson -bare /etc/kubernetes/pki/controller-manager

æ³¨æ„ï¼šä¿®æ”¹é»„è‰²éƒ¨åˆ†çš„IPåœ°å€
# set-clusterï¼šè®¾ç½®ä¸€ä¸ªé›†ç¾¤é¡¹ï¼Œ

kubectl config set-cluster kubernetes \
     --certificate-authority=/etc/kubernetes/pki/ca.pem \
     --embed-certs=true \
     --server=https://192.168.1.70:8443 \
     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig

# è®¾ç½®ä¸€ä¸ªç¯å¢ƒé¡¹ï¼Œä¸€ä¸ªä¸Šä¸‹æ–‡
kubectl config set-context system:kube-controller-manager@kubernetes \
    --cluster=kubernetes \
    --user=system:kube-controller-manager \
    --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig

# set-credentials è®¾ç½®ä¸€ä¸ªç”¨æˆ·é¡¹

kubectl config set-credentials system:kube-controller-manager \
     --client-certificate=/etc/kubernetes/pki/controller-manager.pem \
     --client-key=/etc/kubernetes/pki/controller-manager-key.pem \
     --embed-certs=true \
     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig


# ä½¿ç”¨æŸä¸ªç¯å¢ƒå½“åšé»˜è®¤ç¯å¢ƒ

kubectl config use-context system:kube-controller-manager@kubernetes \
     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;523-schedulerè¯ä¹¦&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#523-schedulerè¯ä¹¦&#34;&gt;#&lt;/a&gt; 5.2.3 Scheduler è¯ä¹¦&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;cfssl gencert \
   -ca=/etc/kubernetes/pki/ca.pem \
   -ca-key=/etc/kubernetes/pki/ca-key.pem \
   -config=ca-config.json \
   -profile=kubernetes \
   scheduler-csr.json | cfssljson -bare /etc/kubernetes/pki/scheduler

æ³¨æ„ï¼šä¿®æ”¹é»„è‰²éƒ¨åˆ†çš„IPåœ°å€

kubectl config set-cluster kubernetes \
     --certificate-authority=/etc/kubernetes/pki/ca.pem \
     --embed-certs=true \
     --server=https://192.168.1.70:8443 \
     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig


kubectl config set-credentials system:kube-scheduler \
     --client-certificate=/etc/kubernetes/pki/scheduler.pem \
     --client-key=/etc/kubernetes/pki/scheduler-key.pem \
     --embed-certs=true \
     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig

kubectl config set-context system:kube-scheduler@kubernetes \
     --cluster=kubernetes \
     --user=system:kube-scheduler \
     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig

kubectl config use-context system:kube-scheduler@kubernetes \
     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;524-ç”Ÿæˆç®¡ç†å‘˜è¯ä¹¦&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#524-ç”Ÿæˆç®¡ç†å‘˜è¯ä¹¦&#34;&gt;#&lt;/a&gt; 5.2.4 ç”Ÿæˆç®¡ç†å‘˜è¯ä¹¦&lt;/h6&gt;
&lt;p&gt;Kubectl /etc/Kubernetes/admin.conf ~/.kube/config&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cfssl gencert \
   -ca=/etc/kubernetes/pki/ca.pem \
   -ca-key=/etc/kubernetes/pki/ca-key.pem \
   -config=ca-config.json \
   -profile=kubernetes \
   admin-csr.json | cfssljson -bare /etc/kubernetes/pki/admin

æ³¨æ„ï¼šä¿®æ”¹é»„è‰²éƒ¨åˆ†çš„IP

kubectl config set-cluster kubernetes     --certificate-authority=/etc/kubernetes/pki/ca.pem     --embed-certs=true     --server=https://192.168.1.70:8443     --kubeconfig=/etc/kubernetes/admin.kubeconfig
kubectl config set-credentials kubernetes-admin     --client-certificate=/etc/kubernetes/pki/admin.pem     --client-key=/etc/kubernetes/pki/admin-key.pem     --embed-certs=true     --kubeconfig=/etc/kubernetes/admin.kubeconfig

kubectl config set-context kubernetes-admin@kubernetes     --cluster=kubernetes     --user=kubernetes-admin     --kubeconfig=/etc/kubernetes/admin.kubeconfig

kubectl config use-context kubernetes-admin@kubernetes     --kubeconfig=/etc/kubernetes/admin.kubeconfig
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;525-åˆ›å»ºserviceaccountè¯ä¹¦&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#525-åˆ›å»ºserviceaccountè¯ä¹¦&#34;&gt;#&lt;/a&gt; 5.2.5 åˆ›å»º ServiceAccount è¯ä¹¦&lt;/h6&gt;
&lt;p&gt;åˆ›å»ºä¸€å¯¹å…¬é’¥ï¼Œç”¨æ¥ç­¾å‘ ServiceAccount çš„ Tokenï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;openssl genrsa -out /etc/kubernetes/pki/sa.key 2048
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;è¿”å›ç»“æœï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Generating RSA private key, 2048 bit long modulus (2 primes)
...................................................................................+++++
...............+++++
e is 65537 (0x010001)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt; openssl rsa -in /etc/kubernetes/pki/sa.key -pubout -out /etc/kubernetes/pki/sa.pub
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å‘é€è¯ä¹¦è‡³å…¶ä»–èŠ‚ç‚¹ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;for NODE in k8s-master02 k8s-master03; do 
  for FILE in $(ls /etc/kubernetes/pki | grep -v etcd); do 
    scp /etc/kubernetes/pki/$&amp;#123;FILE&amp;#125; $NODE:/etc/kubernetes/pki/$&amp;#123;FILE&amp;#125;;
  done; 
  for FILE in admin.kubeconfig controller-manager.kubeconfig scheduler.kubeconfig; do 
    scp /etc/kubernetes/$&amp;#123;FILE&amp;#125; $NODE:/etc/kubernetes/$&amp;#123;FILE&amp;#125;;
  done;
done
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æŸ¥çœ‹è¯ä¹¦æ–‡ä»¶ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 pki]# ls /etc/kubernetes/pki/
admin.csr      apiserver.csr      ca.csr      controller-manager.csr      front-proxy-ca.csr      front-proxy-client.csr      sa.key         scheduler-key.pem
admin-key.pem  apiserver-key.pem  ca-key.pem  controller-manager-key.pem  front-proxy-ca-key.pem  front-proxy-client-key.pem  sa.pub         scheduler.pem
admin.pem      apiserver.pem      ca.pem      controller-manager.pem      front-proxy-ca.pem      front-proxy-client.pem      scheduler.csr
[root@k8s-master01 pki]# ls /etc/kubernetes/pki/ |wc -l
23
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;6-kubernetesç»„ä»¶é…ç½®&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#6-kubernetesç»„ä»¶é…ç½®&#34;&gt;#&lt;/a&gt; 6. Kubernetes ç»„ä»¶é…ç½®&lt;/h4&gt;
&lt;h5 id=&#34;61-ecdé…ç½®&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#61-ecdé…ç½®&#34;&gt;#&lt;/a&gt; 6.1 Ecd é…ç½®&lt;/h5&gt;
&lt;p&gt;Etcd é…ç½®å¤§è‡´ç›¸åŒï¼Œæ³¨æ„ä¿®æ”¹æ¯ä¸ª Master èŠ‚ç‚¹çš„ etcd é…ç½®çš„ä¸»æœºåå’Œ IP åœ°å€&lt;/p&gt;
&lt;h6 id=&#34;611-master01&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#611-master01&#34;&gt;#&lt;/a&gt; 6.1.1 Master01&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;# vim /etc/etcd/etcd.config.yml
name: &#39;k8s-master01&#39;     # k8s-master01åç§°
data-dir: /var/lib/etcd
wal-dir: /var/lib/etcd/wal
snapshot-count: 5000
heartbeat-interval: 100
election-timeout: 1000
quota-backend-bytes: 0
listen-peer-urls: &#39;https://192.168.1.71:2380&#39;            # k8s-master01 IP
listen-client-urls: &#39;https://192.168.1.71:2379,http://127.0.0.1:2379&#39;   # k8s-master01 IP
max-snapshots: 3
max-wals: 5
cors:
initial-advertise-peer-urls: &#39;https://192.168.1.71:2380&#39;  # k8s-master01 IP
advertise-client-urls: &#39;https://192.168.1.71:2379&#39;        # k8s-master01 IP
discovery:
discovery-fallback: &#39;proxy&#39;
discovery-proxy:
discovery-srv:
initial-cluster: &#39;k8s-master01=https://192.168.1.71:2380,k8s-master02=https://192.168.1.72:2380,k8s-master03=https://192.168.1.73:2380&#39;     # k8s-master01ã€k8s-master02ã€k8s-master03 IP 
initial-cluster-token: &#39;etcd-k8s-cluster&#39;
initial-cluster-state: &#39;new&#39;
strict-reconfig-check: false
enable-v2: true
enable-pprof: true
proxy: &#39;off&#39;
proxy-failure-wait: 5000
proxy-refresh-interval: 30000
proxy-dial-timeout: 1000
proxy-write-timeout: 5000
proxy-read-timeout: 0
client-transport-security:
  cert-file: &#39;/etc/kubernetes/pki/etcd/etcd.pem&#39;
  key-file: &#39;/etc/kubernetes/pki/etcd/etcd-key.pem&#39;
  client-cert-auth: true
  trusted-ca-file: &#39;/etc/kubernetes/pki/etcd/etcd-ca.pem&#39;
  auto-tls: true
peer-transport-security:
  cert-file: &#39;/etc/kubernetes/pki/etcd/etcd.pem&#39;
  key-file: &#39;/etc/kubernetes/pki/etcd/etcd-key.pem&#39;
  peer-client-cert-auth: true
  trusted-ca-file: &#39;/etc/kubernetes/pki/etcd/etcd-ca.pem&#39;
  auto-tls: true
debug: false
log-package-levels:
log-outputs: [default]
force-new-cluster: false
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;612-master02&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#612-master02&#34;&gt;#&lt;/a&gt; 6.1.2 Master02&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;# vim /etc/etcd/etcd.config.yml	
name: &#39;k8s-master02&#39;   # k8s-master02åç§°
data-dir: /var/lib/etcd
wal-dir: /var/lib/etcd/wal
snapshot-count: 5000
heartbeat-interval: 100
election-timeout: 1000
quota-backend-bytes: 0
listen-peer-urls: &#39;https://192.168.1.72:2380&#39;      # k8s-master02 IP
listen-client-urls: &#39;https://192.168.1.72:2379,http://127.0.0.1:2379&#39;    # k8s-master02 IP
max-snapshots: 3
max-wals: 5
cors:
initial-advertise-peer-urls: &#39;https://192.168.1.72:2380&#39;    # k8s-master02 IP
advertise-client-urls: &#39;https://192.168.1.72:2379&#39;     # k8s-master02 IP
discovery:
discovery-fallback: &#39;proxy&#39;
discovery-proxy:
discovery-srv:
initial-cluster: &#39;k8s-master01=https://192.168.1.71:2380,k8s-master02=https://192.168.1.72:2380,k8s-master03=https://192.168.1.73:2380&#39;             # k8s-master01ã€k8s-master02ã€k8s-master03 IP 
initial-cluster-token: &#39;etcd-k8s-cluster&#39;
initial-cluster-state: &#39;new&#39;
strict-reconfig-check: false
enable-v2: true
enable-pprof: true
proxy: &#39;off&#39;
proxy-failure-wait: 5000
proxy-refresh-interval: 30000
proxy-dial-timeout: 1000
proxy-write-timeout: 5000
proxy-read-timeout: 0
client-transport-security:
  cert-file: &#39;/etc/kubernetes/pki/etcd/etcd.pem&#39;
  key-file: &#39;/etc/kubernetes/pki/etcd/etcd-key.pem&#39;
  client-cert-auth: true
  trusted-ca-file: &#39;/etc/kubernetes/pki/etcd/etcd-ca.pem&#39;
  auto-tls: true
peer-transport-security:
  cert-file: &#39;/etc/kubernetes/pki/etcd/etcd.pem&#39;
  key-file: &#39;/etc/kubernetes/pki/etcd/etcd-key.pem&#39;
  peer-client-cert-auth: true
  trusted-ca-file: &#39;/etc/kubernetes/pki/etcd/etcd-ca.pem&#39;
  auto-tls: true
debug: false
log-package-levels:
log-outputs: [default]
force-new-cluster: false
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;613-master03&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#613-master03&#34;&gt;#&lt;/a&gt; 6.1.3 Master03&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;# vim /etc/etcd/etcd.config.yml
name: &#39;k8s-master03&#39;           # k8s-master03åç§°
data-dir: /var/lib/etcd
wal-dir: /var/lib/etcd/wal
snapshot-count: 5000
heartbeat-interval: 100
election-timeout: 1000
quota-backend-bytes: 0
listen-peer-urls: &#39;https://192.168.1.73:2380&#39;           # k8s-master03 IP
listen-client-urls: &#39;https://192.168.1.73:2379,http://127.0.0.1:2379&#39;       # k8s-master03 IP
max-snapshots: 3
max-wals: 5
cors:
initial-advertise-peer-urls: &#39;https://192.168.1.73:2380&#39;      # k8s-master03 IP
advertise-client-urls: &#39;https://192.168.1.73:2379&#39;            # k8s-master03 IP
discovery:
discovery-fallback: &#39;proxy&#39;
discovery-proxy:
discovery-srv:
initial-cluster: &#39;k8s-master01=https://192.168.1.71:2380,k8s-master02=https://192.168.1.72:2380,k8s-master03=https://192.168.1.73:2380&#39;                # k8s-master01ã€k8s-master02ã€k8s-master03 IP
initial-cluster-token: &#39;etcd-k8s-cluster&#39;
initial-cluster-state: &#39;new&#39;
strict-reconfig-check: false
enable-v2: true
enable-pprof: true
proxy: &#39;off&#39;
proxy-failure-wait: 5000
proxy-refresh-interval: 30000
proxy-dial-timeout: 1000
proxy-write-timeout: 5000
proxy-read-timeout: 0
client-transport-security:
  cert-file: &#39;/etc/kubernetes/pki/etcd/etcd.pem&#39;
  key-file: &#39;/etc/kubernetes/pki/etcd/etcd-key.pem&#39;
  client-cert-auth: true
  trusted-ca-file: &#39;/etc/kubernetes/pki/etcd/etcd-ca.pem&#39;
  auto-tls: true
peer-transport-security:
  cert-file: &#39;/etc/kubernetes/pki/etcd/etcd.pem&#39;
  key-file: &#39;/etc/kubernetes/pki/etcd/etcd-key.pem&#39;
  peer-client-cert-auth: true
  trusted-ca-file: &#39;/etc/kubernetes/pki/etcd/etcd-ca.pem&#39;
  auto-tls: true
debug: false
log-package-levels:
log-outputs: [default]
force-new-cluster: false
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;614-å¯åŠ¨etcd&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#614-å¯åŠ¨etcd&#34;&gt;#&lt;/a&gt; 6.1.4 å¯åŠ¨ Etcd&lt;/h6&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰ Master èŠ‚ç‚¹&lt;/mark&gt;åˆ›å»º etcd service å¹¶å¯åŠ¨&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# vim /usr/lib/systemd/system/etcd.service
[Unit]
Description=Etcd Service
Documentation=https://coreos.com/etcd/docs/latest/
After=network.target

[Service]
Type=notify
ExecStart=/usr/local/bin/etcd --config-file=/etc/etcd/etcd.config.yml
Restart=on-failure
RestartSec=10
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
Alias=etcd3.service
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰ Master èŠ‚ç‚¹&lt;/mark&gt;åˆ›å»º etcd çš„è¯ä¹¦ç›®å½•ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mkdir /etc/kubernetes/pki/etcd
ln -s /etc/etcd/ssl/* /etc/kubernetes/pki/etcd/
systemctl daemon-reload
systemctl enable --now etcd
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æŸ¥çœ‹ etcd çŠ¶æ€ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export ETCDCTL_API=3
etcdctl --endpoints=&amp;quot;192.168.1.73:2379,192.168.1.72:2379,192.168.1.71:2379&amp;quot; --cacert=/etc/kubernetes/pki/etcd/etcd-ca.pem --cert=/etc/kubernetes/pki/etcd/etcd.pem --key=/etc/kubernetes/pki/etcd/etcd-key.pem  endpoint status --write-out=table
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;62-apiserveré…ç½®&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#62-apiserveré…ç½®&#34;&gt;#&lt;/a&gt; 6.2 APIServer é…ç½®&lt;/h5&gt;
&lt;h6 id=&#34;621-master01&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#621-master01&#34;&gt;#&lt;/a&gt; 6.2.1 Master01&lt;/h6&gt;
&lt;p&gt;æ³¨æ„ï¼šæœ¬æ–‡æ¡£ä½¿ç”¨çš„ k8s service ç½‘æ®µä¸º 10.96.0.0/16ï¼Œè¯¥ç½‘æ®µä¸èƒ½å’Œå®¿ä¸»æœºçš„ç½‘æ®µã€Pod ç½‘æ®µçš„é‡å¤ï¼Œè¯·æŒ‰éœ€ä¿®æ”¹ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 pki]# vim /usr/lib/systemd/system/kube-apiserver.service 

[Unit]
Description=Kubernetes API Server
Documentation=https://github.com/kubernetes/kubernetes
After=network.target

[Service]
ExecStart=/usr/local/bin/kube-apiserver \
      --v=2  \
      --allow-privileged=true  \
      --bind-address=0.0.0.0  \
      --secure-port=6443  \
      --advertise-address=192.168.1.71 \
      --service-cluster-ip-range=10.96.0.0/16  \
      --service-node-port-range=30000-32767  \
      --etcd-servers=https://192.168.1.71:2379,https://192.168.1.72:2379,https://192.168.1.73:2379 \
      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \
      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \
      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \
      --client-ca-file=/etc/kubernetes/pki/ca.pem  \
      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \
      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \
      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \
      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \
      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \
      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \
      --service-account-issuer=https://kubernetes.default.svc.cluster.local \
      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \
      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \
      --authorization-mode=Node,RBAC  \
      --enable-bootstrap-token-auth=true  \
      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \
      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \
      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \
      --requestheader-allowed-names=aggregator  \
      --requestheader-group-headers=X-Remote-Group  \
      --requestheader-extra-headers-prefix=X-Remote-Extra-  \
      --requestheader-username-headers=X-Remote-User
      # --token-auth-file=/etc/kubernetes/token.csv

Restart=on-failure
RestartSec=10s
LimitNOFILE=65535

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;622-master02&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#622-master02&#34;&gt;#&lt;/a&gt; 6.2.2 Master02&lt;/h6&gt;
&lt;p&gt;æ³¨æ„ï¼šæœ¬æ–‡æ¡£ä½¿ç”¨çš„ k8s service ç½‘æ®µä¸º 10.96.0.0/16ï¼Œè¯¥ç½‘æ®µä¸èƒ½å’Œå®¿ä¸»æœºçš„ç½‘æ®µã€Pod ç½‘æ®µçš„é‡å¤ï¼Œè¯·æŒ‰éœ€ä¿®æ”¹ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 pki]# vim  /usr/lib/systemd/system/kube-apiserver.service 

[Unit]
Description=Kubernetes API Server
Documentation=https://github.com/kubernetes/kubernetes
After=network.target

[Service]
ExecStart=/usr/local/bin/kube-apiserver \
      --v=2  \
      --allow-privileged=true  \
      --bind-address=0.0.0.0  \
      --secure-port=6443  \
      --advertise-address=192.168.1.72 \
      --service-cluster-ip-range=10.96.0.0/16  \
      --service-node-port-range=30000-32767  \
      --etcd-servers=https://192.168.1.71:2379,https://192.168.1.72:2379,https://192.168.1.73:2379 \
      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \
      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \
      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \
      --client-ca-file=/etc/kubernetes/pki/ca.pem  \
      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \
      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \
      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \
      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \
      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \
      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \
      --service-account-issuer=https://kubernetes.default.svc.cluster.local \
      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \
      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \
      --authorization-mode=Node,RBAC  \
      --enable-bootstrap-token-auth=true  \
      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \
      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \
      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \
      --requestheader-allowed-names=aggregator  \
      --requestheader-group-headers=X-Remote-Group  \
      --requestheader-extra-headers-prefix=X-Remote-Extra-  \
      --requestheader-username-headers=X-Remote-User

Restart=on-failure
RestartSec=10s
LimitNOFILE=65535

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;623-master03&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#623-master03&#34;&gt;#&lt;/a&gt; 6.2.3 Master03&lt;/h6&gt;
&lt;p&gt;æ³¨æ„ï¼šæœ¬æ–‡æ¡£ä½¿ç”¨çš„ k8s service ç½‘æ®µä¸º 10.96.0.0/16ï¼Œè¯¥ç½‘æ®µä¸èƒ½å’Œå®¿ä¸»æœºçš„ç½‘æ®µã€Pod ç½‘æ®µçš„é‡å¤ï¼Œè¯·æŒ‰éœ€ä¿®æ”¹ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 pki]# vim  /usr/lib/systemd/system/kube-apiserver.service 

[Unit]
Description=Kubernetes API Server
Documentation=https://github.com/kubernetes/kubernetes
After=network.target

[Service]
ExecStart=/usr/local/bin/kube-apiserver \
      --v=2  \
      --allow-privileged=true  \
      --bind-address=0.0.0.0  \
      --secure-port=6443  \
      --advertise-address=192.168.1.73 \
      --service-cluster-ip-range=10.96.0.0/16  \
      --service-node-port-range=30000-32767  \
      --etcd-servers=https://192.168.1.71:2379,https://192.168.1.72:2379,https://192.168.1.73:2379 \
      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \
      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \
      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \
      --client-ca-file=/etc/kubernetes/pki/ca.pem  \
      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \
      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \
      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \
      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \
      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \
      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \
      --service-account-issuer=https://kubernetes.default.svc.cluster.local \
      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \
      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \
      --authorization-mode=Node,RBAC  \
      --enable-bootstrap-token-auth=true  \
      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \
      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \
      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \
      --requestheader-allowed-names=aggregator  \
      --requestheader-group-headers=X-Remote-Group  \
      --requestheader-extra-headers-prefix=X-Remote-Extra-  \
      --requestheader-username-headers=X-Remote-User
      # --token-auth-file=/etc/kubernetes/token.csv

Restart=on-failure
RestartSec=10s
LimitNOFILE=65535

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;624-å¯åŠ¨apiserver&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#624-å¯åŠ¨apiserver&#34;&gt;#&lt;/a&gt; 6.2.4 å¯åŠ¨ apiserver&lt;/h6&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰ Master èŠ‚ç‚¹&lt;/mark&gt;å¼€å¯ kube-apiserverï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;systemctl daemon-reload &amp;amp;&amp;amp; systemctl enable --now kube-apiserver
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æ£€æµ‹ kube-server çŠ¶æ€ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# systemctl status kube-apiserver

â— kube-apiserver.service â€“ Kubernetes API Server
   Loaded: loaded (/usr/lib/systemd/system/kube-apiserver.service; enabled; vendor preset: disabled)
   Active: active (running) since Sat 2020-08-22 21:26:49 CST; 26s agoÂ 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å¦‚æœç³»ç»Ÿæ—¥å¿—æœ‰è¿™äº›æç¤ºå¯ä»¥å¿½ç•¥:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Dec 11 20:51:15 k8s-master01 kube-apiserver: I1211 20:51:15.004739    7450 clientconn.go:948] ClientConn switching balancer to â€œpick_firstâ€
Dec 11 20:51:15 k8s-master01 kube-apiserver: I1211 20:51:15.004843    7450 balancer_conn_wrappers.go:78] pickfirstBalancer: HandleSubConnStateChange: 0xc011bd4c80, &amp;#123;CONNECTING &amp;lt;nil&amp;gt;&amp;#125;
Dec 11 20:51:15 k8s-master01 kube-apiserver: I1211 20:51:15.010725    7450 balancer_conn_wrappers.go:78] pickfirstBalancer: HandleSubConnStateChange: 0xc011bd4c80, &amp;#123;READY &amp;lt;nil&amp;gt;&amp;#125;
Dec 11 20:51:15 k8s-master01 kube-apiserver: I1211 20:51:15.011370    7450 controlbuf.go:508] transport: loopyWriter.run returning. Connection error: desc = â€œtransport is closingâ€
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;63-controllermanage&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#63-controllermanage&#34;&gt;#&lt;/a&gt; 6.3 ControllerManage&lt;/h5&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰ Master èŠ‚ç‚¹&lt;/mark&gt;é…ç½® kube-controller-manager serviceï¼ˆæ‰€æœ‰ master èŠ‚ç‚¹é…ç½®ä¸€æ ·ï¼‰&lt;/p&gt;
&lt;p&gt;æ³¨æ„ï¼šæœ¬æ–‡æ¡£ä½¿ç”¨çš„ k8s Pod ç½‘æ®µä¸º 172.16.0.0/16ï¼Œè¯¥ç½‘æ®µä¸èƒ½å’Œå®¿ä¸»æœºçš„ç½‘æ®µã€k8s Service ç½‘æ®µçš„é‡å¤ï¼Œè¯·æŒ‰éœ€ä¿®æ”¹ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 pki]# vim /usr/lib/systemd/system/kube-controller-manager.service
[Unit]
Description=Kubernetes Controller Manager
Documentation=https://github.com/kubernetes/kubernetes
After=network.target

[Service]
ExecStart=/usr/local/bin/kube-controller-manager \
      --v=2 \
      --root-ca-file=/etc/kubernetes/pki/ca.pem \
      --cluster-signing-cert-file=/etc/kubernetes/pki/ca.pem \
      --cluster-signing-key-file=/etc/kubernetes/pki/ca-key.pem \
      --service-account-private-key-file=/etc/kubernetes/pki/sa.key \
      --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig \
      --authentication-kubeconfig=/etc/kubernetes/controller-manager.kubeconfig \
      --authorization-kubeconfig=/etc/kubernetes/controller-manager.kubeconfig \
      --leader-elect=true \
      --use-service-account-credentials=true \
      --node-monitor-grace-period=40s \
      --node-monitor-period=5s \
      --controllers=*,bootstrapsigner,tokencleaner \
      --allocate-node-cidrs=true \
      --cluster-cidr=172.16.0.0/16 \
      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem \
      --node-cidr-mask-size=24
      
Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰ Master èŠ‚ç‚¹&lt;/mark&gt;å¯åŠ¨ kube-controller-manager&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 pki]# systemctl daemon-reload

[root@k8s-master01 pki]# systemctl enable --now kube-controller-manager
Created symlink /etc/systemd/system/multi-user.target.wants/kube-controller-manager.service â†’ /usr/lib/systemd/system/kube-controller-manager.service.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æŸ¥çœ‹å¯åŠ¨çŠ¶æ€&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 pki]# systemctl  status kube-controller-manager
â— kube-controller-manager.service â€“ Kubernetes Controller Manager
   Loaded: loaded (/usr/lib/ ubern/system/kube-controller-manager.service; enabled; vendor preset: disabled)
 Active: active (running) since Fri 2020-12-11 20:53:05 CST; 8s ago
     Docs: https://github.com/  ubernetes/  ubernetes
 Main PID: 7518 (kube-controller)
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;64-scheduler&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#64-scheduler&#34;&gt;#&lt;/a&gt; 6.4 Scheduler&lt;/h5&gt;
&lt;p&gt;æ‰€æœ‰ Master èŠ‚ç‚¹é…ç½® kube-scheduler serviceï¼ˆæ‰€æœ‰ master èŠ‚ç‚¹é…ç½®ä¸€æ ·ï¼‰&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 pki]# vim /usr/lib/systemd/system/kube-scheduler.service 
[Unit]
Description=Kubernetes Scheduler
Documentation=https://github.com/kubernetes/kubernetes
After=network.target

[Service]
ExecStart=/usr/local/bin/kube-scheduler \
      --v=2 \
      --leader-elect=true \
      --authentication-kubeconfig=/etc/kubernetes/scheduler.kubeconfig \
      --authorization-kubeconfig=/etc/kubernetes/scheduler.kubeconfig \
      --kubeconfig=/etc/kubernetes/scheduler.kubeconfig

Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å¯åŠ¨ schedulerï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 pki]# systemctl daemon-reload

[root@k8s-master01 pki]# systemctl enable --now kube-scheduler
Created symlink /etc/systemd/system/multi-user.target.wants/kube-scheduler.service â†’ /usr/lib/systemd/system/kube-scheduler.service.
[root@k8s-master01 pki]# systemctl status kube-scheduler
â— kube-scheduler.service - Kubernetes Scheduler
   Loaded: loaded (/usr/lib/systemd/system/kube-scheduler.service; enabled; vendor preset: disabled)
   Active: active (running) since Wed 2022-05-04 17:31:13 CST; 6s ago
     Docs: https://github.com/kubernetes/kubernetes
 Main PID: 5815 (kube-scheduler)
    Tasks: 9
   Memory: 19.8M
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;7-tls-bootstrappingé…ç½®&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#7-tls-bootstrappingé…ç½®&#34;&gt;#&lt;/a&gt; 7. TLS Bootstrapping é…ç½®&lt;/h4&gt;
&lt;p&gt;åªéœ€è¦åœ¨&lt;mark&gt; Master01&lt;/mark&gt; åˆ›å»º bootstrap&lt;/p&gt;
&lt;p&gt;æ³¨æ„ï¼š ä¿®æ”¹é»„è‰²éƒ¨åˆ†çš„ IP åœ°å€&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd /root/k8s-ha-install/bootstrap
kubectl config set-cluster kubernetes     --certificate-authority=/etc/kubernetes/pki/ca.pem     --embed-certs=true     --server=https://192.168.1.70:8443     --kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig
kubectl config set-credentials tls-bootstrap-token-user     --token=c8ad9c.2e4d610cf3e7426e --kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig
kubectl config set-context tls-bootstrap-token-user@kubernetes     --cluster=kubernetes     --user=tls-bootstrap-token-user     --kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig
kubectl config use-context tls-bootstrap-token-user@kubernetes     --kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig

[root@k8s-master01 bootstrap]# mkdir -p /root/.kube ; cp /etc/kubernetes/admin.kubeconfig /root/.kube/config
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å¯ä»¥æ­£å¸¸æŸ¥è¯¢é›†ç¾¤çŠ¶æ€ï¼Œæ‰å¯ä»¥ç»§ç»­å¾€ä¸‹ï¼Œå¦åˆ™ä¸è¡Œï¼Œéœ€è¦æ’æŸ¥ k8s ç»„ä»¶æ˜¯å¦æœ‰æ•…éšœï¼ˆåªè¦æœ‰ç»“æœå³å¯ï¼Œå¦‚æœè¿”å›ä¸ä¸€æ ·ä¸å½±å“ï¼‰&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# kubectl get cs
Warning: v1 ComponentStatus is deprecated in v1.19+
NAME                 STATUS    MESSAGE   ERROR
controller-manager   Healthy   ok        
scheduler            Healthy   ok        
etcd-0               Healthy   ok
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;åˆ›å»º bootstrap ç›¸å…³èµ„æºï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 bootstrap]# kubectl create -f bootstrap.secret.yaml 
secret/bootstrap-token-c8ad9c created
clusterrolebinding.rbac.authorization.k8s.io/kubelet-bootstrap created
clusterrolebinding.rbac.authorization.k8s.io/node-autoapprove-bootstrap created
clusterrolebinding.rbac.authorization.k8s.io/node-autoapprove-certificate-rotation created
clusterrole.rbac.authorization.k8s.io/system:kube-apiserver-to-kubelet created
clusterrolebinding.rbac.authorization.k8s.io/system:kube-apiserver created
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;8-nodeèŠ‚ç‚¹é…ç½®&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#8-nodeèŠ‚ç‚¹é…ç½®&#34;&gt;#&lt;/a&gt; 8. Node èŠ‚ç‚¹é…ç½®&lt;/h4&gt;
&lt;h5 id=&#34;81-å¤åˆ¶è¯ä¹¦&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#81-å¤åˆ¶è¯ä¹¦&#34;&gt;#&lt;/a&gt; 8.1 å¤åˆ¶è¯ä¹¦&lt;/h5&gt;
&lt;p&gt;&lt;mark&gt;Master01 èŠ‚ç‚¹&lt;/mark&gt;å¤åˆ¶è¯ä¹¦è‡³å…¶ä»–èŠ‚ç‚¹ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd /etc/kubernetes/

for NODE in k8s-master02 k8s-master03 k8s-node01 k8s-node02; do
     ssh $NODE mkdir -p /etc/kubernetes/pki
     for FILE in pki/ca.pem pki/ca-key.pem pki/front-proxy-ca.pem bootstrap-kubelet.kubeconfig; do
       scp /etc/kubernetes/$FILE $NODE:/etc/kubernetes/$&amp;#123;FILE&amp;#125;
 done
 done
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æ‰§è¡Œç»“æœï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ca.pem                                                                                                                                                                         100% 1407   459.5KB/s   00:00    
â€¦
bootstrap-kubelet.kubeconfig                                                                                                                                                   100% 2291   685.4KB/s   00:00
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;82-kubeleté…ç½®&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#82-kubeleté…ç½®&#34;&gt;#&lt;/a&gt; 8.2 Kubelet é…ç½®&lt;/h5&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;åˆ›å»º Kubelet é…ç½®ç›®å½•&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mkdir -p /var/lib/kubelet /var/log/kubernetes /etc/systemd/system/kubelet.service.d /etc/kubernetes/manifests/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;é…ç½® kubelet service&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 bootstrap]# vim  /usr/lib/systemd/system/kubelet.service

[Unit]
Description=Kubernetes Kubelet
Documentation=https://github.com/kubernetes/kubernetes

[Service]
ExecStart=/usr/local/bin/kubelet

Restart=always
StartLimitInterval=0
RestartSec=10

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;é…ç½® kubelet service çš„é…ç½®æ–‡ä»¶ï¼ˆä¹Ÿå¯ä»¥å†™åˆ° kubelet.serviceï¼‰ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Runtimeä¸ºContainerd
# vim /etc/systemd/system/kubelet.service.d/10-kubelet.conf

[Service]
Environment=&amp;quot;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig --kubeconfig=/etc/kubernetes/kubelet.kubeconfig&amp;quot;
Environment=&amp;quot;KUBELET_SYSTEM_ARGS=--container-runtime-endpoint=unix:///run/containerd/containerd.sock&amp;quot;
Environment=&amp;quot;KUBELET_CONFIG_ARGS=--config=/etc/kubernetes/kubelet-conf.yml&amp;quot;
Environment=&amp;quot;KUBELET_EXTRA_ARGS=--node-labels=node.kubernetes.io/node=&#39;&#39; &amp;quot;
ExecStart=
ExecStart=/usr/local/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_SYSTEM_ARGS $KUBELET_EXTRA_ARGS
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;åˆ›å»º kubelet çš„é…ç½®æ–‡ä»¶&lt;/p&gt;
&lt;p&gt;&lt;em&gt;æ³¨æ„ï¼šå¦‚æœæ›´æ”¹äº† k8s çš„ service ç½‘æ®µï¼Œéœ€è¦æ›´æ”¹ kubelet-conf.yml çš„ clusterDNS: é…ç½®ï¼Œæ”¹æˆ k8s Service ç½‘æ®µçš„ç¬¬åä¸ªåœ°å€ï¼Œæ¯”å¦‚ 10.96.0.10&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 bootstrap]# vim /etc/kubernetes/kubelet-conf.yml

apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
address: 0.0.0.0
port: 10250
readOnlyPort: 10255
authentication:
  anonymous:
    enabled: false
  webhook:
    cacheTTL: 2m0s
    enabled: true
  x509:
    clientCAFile: /etc/kubernetes/pki/ca.pem
authorization:
  mode: Webhook
  webhook:
    cacheAuthorizedTTL: 5m0s
    cacheUnauthorizedTTL: 30s
cgroupDriver: systemd
cgroupsPerQOS: true
clusterDNS:
- 10.96.0.10
clusterDomain: cluster.local
containerLogMaxFiles: 5
containerLogMaxSize: 10Mi
contentType: application/vnd.kubernetes.protobuf
cpuCFSQuota: true
cpuManagerPolicy: none
cpuManagerReconcilePeriod: 10s
enableControllerAttachDetach: true
enableDebuggingHandlers: true
enforceNodeAllocatable:
- pods
eventBurst: 10
eventRecordQPS: 5
evictionHard:
  imagefs.available: 15%
  memory.available: 100Mi
  nodefs.available: 10%
  nodefs.inodesFree: 5%
evictionPressureTransitionPeriod: 5m0s
failSwapOn: true
fileCheckFrequency: 20s
hairpinMode: promiscuous-bridge
healthzBindAddress: 127.0.0.1
healthzPort: 10248
httpCheckFrequency: 20s
imageGCHighThresholdPercent: 85
imageGCLowThresholdPercent: 80
imageMinimumGCAge: 2m0s
iptablesDropBit: 15
iptablesMasqueradeBit: 14
kubeAPIBurst: 10
kubeAPIQPS: 5
makeIPTablesUtilChains: true
maxOpenFiles: 1000000
maxPods: 110
nodeStatusUpdateFrequency: 10s
oomScoreAdj: -999
podPidsLimit: -1
registryBurst: 10
registryPullQPS: 5
resolvConf: /etc/resolv.conf
rotateCertificates: true
runtimeRequestTimeout: 2m0s
serializeImagePulls: true
staticPodPath: /etc/kubernetes/manifests
streamingConnectionIdleTimeout: 4h0m0s
syncFrequency: 1m0s
volumeStatsAggPeriod: 1m0s
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å¯åŠ¨&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt; kubelet&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;systemctl daemon-reload
systemctl enable --now kubelet
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æ­¤æ—¶ç³»ç»Ÿæ—¥å¿— /var/log/messages**** æ˜¾ç¤ºåªæœ‰å¦‚ä¸‹ä¸¤ç§ä¿¡æ¯ä¸ºæ­£å¸¸ ****ï¼Œå®‰è£… calico åå³å¯æ¢å¤&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Unable to update cni config: no networks found in /etc/cni/net.d
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://imgse.com/i/pE2ZkVK&#34;&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://s21.ax1x.com/2025/04/10/pE2ZkVK.png&#34; alt=&#34;pE2ZkVK.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;å¦‚æœæœ‰å¾ˆå¤šæŠ¥é”™æ—¥å¿—ï¼Œæˆ–è€…æœ‰å¤§é‡çœ‹ä¸æ‡‚çš„æŠ¥é”™ï¼Œè¯´æ˜ kubelet çš„é…ç½®æœ‰è¯¯ï¼Œéœ€è¦æ£€æŸ¥ kubelet é…ç½®&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Master01 æŸ¥çœ‹é›†ç¾¤çŠ¶æ€ (Ready æˆ– NotReady éƒ½æ­£å¸¸)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 bootstrap]# kubectl get node
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;83-kube-proxyé…ç½®&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#83-kube-proxyé…ç½®&#34;&gt;#&lt;/a&gt; 8.3 kube-proxy é…ç½®&lt;/h5&gt;
&lt;p&gt;&lt;em&gt;æ³¨æ„ï¼Œå¦‚æœä¸æ˜¯é«˜å¯ç”¨é›†ç¾¤ï¼Œ192.168.1.70:8443 æ”¹ä¸º master01 çš„åœ°å€ï¼Œ8443 æ”¹ä¸º apiserver çš„ç«¯å£ï¼Œé»˜è®¤æ˜¯ 6443&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;ç”Ÿæˆ kube-proxy çš„è¯ä¹¦ï¼Œä»¥ä¸‹æ“ä½œåªåœ¨&lt;mark&gt; Master01&lt;/mark&gt; æ‰§è¡Œ&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd /root/k8s-ha-install/pki
cfssl gencert \
   -ca=/etc/kubernetes/pki/ca.pem \
   -ca-key=/etc/kubernetes/pki/ca-key.pem \
   -config=ca-config.json \
   -profile=kubernetes \
   kube-proxy-csr.json | cfssljson -bare /etc/kubernetes/pki/kube-proxy

kubectl config set-cluster kubernetes \
     --certificate-authority=/etc/kubernetes/pki/ca.pem \
     --embed-certs=true \
     --server=https://192.168.1.70:8443 \
     --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig


kubectl config set-credentials system:kube-proxy \
     --client-certificate=/etc/kubernetes/pki/kube-proxy.pem \
     --client-key=/etc/kubernetes/pki/kube-proxy-key.pem \
     --embed-certs=true \
     --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig

kubectl config set-context system:kube-proxy@kubernetes \
     --cluster=kubernetes \
     --user=system:kube-proxy \
     --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig


kubectl config use-context system:kube-proxy@kubernetes \
     --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å°† kubeconfig å‘é€è‡³å…¶ä»–èŠ‚ç‚¹&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;for NODE in k8s-master02 k8s-master03; do
     scp /etc/kubernetes/kube-proxy.kubeconfig  $NODE:/etc/kubernetes/kube-proxy.kubeconfig
 done

for NODE in k8s-node01 k8s-node02; do
     scp /etc/kubernetes/kube-proxy.kubeconfig $NODE:/etc/kubernetes/kube-proxy.kubeconfig
 done
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;æ·»åŠ  kube-proxy çš„é…ç½®å’Œ service æ–‡ä»¶ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vim /usr/lib/systemd/system/kube-proxy.service

[Unit]
Description=Kubernetes Kube Proxy
Documentation=https://github.com/kubernetes/kubernetes
After=network.target

[Service]
ExecStart=/usr/local/bin/kube-proxy \
  --config=/etc/kubernetes/kube-proxy.yaml \
  --v=2

Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å¦‚æœæ›´æ”¹äº†é›†ç¾¤ Pod çš„ç½‘æ®µï¼Œéœ€è¦æ›´æ”¹ kube-proxy.yaml çš„ clusterCIDR ä¸ºè‡ªå·±çš„ Pod ç½‘æ®µï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vim /etc/kubernetes/kube-proxy.yaml

apiVersion: kubeproxy.config.k8s.io/v1alpha1
bindAddress: 0.0.0.0
clientConnection:
  acceptContentTypes: &amp;quot;&amp;quot;
  burst: 10
  contentType: application/vnd.kubernetes.protobuf
  kubeconfig: /etc/kubernetes/kube-proxy.kubeconfig
  qps: 5
clusterCIDR: 172.16.0.0/16 
configSyncPeriod: 15m0s
conntrack:
  max: null
  maxPerCore: 32768
  min: 131072
  tcpCloseWaitTimeout: 1h0m0s
  tcpEstablishedTimeout: 24h0m0s
enableProfiling: false
healthzBindAddress: 0.0.0.0:10256
hostnameOverride: &amp;quot;&amp;quot;
iptables:
  masqueradeAll: false
  masqueradeBit: 14
  minSyncPeriod: 0s
  syncPeriod: 30s
ipvs:
  masqueradeAll: true
  minSyncPeriod: 5s
  scheduler: &amp;quot;rr&amp;quot;
  syncPeriod: 30s
kind: KubeProxyConfiguration
metricsBindAddress: 127.0.0.1:10249
mode: &amp;quot;ipvs&amp;quot;
nodePortAddresses: null
oomScoreAdj: -999
portRange: &amp;quot;&amp;quot;
udpIdleTimeout: 250ms
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;å¯åŠ¨ kube-proxy&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 k8s-ha-install]# systemctl daemon-reload
[root@k8s-master01 k8s-ha-install]# systemctl enable --now kube-proxy
Created symlink /etc/systemd/system/multi-user.target.wants/kube-proxy.service â†’ /usr/lib/systemd/system/kube-proxy.service.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æ­¤æ—¶ç³»ç»Ÿæ—¥å¿— /var/log/messages**** æ˜¾ç¤ºåªæœ‰å¦‚ä¸‹ä¸¤ç§ä¿¡æ¯ä¸ºæ­£å¸¸ ****ï¼Œå®‰è£… calico åå³å¯æ¢å¤&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Unable to update cni config: no networks found in /etc/cni/net.d
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://imgse.com/i/pE2ZkVK&#34;&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://s21.ax1x.com/2025/04/10/pE2ZkVK.png&#34; alt=&#34;pE2ZkVK.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;9-calicoç»„ä»¶çš„å®‰è£…&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#9-calicoç»„ä»¶çš„å®‰è£…&#34;&gt;#&lt;/a&gt; 9. Calico ç»„ä»¶çš„å®‰è£…&lt;/h4&gt;
&lt;p&gt;ä»¥ä¸‹æ­¥éª¤åªåœ¨ master01 æ‰§è¡Œï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd /root/k8s-ha-install/calico/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æ›´æ”¹ calico çš„ç½‘æ®µï¼Œä¸»è¦éœ€è¦å°†çº¢è‰²éƒ¨åˆ†çš„ç½‘æ®µï¼Œæ”¹ä¸ºè‡ªå·±çš„ Pod ç½‘æ®µ&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sed -i &amp;quot;s#POD_CIDR#172.16.0.0/16#g&amp;quot; calico.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;æ£€æŸ¥ç½‘æ®µæ˜¯è‡ªå·±çš„ Pod ç½‘æ®µï¼Œ grep &amp;quot;IPV4POOL_CIDR&amp;quot; calico.yaml  -A 1&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;æŸ¥çœ‹å®¹å™¨å’ŒèŠ‚ç‚¹çŠ¶æ€ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 calico]# kubectl get po -n kube-system
NAME                                       READY   STATUS    RESTARTS      AGE
calico-kube-controllers-66686fdb54-mk2g6   1/1     Running   1 (20s ago)   85s
calico-node-8fxqp                          1/1     Running   0             85s
calico-node-8nkfl                          1/1     Running   0             86s
calico-node-pmpf4                          1/1     Running   0             86s
calico-node-vnlk7                          1/1     Running   0             86s
calico-node-xpchb                          1/1     Running   0             85s
calico-typha-67c6dc57d6-259t8              1/1     Running   0             86s
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;å¦‚æœå®¹å™¨çŠ¶æ€å¼‚å¸¸å¯ä»¥ä½¿ç”¨ kubectl describe æˆ–è€… kubectl logs æŸ¥çœ‹å®¹å™¨çš„æ—¥å¿—&lt;/em&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Kubectl logs -f POD_NAME -n kube-system&lt;/li&gt;
&lt;li&gt;Kubectl logs -f POD_NAME -c upgrade-ipam -n kube-system&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;10-å®‰è£…coredns&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#10-å®‰è£…coredns&#34;&gt;#&lt;/a&gt; 10. å®‰è£… CoreDNS&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;cd /root/k8s-ha-install/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å¦‚æœæ›´æ”¹äº† k8s service çš„ç½‘æ®µéœ€è¦å°† coredns çš„ serviceIP æ”¹æˆ k8s service ç½‘æ®µçš„ç¬¬åä¸ª IP&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;COREDNS_SERVICE_IP=`kubectl get svc | grep kubernetes | awk &#39;&amp;#123;print $3&amp;#125;&#39;`0
sed -i &amp;quot;s#KUBEDNS_SERVICE_IP#$&amp;#123;COREDNS_SERVICE_IP&amp;#125;#g&amp;quot; CoreDNS/coredns.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å®‰è£… coredns&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 k8s-ha-install]# kubectl  create -f CoreDNS/coredns.yaml 
serviceaccount/coredns created
clusterrole.rbac.authorization.k8s.io/system:coredns created
clusterrolebinding.rbac.authorization.k8s.io/system:coredns created
configmap/coredns created
deployment.apps/coredns created
service/kube-dns created
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;11-metricséƒ¨ç½²&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#11-metricséƒ¨ç½²&#34;&gt;#&lt;/a&gt; 11. Metrics éƒ¨ç½²&lt;/h4&gt;
&lt;p&gt;åœ¨æ–°ç‰ˆçš„ Kubernetes ä¸­ç³»ç»Ÿèµ„æºçš„é‡‡é›†å‡ä½¿ç”¨ Metrics-serverï¼Œå¯ä»¥é€šè¿‡ Metrics é‡‡é›†èŠ‚ç‚¹å’Œ Pod çš„å†…å­˜ã€ç£ç›˜ã€CPU å’Œç½‘ç»œçš„ä½¿ç”¨ç‡ã€‚&lt;/p&gt;
&lt;p&gt;ä»¥ä¸‹æ“ä½œå‡åœ¨&lt;mark&gt; master01 èŠ‚ç‚¹&lt;/mark&gt;æ‰§è¡Œï¼Œå®‰è£… metrics server:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd /root/k8s-ha-install/metrics-server
kubectl  create -f . 

serviceaccount/metrics-server created
clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created
clusterrole.rbac.authorization.k8s.io/system:metrics-server created
rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created
clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created
clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created
service/metrics-server created
deployment.apps/metrics-server created
apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ç­‰å¾… metrics server å¯åŠ¨ç„¶åæŸ¥çœ‹çŠ¶æ€ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# kubectl  top node
NAME           CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   
k8s-master01   231m         5%     1620Mi          42%       
k8s-master02   274m         6%     1203Mi          31%       
k8s-master03   202m         5%     1251Mi          32%       
k8s-node01     69m          1%     667Mi           17%       
k8s-node02     73m          1%     650Mi           16%
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å¦‚æœæœ‰å¦‚ä¸‹æŠ¥é”™ï¼Œå¯ä»¥ç­‰å¾… 10 åˆ†é’Ÿåï¼Œå†æ¬¡æŸ¥çœ‹ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Error from server (ServiceUnavailable): the server is currently unable to handle the request (get nodes.metrics.k8s.io)
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;12-dashboardéƒ¨ç½²&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#12-dashboardéƒ¨ç½²&#34;&gt;#&lt;/a&gt; 12. Dashboard éƒ¨ç½²&lt;/h4&gt;
&lt;h5 id=&#34;121-å®‰è£…dashboard&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#121-å®‰è£…dashboard&#34;&gt;#&lt;/a&gt; 12.1 å®‰è£… Dashboard&lt;/h5&gt;
&lt;p&gt;Dashboard ç”¨äºå±•ç¤ºé›†ç¾¤ä¸­çš„å„ç±»èµ„æºï¼ŒåŒæ—¶ä¹Ÿå¯ä»¥é€šè¿‡ Dashboard å®æ—¶æŸ¥çœ‹ Pod çš„æ—¥å¿—å’Œåœ¨å®¹å™¨ä¸­æ‰§è¡Œä¸€äº›å‘½ä»¤ç­‰ã€‚&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd /root/k8s-ha-install/dashboard/

[root@k8s-master01 dashboard]# kubectl  create -f .
serviceaccount/admin-user created
clusterrolebinding.rbac.authorization.k8s.io/admin-user created
namespace/kubernetes-dashboard created
serviceaccount/kubernetes-dashboard created
service/kubernetes-dashboard created
secret/kubernetes-dashboard-certs created
secret/kubernetes-dashboard-csrf created
secret/kubernetes-dashboard-key-holder created
configmap/kubernetes-dashboard-settings created
role.rbac.authorization.k8s.io/kubernetes-dashboard created
clusterrole.rbac.authorization.k8s.io/kubernetes-dashboard created
rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created
clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created
deployment.apps/kubernetes-dashboard created
service/dashboard-metrics-scraper created
deployment.apps/dashboard-metrics-scraper created
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;122-ç™»å½•dashboard&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#122-ç™»å½•dashboard&#34;&gt;#&lt;/a&gt; 12.2 ç™»å½• dashboard&lt;/h5&gt;
&lt;p&gt;åœ¨è°·æ­Œæµè§ˆå™¨ï¼ˆChromeï¼‰å¯åŠ¨æ–‡ä»¶ä¸­åŠ å…¥å¯åŠ¨å‚æ•°ï¼Œç”¨äºè§£å†³æ— æ³•è®¿é—® Dashboard çš„é—®é¢˜ï¼Œå‚è€ƒä¸‹å›¾ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--test-type --ignore-certificate-errors
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://imgse.com/i/pEgWfHJ&#34;&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://s21.ax1x.com/2025/04/09/pEgWfHJ.png&#34; alt=&#34;pEgWfHJ.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;æ›´æ”¹ dashboard çš„ svc ä¸º NodePort:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl edit svc kubernetes-dashboard -n kubernetes-dashboard
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://imgse.com/i/pEgW5NR&#34;&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://s21.ax1x.com/2025/04/09/pEgW5NR.png&#34; alt=&#34;pEgW5NR.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;å°† ClusterIP æ›´æ”¹ä¸º NodePortï¼ˆå¦‚æœå·²ç»ä¸º NodePort å¿½ç•¥æ­¤æ­¥éª¤ï¼‰&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;æŸ¥çœ‹ç«¯å£å·ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# kubectl get svc kubernetes-dashboard -n kubernetes-dashboard
NAME                   TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)         AGE
kubernetes-dashboard   NodePort   10.96.139.11   &amp;lt;none&amp;gt;        443:32409/TCP   24h
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æ ¹æ®è‡ªå·±çš„å®ä¾‹ç«¯å£å·ï¼Œé€šè¿‡ä»»æ„å®‰è£…äº† kube-proxy çš„å®¿ä¸»æœºçš„ IP + ç«¯å£å³å¯è®¿é—®åˆ° dashboardï¼š&lt;/p&gt;
&lt;p&gt;è®¿é—® Dashboardï¼š&lt;a href=&#34;https://192.168.181.129:31106&#34;&gt;https://192.168.1.71:32409&lt;/a&gt; ï¼ˆæŠŠ IP åœ°å€å’Œç«¯å£æ”¹æˆä½ è‡ªå·±çš„ï¼‰é€‰æ‹©ç™»å½•æ–¹å¼ä¸ºä»¤ç‰Œï¼ˆå³ token æ–¹å¼ï¼‰ï¼Œå‚è€ƒä¸‹å›¾ï¼š&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://imgse.com/i/pEgW736&#34;&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://s21.ax1x.com/2025/04/09/pEgW736.png&#34; alt=&#34;pEgW736.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;åˆ›å»ºç™»å½• Tokenï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl create token admin-user -n kube-system
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å°† token å€¼è¾“å…¥åˆ°ä»¤ç‰Œåï¼Œå•å‡»ç™»å½•å³å¯è®¿é—® Dashboardï¼Œå‚è€ƒä¸‹å›¾ï¼š&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://imgse.com/i/pEgfPv8&#34;&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://s21.ax1x.com/2025/04/09/pEgfPv8.png&#34; alt=&#34;pEgfPv8.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;14-containerdé…ç½®é•œåƒåŠ é€Ÿ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#14-containerdé…ç½®é•œåƒåŠ é€Ÿ&#34;&gt;#&lt;/a&gt; 14. Containerd é…ç½®é•œåƒåŠ é€Ÿ&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;# vim /etc/containerd/config.toml
#æ·»åŠ ä»¥ä¸‹é…ç½®é•œåƒåŠ é€ŸæœåŠ¡
       [plugins.&amp;quot;io.containerd.grpc.v1.cri&amp;quot;.registry.mirrors.&amp;quot;docker.io&amp;quot;]
        endpoint=[&amp;quot;https://dockerproxy.com&amp;quot;, &amp;quot;https://mirror.baidubce.com&amp;quot;,&amp;quot;https://ccr.ccs.tencentyun.com&amp;quot;,&amp;quot;https://docker.m.daocloud.io&amp;quot;,&amp;quot;https://docker.nju.edu.cn&amp;quot;,&amp;quot;https://docker.mirrors.ustc.edu.cn&amp;quot;,&amp;quot;https://registry-1.docker.io&amp;quot;, &amp;quot;https://hbv0b596.mirror.aliyuncs.com&amp;quot;]
       [plugins.&amp;quot;io.containerd.grpc.v1.cri&amp;quot;.registry.mirrors.&amp;quot;registry.k8s.io&amp;quot;]
        endpoint=[&amp;quot;https://dockerproxy.com&amp;quot;, &amp;quot;https://mirror.baidubce.com&amp;quot;,&amp;quot;https://ccr.ccs.tencentyun.com&amp;quot;,&amp;quot;https://docker.m.daocloud.io&amp;quot;,&amp;quot;https://docker.nju.edu.cn&amp;quot;,&amp;quot;https://docker.mirrors.ustc.edu.cn&amp;quot;,&amp;quot;https://hbv0b596.mirror.aliyuncs.com&amp;quot;, &amp;quot;https://k8s.m.daocloud.io&amp;quot;, &amp;quot;https://docker.mirrors.ustc.edu.cn&amp;quot;,&amp;quot;https://hub-mirror.c.163.com&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æ‰€æœ‰èŠ‚ç‚¹é‡æ–°å¯åŠ¨ Containerdï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# systemctl daemon-reload
# systemctl restart containerd
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;15-dockeré…ç½®é•œåƒåŠ é€Ÿ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#15-dockeré…ç½®é•œåƒåŠ é€Ÿ&#34;&gt;#&lt;/a&gt; 15. Docker é…ç½®é•œåƒåŠ é€Ÿ&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;# sudo mkdir -p /etc/docker
# sudo tee /etc/docker/daemon.json &amp;lt;&amp;lt;-&#39;EOF&#39;
&amp;#123;
  &amp;quot;registry-mirrors&amp;quot;: [
	  &amp;quot;https://docker.credclouds.com&amp;quot;,
	  &amp;quot;https://k8s.credclouds.com&amp;quot;,
	  &amp;quot;https://quay.credclouds.com&amp;quot;,
	  &amp;quot;https://gcr.credclouds.com&amp;quot;,
	  &amp;quot;https://k8s-gcr.credclouds.com&amp;quot;,
	  &amp;quot;https://ghcr.credclouds.com&amp;quot;,
	  &amp;quot;https://do.nark.eu.org&amp;quot;,
	  &amp;quot;https://docker.m.daocloud.io&amp;quot;,
	  &amp;quot;https://docker.nju.edu.cn&amp;quot;,
	  &amp;quot;https://docker.mirrors.sjtug.sjtu.edu.cn&amp;quot;,
	  &amp;quot;https://docker.1panel.live&amp;quot;,
	  &amp;quot;https://docker.rainbond.cc&amp;quot;
  ], 
  &amp;quot;exec-opts&amp;quot;: [&amp;quot;native.cgroupdriver=systemd&amp;quot;] 
&amp;#125;
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æ‰€æœ‰èŠ‚ç‚¹é‡æ–°å¯åŠ¨ Dockerï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# systemctl daemon-reload
# systemctl enable --now docker
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;æœ¬æ–‡å‡ºè‡ªäºï¼š&lt;a href=&#34;https://edu.51cto.com/course/23845.html&#34;&gt;https://edu.51cto.com/course/23845.html&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</content>
        <category term="Kubernetes" />
        <updated>2025-04-10T12:58:40.000Z</updated>
    </entry>
    <entry>
        <id>http://ixuyong.cn/posts/2628187572.html</id>
        <title>MySQLè¿ç»´DBAåº”ç”¨ä¸å®è·µ</title>
        <link rel="alternate" href="http://ixuyong.cn/posts/2628187572.html"/>
        <content type="html">&lt;h3 id=&#34;mysqlè¿ç»´dbaåº”ç”¨ä¸å®è·µ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#mysqlè¿ç»´dbaåº”ç”¨ä¸å®è·µ&#34;&gt;#&lt;/a&gt; MySQL è¿ç»´ DBA åº”ç”¨ä¸å®è·µ&lt;/h3&gt;
&lt;h4 id=&#34;1æ—¥å¿—&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1æ—¥å¿—&#34;&gt;#&lt;/a&gt; 1. æ—¥å¿—&lt;/h4&gt;
&lt;p&gt;åœ¨ä»»ä½•ä¸€ç§æ•°æ®åº“ä¸­ï¼Œéƒ½ä¼šæœ‰å„ç§å„æ ·çš„æ—¥å¿—ï¼Œè¿™äº›æ—¥å¿—è®°å½•äº†æ•°æ®åº“è¿è¡Œçš„å„ä¸ªæ–¹é¢ã€‚å¯ä»¥å¸®åŠ©æ•°æ®åº“ç®¡ç†å‘˜è¿½è¸ªæ•°æ®åº“æ›¾ç»å‘ç”Ÿçš„ä¸€äº›äº‹æƒ…ã€‚&lt;/p&gt;
&lt;p&gt;å¯¹äº MySQL æ•°æ®åº“ï¼Œæä¾›äº†å››ç§ä¸åŒçš„æ—¥å¿—å¸®åŠ©æˆ‘ä»¬è¿½è¸ªã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;é”™è¯¯æ—¥å¿—&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;äºŒè¿›åˆ¶æ—¥å¿—&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;æŸ¥è¯¢æ—¥å¿—&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;æ…¢æŸ¥è¯¢æ—¥å¿—&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;11-é”™è¯¯æ—¥å¿—&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#11-é”™è¯¯æ—¥å¿—&#34;&gt;#&lt;/a&gt; 1.1 é”™è¯¯æ—¥å¿—&lt;/h5&gt;
&lt;p&gt;é”™è¯¯æ—¥å¿—æ˜¯ MySQL ä¸­æœ€é‡è¦çš„æ—¥å¿—ä¹‹ä¸€ï¼Œå®ƒè®°å½•äº†å½“ mysqld (MySQL æœåŠ¡) å¯åŠ¨å’Œåœæ­¢æ—¶ï¼Œä»¥åŠæœåŠ¡å™¨åœ¨è¿è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿä»»ä½•ä¸¥é‡é”™è¯¯æ—¶çš„ç›¸å…³ä¿¡æ¯ã€‚å½“æ•°æ®åº“å‡ºç°ä»»ä½•æ•…éšœå¯¼è‡´æ— æ³•æ­£å¸¸ä½¿ç”¨æ—¶ï¼Œå»ºè®®é¦–å…ˆæŸ¥çœ‹æ­¤æ—¥å¿—ã€‚&lt;/p&gt;
&lt;p&gt;è¯¥æ—¥å¿—æ˜¯é»˜è®¤å¼€å¯çš„ï¼Œé»˜è®¤å­˜æ”¾ç›®å½• /var/log/ï¼Œé»˜è®¤çš„æ—¥å¿—æ–‡ä»¶åä¸º mysqld.logã€‚æŸ¥çœ‹æ—¥å¿—ä½ç½®ï¼›&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; show variables like &#39;%log_error%&#39;;
+---------------------+---------------------+
| Variable_name       | Value               |
+---------------------+---------------------+
| binlog_error_action | ABORT_SERVER        |
| log_error           | /var/log/mysqld.log |
| log_error_verbosity | 3                   |
+---------------------+---------------------+
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;12-äºŒè¿›åˆ¶æ—¥å¿—&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#12-äºŒè¿›åˆ¶æ—¥å¿—&#34;&gt;#&lt;/a&gt; 1.2 äºŒè¿›åˆ¶æ—¥å¿—&lt;/h5&gt;
&lt;p&gt;äºŒè¿›åˆ¶æ—¥å¿— (BINLOG) è®°å½•äº†æ‰€æœ‰çš„ DDL (æ•°æ®å®šä¹‰è¯­è¨€) è¯­å¥å’Œ DML (æ•°æ®æ“çºµè¯­è¨€) è¯­å¥ï¼Œä½†ä¸åŒ…æ‹¬æ•°æ®æŸ¥è¯¢ï¼ˆSELECTã€ SHOWï¼‰è¯­å¥ã€‚&lt;/p&gt;
&lt;p&gt;ä½œç”¨:&lt;/p&gt;
&lt;p&gt;â‘ . ç¾éš¾æ—¶çš„æ•°æ®æ¢å¤ï¼›&lt;/p&gt;
&lt;p&gt;â‘¡. MySQL çš„ä¸»ä»å¤åˆ¶ã€‚&lt;/p&gt;
&lt;p&gt;åœ¨ MySQL5.7 ç‰ˆæœ¬ä¸­ï¼Œé»˜è®¤äºŒè¿›åˆ¶æ—¥å¿—æ˜¯å…³é—­ç€çš„ï¼Œæ¶‰åŠåˆ°çš„å‚æ•°å¦‚ä¸‹:&lt;/p&gt;
&lt;h6 id=&#34;121-å¼€å¯-bin-logè®°å½•&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#121-å¼€å¯-bin-logè®°å½•&#34;&gt;#&lt;/a&gt; 1.2.1 å¼€å¯ bin-log è®°å½•&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;1.1æ”¹ä¿®é…ç½®æ–‡ä»¶
[root@db01 ~]# vim /etc/my.cnf
server-id=1
log-bin=mysql-bin
max_binlog_size=500M
expire_logs_days=15

1.2æŸ¥çœ‹æ˜¯å¦å¼€å¯binlog.
mysql&amp;gt; show variables like &#39;log_%&#39;;
+----------------------------------------+--------------------------------+
| Variable_name                          | Value                          |
+----------------------------------------+--------------------------------+
| log_bin                                | ON                             |
| log_bin_basename                       | /var/lib/mysql/mysql-bin       |
| log_bin_index                          | /var/lib/mysql/mysql-bin.index |
| log_bin_trust_function_creators        | OFF                            |
| log_bin_use_v1_row_events              | OFF                            |
| log_builtin_as_identified_by_password  | OFF                            |
| log_error                              | /var/log/mysqld.log            |
| log_error_verbosity                    | 3                              |
| log_output                             | FILE                           |
| log_queries_not_using_indexes          | OFF                            |
| log_slave_updates                      | OFF                            |
| log_slow_admin_statements              | OFF                            |
| log_slow_slave_statements              | OFF                            |
| log_statements_unsafe_for_binlog       | ON                             |
| log_syslog                             | OFF                            |
| log_syslog_facility                    | daemon                         |
| log_syslog_include_pid                 | ON                             |
| log_syslog_tag                         |                                |
| log_throttle_queries_not_using_indexes | 0                              |
| log_timestamps                         | UTC                            |
| log_warnings                           | 2                              |
+----------------------------------------+--------------------------------+

1.3æŸ¥çœ‹binlog
mysql&amp;gt; show binary logs;
+------------------+-----------+
| Log_name         | File_size |
+------------------+-----------+
| mysql-bin.000001 |     36825 |
| mysql-bin.000002 |    200464 |
| mysql-bin.000003 |    419809 |
+------------------+-----------+

1.4æŸ¥çœ‹binlogæ—¥å¿—ä¿å­˜å¤©æ•° 
# 0è¡¨ç¤ºæ°¸ä¹…ä¿ç•™ï¼Œexpire_logs_daysï¼šä¿ç•™æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„binlogå†å²æ—¥å¿—ï¼Œä¸Šç¤ºä¾‹è®¾ç½®çš„15å¤©å†…
mysql&amp;gt; show variables like &#39;expire_logs_days&#39;;
+------------------+-------+
| Variable_name    | Value |
+------------------+-------+
| expire_logs_days | 15    |
+------------------+-------+
1 row in set (0.00 sec)

1.5æŸ¥çœ‹binlogæ—¥å¿—ä¿å­˜å¤§å°
#max_binlog_sizeï¼šbin logæ—¥å¿—æ¯è¾¾åˆ°è®¾å®šå¤§å°åï¼Œä¼šä½¿ç”¨æ–°çš„bin logæ—¥å¿—ã€‚å¦‚mysql-bin.000002è¾¾åˆ°500Måï¼Œåˆ›å»ºå¹¶ä½¿ç”¨mysql-bin.000003æ–‡ä»¶ä½œä¸ºæ—¥å¿—è®°å½•ã€‚
mysql&amp;gt; show variables like &#39;max_binlog_size&#39;;
+-----------------+-----------+
| Variable_name   | Value     |
+-----------------+-----------+
| max_binlog_size | 524288000 |
+-----------------+-----------+

1.6æ‰‹åŠ¨æ‰§è¡Œflush logs
#å°†ä¼šnewä¸€ä¸ªæ–°æ–‡ä»¶ç”¨äºè®°å½•binlog
mysql&amp;gt; flush logs;

1.7æ‰‹åŠ¨æ¸…ç†binlog
#å°†mysql-bin.000010ä¹‹å‰çš„æ—¥å¿—æ¸…ç†æ‰
mysql&amp;gt; purge binary logs to &#39;mysql-bin.000010&#39;;
Query OK, 0 rows affected (0.01 sec)

#åˆ é™¤2022-04-21 18:08:00ä¹‹å‰çš„binlogæ—¥å¿—
mysql&amp;gt; purge binary logs before &#39;2022-04-21 18:08:00&#39;;

#æ¸…é™¤å…¨éƒ¨binlog
mysql&amp;gt; reset master;
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;122-æ—¥å¿—æ ¼å¼&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#122-æ—¥å¿—æ ¼å¼&#34;&gt;#&lt;/a&gt; &lt;strong&gt;1.2.2 æ—¥å¿—æ ¼å¼&lt;/strong&gt;&lt;/h6&gt;
&lt;p&gt;MySQL æœåŠ¡å™¨ä¸­æä¾›äº†å¤šç§æ ¼å¼æ¥è®°å½•äºŒè¿›åˆ¶æ—¥å¿—ï¼Œå…·ä½“æ ¼å¼åŠç‰¹ç‚¹å¦‚ä¸‹ï¼š&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;æ—¥å¿—æ ¼å¼&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;å«ä¹‰&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;STATEMENT&lt;/td&gt;
&lt;td&gt;åŸºäº SQL è¯­å¥çš„æ—¥å¿—è®°å½•ï¼Œè®°å½•çš„æ˜¯ SQL è¯­å¥ï¼Œå¯¹æ•°æ®è¿›è¡Œä¿®æ”¹çš„ SQL éƒ½ä¼šè®°å½•åœ¨æ—¥å¿—æ–‡ä»¶ä¸­ã€‚&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ROW&lt;/td&gt;
&lt;td&gt;åŸºäºè¡Œçš„æ—¥å¿—è®°å½•ï¼Œè®°å½•çš„æ˜¯æ¯ä¸€è¡Œçš„æ•°æ®å˜æ›´ã€‚(é»˜è®¤)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MIXED&lt;/td&gt;
&lt;td&gt;æ··åˆäº† STATEMENT å’Œ ROW ä¸¤ç§æ ¼å¼ï¼Œé»˜è®¤é‡‡ç”¨ STATEMENT, åœ¨æŸäº›ç‰¹æ®Šæƒ…å†µä¸‹ä¼šè‡ªåŠ¨åˆ‡æ¢ä¸º ROW è¿›è¡Œè®°å½•ã€‚&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; show variables like &#39;binlog_format&#39;;
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| binlog_format | ROW   |
+---------------+-------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ç”±äºæ—¥å¿—æ˜¯ä»¥äºŒè¿›åˆ¶æ–¹å¼å­˜å‚¨çš„ï¼Œä¸èƒ½ç›´æ¥è¯»å–ï¼Œéœ€è¦é€šè¿‡äºŒè¿›åˆ¶æ—¥å¿—æŸ¥è¯¢å·¥å…· &lt;code&gt;mysqlbinlog&lt;/code&gt;  æ¥æŸ¥çœ‹ï¼Œå…·ä½“è¯­æ³•:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysqlbinlog [ å‚æ•°é€‰é¡¹] logfilename
å‚æ•°é€‰é¡¹:
	-d			æŒ‡å®šæ•°æ®åº“åç§°ï¼Œåªåˆ—å‡ºæŒ‡å®šçš„æ•°æ®åº“ç›¸å…³æ“ä½œã€‚
	-o			å¿½ç•¥æ‰æ—¥å¿—ä¸­çš„å‰nè¡Œå‘½ä»¤ã€‚
	-v			å°†è¡Œäº‹ä»¶(æ•°æ®å˜æ›´)é‡æ„ä¸ºSQLè¯­å¥
	-vv			å°†è¡Œäº‹ä»¶(æ•°æ®å˜æ›´)é‡æ„ä¸ºSQLè¯­å¥ï¼Œå¹¶è¾“å‡ºæ³¨é‡Šä¿¡æ¯
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; use zh;
Database changed
mysql&amp;gt; show tables;
+----------------+
| Tables_in_zh   |
+----------------+
| account        |
| course         |
| dept           |
| emp            |
| score          |
| student        |
| student_course |
| tb_user        |
| tb_user_edu    |
| user           |
| user1          |
+----------------+
11 rows in set (0.00 sec)

mysql&amp;gt;  update tb_user_edu set university = &amp;quot;åŒ—äº¬å¤§å­¦&amp;quot;;
Query OK, 4 rows affected (0.00 sec)
Rows matched: 4  Changed: 4  Warnings: 0

#äºŒè¿›åˆ¶æ—¥å¿—æŸ¥çœ‹
[root@db01 ~]# mysqlbinlog -v /var/lib/mysql/mysql-bin.000001 
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;123-ä¿®æ”¹binlogæ ¼å¼&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#123-ä¿®æ”¹binlogæ ¼å¼&#34;&gt;#&lt;/a&gt; 1.2.3 ä¿®æ”¹ binlog æ ¼å¼&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;[root@db01 ~]# vim /etc/my.cnf
...
binlog_format=STATEMENT
...
[root@db01 ~]# systemctl restart mysqld

mysql&amp;gt;  update tb_user_edu set university = &#39;æ¸…åå¤§å­¦&#39;;
[root@db01 ~]# mysqlbinlog -v /var/lib/mysql/mysql-bin.000002 
...
SET TIMESTAMP=1701440373/*!*/;
update tb_user_edu set university = &#39;æ¸…åå¤§å­¦&#39;
...
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;13-æŸ¥è¯¢æ—¥å¿—&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#13-æŸ¥è¯¢æ—¥å¿—&#34;&gt;#&lt;/a&gt; 1.3 æŸ¥è¯¢æ—¥å¿—&lt;/h5&gt;
&lt;p&gt;æŸ¥è¯¢æ—¥å¿—ä¸­è®°å½•äº†å®¢æˆ·ç«¯çš„æ‰€æœ‰æ“ä½œè¯­å¥ï¼Œè€ŒäºŒè¿›åˆ¶æ—¥å¿—ä¸åŒ…å«æŸ¥è¯¢æ•°æ®çš„ SQL è¯­å¥ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œ&lt;strong&gt;æŸ¥è¯¢æ—¥å¿—æ˜¯æœªå¼€å¯çš„&lt;/strong&gt;ã€‚å¦‚æœéœ€è¦å¼€å¯æŸ¥è¯¢æ—¥å¿—ï¼Œå¯ä»¥è®¾ç½®ä»¥ä¸‹é…ç½®ï¸°&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; show variables like &#39;%general%&#39;;
+------------------+-------------------------+
| Variable_name    | Value                   |
+------------------+-------------------------+
| general_log      | OFF                     |
| general_log_file | /var/lib/mysql/db01.log |
+------------------+-------------------------+
2 rows in set (0.00 sec)

#å¼€å¯æŸ¥è¯¢æ—¥å¿—åŠŸèƒ½
[root@db01 ~]# cat /etc/my.cnf
general_log=1
general_log_file=/var/lib/mysql/mysql_query.log 
[root@db01 ~]# systemctl restart mysqld

[root@db01 ~]# tail -f /var/lib/mysql/mysql_query.log 
2023-12-01T14:31:28.554384Z	    2 Field List	student 
2023-12-01T14:31:28.554743Z	    2 Field List	student_course 
2023-12-01T14:31:35.737041Z	    2 Query	show variables like &#39;%general%&#39;
2023-12-01T14:31:37.345179Z	    2 Query	show variables like &#39;%general%&#39;
2023-12-01T14:32:17.593471Z	    2 Query	SELECT DATABASE()
2023-12-01T14:32:17.593651Z	    2 Init DB	zh
2023-12-01T14:32:25.249258Z	    2 Query	select * from emp
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;14-æ…¢æŸ¥è¯¢æ—¥å¿—&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#14-æ…¢æŸ¥è¯¢æ—¥å¿—&#34;&gt;#&lt;/a&gt; 1.4 æ…¢æŸ¥è¯¢æ—¥å¿—&lt;/h5&gt;
&lt;p&gt;æ…¢æŸ¥è¯¢&lt;a href=&#34;https://so.csdn.net/so/search?q=%E6%97%A5%E5%BF%97%E8%AE%B0%E5%BD%95&amp;amp;spm=1001.2101.3001.7020&#34;&gt;æ—¥å¿—è®°å½•&lt;/a&gt;äº†æ‰€æœ‰æ‰§è¡Œæ—¶é—´è¶…è¿‡å‚æ•° &lt;code&gt;long_ query_time&lt;/code&gt;  è®¾ç½®å€¼å¹¶ä¸”æ‰«æè®°å½•æ•°ä¸å°äº &lt;code&gt;min_examined_row_limit&lt;/code&gt;  çš„æ‰€æœ‰çš„ SQL è¯­å¥çš„æ—¥å¿—ï¼Œé»˜è®¤æœªå¼€å¯ã€‚&lt;strong&gt; &lt;code&gt;long_query_time&lt;/code&gt;  é»˜è®¤ä¸º 10 ç§’ï¼Œæœ€å°ä¸º 0ï¼Œç²¾åº¦å¯ä»¥åˆ°å¾®ç§’ã€‚&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@db01 ~]# vim /etc/my.cnf
#æ…¢æŸ¥è¯¢æ—¥å¿—
slow_query_log=on
##æ‰§è¡Œæ—¶é—´å‚æ•°
long_query_time=2
# è‹¥æ²¡æœ‰æŒ‡å®šï¼Œé»˜è®¤åå­—ä¸ºhostname_slow.log
slow_query_log_file = /var/lib/mysql/slow-query.log
[root@db01 ~]# systemctl restart mysqld

#åˆ¶é€ æ…¢æŸ¥è¯¢å¹¶æ‰§è¡Œ
mysql&amp;gt; select sleep(3);
[root@db01 ~]# tail -f /var/lib/mysql/slow-query.log 
/usr/sbin/mysqld, Version: 5.7.43-log (MySQL Community Server (GPL)). started with:
Tcp port: 0  Unix socket: /var/lib/mysql/mysql.sock
Time                 Id Command    Argument
# Time: 2023-12-01T14:47:57.763735Z
# User@Host: root[root] @ localhost []  Id:     2
# Query_time: 3.001229  Lock_time: 0.000000 Rows_sent: 1  Rows_examined: 0
use zh;
SET timestamp=1701442077;
select sleep(3);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;é»˜è®¤æƒ…å†µä¸‹ï¼Œä¸ä¼šè®°å½•ç®¡ç†è¯­å¥ï¼Œä¹Ÿä¸ä¼šè®°å½•ä¸ä½¿ç”¨ç´¢å¼•è¿›è¡ŒæŸ¥æ‰¾çš„æŸ¥è¯¢ã€‚å¯ä»¥ä½¿ç”¨ &lt;code&gt;log_slow_admin_statements&lt;/code&gt;  å’Œæ›´æ”¹æ­¤è¡Œä¸º &lt;code&gt;log_queries_not_using_indexes&lt;/code&gt; , å¦‚ä¸‹æ‰€è¿°ã€‚&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#è®°å½•æ‰§è¡Œè¾ƒæ…¢çš„ç®¡ç†è¯­å¥
log_slow_admin_statements = 1
#è®°å½•æ‰§è¡Œè¾ƒæ…¢çš„æœªä½¿ç”¨ç´¢å¼•çš„è¯­å¥
log_queries_not_using_indexes = 1
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2-ä¸»ä»å¤åˆ¶&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-ä¸»ä»å¤åˆ¶&#34;&gt;#&lt;/a&gt; 2. ä¸»ä»å¤åˆ¶&lt;/h4&gt;
&lt;h5 id=&#34;21-ä¸»ä»å¤åˆ¶çš„æ¦‚è¿°&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#21-ä¸»ä»å¤åˆ¶çš„æ¦‚è¿°&#34;&gt;#&lt;/a&gt; 2.1 ä¸»ä»å¤åˆ¶çš„æ¦‚è¿°&lt;/h5&gt;
&lt;p&gt;ä¸»ä»å¤åˆ¶æ˜¯æŒ‡å°†&lt;strong&gt;ä¸»æ•°æ®åº“çš„ DDL å’Œ DML æ“ä½œ&lt;/strong&gt;é€šè¿‡&lt;strong&gt;äºŒè¿›åˆ¶æ—¥å¿—&lt;/strong&gt;ä¼ åˆ°&lt;strong&gt;ä»åº“æœåŠ¡å™¨&lt;/strong&gt;ä¸­ï¼Œç„¶ååœ¨ä»åº“ä¸Šå¯¹è¿™äº›æ—¥å¿—é‡æ–°æ‰§è¡Œ (ä¹Ÿå«é‡åš) ï¼Œä»è€Œä½¿å¾—ä»åº“å’Œä¸»åº“çš„æ•°æ®ä¿æŒåŒæ­¥ã€‚&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://imgse.com/i/pEgO0Mj&#34;&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://s21.ax1x.com/2025/04/09/pEgO0Mj.png&#34; alt=&#34;pEgO0Mj.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;MySQL æ”¯æŒä¸€å°ä¸»åº“åŒæ—¶å‘å¤šå°ä»åº“è¿›è¡Œå¤åˆ¶ï¼Œä»åº“åŒæ—¶ä¹Ÿå¯ä»¥ä½œä¸ºå…¶ä»–ä»æœåŠ¡å™¨çš„ä¸»åº“ï¼Œ å®ç°é“¾çŠ¶å¤åˆ¶ã€‚&lt;/p&gt;
&lt;p&gt;MySQL å¤åˆ¶çš„æœ‰ç‚¹ä¸»è¦åŒ…å«ä»¥ä¸‹ä¸‰ä¸ªæ–¹é¢ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;ä¸»åº“å‡ºç°é—®é¢˜ï¼Œå¯ä»¥å¿«é€Ÿåˆ‡æ¢åˆ°ä»åº“æä¾›æœåŠ¡ï¼›&lt;/li&gt;
&lt;li&gt;å®ç°è¯»å†™åˆ†ç¦»ï¼Œé™ä½ä¸»åº“çš„è®¿é—®å‹åŠ›ï¼›ï¼ˆå¦‚æœå¢åˆ æ”¹å¯¹ä¸»åº“ æŸ¥è¯¢å¯¹ä»åº“ï¼‰&lt;/li&gt;
&lt;li&gt;å¯ä»¥åœ¨ä»åº“ä¸­æ‰§è¡Œå¤‡ä»½ï¼Œä»¥é¿å…å¤‡ä»½æœŸé—´å½±å“ä¸»åº“æœåŠ¡ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;22-ä¸»ä»å¤åˆ¶çš„åŸç†&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#22-ä¸»ä»å¤åˆ¶çš„åŸç†&#34;&gt;#&lt;/a&gt; 2.2 ä¸»ä»å¤åˆ¶çš„åŸç†&lt;/h5&gt;
&lt;p&gt;&lt;a href=&#34;https://imgse.com/i/pEgOdzQ&#34;&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://s21.ax1x.com/2025/04/09/pEgOdzQ.png&#34; alt=&#34;pEgOdzQ.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ä»ä¸Šå›¾æ¥çœ‹ï¼Œå¤åˆ¶åˆ†æˆä¸‰æ­¥ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Master ä¸»åº“åœ¨äº‹åŠ¡æäº¤æ—¶ï¼Œä¼šæŠŠæ•°æ®å˜æ›´è®°å½•åœ¨äºŒè¿›åˆ¶æ—¥å¿—æ–‡ä»¶ Binlog ä¸­ã€‚&lt;/li&gt;
&lt;li&gt;ä»åº“ IO çº¿ç¨‹è¯»å–ä¸»åº“çš„äºŒè¿›åˆ¶æ—¥å¿—æ–‡ä»¶ Binlogï¼Œå†™å…¥åˆ°ä»åº“çš„ä¸­ç»§æ—¥å¿— Relay Logã€‚&lt;/li&gt;
&lt;li&gt;slave é‡åšä¸­ç»§æ—¥å¿—ä¸­çš„äº‹ä»¶ï¼ŒSQL çº¿ç¨‹å°†æ”¹å˜åæ˜ å®ƒè‡ªå·±çš„æ•°æ®ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;23-ä¸»ä»å¤åˆ¶çš„æ­å»º&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#23-ä¸»ä»å¤åˆ¶çš„æ­å»º&#34;&gt;#&lt;/a&gt; 2.3 ä¸»ä»å¤åˆ¶çš„æ­å»º&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;ä¸»ä»å¤åˆ¶çš„æ­å»ºæ­¥éª¤&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;å‡†å¤‡ä¸»ä»å¤åˆ¶æœåŠ¡å™¨ç¯å¢ƒ&lt;/li&gt;
&lt;li&gt;å®Œæˆä¸»åº“é…ç½®&lt;/li&gt;
&lt;li&gt;å®Œæˆä»åº“é…ç½®&lt;/li&gt;
&lt;/ol&gt;
&lt;h6 id=&#34;231-æœåŠ¡å™¨å‡†å¤‡&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#231-æœåŠ¡å™¨å‡†å¤‡&#34;&gt;#&lt;/a&gt; 2.3.1 æœåŠ¡å™¨å‡†å¤‡&lt;/h6&gt;
&lt;p&gt;&lt;a href=&#34;https://imgse.com/i/pEgODLn&#34;&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://s21.ax1x.com/2025/04/09/pEgODLn.png&#34; alt=&#34;pEgODLn.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h6 id=&#34;232-ä¸»åº“é…ç½®&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#232-ä¸»åº“é…ç½®&#34;&gt;#&lt;/a&gt; 2.3.2 ä¸»åº“é…ç½®&lt;/h6&gt;
&lt;p&gt;&lt;strong&gt;#1. å®‰è£… MySQL&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#1ã€å…³é—­é˜²ç«å¢™ã€selinuxã€ç¯å¢ƒé…ç½®
[root@db01 ~]# hostnamectl set-hostname db01
[root@db01 ~]# systemctl stop firewalld
[root@db01 ~]# systemctl disable firewalld
[root@db01 ~]# sed -i &#39;s/^SELINUX=enforcing/SELINUX=disabled/g&#39; /etc/sysconfig/selinux
[root@db01 ~]# sed -i &#39;s/^SELINUX=enforcing/SELINUX=disabled/g&#39; /etc/selinux/config
[root@db01 ~]# yum install net-tools vim tree lrzsz wget unzip dos2unix bash-completion  lsof ntp ntpdate git -y
[root@db01 ~]# yum update -y --exclude=kernel* &amp;amp;&amp;amp; reboot
[root@db01 ~]# echo &#39;Asia/Shanghai&#39; &amp;gt;/etc/timezone
[root@db01 ~]# ntpdate time2.aliyun.com
[root@db01 ~]# crontab -e
*/5 * * * * /usr/sbin/ntpdate time2.aliyun.com &amp;amp;&amp;gt; /dev/nul
[root@db01 ~]# mkdir /soft /data /scripts /backup

#2ã€å®‰è£…Mysql5.7
[root@db01 ~]# yum install -y mysql-community-server
[root@db01 ~]# systemctl start mysqld &amp;amp;&amp;amp; systemctl enable mysqld

[root@db01 ~]# mysql -uroot -p$(awk &#39;/temporary password/&amp;#123;print $NF&amp;#125;&#39; /var/log/mysqld.log)
mysql&amp;gt; ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;passwd&#39;;
mysql&amp;gt; grant all on *.* to &#39;root&#39;@&#39;192.168.1.%&#39; identified by &#39;passwd&#39;;

#3ã€å…è®¸rootç”¨æˆ·åœ¨ä»»ä½•åœ°æ–¹è¿›è¡Œè¿œç¨‹ç™»å½•ï¼Œå¹¶å…·æœ‰æ‰€æœ‰åº“ä»»ä½•æ“ä½œæƒé™ï¼Œå…·ä½“æ“ä½œå¦‚ä¸‹ï¼š
mysql -u root -p&amp;quot;youpass&amp;quot;
mysql&amp;gt;GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;passwd&#39; WITH GRANT OPTION;
FLUSH PRIVILEGES;

#4.é…ç½®ä¸»åº“
[root@db01 ~]# vim /etc/my.cnf
server-id=1                #mysqlæœåŠ¡IDï¼Œä¿è¯æ•´ä¸ªé›†ç¾¤ç¯å¢ƒä¸­å”¯ä¸€ï¼Œ å–å€¼èŒƒå›´: 1 - 2^&amp;#123;32&amp;#125;-1
log-bin=mysql-bin          #å¯åŠ¨äºŒè¿›åˆ¶æ—¥å¿—
read-only=0                #æ˜¯å¦åªè¯»,1ä»£è¡¨åªè¯», 0ä»£è¡¨è¯»å†™
#binlog-ignore-db=mysql    #å¿½ç•¥çš„æ•°æ®ï¼ŒæŒ‡ä¸éœ€è¦åŒæ­¥çš„æ•°æ®åº“
#binlog-do-db=db01         #æŒ‡å®šåŒæ­¥çš„æ•°æ®åº“
[root@db01 ~]# systemctl restart mysqld

#5.åˆ›å»ºreplç”¨æˆ·ï¼Œå¹¶è®¾ç½®å¯†ç ï¼Œè¯¥ç”¨æˆ·å¯åœ¨ä»»æ„ä¸»æœºè¿æ¥è¯¥MySQLæœåŠ¡
mysql&amp;gt; grant replication slave on *.* to &#39;repl&#39;@&#39;%&#39; identified by &#39;passwd&#39;;

#6.æŸ¥çœ‹masterä½ç½®ç‚¹
mysql&amp;gt; show master status;        
+------------------+----------+--------------+------------------+-------------------+
| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |
+------------------+----------+--------------+------------------+-------------------+
| mysql-bin.000006 |      889 |              |                  |                   |
+------------------+----------+--------------+------------------+-------------------+
1 row in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;233-ä»åº“é…ç½®&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#233-ä»åº“é…ç½®&#34;&gt;#&lt;/a&gt; 2.3.3 ä»åº“é…ç½®&lt;/h6&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;å‚æ•°å&lt;/th&gt;
&lt;th&gt;å«ä¹‰&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;8.0.23 ä¹‹å‰&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;SOURCE_HOST&lt;/td&gt;
&lt;td&gt;ä¸»åº“ IP åœ°å€&lt;/td&gt;
&lt;td&gt;MASTER_HOST&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SOURCE_USER&lt;/td&gt;
&lt;td&gt;è¿æ¥ä¸»åº“çš„ç”¨æˆ·å&lt;/td&gt;
&lt;td&gt;MASTER_USER&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SOURCE_PASSWORD&lt;/td&gt;
&lt;td&gt;è¿æ¥ä¸»åº“çš„å¯†ç &lt;/td&gt;
&lt;td&gt;MASTER_PASSWORD&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SOURCE_LOG FILE&lt;/td&gt;
&lt;td&gt;binlog æ—¥å¿—æ–‡ä»¶å&lt;/td&gt;
&lt;td&gt;MASTER LOG_FILE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SOURCE_LOG POS&lt;/td&gt;
&lt;td&gt;binlog æ—¥å¿—æ–‡ä»¶ä½ç½®&lt;/td&gt;
&lt;td&gt;MASTER_LOG_POS&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre&gt;&lt;code&gt;#1.é…ç½®ä»åº“
[root@db02 ~]# vim /etc/my.cnf
server-id=2           #mysqlæœåŠ¡ID
read-only=1           #æ˜¯å¦åªè¯»,1ä»£è¡¨åªè¯», 0ä»£è¡¨è¯»å†™
[root@db02 ~]# systemctl restart mysqld

#2..é…ç½®ä»æœåŠ¡å™¨ï¼Œè¿æ¥ä¸»æœåŠ¡å™¨
mysql&amp;gt; change master to master_host=&#39;192.168.40.150&#39;,master_user=&#39;repl&#39;,master_password=&#39;passwd&#39;,master_log_file=&#39;mysql-bin.000006&#39;,master_log_pos=889;

#3.å¼€å¯ä»åº“
mysql&amp;gt; start slave;
Query OK, 0 rows affected (0.00 sec)

#4.æ£€æŸ¥ä¸»ä»å¤åˆ¶çŠ¶æ€
mysql&amp;gt; show slave status\G
*************************** 1. row ***************************
               Slave_IO_State: Waiting for master to send event
                  Master_Host: 192.168.40.150
                  Master_User: repl
                  Master_Port: 3306
                Connect_Retry: 60
              Master_Log_File: mysql-bin.000006
          Read_Master_Log_Pos: 889
               Relay_Log_File: db02-relay-bin.000002
                Relay_Log_Pos: 320
        Relay_Master_Log_File: mysql-bin.000006
             Slave_IO_Running: Yes
            Slave_SQL_Running: Yes
              Replicate_Do_DB: 
          Replicate_Ignore_DB: 
           Replicate_Do_Table: 
       Replicate_Ignore_Table: 
      Replicate_Wild_Do_Table: 
  Replicate_Wild_Ignore_Table: 
                   Last_Errno: 0
                   Last_Error: 
                 Skip_Counter: 0
          Exec_Master_Log_Pos: 889
              Relay_Log_Space: 526
              Until_Condition: None
               Until_Log_File: 
                Until_Log_Pos: 0
           Master_SSL_Allowed: No
           Master_SSL_CA_File: 
           Master_SSL_CA_Path: 
              Master_SSL_Cert: 
            Master_SSL_Cipher: 
               Master_SSL_Key: 
        Seconds_Behind_Master: 0
Master_SSL_Verify_Server_Cert: No
                Last_IO_Errno: 0
                Last_IO_Error: 
               Last_SQL_Errno: 0
               Last_SQL_Error: 
  Replicate_Ignore_Server_Ids: 
             Master_Server_Id: 1
                  Master_UUID: 9b911bea-43e6-11ee-b239-000c29074f5d
             Master_Info_File: /var/lib/mysql/master.info
                    SQL_Delay: 0
          SQL_Remaining_Delay: NULL
      Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates
           Master_Retry_Count: 86400
                  Master_Bind: 
      Last_IO_Error_Timestamp: 
     Last_SQL_Error_Timestamp: 
               Master_SSL_Crl: 
           Master_SSL_Crlpath: 
           Retrieved_Gtid_Set: 
            Executed_Gtid_Set: 
                Auto_Position: 0
         Replicate_Rewrite_DB: 
                 Channel_Name: 
           Master_TLS_Version: 
1 row in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;3-åˆ†åº“åˆ†è¡¨&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3-åˆ†åº“åˆ†è¡¨&#34;&gt;#&lt;/a&gt; 3. &lt;a href=&#34;https://so.csdn.net/so/search?q=%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8&amp;amp;spm=1001.2101.3001.7020&#34;&gt;åˆ†åº“åˆ†è¡¨&lt;/a&gt;&lt;/h4&gt;
&lt;h5 id=&#34;31-åˆ†åº“åˆ†è¡¨ä»‹ç»&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#31-åˆ†åº“åˆ†è¡¨ä»‹ç»&#34;&gt;#&lt;/a&gt; 3.1 åˆ†åº“åˆ†è¡¨ä»‹ç»&lt;/h5&gt;
&lt;h6 id=&#34;311-ç°åœ¨çš„é—®é¢˜&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#311-ç°åœ¨çš„é—®é¢˜&#34;&gt;#&lt;/a&gt; 3.1.1 ç°åœ¨çš„é—®é¢˜&lt;/h6&gt;
&lt;p&gt;&lt;strong&gt;å•æ•°æ®åº“&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;æ‰€æœ‰æ•°æ®éƒ½æ˜¯å­˜æ”¾åœ¨ä¸€ä¸ª&lt;a href=&#34;https://so.csdn.net/so/search?q=%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6&amp;amp;spm=1001.2101.3001.7020&#34;&gt;æ•°æ®åº“æ–‡ä»¶&lt;/a&gt;é‡Œçš„ï¼Œç»è¿‡å¸¸å¹´ç´¯æœˆï¼Œå†…å­˜ä¸è¶³äº†æ€ä¹ˆåŠï¼Ÿ&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://imgse.com/i/pEgOyd0&#34;&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://s21.ax1x.com/2025/04/09/pEgOyd0.png&#34; alt=&#34;pEgOyd0.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;éšç€äº’è”ç½‘åŠç§»åŠ¨äº’è”ç½‘çš„å‘å±•ï¼Œåº”ç”¨ç³»ç»Ÿçš„æ•°æ®é‡ä¹Ÿæ˜¯æˆæŒ‡æ•°å¼å¢é•¿ï¼Œè‹¥é‡‡ç”¨å•æ•°æ®åº“è¿›è¡Œæ•°æ®å­˜å‚¨ï¼Œå­˜åœ¨ä»¥ä¸‹æ€§èƒ½ç“¶é¢ˆï¼š&lt;/p&gt;
&lt;p&gt;IO ç“¶é¢ˆï¼šçƒ­ç‚¹æ•°æ®å¤ªå¤šï¼Œæ•°æ®åº“ç¼“å­˜ä¸è¶³ï¼Œäº§ç”Ÿå¤§é‡ç£ç›˜ IOï¼Œæ•ˆç‡è¾ƒä½ã€‚è¯·æ±‚æ•°æ®å¤ªå¤šï¼Œå¸¦å®½ä¸å¤Ÿï¼Œç½‘ç»œ IO ç“¶é¢ˆã€‚&lt;br /&gt;
CPU ç“¶é¢ˆï¼š æ’åºã€åˆ†ç»„ã€è¿æ¥æŸ¥è¯¢ã€èšåˆç»Ÿè®¡ç­‰ SQL ä¼šè€—è´¹å¤§é‡çš„ CPU èµ„æºï¼Œè¯·æ±‚æ•°å¤ªå¤šï¼ŒCPU å‡ºç°ç“¶é¢ˆã€‚&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://imgse.com/i/pEgO6oV&#34;&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://s21.ax1x.com/2025/04/09/pEgO6oV.png&#34; alt=&#34;pEgO6oV.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;åˆ†åº“åˆ†è¡¨çš„ä¸­å¿ƒæ€æƒ³ï¼š&lt;br /&gt;
å°†æ•°æ®åˆ†æ•£å­˜å‚¨ï¼Œä½¿å¾—å•ä¸€æ•°æ®åº“ / è¡¨çš„æ•°æ®é‡å˜å°æ¥ç¼“è§£å•ä¸€æ•°æ®åº“çš„æ€§èƒ½é—®é¢˜ï¼Œä»è€Œè¾¾åˆ°æå‡æ•°æ®åº“æ€§èƒ½çš„ç›®çš„ã€‚&lt;/strong&gt;&lt;/p&gt;
&lt;h6 id=&#34;312-æ‹†åˆ†ç­–ç•¥&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#312-æ‹†åˆ†ç­–ç•¥&#34;&gt;#&lt;/a&gt; 3.1.2 æ‹†åˆ†ç­–ç•¥&lt;/h6&gt;
&lt;p&gt;&lt;a href=&#34;https://imgse.com/i/pE2dAXt&#34;&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://s21.ax1x.com/2025/04/10/pE2dAXt.png&#34; alt=&#34;pE2dAXt.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h6 id=&#34;313-å‚ç›´æ‹†åˆ†ç­–ç•¥&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#313-å‚ç›´æ‹†åˆ†ç­–ç•¥&#34;&gt;#&lt;/a&gt; 3.1.3 å‚ç›´æ‹†åˆ†ç­–ç•¥&lt;/h6&gt;
&lt;p&gt;&lt;a href=&#34;https://imgse.com/i/pE2dnAS&#34;&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://s21.ax1x.com/2025/04/10/pE2dnAS.png&#34; alt=&#34;pE2dnAS.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ç‰¹ç‚¹:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;æ¯ä¸ªåº“çš„è¡¨ç»“æ„éƒ½ä¸ä¸€æ ·ã€‚&lt;/li&gt;
&lt;li&gt;æ¯ä¸ªåº“çš„æ•°æ®ä¹Ÿä¸ä¸€æ · ã€‚&lt;/li&gt;
&lt;li&gt;æ‰€æœ‰ï¼Œåº“çš„å¹¶é›†æ˜¯å…¨é‡æ•°æ®ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href=&#34;https://imgse.com/i/pE2dQpj&#34;&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://s21.ax1x.com/2025/04/10/pE2dQpj.png&#34; alt=&#34;pE2dQpj.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ç‰¹ç‚¹:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;æ¯ä¸ªè¡¨çš„ç»“æ„éƒ½ä¸ä¸€æ ·ã€‚&lt;/li&gt;
&lt;li&gt;æ¯ä¸ªè¡¨çš„æ•°æ®ä¹Ÿæœ¯ä¸€æ ·ï¼Œä¸€èˆ¬é€šè¿‡ä¸€åˆ— (ä¸»é”® / å¤–é”®) å…³è”ã€‚&lt;/li&gt;
&lt;li&gt;æ‰€æœ‰è¡¨çš„å¹¶é›†æ˜¯å…¨é‡æ•°æ®ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;h6 id=&#34;314-æ°´å¹³æ‹†åˆ†ç­–ç•¥&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#314-æ°´å¹³æ‹†åˆ†ç­–ç•¥&#34;&gt;#&lt;/a&gt; 3.1.4 æ°´å¹³æ‹†åˆ†ç­–ç•¥&lt;/h6&gt;
&lt;p&gt;&lt;a href=&#34;https://imgse.com/i/pE2d3Xq&#34;&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://s21.ax1x.com/2025/04/10/pE2d3Xq.png&#34; alt=&#34;pE2d3Xq.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;æ°´å¹³åˆ†åº“ï¼šä»¥ â€œå­—æ®µâ€ ä¸ºä¾æ®ï¼Œæ”¹ä¸ºä»¥ â€œè¡Œï¼ˆè®°å½•ï¼‰â€ ä¸ºä¾æ®ã€‚è®²ä¸€ä¸ªåº“çš„æ•°æ®æ‹†åˆ†åˆ°å¤šä¸ªåº“&lt;/p&gt;
&lt;p&gt;ç‰¹ç‚¹ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;æ¯ä¸ªåº“çš„è¡¨ç»“æ„éƒ½ä¸€æ ·ã€‚&lt;/li&gt;
&lt;li&gt;æ¯ä¸ªåº“çš„æ•°æ®éƒ½ä¸ä¸€æ ·ã€‚&lt;/li&gt;
&lt;li&gt;æ‰€æœ‰åº“çš„å¹¶é›†æ˜¯å…¨é‡æ•°æ®ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/8Vp5L6j.png&#34; alt=&#34;1.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;ç‰¹ç‚¹ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;æ¯ä¸ªè¡¨çš„è¡¨ç»“æ„éƒ½ä¸€æ · ã€‚&lt;/li&gt;
&lt;li&gt;æ¯ä¸ªè¡¨çš„æ•°æ®éƒ½ä¸ä¸€æ · ã€‚&lt;/li&gt;
&lt;li&gt;æ‰€æœ‰è¡¨çš„å¹¶é›†æ˜¯å…¨é‡æ•°æ®ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/2ctPFwi.png&#34; alt=&#34;2.png&#34; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;shardingJDBCï¼šåŸºäº AOP åŸç†ï¼Œåœ¨åº”ç”¨ç¨‹åºä¸­å¯¹æœ¬åœ°æ‰§è¡Œçš„ SQL è¿›è¡Œæ‹¦æˆªï¼Œè§£æã€æ”¹å†™ã€è·¯ç”±å¤„ç†ã€‚éœ€è¦è‡ªè¡Œç¼–ç é…ç½®å®ç°ï¼Œåªæ”¯æŒ java è¯­è¨€ï¼Œæ€§èƒ½è¾ƒé«˜ã€‚&lt;/li&gt;
&lt;li&gt;MyCatï¼šæ•°æ®åº“åˆ†åº“åˆ†è¡¨ä¸­é—´ä»¶ï¼Œä¸ç”¨è°ƒæ•´ä»£ç å³å¯å®ç°åˆ†åº“åˆ†è¡¨ï¼Œæ”¯æŒå¤šç§è¯­è¨€ï¼Œæ€§èƒ½ä¸åŠå‰è€…ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/lgs1r8g.png&#34; alt=&#34;3.png&#34; /&gt;&lt;/p&gt;
&lt;h5 id=&#34;32-mycatæ¦‚è¿°&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#32-mycatæ¦‚è¿°&#34;&gt;#&lt;/a&gt; 3.2 Mycat æ¦‚è¿°&lt;/h5&gt;
&lt;p&gt;Mycat æ˜¯å¼€æºçš„ã€æ´»è·ƒçš„ã€åŸºäº Java è¯­è¨€ç¼–å†™çš„&lt;strong&gt; MySQL æ•°æ®åº“ä¸­é—´ä»¶&lt;/strong&gt;ã€‚å¯ä»¥åƒä½¿ç”¨ mysql ä¸€æ ·æ¥ä½¿ç”¨ mycatï¼Œå¯¹äºå¼€å‘äººå‘˜æ¥è¯´æ ¹æœ¬æ„Ÿè§‰ä¸åˆ° mycat çš„å­˜åœ¨ã€‚&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/KFB4gQ8.png&#34; alt=&#34;5.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;ä¼˜åŠ¿ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;æ€§èƒ½å¯é ç¨³å®š&lt;/li&gt;
&lt;li&gt;å¼ºå¤§çš„æŠ€æœ¯å›¢é˜Ÿ&lt;/li&gt;
&lt;li&gt;ä½“ç³»å®Œå–„&lt;/li&gt;
&lt;li&gt;ç¤¾åŒºæ´»è·ƒ&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Mycat æ˜¯é‡‡ç”¨ java è¯­è¨€å¼€å‘çš„å¼€æºçš„æ•°æ®åº“ä¸­é—´ä»¶ï¼Œæ”¯æŒ Windows å’Œ Linux è¿è¡Œç¯å¢ƒï¼Œä¸‹é¢ä»‹ç» MyCat çš„ Linux ä¸­çš„ç¯å¢ƒæ­å»ºã€‚ æˆ‘ä»¬éœ€è¦åœ¨å‡†å¤‡å¥½çš„æœåŠ¡å™¨ä¸­å®‰è£…å¦‚ä¸‹è½¯ä»¶ã€‚&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;æœåŠ¡å™¨&lt;/th&gt;
&lt;th&gt;å®‰è£…è½¯ä»¶&lt;/th&gt;
&lt;th&gt;è¯´æ˜&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;192.168.40.213&lt;/td&gt;
&lt;td&gt;JDKã€Mycat&lt;/td&gt;
&lt;td&gt;MyCat ä¸­é—´ä»¶æœåŠ¡å™¨&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;192.168.40.210&lt;/td&gt;
&lt;td&gt;MySQL&lt;/td&gt;
&lt;td&gt;åˆ†ç‰‡æœåŠ¡å™¨&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;192.168.40.211&lt;/td&gt;
&lt;td&gt;MySQL&lt;/td&gt;
&lt;td&gt;åˆ†ç‰‡æœåŠ¡å™¨&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;192.168.40.212&lt;/td&gt;
&lt;td&gt;MySQL&lt;/td&gt;
&lt;td&gt;åˆ†ç‰‡æœåŠ¡å™¨&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;JDK å®‰è£…&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#è§£å‹jdk
[root@mycat ~]# tar xf jdk-8u371-linux-x64.tar.gz -C /usr/local
[root@mycat ~]# ln -s /usr/local/jdk1.8.0_371/ /usr/local/jdk

# æ·»åŠ ç¯å¢ƒå˜é‡
[root@mycat ~]# vim /etc/profile.d/jdk.sh 
export JAVA_HOME=/usr/local/jdk
export PATH=$PATH:$JAVA_HOME/bin
export JRE_HOME=$JAVA_HOME/jre 
export CLASSPATH=$JAVA_HOME/lib/:$JRE_HOME/lib/

[root@mycat ~]# source /etc/profile
[root@mycat ~]# java -version
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Mycat å®‰è£…&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@mycat ~]# tar xf Mycat-server-1.6-RELEASE-20161028204710-linux.tar.gz -C /usr/local/
[root@mycat ~]# ll /usr/local/mycat/
total 12
drwxr-xr-x 2 root root  190 Dec  2 22:15 bin
drwxrwxrwx 2 root root    6 Mar  1  2016 catlet
drwxrwxrwx 4 root root 4096 Dec  2 22:15 conf
drwxr-xr-x 2 root root 4096 Dec  2 22:15 lib
drwxrwxrwx 2 root root    6 Oct 28  2016 logs
-rwxrwxrwx 1 root root  217 Oct 28  2016 version.txt

#ä¸Šä¼ jaråŒ…
[root@mycat ~]# rz /usr/local/mycat/lib/mysql-connector-java-8.0.25.jar
[root@mycat lib]# chmod 777 mysql-connector-java-8.0.25.jar 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/n86yXtx.png&#34; alt=&#34;4.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/U26clQE.png&#34; alt=&#34;6.png&#34; /&gt;&lt;/p&gt;
&lt;h6 id=&#34;321-mycatå…¥é—¨&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#321-mycatå…¥é—¨&#34;&gt;#&lt;/a&gt; 3.2.1 Mycat å…¥é—¨&lt;/h6&gt;
&lt;p&gt;ç”±äº tb_gorder è¡¨ä¸­æ•°æ®é‡å¾ˆå¤§ï¼Œç£ç›˜ IO åŠå®¹é‡éƒ½åˆ°è¾¾äº†ç“¶é¢ˆï¼Œç°åœ¨éœ€è¦å¯¹ tb_order è¡¨è¿›è¡Œæ•°æ®åˆ†ç‰‡ï¼Œåˆ†ä¸ºä¸‰ä¸ªæ•°æ®èŠ‚ç‚¹ï¼Œæ¯ä¸€ä¸ªèŠ‚ç‚¹ä¸»æœºä½äºä¸åŒçš„æœåŠ¡å™¨ä¸Šï¼Œå…·ä½“çš„ç»“æ„ï¼Œå‚è€ƒä¸‹å›¾ï¼š&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/YjmWPQf.png&#34; alt=&#34;5.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/PQqJdjJ.png&#34; alt=&#34;8.png&#34; /&gt;&lt;/p&gt;
&lt;h6 id=&#34;322-mycaté…ç½®&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#322-mycaté…ç½®&#34;&gt;#&lt;/a&gt; 3.2.2 Mycat é…ç½®&lt;/h6&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/iXUxPhi.png&#34; alt=&#34;9.png&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@mycat ~]# cat /usr/local/mycat/conf/schema.xml 
&amp;lt;?xml version=&amp;quot;1.0&amp;quot;?&amp;gt;
&amp;lt;!DOCTYPE mycat:schema SYSTEM &amp;quot;schema.dtd&amp;quot;&amp;gt;
&amp;lt;mycat:schema xmlns:mycat=&amp;quot;http://io.mycat/&amp;quot;&amp;gt;
	&amp;lt;schema name=&amp;quot;DB01&amp;quot; checkSQLschema=&amp;quot;true&amp;quot; sqlMaxLimit=&amp;quot;100&amp;quot;&amp;gt;
		&amp;lt;table name=&amp;quot;TB_ORDER&amp;quot; dataNode=&amp;quot;dn1,dn2,dn3&amp;quot; rule=&amp;quot;auto-sharding-long&amp;quot; /&amp;gt;
	&amp;lt;/schema&amp;gt;
	
	&amp;lt;dataNode name=&amp;quot;dn1&amp;quot; dataHost=&amp;quot;dhost1&amp;quot; database=&amp;quot;db01&amp;quot; /&amp;gt;
	&amp;lt;dataNode name=&amp;quot;dn2&amp;quot; dataHost=&amp;quot;dhost2&amp;quot; database=&amp;quot;db01&amp;quot; /&amp;gt;
	&amp;lt;dataNode name=&amp;quot;dn3&amp;quot; dataHost=&amp;quot;dhost3&amp;quot; database=&amp;quot;db01&amp;quot; /&amp;gt;
	
	&amp;lt;dataHost name=&amp;quot;dhost1&amp;quot; maxCon=&amp;quot;1000&amp;quot; minCon=&amp;quot;10&amp;quot; balance=&amp;quot;0&amp;quot;
			  writeType=&amp;quot;0&amp;quot; dbType=&amp;quot;mysql&amp;quot; dbDriver=&amp;quot;jdbc&amp;quot; switchType=&amp;quot;1&amp;quot;  slaveThreshold=&amp;quot;100&amp;quot;&amp;gt;
		&amp;lt;heartbeat&amp;gt;select user()&amp;lt;/heartbeat&amp;gt;
		
		&amp;lt;writeHost host=&amp;quot;master&amp;quot; url=&amp;quot;jdbc:mysql://192.168.40.210:3306?useSSL=false&amp;amp;amp;serverTimezone=Asia/Shanghai&amp;amp;amp;characterEncoding=utf8&amp;quot; user=&amp;quot;root&amp;quot; password=&amp;quot;Superman*2023&amp;quot; /&amp;gt;
	&amp;lt;/dataHost&amp;gt;
	
	&amp;lt;dataHost name=&amp;quot;dhost2&amp;quot; maxCon=&amp;quot;1000&amp;quot; minCon=&amp;quot;10&amp;quot; balance=&amp;quot;0&amp;quot;
			  writeType=&amp;quot;0&amp;quot; dbType=&amp;quot;mysql&amp;quot; dbDriver=&amp;quot;jdbc&amp;quot; switchType=&amp;quot;1&amp;quot;  slaveThreshold=&amp;quot;100&amp;quot;&amp;gt;
		&amp;lt;heartbeat&amp;gt;select user()&amp;lt;/heartbeat&amp;gt;
		
		&amp;lt;writeHost host=&amp;quot;master&amp;quot; url=&amp;quot;jdbc:mysql://192.168.40.211:3306?useSSL=false&amp;amp;amp;serverTimezone=Asia/Shanghai&amp;amp;amp;characterEncoding=utf8&amp;quot; user=&amp;quot;root&amp;quot; password=&amp;quot;Superman*2023&amp;quot; /&amp;gt;
	&amp;lt;/dataHost&amp;gt;
	
	&amp;lt;dataHost name=&amp;quot;dhost3&amp;quot; maxCon=&amp;quot;1000&amp;quot; minCon=&amp;quot;10&amp;quot; balance=&amp;quot;0&amp;quot;
			  writeType=&amp;quot;0&amp;quot; dbType=&amp;quot;mysql&amp;quot; dbDriver=&amp;quot;jdbc&amp;quot; switchType=&amp;quot;1&amp;quot;  slaveThreshold=&amp;quot;100&amp;quot;&amp;gt;
		&amp;lt;heartbeat&amp;gt;select user()&amp;lt;/heartbeat&amp;gt;
		
		&amp;lt;writeHost host=&amp;quot;master&amp;quot; url=&amp;quot;jdbc:mysql://192.168.40.212:3306?useSSL=false&amp;amp;amp;serverTimezone=Asia/Shanghai&amp;amp;amp;characterEncoding=utf8&amp;quot; user=&amp;quot;root&amp;quot; password=&amp;quot;Superman*2023&amp;quot; /&amp;gt;
	&amp;lt;/dataHost&amp;gt;
&amp;lt;/mycat:schema&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/KkUttwJ.png&#34; alt=&#34;10.png&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@mycat mycat]# cat /usr/local/mycat/conf/server.xml 
&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
&amp;lt;!-- - - Licensed under the Apache License, Version 2.0 (the &amp;quot;License&amp;quot;); 
	- you may not use this file except in compliance with the License. - You 
	may obtain a copy of the License at - - http://www.apache.org/licenses/LICENSE-2.0 
	- - Unless required by applicable law or agreed to in writing, software - 
	distributed under the License is distributed on an &amp;quot;AS IS&amp;quot; BASIS, - WITHOUT 
	WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. - See the 
	License for the specific language governing permissions and - limitations 
	under the License. --&amp;gt;
&amp;lt;!DOCTYPE mycat:server SYSTEM &amp;quot;server.dtd&amp;quot;&amp;gt;
&amp;lt;mycat:server xmlns:mycat=&amp;quot;http://io.mycat/&amp;quot;&amp;gt;
	&amp;lt;system&amp;gt;
	&amp;lt;property name=&amp;quot;useSqlStat&amp;quot;&amp;gt;0&amp;lt;/property&amp;gt;  &amp;lt;!-- 1ä¸ºå¼€å¯å®æ—¶ç»Ÿè®¡ã€0ä¸ºå…³é—­ --&amp;gt;
	&amp;lt;property name=&amp;quot;useGlobleTableCheck&amp;quot;&amp;gt;0&amp;lt;/property&amp;gt;  &amp;lt;!-- 1ä¸ºå¼€å¯å…¨åŠ ç­ä¸€è‡´æ€§æ£€æµ‹ã€0ä¸ºå…³é—­ --&amp;gt;

		&amp;lt;property name=&amp;quot;sequnceHandlerType&amp;quot;&amp;gt;2&amp;lt;/property&amp;gt;
      &amp;lt;!--  &amp;lt;property name=&amp;quot;useCompression&amp;quot;&amp;gt;1&amp;lt;/property&amp;gt;--&amp;gt; &amp;lt;!--1ä¸ºå¼€å¯mysqlå‹ç¼©åè®®--&amp;gt;
        &amp;lt;!--  &amp;lt;property name=&amp;quot;fakeMySQLVersion&amp;quot;&amp;gt;5.6.20&amp;lt;/property&amp;gt;--&amp;gt; &amp;lt;!--è®¾ç½®æ¨¡æ‹Ÿçš„MySQLç‰ˆæœ¬å·--&amp;gt;
	&amp;lt;!-- &amp;lt;property name=&amp;quot;processorBufferChunk&amp;quot;&amp;gt;40960&amp;lt;/property&amp;gt; --&amp;gt;
	&amp;lt;!-- 
	&amp;lt;property name=&amp;quot;processors&amp;quot;&amp;gt;1&amp;lt;/property&amp;gt; 
	&amp;lt;property name=&amp;quot;processorExecutor&amp;quot;&amp;gt;32&amp;lt;/property&amp;gt; 
	 --&amp;gt;
		&amp;lt;!--é»˜è®¤ä¸ºtype 0: DirectByteBufferPool | type 1 ByteBufferArena--&amp;gt;
		&amp;lt;property name=&amp;quot;processorBufferPoolType&amp;quot;&amp;gt;0&amp;lt;/property&amp;gt;
		&amp;lt;!--é»˜è®¤æ˜¯65535 64K ç”¨äºsqlè§£ææ—¶æœ€å¤§æ–‡æœ¬é•¿åº¦ --&amp;gt;
		&amp;lt;!--&amp;lt;property name=&amp;quot;maxStringLiteralLength&amp;quot;&amp;gt;65535&amp;lt;/property&amp;gt;--&amp;gt;
		&amp;lt;!--&amp;lt;property name=&amp;quot;sequnceHandlerType&amp;quot;&amp;gt;0&amp;lt;/property&amp;gt;--&amp;gt;
		&amp;lt;!--&amp;lt;property name=&amp;quot;backSocketNoDelay&amp;quot;&amp;gt;1&amp;lt;/property&amp;gt;--&amp;gt;
		&amp;lt;!--&amp;lt;property name=&amp;quot;frontSocketNoDelay&amp;quot;&amp;gt;1&amp;lt;/property&amp;gt;--&amp;gt;
		&amp;lt;!--&amp;lt;property name=&amp;quot;processorExecutor&amp;quot;&amp;gt;16&amp;lt;/property&amp;gt;--&amp;gt;
		&amp;lt;!--
			&amp;lt;property name=&amp;quot;serverPort&amp;quot;&amp;gt;8066&amp;lt;/property&amp;gt; &amp;lt;property name=&amp;quot;managerPort&amp;quot;&amp;gt;9066&amp;lt;/property&amp;gt; 
			&amp;lt;property name=&amp;quot;idleTimeout&amp;quot;&amp;gt;300000&amp;lt;/property&amp;gt; &amp;lt;property name=&amp;quot;bindIp&amp;quot;&amp;gt;0.0.0.0&amp;lt;/property&amp;gt; 
			&amp;lt;property name=&amp;quot;frontWriteQueueSize&amp;quot;&amp;gt;4096&amp;lt;/property&amp;gt; &amp;lt;property name=&amp;quot;processors&amp;quot;&amp;gt;32&amp;lt;/property&amp;gt; --&amp;gt;
		&amp;lt;!--åˆ†å¸ƒå¼äº‹åŠ¡å¼€å…³ï¼Œ0ä¸ºä¸è¿‡æ»¤åˆ†å¸ƒå¼äº‹åŠ¡ï¼Œ1ä¸ºè¿‡æ»¤åˆ†å¸ƒå¼äº‹åŠ¡ï¼ˆå¦‚æœåˆ†å¸ƒå¼äº‹åŠ¡å†…åªæ¶‰åŠå…¨å±€è¡¨ï¼Œåˆ™ä¸è¿‡æ»¤ï¼‰ï¼Œ2ä¸ºä¸è¿‡æ»¤åˆ†å¸ƒå¼äº‹åŠ¡,ä½†æ˜¯è®°å½•åˆ†å¸ƒå¼äº‹åŠ¡æ—¥å¿—--&amp;gt;
		&amp;lt;property name=&amp;quot;handleDistributedTransactions&amp;quot;&amp;gt;0&amp;lt;/property&amp;gt;
		
			&amp;lt;!--
			off heap for merge/order/group/limit      1å¼€å¯   0å…³é—­
		--&amp;gt;
		&amp;lt;property name=&amp;quot;useOffHeapForMerge&amp;quot;&amp;gt;1&amp;lt;/property&amp;gt;

		&amp;lt;!--
			å•ä½ä¸ºm
		--&amp;gt;
		&amp;lt;property name=&amp;quot;memoryPageSize&amp;quot;&amp;gt;1m&amp;lt;/property&amp;gt;

		&amp;lt;!--
			å•ä½ä¸ºk
		--&amp;gt;
		&amp;lt;property name=&amp;quot;spillsFileBufferSize&amp;quot;&amp;gt;1k&amp;lt;/property&amp;gt;

		&amp;lt;property name=&amp;quot;useStreamOutput&amp;quot;&amp;gt;0&amp;lt;/property&amp;gt;

		&amp;lt;!--
			å•ä½ä¸ºm
		--&amp;gt;
		&amp;lt;property name=&amp;quot;systemReserveMemorySize&amp;quot;&amp;gt;384m&amp;lt;/property&amp;gt;


		&amp;lt;!--æ˜¯å¦é‡‡ç”¨zookeeperåè°ƒåˆ‡æ¢  --&amp;gt;
		&amp;lt;property name=&amp;quot;useZKSwitch&amp;quot;&amp;gt;true&amp;lt;/property&amp;gt;


	&amp;lt;/system&amp;gt;
	
	&amp;lt;!-- å…¨å±€SQLé˜²ç«å¢™è®¾ç½® --&amp;gt;
	&amp;lt;!-- 
	&amp;lt;firewall&amp;gt; 
	   &amp;lt;whitehost&amp;gt;
	      &amp;lt;host host=&amp;quot;127.0.0.1&amp;quot; user=&amp;quot;mycat&amp;quot;/&amp;gt;
	      &amp;lt;host host=&amp;quot;127.0.0.2&amp;quot; user=&amp;quot;mycat&amp;quot;/&amp;gt;
	   &amp;lt;/whitehost&amp;gt;
       &amp;lt;blacklist check=&amp;quot;false&amp;quot;&amp;gt;
       &amp;lt;/blacklist&amp;gt;
	&amp;lt;/firewall&amp;gt;
	--&amp;gt;
	
	&amp;lt;user name=&amp;quot;root&amp;quot;&amp;gt;
		&amp;lt;property name=&amp;quot;password&amp;quot;&amp;gt;Superman*2023&amp;lt;/property&amp;gt;
		&amp;lt;property name=&amp;quot;schemas&amp;quot;&amp;gt;DB01&amp;lt;/property&amp;gt;
		
		&amp;lt;!-- è¡¨çº§ DML æƒé™è®¾ç½® --&amp;gt;
		&amp;lt;!-- 		
		&amp;lt;privileges check=&amp;quot;false&amp;quot;&amp;gt;
			&amp;lt;schema name=&amp;quot;TESTDB&amp;quot; dml=&amp;quot;0110&amp;quot; &amp;gt;
				&amp;lt;table name=&amp;quot;tb01&amp;quot; dml=&amp;quot;0000&amp;quot;&amp;gt;&amp;lt;/table&amp;gt;
				&amp;lt;table name=&amp;quot;tb02&amp;quot; dml=&amp;quot;1111&amp;quot;&amp;gt;&amp;lt;/table&amp;gt;
			&amp;lt;/schema&amp;gt;
		&amp;lt;/privileges&amp;gt;		
		 --&amp;gt;
	&amp;lt;/user&amp;gt;

	&amp;lt;user name=&amp;quot;user&amp;quot;&amp;gt;
		&amp;lt;property name=&amp;quot;password&amp;quot;&amp;gt;Superman*2023&amp;lt;/property&amp;gt;
		&amp;lt;property name=&amp;quot;schemas&amp;quot;&amp;gt;DB01&amp;lt;/property&amp;gt;
		&amp;lt;property name=&amp;quot;readOnly&amp;quot;&amp;gt;true&amp;lt;/property&amp;gt;
	&amp;lt;/user&amp;gt;

&amp;lt;/mycat:server&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;323-mycatå¯åŠ¨&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#323-mycatå¯åŠ¨&#34;&gt;#&lt;/a&gt; 3.2.3 Mycat å¯åŠ¨&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;#1.å¯åŠ¨mycat
[root@mycat mycat]# ./bin/mycat restart

#2.wrapper.logæ—¥å¿—ä¸­å¸¸è§é”™è¯¯
ERROR | wrapper | 2021/1/10 13:31:05 | Startup failed: Timed out waiting for signal from JVM.
ERROR | wrapper | 2021/1/10 13:31:05 | JVM did not exit on request, terminated

#3.å¯åŠ¨Mycatè¶…æ—¶,å‰å¾€wrapper.confé…ç½®è¶…æ—¶ç­–ç•¥
[root@mycat mycat]# vim /usr/local/mycat/conf/wrapper.conf
...
wrapper.startup.timeout=300     //æ·»åŠ æ­¤è¡Œï¼Œè¶…æ—¶æ—¶é—´300ç§’
wrapper.ping.timeout=120

#4.æŸ¥çœ‹mycatæ˜¯å¦å¯åŠ¨
[root@mycat mycat]# tail -f logs/wrapper.log
...
INFO   | jvm 1    | 2023/12/02 22:53:44 | MyCAT Server startup successfully. see logs in logs/mycat.log
[root@mycat mycat]# netstat -lntp|grep 8066
tcp6       0      0 :::8066                 :::*                    LISTEN      18028/java
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;324-åˆ†ç‰‡æµ‹è¯•&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#324-åˆ†ç‰‡æµ‹è¯•&#34;&gt;#&lt;/a&gt; 3.2.4 åˆ†ç‰‡æµ‹è¯•&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;[root@db3 ~]#  mysql -h 192.168.40.213 -P 8066 -uroot -p&#39;Superman*2023&#39;
mysql: [Warning] Using a password on the command line interface can be insecure.
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 3
Server version: 5.6.29-mycat-1.6-RELEASE-20161028204710 MyCat Server (OpenCloundDB)

Copyright (c) 2000, 2023, Oracle and/or its affiliates.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type &#39;help;&#39; or &#39;\h&#39; for help. Type &#39;\c&#39; to clear the current input statement.

mysql&amp;gt; show databases;
+----------+
| DATABASE |
+----------+
| DB01     |
+----------+
1 row in set (0.00 sec)

mysql&amp;gt; use DB01;
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Database changed
mysql&amp;gt; show tables;
+----------------+
| Tables in DB01 |
+----------------+
| tb_order       |
+----------------+
1 row in set (0.00 sec)
mysql&amp;gt; CREATE TABLE TB_ORDER(
    -&amp;gt; id BIGINT(20) NOT NULL,
    -&amp;gt; title VARCHAR(100) NOT NULL,
    -&amp;gt; PRIMARY KEY (id)
    -&amp;gt; )ENGINE=INNODB DEFAULT CHARSET=utf8;
Query OK, 0 rows affected (0.04 sec)
 OK!
mysql&amp;gt;INSERT INTO TB_ORDER(id,title) VALUES(1,&#39;guods1&#39;);
mysql&amp;gt;INSERT INTO TB_ORDER(id,title) VALUES(2,&#39;guods2&#39;);
mysql&amp;gt;INSERT INTO TB_ORDER(id,title) VALUES(3,&#39;guods3&#39;);
mysql&amp;gt;INSERT INTO TB_ORDER(id,title) VALUES(4,&#39;guods4&#39;);
mysql&amp;gt; select * from TB_ORDER;
+------+--------+
| id   | title  |
+------+--------+
|    1 | guods1 |
|    2 | guods2 |
|    3 | guods3 |
|    4 | guods4 |
+------+--------+
4 rows in set (0.03 sec)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;æ•°æ®å†™å…¥åˆ° db1 ä¸­ï¼Œå› ä¸º mycat åˆ†ç‰‡è§„åˆ™ä¸º 0-50000000 å­˜å…¥èŠ‚ç‚¹ 1,5000001-10000000 å­˜å…¥èŠ‚ç‚¹ 2,10000001-15000000 å­˜å…¥èŠ‚ç‚¹ 3ï¼Œ15000001 ä»¥ä¸Šæ— æ³•æ’å…¥æ•°æ®ï¼Œéœ€è¦å¢åŠ æ•°æ®èŠ‚ç‚¹ã€‚&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@mycat mycat]# vim conf/rule.xml
...
        &amp;lt;tableRule name=&amp;quot;auto-sharding-long&amp;quot;&amp;gt;
                &amp;lt;rule&amp;gt;
                        &amp;lt;columns&amp;gt;id&amp;lt;/columns&amp;gt;
                        &amp;lt;algorithm&amp;gt;rang-long&amp;lt;/algorithm&amp;gt;
                &amp;lt;/rule&amp;gt;
        &amp;lt;/tableRule&amp;gt;

....
       &amp;lt;function name=&amp;quot;rang-long&amp;quot;
                class=&amp;quot;io.mycat.route.function.AutoPartitionByLong&amp;quot;&amp;gt;
                &amp;lt;property name=&amp;quot;mapFile&amp;quot;&amp;gt;autopartition-long.txt&amp;lt;/property&amp;gt;
        &amp;lt;/function&amp;gt;

...

[root@mycat mycat]# cat conf/autopartition-long.txt
# range start-end ,data node index
# K=1000,M=10000.
0-500M=0
500M-1000M=1

#5000001-10000000å­˜å…¥èŠ‚ç‚¹2 
mysql&amp;gt; INSERT INTO TB_ORDER(id,title) VALUES(5000001,&#39;guods5000001&#39;);
Query OK, 1 row affected (0.01 sec)
 OK!
 
#10000001-15000000å­˜å…¥èŠ‚ç‚¹3 
mysql&amp;gt; INSERT INTO TB_ORDER(id,title) VALUES(10000001,&#39;guods10000001&#39;);
Query OK, 1 row affected (0.00 sec)
 OK!

#15000001ä»¥ä¸Šæ— æ³•æ’å…¥æ•°æ®ï¼Œéœ€è¦å¢åŠ æ•°æ®èŠ‚ç‚¹
mysql&amp;gt; INSERT INTO TB_ORDER(id,title) VALUES(15000001,&#39;guods15000001&#39;);
ERROR 1064 (HY000): can&#39;t find any valid datanode :TB_ORDER -&amp;gt; ID -&amp;gt; 15000001
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;33-mycaté…ç½®&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#33-mycaté…ç½®&#34;&gt;#&lt;/a&gt; 3.3 Mycat é…ç½®&lt;/h5&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/I9QLBBR.png&#34; alt=&#34;11.png&#34; /&gt;&lt;/p&gt;
&lt;h6 id=&#34;331-schemaæ ‡ç­¾&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#331-schemaæ ‡ç­¾&#34;&gt;#&lt;/a&gt; 3.3.1 Schema æ ‡ç­¾&lt;/h6&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/TmYK7fP.png&#34; alt=&#34;13.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;schema æ ‡ç­¾ç”¨äºå®šä¹‰ MyCat å®ä¾‹ä¸­çš„é€»è¾‘åº“ï¼Œä¸€ä¸ª MyCat å®ä¾‹ä¸­ï¼Œå¯ä»¥æœ‰å¤šä¸ªé€»è¾‘åº“ï¼Œå¯ä»¥é€šè¿‡ schema æ ‡ç­¾æ¥åˆ’åˆ†ä¸åŒçš„é€»è¾‘åº“ã€‚MyCat ä¸­çš„é€»è¾‘åº“çš„æ¦‚å¿µï¼Œç­‰åŒäº MySQL ä¸­çš„ database æ¦‚å¿µï¼Œéœ€è¦æ“ä½œæŸä¸ªé€»è¾‘åº“ä¸‹çš„è¡¨æ—¶ä¹Ÿéœ€è¦åˆ‡æ¢é€»è¾‘åº“ (use xxx)ã€‚&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/SGo0DCv.png&#34; alt=&#34;14.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/XtDxXWj.png&#34; alt=&#34;15.png&#34; /&gt;&lt;/p&gt;
&lt;h6 id=&#34;332-datanodeæ ‡ç­¾&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#332-datanodeæ ‡ç­¾&#34;&gt;#&lt;/a&gt; 3.3.2 Datanode æ ‡ç­¾&lt;/h6&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/phHZ48F.png&#34; alt=&#34;16.png&#34; /&gt;&lt;/p&gt;
&lt;h6 id=&#34;333-datahostæ ‡ç­¾&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#333-datahostæ ‡ç­¾&#34;&gt;#&lt;/a&gt; 3.3.3 Datahost æ ‡ç­¾&lt;/h6&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/fXBnwcS.png&#34; alt=&#34;17.png&#34; /&gt;&lt;/p&gt;
&lt;h6 id=&#34;334-rulexml&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#334-rulexml&#34;&gt;#&lt;/a&gt; 3.3.4 rule.xml&lt;/h6&gt;
&lt;p&gt;rule.xml ä¸­å®šä¹‰æ‰€æœ‰æ‹†åˆ†è¡¨çš„è§„åˆ™ï¼Œåœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­å¯ä»¥çµæ´»çš„ä½¿ç”¨åˆ†ç‰‡ç®—æ³•ï¼Œæˆ–è€…å¯¹åŒä¸€ä¸ªåˆ†ç‰‡ç®—æ³•ä½¿ç”¨ä¸åŒçš„å‚æ•°ï¼Œå®ƒè®©åˆ†ç‰‡è¿‡ç¨‹å¯é…ç½®åŒ–ã€‚ä¸»è¦åŒ…å«ä¸¤ç±»æ ‡ç­¾ï¼š &lt;code&gt;tableRule&lt;/code&gt; ã€ &lt;code&gt;Function&lt;/code&gt; ã€‚&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/Ecm1Nvr.png&#34; alt=&#34;18.png&#34; /&gt;&lt;/p&gt;
&lt;h6 id=&#34;335-serverxml&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#335-serverxml&#34;&gt;#&lt;/a&gt; 3.3.5 server.xml&lt;/h6&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/xIDxYpu.png&#34; alt=&#34;19.png&#34; /&gt;&lt;/p&gt;
&lt;h5 id=&#34;34-mycatåˆ†ç‰‡&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#34-mycatåˆ†ç‰‡&#34;&gt;#&lt;/a&gt; 3.4 Mycat åˆ†ç‰‡&lt;/h5&gt;
&lt;h6 id=&#34;341-åˆ†åº“åˆ†è¡¨-mycatåˆ†ç‰‡-å‚ç›´åˆ†åº“&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#341-åˆ†åº“åˆ†è¡¨-mycatåˆ†ç‰‡-å‚ç›´åˆ†åº“&#34;&gt;#&lt;/a&gt; 3.4.1 åˆ†åº“åˆ†è¡¨ - MyCat åˆ†ç‰‡ - å‚ç›´åˆ†åº“&lt;/h6&gt;
&lt;p&gt;åœºæ™¯ï¼šåœ¨ä¸šåŠ¡ç³»ç»Ÿä¸­ï¼Œæ¶‰åŠä»¥ä¸‹è¡¨ç»“æ„ï¼Œä½†æ˜¯ç”±äºç”¨æˆ·ä¸è®¢å•æ¯å¤©éƒ½ä¼šäº§ç”Ÿå¤§é‡çš„æ•°æ®ï¼Œå•å°æœåŠ¡å™¨çš„æ•°æ®å­˜å‚¨åŠå¤„ç†èƒ½åŠ›æ˜¯æœ‰é™çš„ï¼Œå¯ä»¥å¯¹æ•°æ®åº“è¡¨è¿›è¡Œæ‹†åˆ†ï¼ŒåŸæœ‰çš„æ•°æ®åº“è¡¨å¦‚ä¸‹ã€‚&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/plSdAyY.png&#34; alt=&#34;20.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ps: åˆ†åº“ä¸éœ€è¦æŒ‡å®š ruleï¼Œæ¶‰åŠåˆ†è¡¨éœ€è¦ä½¿ç”¨ ruleï¼›&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ç¯å¢ƒå‡†å¤‡&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;â‘ å¦‚å›¾æ‰€ç¤ºå‡†å¤‡ä¸‰å° Linux æœåŠ¡å™¨ï¼ˆip ä¸ºï¼š192.168.40.210ã€192.168.40.211ã€192.168.40.212ï¼‰å¯ä»¥æ ¹æ®è‡ªå·±çš„å®é™…æƒ…å†µè¿›è¡Œå‡†å¤‡ã€‚&lt;br /&gt;
â‘¡ä¸‰å°æœåŠ¡å™¨ä¸Šéƒ½å®‰è£… MySQLï¼Œåœ¨ 192.168.40.213 æœåŠ¡å™¨ä¸Šå®‰è£… MyCatã€‚&lt;br /&gt;
â‘¢ä¸‰å°æœåŠ¡å™¨å…³é—­é˜²ç«å¢™æˆ–è€…å¼€æ”¾å¯¹åº”çš„ç«¯å£ã€‚&lt;br /&gt;
â‘£åˆ†åˆ«åœ¨ä¸‰å° MySQL ä¸­åˆ›å»ºæ•°æ®åº“ shoppingã€‚&lt;br /&gt;
&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/uMZB18q.png&#34; alt=&#34;21.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;schema.xml æ–‡ä»¶é…ç½®å¦‚ä¸‹ï¼š&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@mycat ~]# cat /usr/local/mycat/conf/schema.xml 
&amp;lt;?xml version=&amp;quot;1.0&amp;quot;?&amp;gt;
&amp;lt;!DOCTYPE mycat:schema SYSTEM &amp;quot;schema.dtd&amp;quot;&amp;gt;
&amp;lt;mycat:schema xmlns:mycat=&amp;quot;http://io.mycat/&amp;quot;&amp;gt;
	&amp;lt;schema name=&amp;quot;SHOPPING&amp;quot; checkSQLschema=&amp;quot;true&amp;quot; sqlMaxLimit=&amp;quot;100&amp;quot;&amp;gt;
		&amp;lt;table name=&amp;quot;tb_goods_base&amp;quot; dataNode=&amp;quot;dn1&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_goods_brand&amp;quot; dataNode=&amp;quot;dn1&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_goods_cat&amp;quot; dataNode=&amp;quot;dn1&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_goods_desc&amp;quot; dataNode=&amp;quot;dn1&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_goods_item&amp;quot; dataNode=&amp;quot;dn1&amp;quot; primaryKey=&amp;quot;goods_id&amp;quot; /&amp;gt;
		
		&amp;lt;table name=&amp;quot;tb_order_item&amp;quot; dataNode=&amp;quot;dn2&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_order_master&amp;quot; dataNode=&amp;quot;dn2&amp;quot; primaryKey=&amp;quot;order_id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_order_pay_log&amp;quot; dataNode=&amp;quot;dn2&amp;quot; primaryKey=&amp;quot;out_trade_no&amp;quot; /&amp;gt;
		
		&amp;lt;table name=&amp;quot;tb_user&amp;quot; dataNode=&amp;quot;dn3&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_user_address&amp;quot; dataNode=&amp;quot;dn3&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_areas_provinces&amp;quot; dataNode=&amp;quot;dn3&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_areas_city&amp;quot; dataNode=&amp;quot;dn3&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_areas_region&amp;quot; dataNode=&amp;quot;dn3&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
	&amp;lt;/schema&amp;gt;
	
	&amp;lt;dataNode name=&amp;quot;dn1&amp;quot; dataHost=&amp;quot;dhost1&amp;quot; database=&amp;quot;shopping&amp;quot; /&amp;gt;
	&amp;lt;dataNode name=&amp;quot;dn2&amp;quot; dataHost=&amp;quot;dhost2&amp;quot; database=&amp;quot;shopping&amp;quot; /&amp;gt;
	&amp;lt;dataNode name=&amp;quot;dn3&amp;quot; dataHost=&amp;quot;dhost3&amp;quot; database=&amp;quot;shopping&amp;quot; /&amp;gt;
	
	&amp;lt;dataHost name=&amp;quot;dhost1&amp;quot; maxCon=&amp;quot;1000&amp;quot; minCon=&amp;quot;10&amp;quot; balance=&amp;quot;0&amp;quot;
			  writeType=&amp;quot;0&amp;quot; dbType=&amp;quot;mysql&amp;quot; dbDriver=&amp;quot;jdbc&amp;quot; switchType=&amp;quot;1&amp;quot;  slaveThreshold=&amp;quot;100&amp;quot;&amp;gt;
		&amp;lt;heartbeat&amp;gt;select user()&amp;lt;/heartbeat&amp;gt;
		
		&amp;lt;writeHost host=&amp;quot;master&amp;quot; url=&amp;quot;jdbc:mysql://192.168.40.210:3306?useSSL=false&amp;amp;amp;serverTimezone=Asia/Shanghai&amp;amp;amp;characterEncoding=utf8&amp;quot; user=&amp;quot;root&amp;quot; password=&amp;quot;Superman*2023&amp;quot; /&amp;gt;
	&amp;lt;/dataHost&amp;gt;
	
	&amp;lt;dataHost name=&amp;quot;dhost2&amp;quot; maxCon=&amp;quot;1000&amp;quot; minCon=&amp;quot;10&amp;quot; balance=&amp;quot;0&amp;quot;
			  writeType=&amp;quot;0&amp;quot; dbType=&amp;quot;mysql&amp;quot; dbDriver=&amp;quot;jdbc&amp;quot; switchType=&amp;quot;1&amp;quot;  slaveThreshold=&amp;quot;100&amp;quot;&amp;gt;
		&amp;lt;heartbeat&amp;gt;select user()&amp;lt;/heartbeat&amp;gt;
		
		&amp;lt;writeHost host=&amp;quot;master&amp;quot; url=&amp;quot;jdbc:mysql://192.168.40.211:3306?useSSL=false&amp;amp;amp;serverTimezone=Asia/Shanghai&amp;amp;amp;characterEncoding=utf8&amp;quot; user=&amp;quot;root&amp;quot; password=&amp;quot;Superman*2023&amp;quot; /&amp;gt;
	&amp;lt;/dataHost&amp;gt;
	
	&amp;lt;dataHost name=&amp;quot;dhost3&amp;quot; maxCon=&amp;quot;1000&amp;quot; minCon=&amp;quot;10&amp;quot; balance=&amp;quot;0&amp;quot;
			  writeType=&amp;quot;0&amp;quot; dbType=&amp;quot;mysql&amp;quot; dbDriver=&amp;quot;jdbc&amp;quot; switchType=&amp;quot;1&amp;quot;  slaveThreshold=&amp;quot;100&amp;quot;&amp;gt;
		&amp;lt;heartbeat&amp;gt;select user()&amp;lt;/heartbeat&amp;gt;
		
		&amp;lt;writeHost host=&amp;quot;master&amp;quot; url=&amp;quot;jdbc:mysql://192.168.40.212:3306?useSSL=false&amp;amp;amp;serverTimezone=Asia/Shanghai&amp;amp;amp;characterEncoding=utf8&amp;quot; user=&amp;quot;root&amp;quot; password=&amp;quot;Superman*2023&amp;quot; /&amp;gt;
	&amp;lt;/dataHost&amp;gt;
&amp;lt;/mycat:schema&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;server.xml æ–‡ä»¶é…ç½®å¦‚ä¸‹ï¼š&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@mycat ~]# cat /usr/local/mycat/conf/server.xml 
...
	&amp;lt;user name=&amp;quot;root&amp;quot;&amp;gt;
		&amp;lt;property name=&amp;quot;password&amp;quot;&amp;gt;Superman*2023&amp;lt;/property&amp;gt;
		&amp;lt;property name=&amp;quot;schemas&amp;quot;&amp;gt;SHOPPING&amp;lt;/property&amp;gt;
		
		&amp;lt;!-- è¡¨çº§ DML æƒé™è®¾ç½® --&amp;gt;
		&amp;lt;!-- 		
		&amp;lt;privileges check=&amp;quot;false&amp;quot;&amp;gt;
			&amp;lt;schema name=&amp;quot;TESTDB&amp;quot; dml=&amp;quot;0110&amp;quot; &amp;gt;
				&amp;lt;table name=&amp;quot;tb01&amp;quot; dml=&amp;quot;0000&amp;quot;&amp;gt;&amp;lt;/table&amp;gt;
				&amp;lt;table name=&amp;quot;tb02&amp;quot; dml=&amp;quot;1111&amp;quot;&amp;gt;&amp;lt;/table&amp;gt;
			&amp;lt;/schema&amp;gt;
		&amp;lt;/privileges&amp;gt;		
		 --&amp;gt;
	&amp;lt;/user&amp;gt;

	&amp;lt;user name=&amp;quot;user&amp;quot;&amp;gt;
		&amp;lt;property name=&amp;quot;password&amp;quot;&amp;gt;Superman*2023&amp;lt;/property&amp;gt;
		&amp;lt;property name=&amp;quot;schemas&amp;quot;&amp;gt;SHOPPING&amp;lt;/property&amp;gt;
		&amp;lt;property name=&amp;quot;readOnly&amp;quot;&amp;gt;true&amp;lt;/property&amp;gt;
	&amp;lt;/user&amp;gt;

&amp;lt;/mycat:server&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;åˆ†åº“åˆ†è¡¨ - MyCat åˆ†ç‰‡ - å‚ç›´åˆ†åº“ - æµ‹è¯•&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;å‚ç›´åˆ†åº“ - æµ‹è¯•&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#1.é‡å¯mycat
[root@mycat ~]# /usr/local/mycat/bin/mycat restart
Stopping Mycat-server...
Stopped Mycat-server.
Starting Mycat-server...
[root@mycat ~]# tail -f  /usr/local/mycat/logs/wrapper.log 
...
INFO   | jvm 1    | 2023/12/03 15:29:02 | MyCAT Server startup successfully. see logs in logs/mycat.log
create database shopping default charset utf8mb4;

#2.åœ¨3å°èŠ‚ç‚¹åˆ›å»ºshoppingæ•°æ®åº“
mysql&amp;gt; create database shopping default charset utf8mb4;
mysql&amp;gt; create database shopping default charset utf8mb4;
mysql&amp;gt; create database shopping default charset utf8mb4;

#3.ç™»å…¥mycat
[root@db3 ~]# mysql -h 192.168.40.213 -P 8066 -uroot -p&#39;Superman*2023&#39;
mysql&amp;gt; show databases;
+----------+
| DATABASE |
+----------+
| SHOPPING |
+----------+
1 row in set (0.01 sec)

#4.æŸ¥çœ‹é€»è¾‘åº“
mysql&amp;gt; show databases;
+----------+
| DATABASE |
+----------+
| SHOPPING |
+----------+
1 row in set (0.01 sec)

#5.åˆ‡æ¢åˆ°SHOPPINGæ•°æ®åº“
mysql&amp;gt; use SHOPPING;
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Database changed

#6.æŸ¥çœ‹é€»è¾‘è¡¨
mysql&amp;gt; show tables;
+--------------------+
| Tables in SHOPPING |
+--------------------+
| tb_areas_city      |
| tb_areas_provinces |
| tb_areas_region    |
| tb_goods_base      |
| tb_goods_brand     |
| tb_goods_cat       |
| tb_goods_desc      |
| tb_goods_item      |
| tb_order_item      |
| tb_order_master    |
| tb_order_pay_log   |
| tb_user            |
| tb_user_address    |
+--------------------+
13 rows in set (0.00 sec)

#7.ä¸Šä¼ shopping-table.sqlè¡¨ç»“æ„æ–‡ä»¶ä¸shopping-insert.sqlæ•°æ®æ–‡ä»¶

#8.æ‰§è¡Œshopping-table.sqlæ–‡ä»¶
mysql&amp;gt; source /root/shopping-table.sql

#9.æ‰§è¡Œshopping-insert.sqlæ–‡ä»¶
mysql&amp;gt; source /root/shopping-insert.sql

#10.æŸ¥çœ‹ä¸‰ä¸ªæ•°æ®åº“å¯ä»¥å‘ç°ï¼ˆæ ¹æ®schema.xmlé…ç½®æ–‡ä»¶çš„é…ç½®è¿›è¡Œäº†å®ç°ï¼‰
â‘ 192.168.40.210çš„æ•°æ®åº“ä¸­å­˜æ”¾äº† tb_goods_baseã€tb_goods_brandã€tb_goods_catã€tb_goods_descã€tb_goods_itemè¿™äº”å¼ è¡¨
â‘¡192.168.40.211çš„æ•°æ®åº“ä¸­å­˜æ”¾äº† tb_order_itemã€tb_order_masterã€tb_order_pay_logè¿™ä¸‰å¼ è¡¨ï¼›
â‘¢192.168.40.212çš„æ•°æ®åº“ä¸­å­˜æ”¾äº† tb_userã€tb_user_addressã€tb_areas_provincesã€tb_areas_cityã€tb_areas_regionè¿™äº”å¼ è¡¨
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;exam1: æŸ¥è¯¢ç”¨æˆ·çš„æ”¶ä»¶äººåŠæ”¶ä»¶äººåœ°å€ä¿¡æ¯ (åŒ…å«çœã€å¸‚ã€åŒº)ã€‚&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; select ua.user_id,ua.contact,p.province,c.city,r.area,ua.address from tb_user_address ua,tb_areas_city c,tb_areas_provinces p,tb_areas_region r where ua.province_id = p.provinceid and ua.city_id = c.cityid and ua.town_id = r.areaid;
+-----------+-----------+-----------+-----------+-----------+--------------------+
| user_id   | contact   | province  | city      | area      | address            |
+-----------+-----------+-----------+-----------+-----------+--------------------+
| deng      | å¶é—®      | åŒ—äº¬å¸‚    | å¸‚è¾–åŒº    | è¥¿åŸåŒº    | å’æ˜¥æ­¦é¦†æ€»éƒ¨       |
| java00001 | æä½³çº¢    | åŒ—äº¬å¸‚    | å¸‚è¾–åŒº    | å´‡æ–‡åŒº    | ä¿®æ­£å¤§å¦           |
| deng      | æå°é¾™    | åŒ—äº¬å¸‚    | å¸‚è¾–åŒº    | å´‡æ–‡åŒº    | æ°¸æ˜¥æ­¦é¦†           |
| zhaoliu   | èµµä¸‰      | åŒ—äº¬å¸‚    | å¸‚è¾–åŒº    | å®£æ­¦åŒº    | è¥¿ç›´é—¨             |
| java00001 | æå˜‰è¯š    | åŒ—äº¬å¸‚    | å¸‚è¾–åŒº    | æœé˜³åŒº    | é‡‘ç‡•é¾™åŠå…¬æ¥¼       |
| java00001 | æä½³æ˜Ÿ    | åŒ—äº¬å¸‚    | å¸‚è¾–åŒº    | æœé˜³åŒº    | ä¸­è…¾å¤§å¦           |
+-----------+-----------+-----------+-----------+-----------+--------------------+
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;ps: æ­¤æŸ¥è¯¢è¯­å¥åªæ¶‰åŠäº†ä¸€ä¸ªåˆ†ç‰‡æ‰€ä»¥æŸ¥è¯¢æˆåŠŸ&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;exam2: æŸ¥è¯¢æ¯ä¸€ç¬”è®¢å•åŠè®¢å•çš„æ”¶ä»¶åœ°å€ä¿¡æ¯ (åŒ…å«çœã€å¸‚ã€åŒº)ã€‚&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; SELECT order_id,payment,receiver,province,city,area FROM tb_order_master o,tb_areas_provinces p,tb_areas_city c,tb_areas_region r WHERE o.receiver_province = p.provinceid AND o.receiver_city = c.cityid AND o.receiver_region = r.areaid;
ERROR 1064 (HY000): invalid route in sql, multi tables found but datanode has no intersection  sql:SELECT order_id,payment,receiver,province,city,area FROM tb_order_master o,tb_areas_provinces p,tb_areas_city c,tb_areas_region r WHERE o.receiver_province = p.provinceid AND o.receiver_city = c.cityid AND o.receiver_region = r.areaid
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;ps: æ­¤æŸ¥è¯¢è¯­å¥æ¶‰åŠå¤šä¸ªåˆ†ç‰‡æ‰€ä»¥æŸ¥è¯¢æŠ¥é”™ï¼Œä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜éœ€è¦è¿›è¡Œå…¨å±€è¡¨é…ç½®&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;å…¨å±€è¡¨é…ç½®&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;å¯¹äºçœã€å¸‚ã€åŒº / å¿è¡¨ tb_areas_provincesï¼Œtb_areas_cityï¼Œtb_areas_regionï¼Œæ˜¯å±äºæ•°æ®å­—å…¸è¡¨ï¼Œåœ¨å¤šä¸ªä¸šåŠ¡æ¨¡å—ä¸­éƒ½å¯èƒ½ä¼šé‡åˆ°ï¼Œå¯ä»¥å°†å…¶è®¾ç½®ä¸ºå…¨å±€è¡¨ï¼Œåˆ©äºä¸šåŠ¡æ“ä½œã€‚&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/EqJJ3Yv.png&#34; alt=&#34;22.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. ä¿®æ”¹ MyCatâ€”schema.xml æ–‡ä»¶é…ç½®&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;schema.xml æ–‡ä»¶é…ç½®å¦‚ä¸‹ï¼š&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@mycat ~]# cat /usr/local/mycat/conf/schema.xml 
&amp;lt;?xml version=&amp;quot;1.0&amp;quot;?&amp;gt;
&amp;lt;!DOCTYPE mycat:schema SYSTEM &amp;quot;schema.dtd&amp;quot;&amp;gt;
&amp;lt;mycat:schema xmlns:mycat=&amp;quot;http://io.mycat/&amp;quot;&amp;gt;
	&amp;lt;schema name=&amp;quot;SHOPPING&amp;quot; checkSQLschema=&amp;quot;true&amp;quot; sqlMaxLimit=&amp;quot;100&amp;quot;&amp;gt;
		&amp;lt;table name=&amp;quot;tb_goods_base&amp;quot; dataNode=&amp;quot;dn1&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_goods_brand&amp;quot; dataNode=&amp;quot;dn1&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_goods_cat&amp;quot; dataNode=&amp;quot;dn1&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_goods_desc&amp;quot; dataNode=&amp;quot;dn1&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_goods_item&amp;quot; dataNode=&amp;quot;dn1&amp;quot; primaryKey=&amp;quot;goods_id&amp;quot; /&amp;gt;
		
		&amp;lt;table name=&amp;quot;tb_order_item&amp;quot; dataNode=&amp;quot;dn2&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_order_master&amp;quot; dataNode=&amp;quot;dn2&amp;quot; primaryKey=&amp;quot;order_id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_order_pay_log&amp;quot; dataNode=&amp;quot;dn2&amp;quot; primaryKey=&amp;quot;out_trade_no&amp;quot; /&amp;gt;
		
		&amp;lt;table name=&amp;quot;tb_user&amp;quot; dataNode=&amp;quot;dn3&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_user_address&amp;quot; dataNode=&amp;quot;dn3&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;

		&amp;lt;table name=&amp;quot;tb_areas_provinces&amp;quot; dataNode=&amp;quot;dn1,dn2,dn3&amp;quot; primaryKey=&amp;quot;id&amp;quot; type=&amp;quot;global&amp;quot;/&amp;gt;
		&amp;lt;table name=&amp;quot;tb_areas_city&amp;quot; dataNode=&amp;quot;dn1,dn2,dn3&amp;quot; primaryKey=&amp;quot;id&amp;quot; type=&amp;quot;global&amp;quot;/&amp;gt;
		&amp;lt;table name=&amp;quot;tb_areas_region&amp;quot; dataNode=&amp;quot;dn1,dn2,dn3&amp;quot; primaryKey=&amp;quot;id&amp;quot; type=&amp;quot;global&amp;quot; /&amp;gt;
	&amp;lt;/schema&amp;gt;
	
	&amp;lt;dataNode name=&amp;quot;dn1&amp;quot; dataHost=&amp;quot;dhost1&amp;quot; database=&amp;quot;shopping&amp;quot; /&amp;gt;
	&amp;lt;dataNode name=&amp;quot;dn2&amp;quot; dataHost=&amp;quot;dhost2&amp;quot; database=&amp;quot;shopping&amp;quot; /&amp;gt;
	&amp;lt;dataNode name=&amp;quot;dn3&amp;quot; dataHost=&amp;quot;dhost3&amp;quot; database=&amp;quot;shopping&amp;quot; /&amp;gt;
	
	&amp;lt;dataHost name=&amp;quot;dhost1&amp;quot; maxCon=&amp;quot;1000&amp;quot; minCon=&amp;quot;10&amp;quot; balance=&amp;quot;0&amp;quot;
			  writeType=&amp;quot;0&amp;quot; dbType=&amp;quot;mysql&amp;quot; dbDriver=&amp;quot;jdbc&amp;quot; switchType=&amp;quot;1&amp;quot;  slaveThreshold=&amp;quot;100&amp;quot;&amp;gt;
		&amp;lt;heartbeat&amp;gt;select user()&amp;lt;/heartbeat&amp;gt;
		
		&amp;lt;writeHost host=&amp;quot;master&amp;quot; url=&amp;quot;jdbc:mysql://192.168.40.210:3306?useSSL=false&amp;amp;amp;serverTimezone=Asia/Shanghai&amp;amp;amp;characterEncoding=utf8&amp;quot; user=&amp;quot;root&amp;quot; password=&amp;quot;Superman*2023&amp;quot; /&amp;gt;
	&amp;lt;/dataHost&amp;gt;
	
	&amp;lt;dataHost name=&amp;quot;dhost2&amp;quot; maxCon=&amp;quot;1000&amp;quot; minCon=&amp;quot;10&amp;quot; balance=&amp;quot;0&amp;quot;
			  writeType=&amp;quot;0&amp;quot; dbType=&amp;quot;mysql&amp;quot; dbDriver=&amp;quot;jdbc&amp;quot; switchType=&amp;quot;1&amp;quot;  slaveThreshold=&amp;quot;100&amp;quot;&amp;gt;
		&amp;lt;heartbeat&amp;gt;select user()&amp;lt;/heartbeat&amp;gt;
		
		&amp;lt;writeHost host=&amp;quot;master&amp;quot; url=&amp;quot;jdbc:mysql://192.168.40.211:3306?useSSL=false&amp;amp;amp;serverTimezone=Asia/Shanghai&amp;amp;amp;characterEncoding=utf8&amp;quot; user=&amp;quot;root&amp;quot; password=&amp;quot;Superman*2023&amp;quot; /&amp;gt;
	&amp;lt;/dataHost&amp;gt;
	
	&amp;lt;dataHost name=&amp;quot;dhost3&amp;quot; maxCon=&amp;quot;1000&amp;quot; minCon=&amp;quot;10&amp;quot; balance=&amp;quot;0&amp;quot;
			  writeType=&amp;quot;0&amp;quot; dbType=&amp;quot;mysql&amp;quot; dbDriver=&amp;quot;jdbc&amp;quot; switchType=&amp;quot;1&amp;quot;  slaveThreshold=&amp;quot;100&amp;quot;&amp;gt;
		&amp;lt;heartbeat&amp;gt;select user()&amp;lt;/heartbeat&amp;gt;
		
		&amp;lt;writeHost host=&amp;quot;master&amp;quot; url=&amp;quot;jdbc:mysql://192.168.40.212:3306?useSSL=false&amp;amp;amp;serverTimezone=Asia/Shanghai&amp;amp;amp;characterEncoding=utf8&amp;quot; user=&amp;quot;root&amp;quot; password=&amp;quot;Superman*2023&amp;quot; /&amp;gt;
	&amp;lt;/dataHost&amp;gt;
&amp;lt;/mycat:schema&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;2. å…¨å±€è¡¨æµ‹è¯•&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#1.åˆ é™¤3ä¸ªèŠ‚ç‚¹ä¸ŠåŸæœ‰è¡¨

#2.é‡å¯mycat
[root@mycat ~]# /usr/local/mycat/bin/mycat restart
Stopping Mycat-server...
Stopped Mycat-server.
Starting Mycat-server...
[root@mycat ~]# tail -f  /usr/local/mycat/logs/wrapper.log 
...
INFO   | jvm 1    | 2023/12/03 15:29:02 | MyCAT Server startup successfully. see logs in logs/mycat.log
create database shopping default charset utf8mb4;

#3.æ‰§è¡Œshopping-table.sqlæ–‡ä»¶
[root@db3 ~]# mysql -h 192.168.40.213 -P 8066 -uroot -p&#39;Superman*2023&#39;
mysql&amp;gt; source /root/shopping-table.sql

#4.æ‰§è¡Œshopping-insert.sqlæ–‡ä»¶
mysql&amp;gt; source /root/shopping-insert.sql

#5 exam1:æŸ¥è¯¢ç”¨æˆ·çš„æ”¶ä»¶äººåŠæ”¶ä»¶äººåœ°å€ä¿¡æ¯(åŒ…å«çœã€å¸‚ã€åŒº)ã€‚
mysql&amp;gt; select ua.user_id,ua.contact,p.province,c.city,r.area,ua.address from tb_user_address ua,tb_areas_city c,tb_areas_provinces p,tb_areas_region r where ua.province_id = p.provinceid and ua.city_id = c.cityid and ua.town_id = r.areaid;

#6 exam2:æŸ¥è¯¢æ¯ä¸€ç¬”è®¢å•åŠè®¢å•çš„æ”¶ä»¶åœ°å€ä¿¡æ¯(åŒ…å«çœã€å¸‚ã€åŒº)
mysql&amp;gt; SELECT order_id,payment,receiver,province,city,area FROM tb_order_master o,tb_areas_provinces p,tb_areas_city c,tb_areas_region r WHERE o.receiver_province = p.provinceid AND o.receiver_city = c.cityid AND o.receiver_region = r.areaid;
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;342-åˆ†åº“åˆ†è¡¨-mycatåˆ†ç‰‡-æ°´å¹³åˆ†è¡¨&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#342-åˆ†åº“åˆ†è¡¨-mycatåˆ†ç‰‡-æ°´å¹³åˆ†è¡¨&#34;&gt;#&lt;/a&gt; 3.4.2 åˆ†åº“åˆ†è¡¨ - MyCat åˆ†ç‰‡ - æ°´å¹³åˆ†è¡¨&lt;/h6&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æ°´å¹³åˆ†è¡¨&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;åœºæ™¯&lt;/strong&gt;ï¼šåœ¨ä¸šåŠ¡ç³»ç»Ÿä¸­ï¼Œæœ‰ä¸€å¼ è¡¨ï¼ˆæ—¥å¿—è¡¨ï¼‰ï¼Œä¸šåŠ¡ç³»ç»Ÿæ¯å¤©éƒ½ä¼šäº§ç”Ÿå¤§é‡çš„æ—¥å¿—æ•°æ®ï¼Œå•å°æœåŠ¡å™¨çš„æ•°æ®å­˜å‚¨åŠå¤„ç†èƒ½åŠ›æ˜¯æœ‰é™çš„ï¼Œå¯ä»¥å¯¹æ•°æ®åº“è¡¨è¿›è¡Œæ‹†åˆ†ã€‚&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/0kMP4Ru.png&#34; alt=&#34;23.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;å‡†å¤‡ç¯å¢ƒï¼š&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;â‘ å¦‚å›¾æ‰€ç¤ºå‡†å¤‡ä¸‰å° Linux æœåŠ¡å™¨ï¼ˆip ä¸ºï¼š192.168.40.210ã€192.168.40.211ã€192.168.40.212ï¼‰å¯ä»¥æ ¹æ®è‡ªå·±çš„å®é™…æƒ…å†µè¿›è¡Œå‡†å¤‡ã€‚&lt;br /&gt;
â‘¡ä¸‰å°æœåŠ¡å™¨ä¸Šéƒ½å®‰è£… MySQLï¼Œåœ¨ 192.168.40.213 æœåŠ¡å™¨ä¸Šå®‰è£… MyCatã€‚&lt;br /&gt;
â‘¢ä¸‰å°æœåŠ¡å™¨å…³é—­é˜²ç«å¢™æˆ–è€…å¼€æ”¾å¯¹åº”çš„ç«¯å£ã€‚&lt;br /&gt;
â‘£åˆ†åˆ«åœ¨ä¸‰å° MySQL ä¸­åˆ›å»ºæ•°æ®åº“ itcastã€‚&lt;br /&gt;
&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/zTm8XwU.png&#34; alt=&#34;24.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. ä¸‰å° MySQL ä¸­åˆ›å»ºæ•°æ®åº“ itcast&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; create database itcast default charset utf8mb4;
mysql&amp;gt; create database itcast default charset utf8mb4;
mysql&amp;gt; create database itcast default charset utf8mb4;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;2.MyCatâ€”server.xml æ–‡ä»¶é…ç½®&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;server.xml æ–‡ä»¶é…ç½®å¦‚ä¸‹ï¼š&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@mycat ~]# cat /usr/local/mycat/conf/schema.xml 
&amp;lt;?xml version=&amp;quot;1.0&amp;quot;?&amp;gt;
&amp;lt;!DOCTYPE mycat:schema SYSTEM &amp;quot;schema.dtd&amp;quot;&amp;gt;
&amp;lt;mycat:schema xmlns:mycat=&amp;quot;http://io.mycat/&amp;quot;&amp;gt;
	&amp;lt;schema name=&amp;quot;SHOPPING&amp;quot; checkSQLschema=&amp;quot;true&amp;quot; sqlMaxLimit=&amp;quot;100&amp;quot;&amp;gt;
		&amp;lt;table name=&amp;quot;tb_goods_base&amp;quot; dataNode=&amp;quot;dn1&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_goods_brand&amp;quot; dataNode=&amp;quot;dn1&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_goods_cat&amp;quot; dataNode=&amp;quot;dn1&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_goods_desc&amp;quot; dataNode=&amp;quot;dn1&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_goods_item&amp;quot; dataNode=&amp;quot;dn1&amp;quot; primaryKey=&amp;quot;goods_id&amp;quot; /&amp;gt;
		
		&amp;lt;table name=&amp;quot;tb_order_item&amp;quot; dataNode=&amp;quot;dn2&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_order_master&amp;quot; dataNode=&amp;quot;dn2&amp;quot; primaryKey=&amp;quot;order_id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_order_pay_log&amp;quot; dataNode=&amp;quot;dn2&amp;quot; primaryKey=&amp;quot;out_trade_no&amp;quot; /&amp;gt;
		
		&amp;lt;table name=&amp;quot;tb_user&amp;quot; dataNode=&amp;quot;dn3&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_user_address&amp;quot; dataNode=&amp;quot;dn3&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;

                &amp;lt;table name=&amp;quot;tb_areas_provinces&amp;quot; dataNode=&amp;quot;dn1,dn2,dn3&amp;quot; primaryKey=&amp;quot;id&amp;quot; type=&amp;quot;global&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_areas_city&amp;quot; dataNode=&amp;quot;dn1,dn2,dn3&amp;quot; primaryKey=&amp;quot;id&amp;quot; type=&amp;quot;global&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_areas_region&amp;quot; dataNode=&amp;quot;dn1,dn2,dn3&amp;quot; primaryKey=&amp;quot;id&amp;quot; type=&amp;quot;global&amp;quot; /&amp;gt;
	&amp;lt;/schema&amp;gt;

        &amp;lt;schema name=&amp;quot;ITCAST&amp;quot; checkSQLschema=&amp;quot;true&amp;quot; sqlMaxLimit=&amp;quot;100&amp;quot;&amp;gt;
        	&amp;lt;table name=&amp;quot;tb_log&amp;quot; dataNode=&amp;quot;dn4,dn5,dn6&amp;quot; primaryKey=&amp;quot;id&amp;quot; rule=&amp;quot;mod-long&amp;quot; /&amp;gt;
        &amp;lt;/schema&amp;gt;
	
	&amp;lt;dataNode name=&amp;quot;dn1&amp;quot; dataHost=&amp;quot;dhost1&amp;quot; database=&amp;quot;shopping&amp;quot; /&amp;gt;
	&amp;lt;dataNode name=&amp;quot;dn2&amp;quot; dataHost=&amp;quot;dhost2&amp;quot; database=&amp;quot;shopping&amp;quot; /&amp;gt;
	&amp;lt;dataNode name=&amp;quot;dn3&amp;quot; dataHost=&amp;quot;dhost3&amp;quot; database=&amp;quot;shopping&amp;quot; /&amp;gt;

	&amp;lt;dataNode name=&amp;quot;dn4&amp;quot; dataHost=&amp;quot;dhost1&amp;quot; database=&amp;quot;itcast&amp;quot; /&amp;gt;
	&amp;lt;dataNode name=&amp;quot;dn5&amp;quot; dataHost=&amp;quot;dhost2&amp;quot; database=&amp;quot;itcast&amp;quot; /&amp;gt;
	&amp;lt;dataNode name=&amp;quot;dn6&amp;quot; dataHost=&amp;quot;dhost3&amp;quot; database=&amp;quot;itcast&amp;quot; /&amp;gt;
	
	&amp;lt;dataHost name=&amp;quot;dhost1&amp;quot; maxCon=&amp;quot;1000&amp;quot; minCon=&amp;quot;10&amp;quot; balance=&amp;quot;0&amp;quot;
			  writeType=&amp;quot;0&amp;quot; dbType=&amp;quot;mysql&amp;quot; dbDriver=&amp;quot;jdbc&amp;quot; switchType=&amp;quot;1&amp;quot;  slaveThreshold=&amp;quot;100&amp;quot;&amp;gt;
		&amp;lt;heartbeat&amp;gt;select user()&amp;lt;/heartbeat&amp;gt;
		
		&amp;lt;writeHost host=&amp;quot;master&amp;quot; url=&amp;quot;jdbc:mysql://192.168.40.210:3306?useSSL=false&amp;amp;amp;serverTimezone=Asia/Shanghai&amp;amp;amp;characterEncoding=utf8&amp;quot; user=&amp;quot;root&amp;quot; password=&amp;quot;Superman*2023&amp;quot; /&amp;gt;
	&amp;lt;/dataHost&amp;gt;
	
	&amp;lt;dataHost name=&amp;quot;dhost2&amp;quot; maxCon=&amp;quot;1000&amp;quot; minCon=&amp;quot;10&amp;quot; balance=&amp;quot;0&amp;quot;
			  writeType=&amp;quot;0&amp;quot; dbType=&amp;quot;mysql&amp;quot; dbDriver=&amp;quot;jdbc&amp;quot; switchType=&amp;quot;1&amp;quot;  slaveThreshold=&amp;quot;100&amp;quot;&amp;gt;
		&amp;lt;heartbeat&amp;gt;select user()&amp;lt;/heartbeat&amp;gt;
		
		&amp;lt;writeHost host=&amp;quot;master&amp;quot; url=&amp;quot;jdbc:mysql://192.168.40.211:3306?useSSL=false&amp;amp;amp;serverTimezone=Asia/Shanghai&amp;amp;amp;characterEncoding=utf8&amp;quot; user=&amp;quot;root&amp;quot; password=&amp;quot;Superman*2023&amp;quot; /&amp;gt;
	&amp;lt;/dataHost&amp;gt;
	
	&amp;lt;dataHost name=&amp;quot;dhost3&amp;quot; maxCon=&amp;quot;1000&amp;quot; minCon=&amp;quot;10&amp;quot; balance=&amp;quot;0&amp;quot;
			  writeType=&amp;quot;0&amp;quot; dbType=&amp;quot;mysql&amp;quot; dbDriver=&amp;quot;jdbc&amp;quot; switchType=&amp;quot;1&amp;quot;  slaveThreshold=&amp;quot;100&amp;quot;&amp;gt;
		&amp;lt;heartbeat&amp;gt;select user()&amp;lt;/heartbeat&amp;gt;
		
		&amp;lt;writeHost host=&amp;quot;master&amp;quot; url=&amp;quot;jdbc:mysql://192.168.40.212:3306?useSSL=false&amp;amp;amp;serverTimezone=Asia/Shanghai&amp;amp;amp;characterEncoding=utf8&amp;quot; user=&amp;quot;root&amp;quot; password=&amp;quot;Superman*2023&amp;quot; /&amp;gt;
	&amp;lt;/dataHost&amp;gt;
&amp;lt;/mycat:schema&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;3.MyCatâ€”server.xml æ–‡ä»¶é…ç½®&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;server.xml æ–‡ä»¶é…ç½®å¦‚ä¸‹ï¼š&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@mycat ~]# cat /usr/local/mycat/conf/server.xml 
...
	&amp;lt;user name=&amp;quot;root&amp;quot;&amp;gt;
		&amp;lt;property name=&amp;quot;password&amp;quot;&amp;gt;Superman*2023&amp;lt;/property&amp;gt;
		&amp;lt;property name=&amp;quot;schemas&amp;quot;&amp;gt;SHOPPING,ITCAST&amp;lt;/property&amp;gt;
		
		&amp;lt;!-- è¡¨çº§ DML æƒé™è®¾ç½® --&amp;gt;
		&amp;lt;!-- 		
		&amp;lt;privileges check=&amp;quot;false&amp;quot;&amp;gt;
			&amp;lt;schema name=&amp;quot;TESTDB&amp;quot; dml=&amp;quot;0110&amp;quot; &amp;gt;
				&amp;lt;table name=&amp;quot;tb01&amp;quot; dml=&amp;quot;0000&amp;quot;&amp;gt;&amp;lt;/table&amp;gt;
				&amp;lt;table name=&amp;quot;tb02&amp;quot; dml=&amp;quot;1111&amp;quot;&amp;gt;&amp;lt;/table&amp;gt;
			&amp;lt;/schema&amp;gt;
		&amp;lt;/privileges&amp;gt;		
		 --&amp;gt;
	&amp;lt;/user&amp;gt;

	&amp;lt;user name=&amp;quot;user&amp;quot;&amp;gt;
		&amp;lt;property name=&amp;quot;password&amp;quot;&amp;gt;Superman*2023&amp;lt;/property&amp;gt;
		&amp;lt;property name=&amp;quot;schemas&amp;quot;&amp;gt;SHOPPING,ITCAST&amp;lt;/property&amp;gt;
		&amp;lt;property name=&amp;quot;readOnly&amp;quot;&amp;gt;true&amp;lt;/property&amp;gt;
	&amp;lt;/user&amp;gt;

&amp;lt;/mycat:server&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;4.MyCat å¯åŠ¨&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#1.é‡å¯mycat
[root@mycat ~]# /usr/local/mycat/bin/mycat restart
Stopping Mycat-server...
Stopped Mycat-server.
Starting Mycat-server...
[root@mycat ~]# tail -f  /usr/local/mycat/logs/wrapper.log 
...
INFO   | jvm 1    | 2023/12/03 15:29:02 | MyCAT Server startup successfully. see logs in logs/mycat.log
create database shopping default charset utf8mb4;

#2.ç™»å…¥mycat
[root@db3 ~]# mysql -h 192.168.40.213 -P 8066 -uroot -p&#39;Superman*2023&#39;
mysql&amp;gt; show databases;
+----------+
| DATABASE |
+----------+
| ITCAST   |
| SHOPPING |
+----------+
2 rows in set (0.00 sec)

mysql&amp;gt; use ITCAST;
mysql&amp;gt; show tables;
+------------------+
| Tables in ITCAST |
+------------------+
| tb_log           |
+------------------+

#3.åˆ›å»ºè¡¨ç»“æ„åŠæ•°æ®å¯¼å…¥
mysql&amp;gt; CREATE TABLE tb_log (
    -&amp;gt;   id bigint(20) NOT NULL COMMENT &#39;ID&#39;,
    -&amp;gt;   model_name varchar(200) DEFAULT NULL COMMENT &#39;æ¨¡å—å&#39;,
    -&amp;gt;   model_value varchar(200) DEFAULT NULL COMMENT &#39;æ¨¡å—å€¼&#39;,
    -&amp;gt;   return_value varchar(200) DEFAULT NULL COMMENT &#39;è¿”å›å€¼&#39;,
    -&amp;gt;   return_class varchar(200) DEFAULT NULL COMMENT &#39;è¿”å›å€¼ç±»å‹&#39;,
    -&amp;gt;   operate_user varchar(20) DEFAULT NULL COMMENT &#39;æ“ä½œç”¨æˆ·&#39;,
    -&amp;gt;   operate_time varchar(20) DEFAULT NULL COMMENT &#39;æ“ä½œæ—¶é—´&#39;,
    -&amp;gt;   param_and_value varchar(500) DEFAULT NULL COMMENT &#39;è¯·æ±‚å‚æ•°ååŠå‚æ•°å€¼&#39;,
    -&amp;gt;   operate_class varchar(200) DEFAULT NULL COMMENT &#39;æ“ä½œç±»&#39;,
    -&amp;gt;   operate_method varchar(200) DEFAULT NULL COMMENT &#39;æ“ä½œæ–¹æ³•&#39;,
    -&amp;gt;   cost_time bigint(20) DEFAULT NULL COMMENT &#39;æ‰§è¡Œæ–¹æ³•è€—æ—¶, å•ä½ ms&#39;,
    -&amp;gt;   source int(1) DEFAULT NULL COMMENT &#39;æ¥æº : 1 PC , 2 Android , 3 IOS&#39;,
    -&amp;gt;   PRIMARY KEY (id)
    -&amp;gt; ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
Query OK, 0 rows affected (0.09 sec)
 OK!
æŸ¥çœ‹ä¸‰ä¸ªæ•°æ®åº“å¯ä»¥å‘ç°è¡¨å’Œè¡¨ç»“æ„éƒ½æœ‰äº†

#4.æ·»åŠ æ•°æ®
INSERT INTO tb_log (id, model_name, model_value, return_value, return_class, operate_user, operate_time, param_and_value, operate_class, operate_method, cost_timeï¼Œsource) VALUES(&#39;1&#39;,&#39;user&#39;,&#39;insert&#39;,&#39;success&#39;,&#39;java.lang.String&#39;,&#39;10001&#39;,&#39;2022-01-06 18:12:28&#39;,&#39;&amp;#123;\&amp;quot;age\&amp;quot;:\&amp;quot;20\&amp;quot;,\&amp;quot;name\&amp;quot;:\&amp;quot;Tom\&amp;quot;,\&amp;quot;gender\&amp;quot;:\&amp;quot;1\&amp;quot;&amp;#125;&#39;,&#39;cn.itcast.controller.UserController&#39;,&#39;insert&#39;,&#39;10&#39;,1);
INSERT INTO tb_log (id, model_name, model_value, return_value, return_class, operate_user, operate_time, param_and_value, operate_class, operate_method, cost_timeï¼Œsource) VALUES(&#39;2&#39;,&#39;user&#39;,&#39;insert&#39;,&#39;success&#39;,&#39;java.lang.String&#39;,&#39;10001&#39;,&#39;2022-01-06 18:12:27&#39;,&#39;&amp;#123;\&amp;quot;age\&amp;quot;:\&amp;quot;20\&amp;quot;,\&amp;quot;name\&amp;quot;:\&amp;quot;Tom\&amp;quot;,\&amp;quot;gender\&amp;quot;:\&amp;quot;1\&amp;quot;&amp;#125;&#39;,&#39;cn.itcast.controller.UserController&#39;,&#39;insert&#39;,&#39;23&#39;,1);
INSERT INTO tb_log (id, model_name, model_value, return_value, return_class, operate_user, operate_time, param_and_value, operate_class, operate_method, cost_timeï¼Œsource) VALUES(&#39;3&#39;,&#39;user&#39;,&#39;update&#39;,&#39;success&#39;,&#39;java.lang.String&#39;,&#39;10001&#39;,&#39;2022-01-06 18:16:45&#39;,&#39;&amp;#123;\&amp;quot;age\&amp;quot;:\&amp;quot;20\&amp;quot;,\&amp;quot;name\&amp;quot;:\&amp;quot;Tom\&amp;quot;,\&amp;quot;gender\&amp;quot;:\&amp;quot;1\&amp;quot;&amp;#125;&#39;,&#39;cn.itcast.controller.UserController&#39;,&#39;update&#39;,&#39;34&#39;,1);
INSERT INTO tb_log (id, model_name, model_value, return_value, return_class, operate_user, operate_time, param_and_value, operate_class, operate_method, cost_timeï¼Œsource) VALUES(&#39;4&#39;,&#39;user&#39;,&#39;update&#39;,&#39;success&#39;,&#39;java.lang.String&#39;,&#39;10001&#39;,&#39;2022-01-06 18:16:45&#39;,&#39;&amp;#123;\&amp;quot;age\&amp;quot;:\&amp;quot;20\&amp;quot;,\&amp;quot;name\&amp;quot;:\&amp;quot;Tom\&amp;quot;,\&amp;quot;gender\&amp;quot;:\&amp;quot;1\&amp;quot;&amp;#125;&#39;,&#39;cn.itcast.controller.UserController&#39;,&#39;update&#39;,&#39;13&#39;,2);
INSERT INTO tb_log (id, model_name, model_value, return_value, return_class, operate_user, operate_time, param_and_value, operate_class, operate_method, cost_timeï¼Œsource) VALUES(&#39;5&#39;,&#39;user&#39;,&#39;insert&#39;,&#39;success&#39;,&#39;java.lang.String&#39;,&#39;10001&#39;,&#39;2022-01-06 18:30:31&#39;,&#39;&amp;#123;\&amp;quot;age\&amp;quot;:\&amp;quot;200\&amp;quot;,\&amp;quot;name\&amp;quot;:\&amp;quot;TomCat\&amp;quot;,\&amp;quot;gender\&amp;quot;:\&amp;quot;0\&amp;quot;&amp;#125;&#39;,&#39;cn.itcast.controller.UserController&#39;,&#39;insert&#39;,&#39;29&#39;,3);
INSERT INTO tb_log (id, model_name, model_value, return_value, return_class, operate_user, operate_time, param_and_value, operate_class, operate_method, cost_timeï¼Œsource) VALUES(&#39;6&#39;,&#39;user&#39;,&#39;find&#39;,&#39;success&#39;,&#39;java.lang.String&#39;,&#39;10001&#39;,&#39;2022-01-06 18:30:31&#39;,&#39;&amp;#123;\&amp;quot;age\&amp;quot;:\&amp;quot;200\&amp;quot;,\&amp;quot;name\&amp;quot;:\&amp;quot;TomCat\&amp;quot;,\&amp;quot;gender\&amp;quot;:\&amp;quot;0\&amp;quot;&amp;#125;&#39;,&#39;cn.itcast.controller.UserController&#39;,&#39;find&#39;,&#39;29&#39;,2);

æŸ¥çœ‹ä¸‰ä¸ªæ•°æ®åº“å†…çš„tb_logè¡¨å‘ç°æœ‰æ•°æ®äº†ï¼Œæ•°æ®çš„åˆ†å¸ƒè§„åˆ™æ˜¯ idæ¨¡ä»¥3çš„ç»“æœä¸º0çš„æ•°æ®åˆ†å¸ƒåœ¨ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ï¼Œidæ¨¡ä»¥3çš„ç»“æœä¸º1çš„æ•°æ®åˆ†å¸ƒåœ¨ç¬¬äºŒä¸ªèŠ‚ç‚¹ï¼Œidæ¨¡ä»¥3çš„ç»“æœä¸º2çš„æ•°æ®åˆ†å¸ƒåœ¨ç¬¬ä¸‰ä¸ªèŠ‚ç‚¹
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;33-åˆ†åº“åˆ†è¡¨-åˆ†ç‰‡è§„åˆ™&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#33-åˆ†åº“åˆ†è¡¨-åˆ†ç‰‡è§„åˆ™&#34;&gt;#&lt;/a&gt; 3.3 åˆ†åº“åˆ†è¡¨ - åˆ†ç‰‡è§„åˆ™&lt;/h5&gt;
&lt;h6 id=&#34;331-åˆ†åº“åˆ†è¡¨-åˆ†ç‰‡è§„åˆ™-èŒƒå›´åˆ†ç‰‡&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#331-åˆ†åº“åˆ†è¡¨-åˆ†ç‰‡è§„åˆ™-èŒƒå›´åˆ†ç‰‡&#34;&gt;#&lt;/a&gt; 3.3.1 åˆ†åº“åˆ†è¡¨ - åˆ†ç‰‡è§„åˆ™ - èŒƒå›´åˆ†ç‰‡&lt;/h6&gt;
&lt;p&gt;&lt;strong&gt;èŒƒå›´åˆ†ç‰‡&lt;/strong&gt;ï¼šæ ¹æ®æŒ‡å®šçš„å­—æ®µåŠå…¶é…ç½®çš„èŒƒå›´ä¸æ•°æ®èŠ‚ç‚¹çš„å¯¹åº”æƒ…å†µï¼Œæ¥å†³å®šè¯¥æ•°æ®å±äºå“ªä¸€ä¸ªåˆ†ç‰‡ã€‚&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/sdd8bvs.png&#34; alt=&#34;25.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/R3ecZ4k.png&#34; alt=&#34;26.png&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@mycat ~]# cat /usr/local/mycat/conf/autopartition-long.txt
# range start-end ,data node index
# K=1000,M=10000.
0-500M=0
500M-1000M=1
1000M-1500M=2
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;332-åˆ†åº“åˆ†è¡¨-åˆ†ç‰‡è§„åˆ™-å–æ¨¡åˆ†ç‰‡&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#332-åˆ†åº“åˆ†è¡¨-åˆ†ç‰‡è§„åˆ™-å–æ¨¡åˆ†ç‰‡&#34;&gt;#&lt;/a&gt; 3.3.2 åˆ†åº“åˆ†è¡¨ - åˆ†ç‰‡è§„åˆ™ - å–æ¨¡åˆ†ç‰‡&lt;/h6&gt;
&lt;p&gt;&lt;strong&gt;å–æ¨¡åˆ†ç‰‡&lt;/strong&gt;ï¼šæ ¹æ®æŒ‡å®šçš„å­—æ®µå€¼ä¸èŠ‚ç‚¹æ•°é‡è¿›è¡Œæ±‚æ¨¡è¿ç®—ï¼Œæ ¹æ®è¿ç®—ç»“æœï¼Œæ¥å†³å®šè¯¥æ•°æ®å±äºå“ªä¸€ä¸ªåˆ†ç‰‡ã€‚&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/Xvn6sHi.png&#34; alt=&#34;1.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/aaey4H2.png&#34; alt=&#34;2.png&#34; /&gt;&lt;/p&gt;
&lt;h6 id=&#34;333-åˆ†åº“åˆ†è¡¨-åˆ†ç‰‡è§„åˆ™-ä¸€è‡´æ€§hashç®—æ³•&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#333-åˆ†åº“åˆ†è¡¨-åˆ†ç‰‡è§„åˆ™-ä¸€è‡´æ€§hashç®—æ³•&#34;&gt;#&lt;/a&gt; 3.3.3 åˆ†åº“åˆ†è¡¨ - åˆ†ç‰‡è§„åˆ™ - ä¸€è‡´æ€§ hash ç®—æ³•&lt;/h6&gt;
&lt;p&gt;&lt;strong&gt;ä¸€è‡´æ€§ hash ç®—æ³•&lt;/strong&gt;ï¼šæ‰€è°“ä¸€è‡´æ€§å“ˆå¸Œï¼Œç›¸åŒçš„å“ˆå¸Œå› å­è®¡ç®—å€¼æ€»æ˜¯è¢«åˆ’åˆ†åˆ°ç›¸åŒçš„åˆ†åŒºè¡¨ä¸­ï¼Œä¸ä¼šå› ä¸ºåˆ†åŒºèŠ‚ç‚¹çš„å¢åŠ è€Œæ”¹å˜åŸæ¥æ•°æ®çš„åˆ†åŒºä½ç½®ã€‚&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/6ANYtsD.png&#34; alt=&#34;3.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://wp-cdn.4ce.cn/v2/8i8c5Le.png&#34; alt=&#34;4.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ä¸€è‡´æ€§ hash æµ‹è¯•&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;schema.xml é…ç½®&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@mycat ~]# cat /usr/local/mycat/conf/schema.xml 
&amp;lt;?xml version=&amp;quot;1.0&amp;quot;?&amp;gt;
&amp;lt;!DOCTYPE mycat:schema SYSTEM &amp;quot;schema.dtd&amp;quot;&amp;gt;
&amp;lt;mycat:schema xmlns:mycat=&amp;quot;http://io.mycat/&amp;quot;&amp;gt;
	&amp;lt;schema name=&amp;quot;SHOPPING&amp;quot; checkSQLschema=&amp;quot;true&amp;quot; sqlMaxLimit=&amp;quot;100&amp;quot;&amp;gt;
		&amp;lt;table name=&amp;quot;tb_goods_base&amp;quot; dataNode=&amp;quot;dn1&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_goods_brand&amp;quot; dataNode=&amp;quot;dn1&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_goods_cat&amp;quot; dataNode=&amp;quot;dn1&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_goods_desc&amp;quot; dataNode=&amp;quot;dn1&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_goods_item&amp;quot; dataNode=&amp;quot;dn1&amp;quot; primaryKey=&amp;quot;goods_id&amp;quot; /&amp;gt;
		
		&amp;lt;table name=&amp;quot;tb_order_item&amp;quot; dataNode=&amp;quot;dn2&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_order_master&amp;quot; dataNode=&amp;quot;dn2&amp;quot; primaryKey=&amp;quot;order_id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_order_pay_log&amp;quot; dataNode=&amp;quot;dn2&amp;quot; primaryKey=&amp;quot;out_trade_no&amp;quot; /&amp;gt;
		
		&amp;lt;table name=&amp;quot;tb_user&amp;quot; dataNode=&amp;quot;dn3&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_user_address&amp;quot; dataNode=&amp;quot;dn3&amp;quot; primaryKey=&amp;quot;id&amp;quot; /&amp;gt;

                &amp;lt;table name=&amp;quot;tb_areas_provinces&amp;quot; dataNode=&amp;quot;dn1,dn2,dn3&amp;quot; primaryKey=&amp;quot;id&amp;quot; type=&amp;quot;global&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_areas_city&amp;quot; dataNode=&amp;quot;dn1,dn2,dn3&amp;quot; primaryKey=&amp;quot;id&amp;quot; type=&amp;quot;global&amp;quot; /&amp;gt;
		&amp;lt;table name=&amp;quot;tb_areas_region&amp;quot; dataNode=&amp;quot;dn1,dn2,dn3&amp;quot; primaryKey=&amp;quot;id&amp;quot; type=&amp;quot;global&amp;quot; /&amp;gt;
	&amp;lt;/schema&amp;gt;

        &amp;lt;schema name=&amp;quot;ITCAST&amp;quot; checkSQLschema=&amp;quot;true&amp;quot; sqlMaxLimit=&amp;quot;100&amp;quot;&amp;gt;
        	&amp;lt;table name=&amp;quot;tb_log&amp;quot; dataNode=&amp;quot;dn4,dn5,dn6&amp;quot; primaryKey=&amp;quot;id&amp;quot; rule=&amp;quot;mod-long&amp;quot; /&amp;gt;
        	&amp;lt;table name=&amp;quot;tb_order&amp;quot; dataNode=&amp;quot;dn4,dn5,dn6&amp;quot; primaryKey=&amp;quot;id&amp;quot; rule=&amp;quot;sharding-by-murmur&amp;quot; /&amp;gt;
        &amp;lt;/schema&amp;gt;
	
	&amp;lt;dataNode name=&amp;quot;dn1&amp;quot; dataHost=&amp;quot;dhost1&amp;quot; database=&amp;quot;shopping&amp;quot; /&amp;gt;
	&amp;lt;dataNode name=&amp;quot;dn2&amp;quot; dataHost=&amp;quot;dhost2&amp;quot; database=&amp;quot;shopping&amp;quot; /&amp;gt;
	&amp;lt;dataNode name=&amp;quot;dn3&amp;quot; dataHost=&amp;quot;dhost3&amp;quot; database=&amp;quot;shopping&amp;quot; /&amp;gt;

	&amp;lt;dataNode name=&amp;quot;dn4&amp;quot; dataHost=&amp;quot;dhost1&amp;quot; database=&amp;quot;itcast&amp;quot; /&amp;gt;
	&amp;lt;dataNode name=&amp;quot;dn5&amp;quot; dataHost=&amp;quot;dhost2&amp;quot; database=&amp;quot;itcast&amp;quot; /&amp;gt;
	&amp;lt;dataNode name=&amp;quot;dn6&amp;quot; dataHost=&amp;quot;dhost3&amp;quot; database=&amp;quot;itcast&amp;quot; /&amp;gt;
	
	&amp;lt;dataHost name=&amp;quot;dhost1&amp;quot; maxCon=&amp;quot;1000&amp;quot; minCon=&amp;quot;10&amp;quot; balance=&amp;quot;0&amp;quot;
			  writeType=&amp;quot;0&amp;quot; dbType=&amp;quot;mysql&amp;quot; dbDriver=&amp;quot;jdbc&amp;quot; switchType=&amp;quot;1&amp;quot;  slaveThreshold=&amp;quot;100&amp;quot;&amp;gt;
		&amp;lt;heartbeat&amp;gt;select user()&amp;lt;/heartbeat&amp;gt;
		
		&amp;lt;writeHost host=&amp;quot;master&amp;quot; url=&amp;quot;jdbc:mysql://192.168.40.210:3306?useSSL=false&amp;amp;amp;serverTimezone=Asia/Shanghai&amp;amp;amp;characterEncoding=utf8&amp;quot; user=&amp;quot;root&amp;quot; password=&amp;quot;Superman*2023&amp;quot; /&amp;gt;
	&amp;lt;/dataHost&amp;gt;
	
	&amp;lt;dataHost name=&amp;quot;dhost2&amp;quot; maxCon=&amp;quot;1000&amp;quot; minCon=&amp;quot;10&amp;quot; balance=&amp;quot;0&amp;quot;
			  writeType=&amp;quot;0&amp;quot; dbType=&amp;quot;mysql&amp;quot; dbDriver=&amp;quot;jdbc&amp;quot; switchType=&amp;quot;1&amp;quot;  slaveThreshold=&amp;quot;100&amp;quot;&amp;gt;
		&amp;lt;heartbeat&amp;gt;select user()&amp;lt;/heartbeat&amp;gt;
		
		&amp;lt;writeHost host=&amp;quot;master&amp;quot; url=&amp;quot;jdbc:mysql://192.168.40.211:3306?useSSL=false&amp;amp;amp;serverTimezone=Asia/Shanghai&amp;amp;amp;characterEncoding=utf8&amp;quot; user=&amp;quot;root&amp;quot; password=&amp;quot;Superman*2023&amp;quot; /&amp;gt;
	&amp;lt;/dataHost&amp;gt;
	
	&amp;lt;dataHost name=&amp;quot;dhost3&amp;quot; maxCon=&amp;quot;1000&amp;quot; minCon=&amp;quot;10&amp;quot; balance=&amp;quot;0&amp;quot;
			  writeType=&amp;quot;0&amp;quot; dbType=&amp;quot;mysql&amp;quot; dbDriver=&amp;quot;jdbc&amp;quot; switchType=&amp;quot;1&amp;quot;  slaveThreshold=&amp;quot;100&amp;quot;&amp;gt;
		&amp;lt;heartbeat&amp;gt;select user()&amp;lt;/heartbeat&amp;gt;
		
		&amp;lt;writeHost host=&amp;quot;master&amp;quot; url=&amp;quot;jdbc:mysql://192.168.40.212:3306?useSSL=false&amp;amp;amp;serverTimezone=Asia/Shanghai&amp;amp;amp;characterEncoding=utf8&amp;quot; user=&amp;quot;root&amp;quot; password=&amp;quot;Superman*2023&amp;quot; /&amp;gt;
	&amp;lt;/dataHost&amp;gt;
&amp;lt;/mycat:schema&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;rule.xml é…ç½®&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@mycat ~]# cat /usr/local/mycat/conf/rule.xml 
...
	&amp;lt;function name=&amp;quot;murmur&amp;quot;
		class=&amp;quot;io.mycat.route.function.PartitionByMurmurHash&amp;quot;&amp;gt;
		&amp;lt;property name=&amp;quot;seed&amp;quot;&amp;gt;0&amp;lt;/property&amp;gt;&amp;lt;!-- é»˜è®¤æ˜¯0 --&amp;gt;
		&amp;lt;property name=&amp;quot;count&amp;quot;&amp;gt;3&amp;lt;/property&amp;gt;&amp;lt;!-- è¦åˆ†ç‰‡çš„æ•°æ®åº“èŠ‚ç‚¹æ•°é‡ï¼Œå¿…é¡»æŒ‡å®šï¼Œå¦åˆ™æ²¡æ³•åˆ†ç‰‡ --&amp;gt;
		&amp;lt;property name=&amp;quot;virtualBucketTimes&amp;quot;&amp;gt;160&amp;lt;/property&amp;gt;&amp;lt;!-- ä¸€ä¸ªå®é™…çš„æ•°æ®åº“èŠ‚ç‚¹è¢«æ˜ å°„ä¸ºè¿™ä¹ˆå¤šè™šæ‹ŸèŠ‚ç‚¹ï¼Œé»˜è®¤æ˜¯160å€ï¼Œä¹Ÿå°±æ˜¯è™šæ‹ŸèŠ‚ç‚¹æ•°æ˜¯ç‰©ç†èŠ‚ç‚¹æ•°çš„160å€ --&amp;gt;
		&amp;lt;!-- &amp;lt;property name=&amp;quot;weightMapFile&amp;quot;&amp;gt;weightMapFile&amp;lt;/property&amp;gt; èŠ‚ç‚¹çš„æƒé‡ï¼Œæ²¡æœ‰æŒ‡å®šæƒé‡çš„èŠ‚ç‚¹é»˜è®¤æ˜¯1ã€‚ä»¥propertiesæ–‡ä»¶çš„æ ¼å¼å¡«å†™ï¼Œä»¥ä»0å¼€å§‹åˆ°count-1çš„æ•´æ•°å€¼ä¹Ÿå°±æ˜¯èŠ‚ç‚¹ç´¢å¼•ä¸ºkeyï¼Œä»¥èŠ‚ç‚¹æƒé‡å€¼ä¸ºå€¼ã€‚æ‰€æœ‰æƒé‡å€¼å¿…é¡»æ˜¯æ­£æ•´æ•°ï¼Œå¦åˆ™ä»¥1ä»£æ›¿ --&amp;gt;
		&amp;lt;!-- &amp;lt;property name=&amp;quot;bucketMapPath&amp;quot;&amp;gt;/etc/mycat/bucketMapPath&amp;lt;/property&amp;gt; 
			ç”¨äºæµ‹è¯•æ—¶è§‚å¯Ÿå„ç‰©ç†èŠ‚ç‚¹ä¸è™šæ‹ŸèŠ‚ç‚¹çš„åˆ†å¸ƒæƒ…å†µï¼Œå¦‚æœæŒ‡å®šäº†è¿™ä¸ªå±æ€§ï¼Œä¼šæŠŠè™šæ‹ŸèŠ‚ç‚¹çš„murmur hashå€¼ä¸ç‰©ç†èŠ‚ç‚¹çš„æ˜ å°„æŒ‰è¡Œè¾“å‡ºåˆ°è¿™ä¸ªæ–‡ä»¶ï¼Œæ²¡æœ‰é»˜è®¤å€¼ï¼Œå¦‚æœä¸æŒ‡å®šï¼Œå°±ä¸ä¼šè¾“å‡ºä»»ä½•ä¸œè¥¿ --&amp;gt;
	&amp;lt;/function&amp;gt;
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;é‡å¯ mycat å¹¶æ’å…¥æ•°æ®æµ‹è¯•&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@mycat ~]# /usr/local/mycat/bin/mycat restart
Stopping Mycat-server...
Stopped Mycat-server.
Starting Mycat-server...

[root@mycat ~]# tail -f  /usr/local/mycat/logs/wrapper.log
...
INFO   | jvm 1    | 2023/12/03 22:17:47 | MyCAT Server startup successfully. see logs in logs/mycat.log

[root@db3 ~]# mysql -h 192.168.40.213 -P 8066 -uroot -p&#39;Superman*2023&#39;
Server version: 5.6.29-mycat-1.6-RELEASE-20161028204710 MyCat Server (OpenCloundDB)

mysql&amp;gt; show databases;
+----------+
| DATABASE |
+----------+
| ITCAST   |
| SHOPPING |
+----------+
2 rows in set (0.00 sec)

mysql&amp;gt; use ITCAST;
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Database changed
mysql&amp;gt; show tables;
+------------------+
| Tables in ITCAST |
+------------------+
| tb_log           |
| tb_order         |
+------------------+
2 rows in set (0.00 sec)

#åˆ›å»ºè¡¨ç»“æ„
create table tb_order(
    id  varchar(100) not null primary key,
    money   int null,
    content varchar(200) null
);

#æ’å…¥æ•°æ®
INSERT INTO tb_order (id, money, content) VALUES (&#39;b92fdaaf-6fc4-11ec-b831-482ae33c4a2d&#39;, 10, &#39;b92fdaf8-6fc4-11ec-b831-482ae33c4a2d&#39;);
INSERT INTO tb_order (id, money, content) VALUES (&#39;b93482b6-6fc4-11ec-b831-482ae33c4a2d&#39;, 20, &#39;b93482d5-6fc4-11ec-b831-482ae33c4a2d&#39;);
INSERT INTO tb_order (id, money, content) VALUES (&#39;b937e246-6fc4-11ec-b831-482ae33c4a2d&#39;, 50, &#39;b937e25d-6fc4-11ec-b831-482ae33c4a2d&#39;);
INSERT INTO tb_order (id, money, content) VALUES (&#39;b93be2dd-6fc4-11ec-b831-482ae33c4a2d&#39;, 100, &#39;b93be2f9-6fc4-11ec-b831-482ae33c4a2d&#39;);
INSERT INTO tb_order (id, money, content) VALUES (&#39;b93f2d68-6fc4-11ec-b831-482ae33c4a2d&#39;, 130, &#39;b93f2d7d-6fc4-11ec-b831-482ae33c4a2d&#39;);
INSERT INTO tb_order (id, money, content) VALUES (&#39;b9451b98-6fc4-11ec-b831-482ae33c4a2d&#39;, 30, &#39;b9451bcc-6fc4-11ec-b831-482ae33c4a2d&#39;);
INSERT INTO tb_order (id, money, content) VALUES (&#39;b9488ec1-6fc4-11ec-b831-482ae33c4a2d&#39;, 560, &#39;b9488edb-6fc4-11ec-b831-482ae33c4a2d&#39;);
INSERT INTO tb_order (id, money, content) VALUES (&#39;b94be6e6-6fc4-11ec-b831-482ae33c4a2d&#39;, 10, &#39;b94be6ff-6fc4-11ec-b831-482ae33c4a2d&#39;);
INSERT INTO tb_order (id, money, content) VALUES (&#39;b94ee10d-6fc4-11ec-b831-482ae33c4a2d&#39;, 123, &#39;b94ee12c-6fc4-11ec-b831-482ae33c4a2d&#39;);
INSERT INTO tb_order (id, money, content) VALUES (&#39;b952492a-6fc4-11ec-b831-482ae33c4a2d&#39;, 145, &#39;b9524945-6fc4-11ec-b831-482ae33c4a2d&#39;);
INSERT INTO tb_order (id, money, content) VALUES (&#39;b95553ac-6fc4-11ec-b831-482ae33c4a2d&#39;, 543, &#39;b95553c8-6fc4-11ec-b831-482ae33c4a2d&#39;);
INSERT INTO tb_order (id, money, content) VALUES (&#39;b9581cdd-6fc4-11ec-b831-482ae33c4a2d&#39;, 17, &#39;b9581cfa-6fc4-11ec-b831-482ae33c4a2d&#39;);
INSERT INTO tb_order (id, money, content) VALUES (&#39;b95afc0f-6fc4-11ec-b831-482ae33c4a2d&#39;, 18, &#39;b95afc2a-6fc4-11ec-b831-482ae33c4a2d&#39;);
INSERT INTO tb_order (id, money, content) VALUES (&#39;b95daa99-6fc4-11ec-b831-482ae33c4a2d&#39;, 134, &#39;b95daab2-6fc4-11ec-b831-482ae33c4a2d&#39;);
INSERT INTO tb_order (id, money, content) VALUES (&#39;b9667e3c-6fc4-11ec-b831-482ae33c4a2d&#39;, 156, &#39;b9667e60-6fc4-11ec-b831-482ae33c4a2d&#39;);
INSERT INTO tb_order (id, money, content) VALUES (&#39;b96ab489-6fc4-11ec-b831-482ae33c4a2d&#39;, 175, &#39;b96ab4a5-6fc4-11ec-b831-482ae33c4a2d&#39;);
INSERT INTO tb_order (id, money, content) VALUES (&#39;b96e2942-6fc4-11ec-b831-482ae33c4a2d&#39;, 180, &#39;b96e295b-6fc4-11ec-b831-482ae33c4a2d&#39;);
INSERT INTO tb_order (id, money, content) VALUES (&#39;b97092ec-6fc4-11ec-b831-482ae33c4a2d&#39;, 123, &#39;b9709306-6fc4-11ec-b831-482ae33c4a2d&#39;);
INSERT INTO tb_order (id, money, content) VALUES (&#39;b973727a-6fc4-11ec-b831-482ae33c4a2d&#39;, 230, &#39;b9737293-6fc4-11ec-b831-482ae33c4a2d&#39;);
INSERT INTO tb_order (id, money, content) VALUES (&#39;b978840f-6fc4-11ec-b831-482ae33c4a2d&#39;, 560, &#39;b978843c-6fc4-11ec-b831-482ae33c4a2d&#39;);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;PSï¼šæ•°æ®æŒ‰ä¸€è‡´æ€§ hash åˆ†å¸ƒåœ¨ä¸åŒèŠ‚ç‚¹&lt;/p&gt;
</content>
        <category term="MySQL" />
        <updated>2025-04-09T14:02:40.000Z</updated>
    </entry>
    <entry>
        <id>http://ixuyong.cn/posts/2771271649.html</id>
        <title>äº‘åŸç”ŸK8så®‰å…¨ä¸“å®¶CKSè®¤è¯è€ƒé¢˜è¯¦è§£</title>
        <link rel="alternate" href="http://ixuyong.cn/posts/2771271649.html"/>
        <content type="html">&lt;div class=&#34;hbe hbe-container&#34; id=&#34;hexo-blog-encrypt&#34; data-wpm=&#34;æŠ±æ­‰, è¿™ä¸ªå¯†ç çœ‹ç€ä¸å¤ªå¯¹, è¯·å†è¯•è¯•ã€‚&#34; data-whm=&#34;æŠ±æ­‰, è¿™ä¸ªæ–‡ç« ä¸èƒ½è¢«æ ¡éªŒ, ä¸è¿‡æ‚¨è¿˜æ˜¯èƒ½çœ‹çœ‹è§£å¯†åçš„å†…å®¹ã€‚&#34;&gt;
  &lt;script id=&#34;hbeData&#34; type=&#34;hbeData&#34; data-hmacdigest=&#34;51b7696c170db1f393208c9728cf1b39666792a92daee416449ae392a4ae125d&#34;&gt;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&lt;/script&gt;
  &lt;div class=&#34;hbe hbe-content&#34;&gt;
    &lt;div class=&#34;hbe hbe-input hbe-input-xray&#34;&gt;
      &lt;input class=&#34;hbe hbe-input-field hbe-input-field-xray&#34; type=&#34;password&#34; id=&#34;hbePass&#34;&gt;
      &lt;label class=&#34;hbe hbe-input-label hbe-input-label-xray&#34; for=&#34;hbePass&#34;&gt;
        &lt;span class=&#34;hbe hbe-input-label-content hbe-input-label-content-xray&#34;&gt;æ‚¨å¥½, è¿™é‡Œéœ€è¦è¾“å…¥å¯†ç ã€‚&lt;/span&gt;
      &lt;/label&gt;
      &lt;svg class=&#34;hbe hbe-graphic hbe-graphic-xray&#34; width=&#34;300%&#34; height=&#34;100%&#34; viewBox=&#34;0 0 1200 60&#34; preserveAspectRatio=&#34;none&#34;&gt;
        &lt;path d=&#34;M0,56.5c0,0,298.666,0,399.333,0C448.336,56.5,513.994,46,597,46c77.327,0,135,10.5,200.999,10.5c95.996,0,402.001,0,402.001,0&#34;&gt;&lt;/path&gt;
        &lt;path d=&#34;M0,2.5c0,0,298.666,0,399.333,0C448.336,2.5,513.994,13,597,13c77.327,0,135-10.5,200.999-10.5c95.996,0,402.001,0,402.001,0&#34;&gt;&lt;/path&gt;
      &lt;/svg&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;script data-pjax src=&#34;/lib/hbe.js&#34;&gt;&lt;/script&gt;&lt;link href=&#34;/css/hbe.style.css&#34; rel=&#34;stylesheet&#34; type=&#34;text/css&#34;&gt;</content>
        <category term="Kubernetes" />
        <updated>2025-04-09T13:38:39.000Z</updated>
    </entry>
    <entry>
        <id>http://ixuyong.cn/posts/1414180692.html</id>
        <title>Redisé›†ç¾¤ï¼ˆä¸»ä»+å“¨å…µï¼‰æ¨¡å¼</title>
        <link rel="alternate" href="http://ixuyong.cn/posts/1414180692.html"/>
        <content type="html">&lt;h3 id=&#34;redisé›†ç¾¤ä¸»ä»å“¨å…µæ¨¡å¼&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#redisé›†ç¾¤ä¸»ä»å“¨å…µæ¨¡å¼&#34;&gt;#&lt;/a&gt; Redis é›†ç¾¤ï¼ˆä¸»ä» + å“¨å…µï¼‰æ¨¡å¼&lt;/h3&gt;
&lt;h3 id=&#34;ä¸€-ä»€ä¹ˆæ˜¯redisä¸»ä»å¤åˆ¶&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#ä¸€-ä»€ä¹ˆæ˜¯redisä¸»ä»å¤åˆ¶&#34;&gt;#&lt;/a&gt; ä¸€ã€ä»€ä¹ˆæ˜¯ redis ä¸»ä»å¤åˆ¶ï¼Ÿ&lt;/h3&gt;
&lt;p&gt;ä¸»ä»å¤åˆ¶ï¼Œæ˜¯æŒ‡å°†ä¸€å° Redis æœåŠ¡å™¨çš„æ•°æ®ï¼Œå¤åˆ¶åˆ°å…¶ä»–çš„ Redis æœåŠ¡å™¨ã€‚å‰è€…ç§°ä¸ºä¸»èŠ‚ç‚¹ (master)ï¼Œåè€…ç§°ä¸ºä»èŠ‚ç‚¹ (slave), æ•°æ®çš„å¤åˆ¶æ˜¯å•å‘çš„ï¼Œåªèƒ½ç”±ä¸»èŠ‚ç‚¹åˆ°ä»èŠ‚ç‚¹ã€‚master ä»¥å†™ä¸ºä¸»ï¼Œslave ä»¥è¯»ä¸ºä¸»ã€‚&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://imgse.com/i/pEgTlKx&#34;&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://s21.ax1x.com/2025/04/09/pEgTlKx.png&#34; alt=&#34;pEgTlKx.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;äºŒ-ä¸»ä»å¤åˆ¶çš„ä½œç”¨&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#äºŒ-ä¸»ä»å¤åˆ¶çš„ä½œç”¨&#34;&gt;#&lt;/a&gt; äºŒã€ä¸»ä»å¤åˆ¶çš„ä½œç”¨&lt;/h3&gt;
&lt;p&gt;æ•°æ®å†—ä½™ï¼šä¸»ä»å¤åˆ¶å®ç°äº†æ•°æ®çš„çƒ­å¤‡ä»½ï¼Œæ˜¯æŒä¹…åŒ–ä¹‹å¤–çš„ä¸€ç§æ•°æ®å†—ä½™æ–¹å¼ã€‚&lt;br /&gt;
æ•…éšœæ¢å¤ï¼šå½“ä¸»èŠ‚ç‚¹å‡ºç°é—®é¢˜æ—¶ï¼Œå¯ä»¥ç”±ä»èŠ‚ç‚¹æä¾›æœåŠ¡ï¼Œå®ç°å¿«é€Ÿçš„æ•…éšœæ¢å¤ï¼›å®é™…ä¸Šæ˜¯ä¸€ç§æœåŠ¡çš„å†—ä½™ã€‚&lt;br /&gt;
è´Ÿè½½å‡è¡¡ï¼šåœ¨ä¸»ä»å¤åˆ¶çš„åŸºç¡€ä¸Šï¼Œé…åˆè¯»å†™åˆ†ç¦»ï¼Œå¯ä»¥ç”±ä¸»èŠ‚ç‚¹æä¾›å†™æœåŠ¡ï¼Œç”±ä»èŠ‚ç‚¹æä¾›è¯»æœåŠ¡ï¼ˆå³å†™ Redis æ•°æ®æ—¶åº”ç”¨è¿æ¥ä¸»èŠ‚ç‚¹ï¼Œè¯» Redis æ•°æ®æ—¶åº”ç”¨è¿æ¥ä»èŠ‚ç‚¹ï¼‰ï¼Œåˆ†æ‹…æœåŠ¡å™¨è´Ÿè½½ï¼›å°¤å…¶æ˜¯åœ¨å†™å°‘è¯»å¤šçš„åœºæ™¯ä¸‹ï¼Œé€šè¿‡å¤šä¸ªä»èŠ‚ç‚¹åˆ†æ‹…è¯»è´Ÿè½½ï¼Œå¯ä»¥å¤§å¤§æé«˜ Redis æœåŠ¡å™¨çš„å¹¶å‘é‡ã€‚&lt;br /&gt;
è¯»å†™åˆ†ç¦»ï¼šç”¨äºå®ç°è¯»å†™åˆ†ç¦»ï¼Œä¸»åº“å†™ã€ä»åº“è¯»ï¼Œè¯»å†™åˆ†ç¦»ä¸ä»…å¯ä»¥æé«˜æœåŠ¡å™¨çš„è´Ÿè½½èƒ½åŠ›ï¼ŒåŒæ—¶å¯æ ¹æ®éœ€æ±‚çš„å˜åŒ–ï¼Œæ”¹å˜ä»åº“çš„æ•°é‡ï¼›&lt;br /&gt;
é«˜å¯ç”¨åŸºçŸ³ï¼šé™¤äº†ä¸Šè¿°ä½œç”¨ä»¥å¤–ï¼Œä¸»ä»å¤åˆ¶è¿˜æ˜¯å“¨å…µå’Œé›†ç¾¤èƒ½å¤Ÿå®æ–½çš„åŸºç¡€ï¼Œå› æ­¤è¯´ä¸»ä»å¤åˆ¶æ˜¯ Redis é«˜å¯ç”¨çš„åŸºç¡€ã€‚&lt;/p&gt;
&lt;h3 id=&#34;ä¸‰-å®ç°ä¸»ä»å¤åˆ¶&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#ä¸‰-å®ç°ä¸»ä»å¤åˆ¶&#34;&gt;#&lt;/a&gt; ä¸‰ã€å®ç°ä¸»ä»å¤åˆ¶&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;ä¸»æœºå&lt;/th&gt;
&lt;th&gt;IP&lt;/th&gt;
&lt;th&gt;è§’è‰²&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;redis01&lt;/td&gt;
&lt;td&gt;192.168.40.101&lt;/td&gt;
&lt;td&gt;master&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;redis02&lt;/td&gt;
&lt;td&gt;192.168.40.102&lt;/td&gt;
&lt;td&gt;slave&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;redis03&lt;/td&gt;
&lt;td&gt;192.168.40.103&lt;/td&gt;
&lt;td&gt;slave&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;31-å…³é—­é˜²ç«å¢™-selinux&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#31-å…³é—­é˜²ç«å¢™-selinux&#34;&gt;#&lt;/a&gt; 3.1 å…³é—­é˜²ç«å¢™ã€selinux&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@master01 ~]# hostnamectl set-hostname redis01
[root@redis01 ~]# systemctl stop firewalld
[root@redis01 ~]# systemctl disable firewalld
[root@redis01 ~]# sed -i &#39;s/^SELINUX=enforcing/SELINUX=disabled/g&#39; /etc/sysconfig/selinux
[root@redis01 ~]# sed -i &#39;s/^SELINUX=enforcing/SELINUX=disabled/g&#39; /etc/selinux/config
[root@redis01 ~]# yum install net-tools vim tree lrzsz wget unzip dos2unix bash-completion  lsof ntp ntpdate git -y
[root@redis01 ~]# yum update -y --exclude=kernel* &amp;amp;&amp;amp; reboot
[root@redis01 ~]# echo &#39;Asia/Shanghai&#39; &amp;gt;/etc/timezone
[root@redis01 ~]# ntpdate time2.aliyun.com
[root@redis01 ~]# crontab -e
*/5 * * * * /usr/sbin/ntpdate time2.aliyun.com &amp;amp;&amp;gt; /dev/null
[root@redis01 ~]# mkdir /soft /data /scripts /backup
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;32-å®‰è£…redis&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#32-å®‰è£…redis&#34;&gt;#&lt;/a&gt; 3.2 å®‰è£… redis&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@redis01 ~]# yum install gcc-c++ -y
[root@redis01 soft]# wget https://download.redis.io/releases/redis-6.2.11.tar.gz
[root@redis01 soft]# tar xf redis-6.2.11.tar.gz 
[root@redis01 soft]# ln -s /soft/redis-6.2.11 /soft/redis
[root@redis01 soft]# cd /soft/redis
[root@redis01 redis]# make            #æ‰§è¡Œmakeç¼–è¯‘
[root@redis01 redis]# make install    #å°† srcä¸‹çš„è®¸å¤šå¯æ‰§è¡Œæ–‡ä»¶å¤åˆ¶åˆ°/usr/local/bin ç›®å½•ä¸‹
[root@redis01 redis]# redis-server /soft/redis/redis.conf &amp;amp;
[root@redis01 redis]# netstat -lntp|grep redis
tcp        0      0 127.0.0.1:6379          0.0.0.0:*               LISTEN      69686/redis-server  
tcp6       0      0 ::1:6379                :::*                    LISTEN      69686/redis-server     
[root@redis01 redis]# redis-cli shutdown      #å…³é—­RedisæœåŠ¡
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;33-redisé…ç½®æ–‡ä»¶è¯´æ˜&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#33-redisé…ç½®æ–‡ä»¶è¯´æ˜&#34;&gt;#&lt;/a&gt; 3.3 redis é…ç½®æ–‡ä»¶è¯´æ˜&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@db01 redis]# vim redis.conf 
bind 127.0.0.1      		# ç»‘å®šçš„ip
protected-mode yes  		# ä¿æŠ¤æ¨¡å¼
port 6379           		# ç«¯å£è®¾ç½®
daemonize yes               # åå°å¯åŠ¨
bind 127.0.0.1      		# ç»‘å®šçš„ip
protected-mode yes  		# ä¿æŠ¤æ¨¡å¼
port 6379           		# ç«¯å£è®¾ç½®
loglevel notice     		# è®°å½•æ—¥å¿—çº§åˆ«
logfile &amp;quot;redis.log&amp;quot;         # æ—¥å¿—çš„æ–‡ä»¶ä½ç½®å
dir ./               		# æ—¥å¿—å­˜å‚¨ç›®å½•
databases 16        		# æ•°æ®åº“çš„æ•°é‡ï¼Œé»˜è®¤æ˜¯ 16 ä¸ªæ•°æ®åº“
always-show-logo yes 		# æ˜¯å¦æ€»æ˜¯æ˜¾ç¤ºLOGO

# å¦‚æœ900så†…ï¼Œå¦‚æœè‡³å°‘æœ‰ä¸€ä¸ª1 keyè¿›è¡Œäº†ä¿®æ”¹ï¼Œæˆ‘ä»¬åŠè¿›è¡ŒæŒä¹…åŒ–æ“ä½œ
save 900 1
# å¦‚æœ300så†…ï¼Œå¦‚æœè‡³å°‘10 keyè¿›è¡Œäº†ä¿®æ”¹ï¼Œæˆ‘ä»¬åŠè¿›è¡ŒæŒä¹…åŒ–æ“ä½œ
save 300 10
# å¦‚æœ60så†…ï¼Œå¦‚æœè‡³å°‘10000 keyè¿›è¡Œäº†ä¿®æ”¹ï¼Œæˆ‘ä»¬åŠè¿›è¡ŒæŒä¹…åŒ–æ“ä½œ
save 60 10000
# æˆ‘ä»¬ä¹‹åå­¦ä¹ æŒä¹…åŒ–ï¼Œä¼šè‡ªå·±å®šä¹‰è¿™ä¸ªæµ‹è¯•ï¼
stop-writes-on-bgsave-error yes   # æŒä¹…åŒ–å¦‚æœå‡ºé”™ï¼Œæ˜¯å¦è¿˜éœ€è¦ç»§ç»­å·¥ä½œï¼
rdbcompression yes                # æ˜¯å¦å‹ç¼© rdb æ–‡ä»¶ï¼Œéœ€è¦æ¶ˆè€—ä¸€äº›cpuèµ„æºï¼
rdbchecksum yes                   # ä¿å­˜rdbæ–‡ä»¶çš„æ—¶å€™ï¼Œè¿›è¡Œé”™è¯¯çš„æ£€æŸ¥æ ¡éªŒï¼
dbfilename dump.rdb               # rdb æ–‡ä»¶ä¿å­˜çš„åç§°ï¼
dir ./                            # rdb æ–‡ä»¶ä¿å­˜çš„ç›®å½•ï¼

slaveof 192.168.1.154 6379        # é…ç½®ä¸»ä»å¤åˆ¶
requirepass foobared              # é…ç½®redisç™»å½•å¯†ç 

appendonly no    # é»˜è®¤æ˜¯ä¸å¼€å¯aofæ¨¡å¼çš„ï¼Œé»˜è®¤æ˜¯ä½¿ç”¨rdbæ–¹å¼æŒä¹…åŒ–çš„ï¼Œåœ¨å¤§éƒ¨åˆ†æ‰€æœ‰çš„æƒ…å†µä¸‹ï¼Œrdbå®Œå…¨å¤Ÿç”¨ï¼
appendfilename &amp;quot;appendonly.aof&amp;quot;   # æŒä¹…åŒ–çš„æ–‡ä»¶çš„åå­—
# appendfsync always        # æ¯æ¬¡ä¿®æ”¹éƒ½ä¼š syncã€‚æ¶ˆè€—æ€§èƒ½
appendfsync everysec        # æ¯ç§’æ‰§è¡Œä¸€æ¬¡ syncï¼Œå¯èƒ½ä¼šä¸¢å¤±è¿™1sçš„æ•°æ®ï¼
# appendfsync no            # ä¸æ‰§è¡Œ syncï¼Œè¿™ä¸ªæ—¶å€™æ“ä½œç³»ç»Ÿè‡ªå·±åŒæ­¥æ•°æ®ï¼Œé€Ÿåº¦æœ€å¿«ï¼
no-appendfsync-on-rewrite   #é‡å†™æ—¶æ˜¯å¦å¯ä»¥è¿ç”¨appendsyncï¼Œé»˜è®¤noï¼Œå¯ä»¥ä¿è¯æ•°æ®çš„å®‰å…¨æ€§
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;34-redisç¯å¢ƒé…ç½®&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#34-redisç¯å¢ƒé…ç½®&#34;&gt;#&lt;/a&gt; 3.4 redis ç¯å¢ƒé…ç½®&lt;/h4&gt;
&lt;p&gt;#ä¿®æ”¹ maser é…ç½®æ–‡ä»¶&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vim redis.conf
bind 192.168.40.101 #ç»‘å®šæœ¬æœºipåœ°å€
port 6739          #ç»‘å®šç«¯å£å·
daemonize yes      #ç”¨æ¥æŒ‡å®šredisæ˜¯å¦è¦ç”¨å®ˆæŠ¤è¿›ç¨‹çš„æ–¹å¼å¯åŠ¨ï¼Œé»˜è®¤ä¸ºno
pidfile /var/run/redis_6379.pid
logfile &amp;quot;redis.log&amp;quot;   #redisæ—¥å¿—æ–‡ä»¶
requirepass Superman*2023  #æœ¬åœ°rediså¯†ç 
masterauth Superman*2023   #ä¸»èŠ‚ç‚¹rediså¯†ç  æ³¨æ„:ä»èŠ‚ç‚¹ä¹Ÿè¦é…ç½®ï¼Œåè¾¹å“¨å…µå®¹ç¾åˆ‡æ¢ç”¨åˆ°
protected-mode yes    #ä¿æŠ¤æ¨¡å¼
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;#ä¿®æ”¹ slave01 é…ç½®æ–‡ä»¶&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vim redis.conf
bind 192.168.40.102 #ç»‘å®šæœ¬æœºipåœ°å€
port 6739          #ç»‘å®šç«¯å£å·
daemonize yes      #ç”¨æ¥æŒ‡å®šredisæ˜¯å¦è¦ç”¨å®ˆæŠ¤è¿›ç¨‹çš„æ–¹å¼å¯åŠ¨ï¼Œé»˜è®¤ä¸ºno
pidfile /var/run/redis_6379.pid
logfile &amp;quot;redis.log&amp;quot;   #redisæ—¥å¿—æ–‡ä»¶
replicaof  192.168.40.101 6379 #é…ç½®æ–‡ä»¶ä¸­è®¾ç½®ä¸»èŠ‚ç‚¹ï¼Œredisä¸»ä»å¤åˆ¶è¿™ä¸ªåœ°æ–¹åªé…ç½®ä»åº“ï¼Œæ³¨æ„:ä¸»åº“ä¸éœ€è¦è¿™ä¸ªé…ç½®
requirepass Superman*2023  #æœ¬åœ°rediså¯†ç 
masterauth Superman*2023   #ä¸»èŠ‚ç‚¹rediså¯†ç  æ³¨æ„:ä»èŠ‚ç‚¹ä¹Ÿè¦é…ç½®ï¼Œåè¾¹å“¨å…µå®¹ç¾åˆ‡æ¢ç”¨åˆ°
protected-mode yes    #ä¿æŠ¤æ¨¡å¼
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;#ä¿®æ”¹ slave02 é…ç½®æ–‡ä»¶&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vim redis.conf
bind 192.168.40.103 #ç»‘å®šæœ¬æœºipåœ°å€
port 6739          #ç»‘å®šç«¯å£å·
daemonize yes      #ç”¨æ¥æŒ‡å®šredisæ˜¯å¦è¦ç”¨å®ˆæŠ¤è¿›ç¨‹çš„æ–¹å¼å¯åŠ¨ï¼Œé»˜è®¤ä¸ºno
pidfile /var/run/redis_6379.pid
logfile &amp;quot;redis.log&amp;quot;   #redisæ—¥å¿—æ–‡ä»¶
replicaof  192.168.40.101 6379 #é…ç½®æ–‡ä»¶ä¸­è®¾ç½®ä¸»èŠ‚ç‚¹ï¼Œredisä¸»ä»å¤åˆ¶è¿™ä¸ªåœ°æ–¹åªé…ç½®ä»åº“ï¼Œæ³¨æ„:ä¸»åº“ä¸éœ€è¦è¿™ä¸ªé…ç½®
requirepass Superman*2023  #æœ¬åœ°rediså¯†ç 
masterauth Superman*2023   #ä¸»èŠ‚ç‚¹rediså¯†ç  æ³¨æ„:ä»èŠ‚ç‚¹ä¹Ÿè¦é…ç½®ï¼Œåè¾¹å“¨å…µå®¹ç¾åˆ‡æ¢ç”¨åˆ°
protected-mode yes    #ä¿æŠ¤æ¨¡å¼
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;35-å¯åŠ¨3å°redisæœåŠ¡&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#35-å¯åŠ¨3å°redisæœåŠ¡&#34;&gt;#&lt;/a&gt; 3.5 å¯åŠ¨ 3 å° redis æœåŠ¡&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;#å¯åŠ¨redis01
[root@redis01 redis]# redis-server /soft/redis/redis.conf
[root@redis0[root@redis01 redis]# redis-server /soft/redis/redis.conf redis]# netstat -lntp|grep redis
tcp        0      0 192.168.40.101:6379     0.0.0.0:*               LISTEN      117358/redis-server 

#å¯åŠ¨redis02
[root@redis02 redis]# redis-server /soft/redis/redis.conf
[root@redis02 redis]# netstat -lntp|grep redis
tcp        0      0 192.168.40.102:6379     0.0.0.0:*               LISTEN      18210/redis-server

å¯åŠ¨redis03
[root@redis03 redis]# redis-server /soft/redis/redis.conf
[root@redis03 redis]# netstat -lntp|grep redis
tcp        0      0 192.168.40.103:6379     0.0.0.0:*               LISTEN      19186/redis-server 
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;36-æŸ¥çœ‹ä¸»ä»çŠ¶æ€&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#36-æŸ¥çœ‹ä¸»ä»çŠ¶æ€&#34;&gt;#&lt;/a&gt; 3.6 æŸ¥çœ‹ä¸»ä»çŠ¶æ€&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;#ä¸»èŠ‚ç‚¹
[root@redis01 redis]# redis-cli -p 6379 -h 192.168.40.101 -a Superman*2023
192.168.40.101:6379&amp;gt; info replication
# Replication
role:master
connected_slaves:2
slave0:ip=192.168.40.102,port=6379,state=online,offset=616,lag=0
slave1:ip=192.168.40.103,port=6379,state=online,offset=616,lag=0
master_failover_state:no-failover
master_replid:93df7cd5095dcccdbf8266787031b17cf638a2ad
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:616
second_repl_offset:-1
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:1
repl_backlog_histlen:616

#ä»èŠ‚ç‚¹
[root@redis01 redis]# redis-cli -p 6379 -h 192.168.40.103 -a Superman*2023
Warning: Using a password with &#39;-a&#39; or &#39;-u&#39; option on the command line interface may not be safe.
192.168.40.103:6379&amp;gt; info replication
# Replication
role:slave
master_host:192.168.40.101
master_port:6379
master_link_status:up
master_last_io_seconds_ago:1
master_sync_in_progress:0
slave_read_repl_offset:812
slave_repl_offset:812
slave_priority:100
slave_read_only:1
replica_announced:1
connected_slaves:0
master_failover_state:no-failover
master_replid:93df7cd5095dcccdbf8266787031b17cf638a2ad
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:812
second_repl_offset:-1
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:295
repl_backlog_histlen:518
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;37-æµ‹è¯•ä¸»ä»&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#37-æµ‹è¯•ä¸»ä»&#34;&gt;#&lt;/a&gt; 3.7 æµ‹è¯•ä¸»ä»&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@redis01 redis]# redis-cli -p 6379 -h 192.168.40.101 -a Superman*2023
Warning: Using a password with &#39;-a&#39; or &#39;-u&#39; option on the command line interface may not be safe.
192.168.40.101:6379&amp;gt; set k1 v1
OK
192.168.40.101:6379&amp;gt; set k2 v2
OK

[root@redis03 redis]# redis-cli -p 6379 -h 192.168.40.103 -a Superman*2023
Warning: Using a password with &#39;-a&#39; or &#39;-u&#39; option on the command line interface may not be safe.
192.168.40.103:6379&amp;gt; get k1
&amp;quot;v1&amp;quot;
192.168.40.103:6379&amp;gt; get k2
&amp;quot;v2&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;æ³¨æ„:&lt;/strong&gt;&lt;br /&gt;
1ã€ä¸»æœºå¯ä»¥å†™ï¼Œä»æœºä¸èƒ½å†™ï¼Œåªèƒ½è¯»ã€‚ä¸»æœºä¸­çš„æ‰€æœ‰æ•°æ®éƒ½ä¼šä¿å­˜åˆ°ä»æœºä¸­å»ã€‚&lt;br /&gt;
2ã€ä¸»æœºæ–­å¼€è¿æ¥ï¼Œä»æœºä¾æ—§è¿æ¥åˆ°ä¸»æœºçš„ï¼Œä½†æ˜¯æ²¡æœ‰å†™æ“ä½œï¼Œè¿™ä¸ªæ—¶å€™ï¼Œä¸»æœºå¦‚æœå›æ¥äº†ï¼Œä»æœºä¾æ—§å¯ä»¥ç›´æ¥è·å–åˆ°ä¸»æœºå†™çš„ä¿¡æ¯ï¼&lt;br /&gt;
3ã€å¦‚æœæ˜¯ä½¿ç”¨å‘½ä»¤è¡Œï¼Œæ¥é…ç½®çš„ä¸»ä»ï¼Œè¿™ä¸ªæ—¶å€™å¦‚æœé‡å¯äº†ï¼Œå°±ä¼šå˜å›ä¸»æœºï¼åªè¦å˜ä¸ºä»æœºï¼Œç«‹é©¬å°±ä¼šä»ä¸»æœºä¸­è·å–å€¼ï¼&lt;br /&gt;
4ã€ä¸»ä»å¤åˆ¶åŸç†&lt;br /&gt;
 Slave å¯åŠ¨æˆåŠŸè¿æ¥åˆ° master åä¼šå‘é€ä¸€ä¸ª sync åŒæ­¥å‘½ä»¤&lt;br /&gt;
 Master æ¥åˆ°å‘½ä»¤ï¼Œå¯åŠ¨åå°çš„å­˜ç›˜è¿›ç¨‹ï¼ŒåŒæ—¶æ”¶é›†æ‰€æœ‰æ¥æ”¶åˆ°çš„ç”¨äºä¿®æ”¹æ•°æ®é›†å‘½ä»¤ï¼Œåœ¨åå°è¿›ç¨‹æ‰§è¡Œå®Œæ¯•ä¹‹åï¼Œmaster å°†ä¼ é€æ•´ä¸ªæ•°æ®æ–‡ä»¶åˆ° slaveï¼Œå¹¶å®Œæˆä¸€æ¬¡å®Œå…¨åŒæ­¥ã€‚&lt;br /&gt;
å…¨é‡å¤åˆ¶ï¼šslave æœåŠ¡åœ¨æ¥æ”¶åˆ°æ•°æ®åº“æ–‡ä»¶æ•°æ®åï¼Œå°†å…¶å­˜ç›˜å¹¶åŠ è½½åˆ°å†…å­˜ä¸­ã€‚&lt;br /&gt;
å¢é‡å¤åˆ¶ï¼šMaster ç»§ç»­å°†æ–°çš„æ‰€æœ‰æ”¶é›†åˆ°çš„ä¿®æ”¹å‘½ä»¤ä¾æ¬¡ä¼ ç»™ slaveï¼Œå®ŒæˆåŒæ­¥ï¼Œä½†æ˜¯åªè¦æ˜¯é‡æ–°è¿æ¥ masterï¼Œä¸€æ¬¡å®Œå…¨åŒæ­¥ï¼ˆå…¨é‡å¤åˆ¶ï¼‰å°†è¢«è‡ªåŠ¨æ‰§è¡Œï¼ ä¸»æœºçš„æ•°æ®ä¸€å®šå¯ä»¥åœ¨ä»æœºä¸­çœ‹åˆ°ã€‚&lt;/p&gt;
&lt;h3 id=&#34;å››-å“¨å…µæ¨¡å¼æ­å»º&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#å››-å“¨å…µæ¨¡å¼æ­å»º&#34;&gt;#&lt;/a&gt; å››ã€å“¨å…µæ¨¡å¼æ­å»º&lt;/h3&gt;
&lt;p&gt;1ã€ä»€ä¹ˆæ˜¯ redis å“¨å…µï¼Ÿ&lt;br /&gt;
RedisSentinel æ˜¯ Redis çš„é«˜å¯ç”¨æ€§è§£å†³æ–¹æ¡ˆï¼Œç”±ä¸€ä¸ªæˆ–å¤šä¸ª Sentinelï¼ˆå“¨å…µï¼‰å®ä¾‹ç»„æˆã€‚å®ƒå¯ä»¥ç›‘è§†ä»»æ„å¤šä¸ªä¸»æœåŠ¡å™¨ï¼Œä»¥åŠè¿™äº›ä¸»æœåŠ¡å™¨å±ä¸‹çš„æ‰€æœ‰ä»æœåŠ¡å™¨ï¼Œå¹¶åœ¨è¢«ç›‘è§†çš„ä¸»æœåŠ¡å™¨è¿›å…¥ä¸‹çº¿çŠ¶æ€æ—¶ï¼Œè‡ªåŠ¨å°†ä¸‹çº¿ä¸»æœåŠ¡å™¨å±ä¸‹çš„æŸä¸ªä»æœåŠ¡å™¨å‡çº§ä¸ºæ–°çš„ä¸»æœåŠ¡å™¨ï¼Œå®ƒçš„ä¸»è¦åŠŸèƒ½å¦‚ä¸‹ï¼š&lt;br /&gt;
ç›‘æ§ (Monitoring)ï¼šSentinel ä¼šä¸æ–­åœ°æ£€æŸ¥ä½ çš„ä¸»æœåŠ¡å™¨å’Œä»æœåŠ¡å™¨æ˜¯å¦è¿ä½œæ­£å¸¸ã€‚&lt;br /&gt;
é€šçŸ¥ (Notification)ï¼šå½“è¢«ç›‘æ§çš„æŸä¸ª Redis æœåŠ¡å™¨å‡ºç°é—®é¢˜æ—¶ï¼ŒSentinel å¯ä»¥é€šè¿‡ API å‘ç®¡ç†å‘˜æˆ–è€…å…¶ä»–åº”ç”¨ç¨‹åºå‘é€é€šçŸ¥ã€‚&lt;br /&gt;
æ•…éšœè¿ç§»ï¼šå½“ä¸»æœåŠ¡å™¨ä¸èƒ½æ­£å¸¸å·¥ä½œæ—¶ï¼ŒSentinel ä¼šè‡ªåŠ¨è¿›è¡Œæ•…éšœè¿ç§»ï¼Œä¹Ÿå°±æ˜¯ä¸»ä»åˆ‡æ¢ã€‚&lt;br /&gt;
ç»Ÿä¸€çš„é…ç½®ï¼šç®¡ç†è¿æ¥è€…è¯¢é—® sentinel å–å¾—ä¸»ä»çš„åœ°å€ã€‚&lt;/p&gt;
&lt;p&gt;2ã€å“¨å…µåŸç†æ˜¯ä»€ä¹ˆï¼Ÿ&lt;br /&gt;
Sentinel ä½¿ç”¨çš„ç®—æ³•æ ¸å¿ƒæ˜¯ Raft ç®—æ³•ï¼Œä¸»è¦ç”¨é€”å°±æ˜¯ç”¨äºåˆ†å¸ƒå¼ç³»ç»Ÿï¼Œç³»ç»Ÿå®¹é”™ï¼Œä»¥åŠ Leader é€‰ä¸¾ï¼Œæ¯ä¸ª Sentinel éƒ½éœ€è¦å®šæœŸçš„æ‰§è¡Œä»¥ä¸‹ä»»åŠ¡ï¼š&lt;br /&gt;
æ¯ä¸ª Sentinel ä¼šè‡ªåŠ¨å‘ç°å…¶ä»– Sentinel å’Œä»æœåŠ¡å™¨ï¼Œå®ƒä»¥æ¯ç§’é’Ÿä¸€æ¬¡çš„é¢‘ç‡å‘å®ƒæ‰€çŸ¥çš„ä¸»æœåŠ¡å™¨ã€ä»æœåŠ¡å™¨ä»¥åŠå…¶ä»– Sentinel å®ä¾‹å‘é€ä¸€ä¸ª PING å‘½ä»¤ã€‚&lt;br /&gt;
å¦‚æœä¸€ä¸ªå®ä¾‹ï¼ˆinstanceï¼‰è·ç¦»æœ€åä¸€æ¬¡æœ‰æ•ˆå›å¤ PING å‘½ä»¤çš„æ—¶é—´è¶…è¿‡ down-after-milliseconds é€‰é¡¹æ‰€æŒ‡å®šçš„å€¼ï¼Œ é‚£ä¹ˆè¿™ä¸ªå®ä¾‹ä¼šè¢« Sentinel æ ‡è®°ä¸ºä¸»è§‚ä¸‹çº¿ã€‚ æœ‰æ•ˆå›å¤å¯ä»¥æ˜¯ï¼š +PONG ã€ -LOADING æˆ–è€… -MASTERDOWN ã€‚&lt;br /&gt;
å¦‚æœä¸€ä¸ªä¸»æœåŠ¡å™¨è¢«æ ‡è®°ä¸ºä¸»è§‚ä¸‹çº¿ï¼Œ é‚£ä¹ˆæ­£åœ¨ç›‘è§†è¿™ä¸ªä¸»æœåŠ¡å™¨çš„æ‰€æœ‰ Sentinel è¦ä»¥æ¯ç§’ä¸€æ¬¡çš„é¢‘ç‡ç¡®è®¤ä¸»æœåŠ¡å™¨çš„ç¡®è¿›å…¥äº†ä¸»è§‚ä¸‹çº¿çŠ¶æ€ã€‚&lt;br /&gt;
å¦‚æœä¸€ä¸ªä¸»æœåŠ¡å™¨è¢«æ ‡è®°ä¸ºä¸»è§‚ä¸‹çº¿ï¼Œ å¹¶ä¸”æœ‰è¶³å¤Ÿæ•°é‡çš„ Sentinelï¼ˆè‡³å°‘è¦è¾¾åˆ°é…ç½®æ–‡ä»¶æŒ‡å®šçš„æ•°é‡ï¼‰åœ¨æŒ‡å®šçš„æ—¶é—´èŒƒå›´å†…åŒæ„è¿™ä¸€åˆ¤æ–­ï¼Œé‚£ä¹ˆè¿™ä¸ªä¸»æœåŠ¡å™¨è¢«æ ‡è®°ä¸ºå®¢è§‚ä¸‹çº¿ã€‚&lt;br /&gt;
åœ¨ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œ æ¯ä¸ª Sentinel ä¼šä»¥æ¯ 10 ç§’ä¸€æ¬¡çš„é¢‘ç‡å‘å®ƒå·²çŸ¥çš„æ‰€æœ‰ä¸»æœåŠ¡å™¨å’Œä»æœåŠ¡å™¨å‘é€ INFO å‘½ä»¤ã€‚å½“ä¸€ä¸ªä¸»æœåŠ¡å™¨ Sentinel æ ‡è®°ä¸ºå®¢è§‚ä¸‹çº¿æ—¶ï¼ŒSentinel å‘ä¸‹çº¿ä¸»æœåŠ¡å™¨çš„æ‰€æœ‰ä»æœåŠ¡å™¨å‘é€ INFO å‘½ä»¤çš„é¢‘ç‡ä¼šä» 10 ç§’ä¸€æ¬¡æ”¹ä¸ºæ¯ç§’ä¸€æ¬¡ã€‚&lt;br /&gt;
å½“æ²¡æœ‰è¶³å¤Ÿæ•°é‡çš„ Sentinel åŒæ„ä¸»æœåŠ¡å™¨å·²ç»ä¸‹çº¿ï¼Œ ä¸»æœåŠ¡å™¨çš„å®¢è§‚ä¸‹çº¿çŠ¶æ€å°±ä¼šè¢«ç§»é™¤ã€‚ å½“ä¸»æœåŠ¡å™¨é‡æ–°å‘ Sentinel çš„ PING å‘½ä»¤è¿”å›æœ‰æ•ˆå›å¤æ—¶ï¼Œ ä¸»æœåŠ¡å™¨çš„ä¸»ç®¡ä¸‹çº¿çŠ¶æ€å°±ä¼šè¢«ç§»é™¤ã€‚&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://imgse.com/i/pEgT1r6&#34;&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://s21.ax1x.com/2025/04/09/pEgT1r6.png&#34; alt=&#34;pEgT1r6.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;41-æ­å»ºå“¨å…µ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#41-æ­å»ºå“¨å…µ&#34;&gt;#&lt;/a&gt; 4.1 æ­å»ºå“¨å…µ&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;åœ¨æ¯å°æœåŠ¡å™¨ä¸Šéƒ¨ç½²ä¸€ä¸ªå“¨å…µï¼Œé…ç½®æ–¹å¼å¦‚ä¸‹:&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@redis01 redis]# vim sentinel.conf
#ç«¯å£é»˜è®¤ä¸º26379ã€‚
port 26379
#å…³é—­ä¿æŠ¤æ¨¡å¼ï¼Œå¯ä»¥å¤–éƒ¨è®¿é—®ã€‚
protected-mode no
#è®¾ç½®ä¸ºåå°å¯åŠ¨ã€‚
daemonize yes
#æ—¥å¿—æ–‡ä»¶ã€‚
logfile &amp;quot;/soft/redis/sentinel.log&amp;quot;
#æŒ‡å®šæœåŠ¡å™¨IPåœ°å€å’Œç«¯å£ï¼Œå¹¶ä¸”æŒ‡å®šå½“æœ‰2å°å“¨å…µè®¤ä¸ºä¸»æœºæŒ‚äº†ï¼Œåˆ™å¯¹ä¸»æœºè¿›è¡Œå®¹ç¾åˆ‡æ¢ã€‚æ³¨æ„:ä¸‰å°å“¨å…µè¿™é‡Œçš„ipé…ç½®å‡ä¸ºä¸»èŠ‚ç‚¹ip å’Œç«¯å£
sentinel monitor mymaster 192.168.40.101 6379 2
#å½“åœ¨Rediså®ä¾‹ä¸­å¼€å¯äº†requirepassï¼Œè¿™é‡Œå°±éœ€è¦æä¾›å¯†ç ã€‚
sentinel auth-pass mymaster psw66
#è¿™é‡Œè®¾ç½®äº†ä¸»æœºå¤šå°‘ç§’æ— å“åº”ï¼Œåˆ™è®¤ä¸ºæŒ‚äº†ã€‚
sentinel down-after-milliseconds mymaster 3000
#ä¸»å¤‡åˆ‡æ¢æ—¶ï¼Œæœ€å¤šæœ‰å¤šå°‘ä¸ªslaveåŒæ—¶å¯¹æ–°çš„masterè¿›è¡ŒåŒæ­¥ï¼Œè¿™é‡Œè®¾ç½®ä¸ºé»˜è®¤çš„
snetinel parallel-syncs mymaster 1
#æ•…éšœè½¬ç§»çš„è¶…æ—¶æ—¶é—´ï¼Œè¿™é‡Œè®¾ç½®ä¸ºä¸‰åˆ†é’Ÿã€‚
sentinel failover-timeout mymaster 180000
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;42-å¯åŠ¨ä¸‰å°æœåŠ¡å™¨ä¸Šçš„å“¨å…µ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#42-å¯åŠ¨ä¸‰å°æœåŠ¡å™¨ä¸Šçš„å“¨å…µ&#34;&gt;#&lt;/a&gt; 4.2 å¯åŠ¨ä¸‰å°æœåŠ¡å™¨ä¸Šçš„å“¨å…µ&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;#å¯åŠ¨redis01çš„sentine
[root@redis01 redis]# redis-sentinel /soft/redis/sentinel.conf
[root@redis01 redis]#  netstat -lntp|grep redis
tcp        0      0 0.0.0.0:26379           0.0.0.0:*               LISTEN      33536/redis-sentine 
tcp        0      0 192.168.40.101:6379     0.0.0.0:*               LISTEN      117358/redis-server 
tcp6       0      0 :::26379                :::*                    LISTEN      33536/redis-sentine

#å¯åŠ¨redis02çš„sentine
[root@redis02 redis]# redis-sentinel /soft/redis/sentinel.conf
[root@redis02 redis]#  netstat -lntp|grep redis
tcp        0      0 0.0.0.0:26379           0.0.0.0:*               LISTEN      18757/redis-sentine 
tcp        0      0 192.168.40.102:6379     0.0.0.0:*               LISTEN      18210/redis-server  
tcp6       0      0 :::26379                :::*                    LISTEN      18757/redis-sentine

#å¯åŠ¨redis03çš„sentine
[root@redis03 redis]# redis-sentinel /soft/redis/sentinel.conf                     
[root@redis03 redis]# netstat -lntp|grep redis
tcp        0      0 0.0.0.0:26379           0.0.0.0:*               LISTEN      19745/redis-sentine 
tcp        0      0 192.168.40.103:6379     0.0.0.0:*               LISTEN      19186/redis-server  
tcp6       0      0 :::26379                :::*                    LISTEN      19745/redis-sentine
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;43-è¿æ¥å®¢æˆ·ç«¯&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#43-è¿æ¥å®¢æˆ·ç«¯&#34;&gt;#&lt;/a&gt; 4.3 è¿æ¥å®¢æˆ·ç«¯&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@redis01 redis]# redis-cli -p 26379
127.0.0.1:26379&amp;gt;  info sentinel
# Sentinel
sentinel_masters:1
sentinel_tilt:0
sentinel_running_scripts:0
sentinel_scripts_queue_length:0
sentinel_simulate_failure_flags:0
master0:name=mymaster,status=ok,address=192.168.40.101:6379,slaves=2,sentinels=3
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;44-rediså®¹ç¾åˆ‡æ¢&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#44-rediså®¹ç¾åˆ‡æ¢&#34;&gt;#&lt;/a&gt; 4.4 redis å®¹ç¾åˆ‡æ¢&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;#è¿æ¥rediså®¢æˆ·ç«¯
[root@redis01 redis]# redis-cli -p 6379 -h 192.168.40.101 
#éªŒè¯å¯†ç 
192.168.40.101:6379&amp;gt; auth Superman*2023
OK
#å…³é—­redisæœåŠ¡
192.168.40.101:6379&amp;gt; shutdown
not connected&amp;gt;
#é€€å‡ºå®¢æˆ·ç«¯
not connected&amp;gt; exit
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å…³é—­ä¸»èŠ‚ç‚¹ä¹‹åï¼Œæˆ‘ä»¬å»æŸ¥çœ‹å“¨å…µæ—¥å¿—:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@redis01 ~]# tail -f /soft/redis/sentinel.log 
91936:X 14 Apr 2023 23:26:23.838 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo
91936:X 14 Apr 2023 23:26:23.838 # Redis version=6.2.11, bits=64, commit=00000000, modified=0, pid=91936, just started
91936:X 14 Apr 2023 23:26:23.838 # Configuration loaded
91936:X 14 Apr 2023 23:26:23.838 * monotonic clock: POSIX clock_gettime
91936:X 14 Apr 2023 23:26:23.839 * Running mode=sentinel, port=26379.
91936:X 14 Apr 2023 23:26:23.839 # Sentinel ID is 835b4c8544fb250af5fd479f834ee369cc4f388e
91936:X 14 Apr 2023 23:26:23.839 # +monitor master mymaster 192.168.40.101 6379 quorum 2



91936:X 14 Apr 2023 23:31:25.329 # +sdown master mymaster 192.168.40.101 6379   #è¿™é‡Œåº”è¯¥æ˜¯å‘ç°ä¸»èŠ‚ç‚¹å®•æœº
91936:X 14 Apr 2023 23:31:25.359 # +new-epoch 5
91936:X 14 Apr 2023 23:31:25.360 # +vote-for-leader ab43979285cb47b1b459aeb0ab91b63fa9d1a989 5
91936:X 14 Apr 2023 23:31:25.401 # +odown master mymaster 192.168.40.101 6379 #quorum 3/2 ä¸¤ä¸ªå“¨å…µéƒ½è§‰å¾—ä¸»èŠ‚ç‚¹å®•æœºäº†
91936:X 14 Apr 2023 23:31:25.401 # Next failover delay: I will not start a failover before Fri Apr 14 23:37:25 2023
91936:X 14 Apr 2023 23:31:26.468 # +config-update-from sentinel ab43979285cb47b1b459aeb0ab91b63fa9d1a989 192.168.40.102 26379 @ mymaster 192.168.40.101 6379
91936:X 14 Apr 2023 23:31:26.468 # +switch-master mymaster 192.168.40.101 6379 192.168.40.103 6379 #é€šè¿‡æŠ•ç¥¨é€‰ä¸¾40.103ä¸ºæ–°çš„ä¸»èŠ‚ç‚¹
91936:X 14 Apr 2023 23:31:26.468 * +slave slave 192.168.40.102:6379 192.168.40.102 6379 @ mymaster 192.168.40.103 6379
91936:X 14 Apr 2023 23:31:26.469 * +slave slave 192.168.40.101:6379 192.168.40.101 6379 @ mymaster 192.168.40.103 6379
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ä¸‹é¢æˆ‘ä»¬å» 40.103 ä¸‹æŸ¥çœ‹å“¨å…µä¸»ä»åˆ‡æ¢æ˜¯å¦æˆåŠŸ&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@redis03 redis]# redis-cli -p 6379 -h 192.168.40.103
192.168.40.103:6379&amp;gt; auth Superman*2023
OK
192.168.40.103:6379&amp;gt; info replication
# Replication
role:master   # 40.103å˜æˆä¸»èŠ‚ç‚¹äº†
connected_slaves:1   # ä¸‹é¢çš„ä»æœºä¸ªæ•°ä¸º1
slave0:ip=192.168.40.102,port=6379,state=online,offset=108708,lag=1
master_failover_state:no-failover
master_replid:cf36f762dcae0c07b54f7287dc19d7ecc0d50dd3
master_replid2:a7de32d10b2d31f8886c84ca91dc7f055439c935
master_repl_offset:108851
second_repl_offset:59887
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:1
repl_backlog_histlen:108851
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;é‡æ–°è¿æ¥æŒ‚æ‰çš„ä¸»èŠ‚ç‚¹&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@redis01 redis]# redis-server redis.conf 
[root@redis01 redis]#  redis-cli -p 6379 -h 192.168.40.101
192.168.40.101:6379&amp;gt; auth Superman*2023
OK
192.168.40.101:6379&amp;gt; info replication
# Replication
role:slave          #ä¸»èŠ‚ç‚¹è¿æ¥å›æ¥ä¹‹åè‡ªåŠ¨å˜æˆäº†ä»èŠ‚ç‚¹ï¼Œå¹¶ä¸”æˆåŠŸè¿ä¸Šäº†ä¸»æœº
master_host:192.168.40.103
master_port:6379
master_link_status:up
master_last_io_seconds_ago:1
master_sync_in_progress:0
slave_read_repl_offset:130607
slave_repl_offset:130607
slave_priority:100
slave_read_only:1
replica_announced:1
connected_slaves:0
master_failover_state:no-failover
master_replid:cf36f762dcae0c07b54f7287dc19d7ecc0d50dd3
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:130607
second_repl_offset:-1
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:126982
repl_backlog_histlen:3626
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å†å»ä¸»èŠ‚ç‚¹ç¡®è®¤ä¸€ä¸‹&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;192.168.40.103:6379&amp;gt; info replication
# Replication
role:master
connected_slaves:2   #ä¸¤ä¸ªä»èŠ‚ç‚¹
slave0:ip=192.168.40.102,port=6379,state=online,offset=147879,lag=1
slave1:ip=192.168.40.101,port=6379,state=online,offset=147879,lag=1
master_failover_state:no-failover
master_replid:cf36f762dcae0c07b54f7287dc19d7ecc0d50dd3
master_replid2:a7de32d10b2d31f8886c84ca91dc7f055439c935
master_repl_offset:148165
second_repl_offset:59887
repl_backlog_active:1
repl_backlog_size:1048576
repl_backlog_first_byte_offset:1
repl_backlog_histlen:148165
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;äº”ã€å“¨å…µæ¨¡å¼çš„ä¼˜ç¼ºç‚¹&lt;br /&gt;
 1. ä¼˜ç‚¹&lt;/p&gt;
&lt;p&gt;å“¨å…µé›†ç¾¤ï¼ŒåŸºäºä¸»ä»å¤åˆ¶æ¨¡å¼ï¼Œæ‰€æœ‰çš„ä¸»ä»é…ç½®ä¼˜ç‚¹ï¼Œå®ƒå…¨æœ‰&lt;/p&gt;
&lt;p&gt;ä¸»ä»å¯ä»¥åˆ‡æ¢ï¼Œæ•…éšœå¯ä»¥è½¬ç§»ï¼Œç³»ç»Ÿçš„å¯ç”¨æ€§å°±ä¼šæ›´å¥½&lt;/p&gt;
&lt;p&gt;å“¨å…µæ¨¡å¼å°±æ˜¯ä¸»ä»æ¨¡å¼çš„å‡çº§ï¼Œæ‰‹åŠ¨åˆ°è‡ªåŠ¨ï¼Œæ›´åŠ å¥å£®ï¼&lt;/p&gt;
&lt;p&gt;2. ç¼ºç‚¹&lt;/p&gt;
&lt;p&gt;Redis ä¸å¥½åœ¨çº¿æ‰©å®¹ï¼Œé›†ç¾¤å®¹é‡ä¸€æ—¦åˆ°è¾¾ä¸Šé™ï¼Œåœ¨çº¿æ‰©å®¹å°±ååˆ†éº»çƒ¦&lt;/p&gt;
&lt;p&gt;å“¨å…µæ¨¡å¼çš„é…ç½®ç¹ç&lt;/p&gt;
&lt;p&gt;3. å“¨å…µæ¨¡å¼çš„é…ç½®æ–‡ä»¶è¯¦è§£&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Example sentinel.conf
# å“¨å…µsentinelå®ä¾‹è¿è¡Œçš„ç«¯å£ é»˜è®¤26379
port 26379
 
# å“¨å…µsentinelçš„å·¥ä½œç›®å½•
dir /tmp
 
# å“¨å…µsentinelç›‘æ§çš„redisä¸»èŠ‚ç‚¹çš„ ip port
# master-name å¯ä»¥è‡ªå·±å‘½åçš„ä¸»èŠ‚ç‚¹åå­— åªèƒ½ç”±å­—æ¯A-zã€æ•°å­—0-9 ã€è¿™ä¸‰ä¸ªå­—ç¬¦&amp;quot;.-_&amp;quot;ç»„æˆã€‚
# quorum é…ç½®å¤šå°‘ä¸ªsentinelå“¨å…µç»Ÿä¸€è®¤ä¸ºmasterä¸»èŠ‚ç‚¹å¤±è” é‚£ä¹ˆè¿™æ—¶å®¢è§‚ä¸Šè®¤ä¸ºä¸»èŠ‚ç‚¹å¤±è”äº†
# sentinel monitor &amp;lt;master-name&amp;gt; &amp;lt;ip&amp;gt; &amp;lt;redis-port&amp;gt; &amp;lt;quorum&amp;gt;
sentinel monitor mymaster 127.0.0.1 6379 2
  
# å½“åœ¨Rediså®ä¾‹ä¸­å¼€å¯äº†requirepass foobared æˆæƒå¯†ç è¿™æ ·æ‰€æœ‰è¿æ¥Rediså®ä¾‹çš„å®¢æˆ·ç«¯éƒ½è¦æä¾› å¯†ç 
# è®¾ç½®å“¨å…µsentinel è¿æ¥ä¸»ä»çš„å¯†ç  æ³¨æ„å¿…é¡»ä¸ºä¸»ä»è®¾ç½®ä¸€æ ·çš„éªŒè¯å¯†ç 
# sentinel auth-pass &amp;lt;master-name&amp;gt; &amp;lt;password&amp;gt;
sentinel auth-pass mymaster MySUPER--secret-0123passw0rd
 
# æŒ‡å®šå¤šå°‘æ¯«ç§’ä¹‹å ä¸»èŠ‚ç‚¹æ²¡æœ‰åº”ç­”å“¨å…µsentinel æ­¤æ—¶å“¨å…µä¸»è§‚ä¸Šè®¤ä¸ºä¸»èŠ‚ç‚¹ä¸‹çº¿ é»˜è®¤30ç§’
# sentinel down-after-milliseconds &amp;lt;master-name&amp;gt; &amp;lt;milliseconds&amp;gt;
sentinel down-after-milliseconds mymaster 30000
 
# è¿™ä¸ªé…ç½®é¡¹æŒ‡å®šäº†åœ¨å‘ç”Ÿfailoverä¸»å¤‡åˆ‡æ¢æ—¶æœ€å¤šå¯ä»¥æœ‰å¤šå°‘ä¸ªslaveåŒæ—¶å¯¹æ–°çš„masterè¿›è¡ŒåŒæ­¥ï¼Œè¿™ä¸ªæ•°å­—è¶Šå°ï¼Œå®Œæˆfailoveræ‰€éœ€çš„æ—¶é—´å°±è¶Šé•¿ï¼Œ ä½†æ˜¯å¦‚æœè¿™ä¸ªæ•°å­—è¶Šå¤§ï¼Œå°±æ„å‘³ç€è¶Š å¤šçš„slaveå› ä¸ºreplicationè€Œä¸å¯ç”¨ã€‚ å¯ä»¥é€šè¿‡å°†è¿™ä¸ªå€¼è®¾ä¸º 1 æ¥ä¿è¯æ¯æ¬¡åªæœ‰ä¸€ä¸ªslave å¤„äºä¸èƒ½å¤„ç†å‘½ä»¤è¯·æ±‚çš„çŠ¶æ€ã€‚
# sentinel parallel-syncs &amp;lt;master-name&amp;gt; &amp;lt;numslaves&amp;gt;
sentinel parallel-syncs mymaster 1
 
# æ•…éšœè½¬ç§»çš„è¶…æ—¶æ—¶é—´ failover-timeout å¯ä»¥ç”¨åœ¨ä»¥ä¸‹è¿™äº›æ–¹é¢ï¼š
#1. åŒä¸€ä¸ªsentinelå¯¹åŒä¸€ä¸ªmasterä¸¤æ¬¡failoverä¹‹é—´çš„é—´éš”æ—¶é—´ã€‚
#2. å½“ä¸€ä¸ªslaveä»ä¸€ä¸ªé”™è¯¯çš„masteré‚£é‡ŒåŒæ­¥æ•°æ®å¼€å§‹è®¡ç®—æ—¶é—´ã€‚ç›´åˆ°slaveè¢«çº æ­£ä¸ºå‘æ­£ç¡®çš„masteré‚£ é‡ŒåŒæ­¥æ•°æ®æ—¶ã€‚
#3.å½“æƒ³è¦å–æ¶ˆä¸€ä¸ªæ­£åœ¨è¿›è¡Œçš„failoveræ‰€éœ€è¦çš„æ—¶é—´ã€‚
#4.å½“è¿›è¡Œfailoveræ—¶ï¼Œé…ç½®æ‰€æœ‰slavesæŒ‡å‘æ–°çš„masteræ‰€éœ€çš„æœ€å¤§æ—¶é—´ã€‚ä¸è¿‡ï¼Œå³ä½¿è¿‡äº†è¿™ä¸ªè¶…æ—¶ï¼Œ slavesä¾ç„¶ä¼šè¢«æ­£ç¡®é…ç½®ä¸ºæŒ‡å‘masterï¼Œä½†æ˜¯å°±ä¸æŒ‰parallel-syncsæ‰€é…ç½®çš„è§„åˆ™æ¥äº† # é»˜è®¤ä¸‰åˆ†é’Ÿ
# sentinel failover-timeout &amp;lt;master-name&amp;gt; &amp;lt;milliseconds&amp;gt; bilibiliï¼š
sentinel failover-timeout mymaster 180000
 
# SCRIPTS EXECUTION
#é…ç½®å½“æŸä¸€äº‹ä»¶å‘ç”Ÿæ—¶æ‰€éœ€è¦æ‰§è¡Œçš„è„šæœ¬ï¼Œå¯ä»¥é€šè¿‡è„šæœ¬æ¥é€šçŸ¥ç®¡ç†å‘˜ï¼Œä¾‹å¦‚å½“ç³»ç»Ÿè¿è¡Œä¸æ­£å¸¸æ—¶å‘é‚®ä»¶é€šçŸ¥ ç›¸å…³äººå‘˜ã€‚
#å¯¹äºè„šæœ¬çš„è¿è¡Œç»“æœæœ‰ä»¥ä¸‹è§„åˆ™ï¼š
#è‹¥è„šæœ¬æ‰§è¡Œåè¿”å›1ï¼Œé‚£ä¹ˆè¯¥è„šæœ¬ç¨åå°†ä¼šè¢«å†æ¬¡æ‰§è¡Œï¼Œé‡å¤æ¬¡æ•°ç›®å‰é»˜è®¤ä¸º10
#è‹¥è„šæœ¬æ‰§è¡Œåè¿”å›2ï¼Œæˆ–è€…æ¯”2æ›´é«˜çš„ä¸€ä¸ªè¿”å›å€¼ï¼Œè„šæœ¬å°†ä¸ä¼šé‡å¤æ‰§è¡Œã€‚
#å¦‚æœè„šæœ¬åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­ç”±äºæ”¶åˆ°ç³»ç»Ÿä¸­æ–­ä¿¡å·è¢«ç»ˆæ­¢äº†ï¼Œåˆ™åŒè¿”å›å€¼ä¸º1æ—¶çš„è¡Œä¸ºç›¸åŒã€‚
#ä¸€ä¸ªè„šæœ¬çš„æœ€å¤§æ‰§è¡Œæ—¶é—´ä¸º60sï¼Œå¦‚æœè¶…è¿‡è¿™ä¸ªæ—¶é—´ï¼Œè„šæœ¬å°†ä¼šè¢«ä¸€ä¸ªSIGKILLä¿¡å·ç»ˆæ­¢ï¼Œä¹‹åé‡æ–°æ‰§è¡Œã€‚
#é€šçŸ¥å‹è„šæœ¬:å½“sentinelæœ‰ä»»ä½•è­¦å‘Šçº§åˆ«çš„äº‹ä»¶å‘ç”Ÿæ—¶ï¼ˆæ¯”å¦‚è¯´rediså®ä¾‹çš„ä¸»è§‚å¤±æ•ˆå’Œå®¢è§‚å¤±æ•ˆç­‰ç­‰ï¼‰ï¼Œ å°†ä¼šå»è°ƒç”¨è¿™ä¸ªè„šæœ¬ï¼Œè¿™æ—¶è¿™ä¸ªè„šæœ¬åº”è¯¥é€šè¿‡é‚®ä»¶ï¼ŒSMSç­‰æ–¹å¼å»é€šçŸ¥ç³»ç»Ÿç®¡ç†å‘˜å…³äºç³»ç»Ÿä¸æ­£å¸¸è¿è¡Œçš„ä¿¡ æ¯ã€‚è°ƒç”¨è¯¥è„šæœ¬æ—¶ï¼Œå°†ä¼ ç»™è„šæœ¬ä¸¤ä¸ªå‚æ•°ï¼Œä¸€ä¸ªæ˜¯äº‹ä»¶çš„ç±»å‹ï¼Œä¸€ä¸ªæ˜¯äº‹ä»¶çš„æè¿°ã€‚å¦‚æœsentinel.confé… ç½®æ–‡ä»¶ä¸­é…ç½®äº†è¿™ä¸ªè„šæœ¬è·¯å¾„ï¼Œé‚£ä¹ˆå¿…é¡»ä¿è¯è¿™ä¸ªè„šæœ¬å­˜åœ¨äºè¿™ä¸ªè·¯å¾„ï¼Œå¹¶ä¸”æ˜¯å¯æ‰§è¡Œçš„ï¼Œå¦åˆ™sentinelæ—  æ³•æ­£å¸¸å¯åŠ¨æˆåŠŸã€‚
#é€šçŸ¥è„šæœ¬
# shellç¼–ç¨‹
# sentinel notification-script &amp;lt;master-name&amp;gt; &amp;lt;script-path&amp;gt; sentinel
notification-script mymaster /var/redis/notify.sh
 
# å®¢æˆ·ç«¯é‡æ–°é…ç½®ä¸»èŠ‚ç‚¹å‚æ•°è„šæœ¬
# å½“ä¸€ä¸ªmasterç”±äºfailoverè€Œå‘ç”Ÿæ”¹å˜æ—¶ï¼Œè¿™ä¸ªè„šæœ¬å°†ä¼šè¢«è°ƒç”¨ï¼Œé€šçŸ¥ç›¸å…³çš„å®¢æˆ·ç«¯å…³äºmasteråœ°å€å·² ç»å‘ç”Ÿæ”¹å˜çš„ä¿¡æ¯ã€‚
# ä»¥ä¸‹å‚æ•°å°†ä¼šåœ¨è°ƒç”¨è„šæœ¬æ—¶ä¼ ç»™è„šæœ¬:
# &amp;lt;master-name&amp;gt; &amp;lt;role&amp;gt; &amp;lt;state&amp;gt; &amp;lt;from-ip&amp;gt; &amp;lt;from-port&amp;gt; &amp;lt;to-ip&amp;gt; &amp;lt;to-port&amp;gt; # ç›®å‰&amp;lt;state&amp;gt;æ€»æ˜¯â€œfailoverâ€,
# &amp;lt;role&amp;gt;æ˜¯â€œleaderâ€æˆ–è€…â€œobserverâ€ä¸­çš„ä¸€ä¸ªã€‚
# å‚æ•° from-ip, from-port, to-ip, to-portæ˜¯ç”¨æ¥å’Œæ—§çš„masterå’Œæ–°çš„master(å³æ—§çš„slave)é€š ä¿¡çš„# è¿™ä¸ªè„šæœ¬åº”è¯¥æ˜¯é€šç”¨çš„ï¼Œèƒ½è¢«å¤šæ¬¡è°ƒç”¨ï¼Œä¸æ˜¯é’ˆå¯¹æ€§çš„ã€‚
# sentinel client-reconfig-script &amp;lt;master-name&amp;gt; &amp;lt;script-path&amp;gt; sentinel client-reconfig-
script mymaster /var/redis/reconfig.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;å†å»çœ‹ä¸€ä¸‹ redis çš„é…ç½®æ–‡ä»¶å’Œå“¨å…µçš„é…ç½®æ–‡ä»¶ï¼Œä½ ä¼šæƒŠè®¶çš„å‘ç°ï¼Œé‡Œè¾¹çš„é…ç½®æ–‡ä»¶å·²ç»è¢«æ”¹è¿‡æ¥äº†ã€‚&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat redis.con
...
replicaof 192.168.40.103 6379
&lt;/code&gt;&lt;/pre&gt;
</content>
        <category term="Redis" />
        <updated>2025-04-09T11:50:06.000Z</updated>
    </entry>
    <entry>
        <id>http://ixuyong.cn/posts/3166738000.html</id>
        <title>Kubeadmé«˜å¯ç”¨å®‰è£…K8sé›†ç¾¤</title>
        <link rel="alternate" href="http://ixuyong.cn/posts/3166738000.html"/>
        <content type="html">&lt;h2 id=&#34;kubeadmé«˜å¯ç”¨å®‰è£…k8sé›†ç¾¤&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#kubeadmé«˜å¯ç”¨å®‰è£…k8sé›†ç¾¤&#34;&gt;#&lt;/a&gt; Kubeadm é«˜å¯ç”¨å®‰è£… K8s é›†ç¾¤&lt;/h2&gt;
&lt;h4 id=&#34;1-åŸºæœ¬é…ç½®&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-åŸºæœ¬é…ç½®&#34;&gt;#&lt;/a&gt; 1. åŸºæœ¬é…ç½®&lt;/h4&gt;
&lt;h5 id=&#34;11-åŸºæœ¬ç¯å¢ƒé…ç½®&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#11-åŸºæœ¬ç¯å¢ƒé…ç½®&#34;&gt;#&lt;/a&gt; 1.1 åŸºæœ¬ç¯å¢ƒé…ç½®&lt;/h5&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;ä¸»æœºå&lt;/th&gt;
&lt;th&gt;IP åœ°å€&lt;/th&gt;
&lt;th&gt;è¯´æ˜&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;k8s-master01 ~ 03&lt;/td&gt;
&lt;td&gt;192.168.1.71 ~ 73&lt;/td&gt;
&lt;td&gt;master èŠ‚ç‚¹ * 3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;/&lt;/td&gt;
&lt;td&gt;192.168.1.70&lt;/td&gt;
&lt;td&gt;keepalived è™šæ‹Ÿ IPï¼ˆä¸å ç”¨æœºå™¨ï¼‰&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;k8s-node01 ~ 02&lt;/td&gt;
&lt;td&gt;192.168.1.74/75&lt;/td&gt;
&lt;td&gt;worker èŠ‚ç‚¹ * 2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;em&gt;è¯·ç»Ÿä¸€æ›¿æ¢è¿™äº›ç½‘æ®µï¼ŒPod ç½‘æ®µå’Œ service å’Œå®¿ä¸»æœºç½‘æ®µä¸è¦é‡å¤ï¼ï¼ï¼&lt;/em&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;em&gt;&lt;strong&gt;* é…ç½®ä¿¡æ¯ *&lt;/strong&gt;&lt;/em&gt;&lt;/th&gt;
&lt;th&gt;å¤‡æ³¨&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;ç³»ç»Ÿç‰ˆæœ¬&lt;/td&gt;
&lt;td&gt;Rocky Linux 8/9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Containerd&lt;/td&gt;
&lt;td&gt;latest&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Pod ç½‘æ®µ&lt;/td&gt;
&lt;td&gt;172.16.0.0/16&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Service ç½‘æ®µ&lt;/td&gt;
&lt;td&gt;10.96.0.0/16&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;æ›´æ”¹ä¸»æœºåï¼ˆå…¶å®ƒèŠ‚ç‚¹æŒ‰éœ€ä¿®æ”¹ï¼‰ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;hostnamectl set-hostname k8s-master01 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;é…ç½® hostsï¼Œä¿®æ”¹ /etc/hosts å¦‚ä¸‹ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# cat /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
192.168.1.71 k8s-master01
192.168.1.72 k8s-master02
192.168.1.73 k8s-master03
192.168.1.74 k8s-node01
192.168.1.75 k8s-node02
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;é…ç½® yum æºï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# é…ç½®åŸºç¡€æº
sed -e &#39;s|^mirrorlist=|#mirrorlist=|g&#39; \
    -e &#39;s|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g&#39; \
    -i.bak \
    /etc/yum.repos.d/*.repo

yum makecache
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;å¿…å¤‡å·¥å…·å®‰è£…ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yum install wget jq psmisc vim net-tools telnet yum-utils device-mapper-persistent-data lvm2 git rsyslog -y
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;å…³é—­é˜²ç«å¢™ã€selinuxã€dnsmasqã€swapã€å¼€å¯ rsyslogã€‚æœåŠ¡å™¨é…ç½®å¦‚ä¸‹ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;systemctl disable --now firewalld 
systemctl disable --now dnsmasq
setenforce 0
sed -i &#39;s#SELINUX=enforcing#SELINUX=disabled#g&#39; /etc/sysconfig/selinux
sed -i &#39;s#SELINUX=enforcing#SELINUX=disabled#g&#39; /etc/selinux/config
systemctl enable --now rsyslog
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;å…³é—­ swap åˆ†åŒºï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;swapoff -a &amp;amp;&amp;amp; sysctl -w vm.swappiness=0
sed -ri &#39;/^[^#]*swap/s@^@#@&#39; /etc/fstab
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;å®‰è£… ntpdateï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo dnf install epel-release -y
sudo dnf config-manager --set-enabled epel
sudo dnf install ntpsec
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;åŒæ­¥æ—¶é—´å¹¶é…ç½®ä¸Šæµ·æ—¶åŒºï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
echo &#39;Asia/Shanghai&#39; &amp;gt;/etc/timezone
ntpdate time2.aliyun.com
# åŠ å…¥åˆ°crontab
crontab -e
*/5 * * * * /usr/sbin/ntpdate time2.aliyun.com
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;é…ç½® limitï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ulimit -SHn 65535
vim /etc/security/limits.conf
# æœ«å°¾æ·»åŠ å¦‚ä¸‹å†…å®¹
* soft nofile 65536
* hard nofile 131072
* soft nproc 65535
* hard nproc 655350
* soft memlock unlimited
* hard memlock unlimited
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;å‡çº§ç³»ç»Ÿï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yum update -y
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;Master01 èŠ‚ç‚¹&lt;/mark&gt;å…å¯†é’¥ç™»å½•å…¶ä»–èŠ‚ç‚¹ï¼Œå®‰è£…è¿‡ç¨‹ä¸­ç”Ÿæˆé…ç½®æ–‡ä»¶å’Œè¯ä¹¦å‡åœ¨ Master01 ä¸Šæ“ä½œï¼Œé›†ç¾¤ç®¡ç†ä¹Ÿåœ¨ Master01 ä¸Šæ“ä½œï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ssh-keygen -t rsa
for i in k8s-master01 k8s-master02 k8s-master03 k8s-node01 k8s-node02;do ssh-copy-id -i .ssh/id_rsa.pub $i;done
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;æ³¨æ„ï¼šå…¬æœ‰äº‘ç¯å¢ƒï¼Œå¯èƒ½éœ€è¦æŠŠ kubectl æ”¾åœ¨ä¸€ä¸ªé Master èŠ‚ç‚¹ä¸Š&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;mark&gt;Master01 èŠ‚ç‚¹&lt;/mark&gt;ä¸‹è½½å®‰è£…æ‰€æœ‰çš„æºç æ–‡ä»¶ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd /root/ ; git clone https://gitee.com/chinagei/k8s-ha-install
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;12-å†…æ ¸é…ç½®&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#12-å†…æ ¸é…ç½®&#34;&gt;#&lt;/a&gt; 1.2 å†…æ ¸é…ç½®&lt;/h5&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;å®‰è£… ipvsadmï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yum install ipvsadm ipset sysstat conntrack libseccomp -y
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;é…ç½® ipvs æ¨¡å—ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;modprobe -- ip_vs
modprobe -- ip_vs_rr
modprobe -- ip_vs_wrr
modprobe -- ip_vs_sh
modprobe -- nf_conntrack
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;åˆ›å»º ipvs.confï¼Œå¹¶é…ç½®å¼€æœºè‡ªåŠ¨åŠ è½½ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vim /etc/modules-load.d/ipvs.conf 
# åŠ å…¥ä»¥ä¸‹å†…å®¹
ip_vs
ip_vs_lc
ip_vs_wlc
ip_vs_rr
ip_vs_wrr
ip_vs_lblc
ip_vs_lblcr
ip_vs_dh
ip_vs_sh
ip_vs_fo
ip_vs_nq
ip_vs_sed
ip_vs_ftp
ip_vs_sh
nf_conntrack
ip_tables
ip_set
xt_set
ipt_set
ipt_rpfilter
ipt_REJECT
ipip
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;ç„¶åæ‰§è¡Œ systemctl enable --now systemd-modules-load.service å³å¯ï¼ˆæŠ¥é”™ä¸ç”¨ç®¡ï¼‰&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;systemctl enable --now systemd-modules-load.service
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;å†…æ ¸ä¼˜åŒ–é…ç½®ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt;EOF &amp;gt; /etc/sysctl.d/k8s.conf
net.ipv4.ip_forward = 1
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-ip6tables = 1
fs.may_detach_mounts = 1
net.ipv4.conf.all.route_localnet = 1
vm.overcommit_memory=1
vm.panic_on_oom=0
fs.inotify.max_user_watches=89100
fs.file-max=52706963
fs.nr_open=52706963
net.netfilter.nf_conntrack_max=2310720

net.ipv4.tcp_keepalive_time = 600
net.ipv4.tcp_keepalive_probes = 3
net.ipv4.tcp_keepalive_intvl =15
net.ipv4.tcp_max_tw_buckets = 36000
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_max_orphans = 327680
net.ipv4.tcp_orphan_retries = 3
net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_max_syn_backlog = 16384
net.ipv4.ip_conntrack_max = 65536
net.ipv4.tcp_max_syn_backlog = 16384
net.ipv4.tcp_timestamps = 0
net.core.somaxconn = 16384
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;åº”ç”¨é…ç½®ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sysctl --system
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;é…ç½®å®Œå†…æ ¸åï¼Œé‡å¯æœºå™¨ï¼Œä¹‹åæŸ¥çœ‹å†…æ ¸æ¨¡å—æ˜¯å¦å·²è‡ªåŠ¨åŠ è½½ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;reboot
lsmod | grep --color=auto -e ip_vs -e nf_conntrack
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2-é«˜å¯ç”¨ç»„ä»¶å®‰è£…&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-é«˜å¯ç”¨ç»„ä»¶å®‰è£…&#34;&gt;#&lt;/a&gt; 2. é«˜å¯ç”¨ç»„ä»¶å®‰è£…&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;æ³¨æ„ï¼šå¦‚æœå®‰è£…çš„ä¸æ˜¯é«˜å¯ç”¨é›†ç¾¤ï¼Œhaproxy å’Œ keepalived æ— éœ€å®‰è£…&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;æ³¨æ„ï¼šå…¬æœ‰äº‘è¦ç”¨å…¬æœ‰äº‘è‡ªå¸¦çš„è´Ÿè½½å‡è¡¡ï¼Œæ¯”å¦‚é˜¿é‡Œäº‘çš„ SLBã€NLBï¼Œè…¾è®¯äº‘çš„ ELBï¼Œç”¨æ¥æ›¿ä»£ haproxy å’Œ keepalivedï¼Œå› ä¸ºå…¬æœ‰äº‘å¤§éƒ¨åˆ†éƒ½æ˜¯ä¸æ”¯æŒ keepalived çš„ã€‚&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰ Master èŠ‚ç‚¹&lt;/mark&gt;é€šè¿‡ yum å®‰è£… HAProxy å’Œ KeepAlivedï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yum install keepalived haproxy -y
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰ Master èŠ‚ç‚¹&lt;/mark&gt;é…ç½® HAProxyï¼Œéœ€è¦æ³¨æ„é»„è‰²éƒ¨åˆ†çš„ IPï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 etc]# mkdir /etc/haproxy
[root@k8s-master01 etc]# vim /etc/haproxy/haproxy.cfg 
global
  maxconn  2000
  ulimit-n  16384
  log  127.0.0.1 local0 err
  stats timeout 30s

defaults
  log global
  mode  http
  option  httplog
  timeout connect 5000
  timeout client  50000
  timeout server  50000
  timeout http-request 15s
  timeout http-keep-alive 15s

frontend monitor-in
  bind *:33305
  mode http
  option httplog
  monitor-uri /monitor

frontend k8s-master
  bind 0.0.0.0:16443       #HAProxyç›‘å¬ç«¯å£
  bind 127.0.0.1:16443     #HAProxyç›‘å¬ç«¯å£
  mode tcp
  option tcplog
  tcp-request inspect-delay 5s
  default_backend k8s-master

backend k8s-master
  mode tcp
  option tcplog
  option tcp-check
  balance roundrobin
  default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100
  server k8s-master01	192.168.1.71:6443  check       #API Server IPåœ°å€
  server k8s-master02	192.168.1.72:6443  check       #API Server IPåœ°å€
  server k8s-master03	192.168.1.73:6443  check       #API Server IPåœ°å€
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰ Master èŠ‚ç‚¹&lt;/mark&gt;é…ç½® KeepAlivedï¼Œéœ€è¦æ³¨æ„é»„è‰²éƒ¨åˆ†çš„é…ç½®ã€‚&lt;/p&gt;
&lt;p&gt;&lt;mark&gt;Master01 èŠ‚ç‚¹&lt;/mark&gt;çš„é…ç½®ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 etc]# mkdir /etc/keepalived

[root@k8s-master01 ~]# vim /etc/keepalived/keepalived.conf 
! Configuration File for keepalived
global_defs &amp;#123;
    router_id LVS_DEVEL
script_user root
    enable_script_security
&amp;#125;
vrrp_script chk_apiserver &amp;#123;
    script &amp;quot;/etc/keepalived/check_apiserver.sh&amp;quot;
    interval 5
    weight -5
    fall 2  
rise 1
&amp;#125;
vrrp_instance VI_1 &amp;#123;
    state MASTER
    interface ens160               #ç½‘å¡åç§°
    mcast_src_ip 192.168.1.71      #K8s-master01 IPåœ°å€
    virtual_router_id 51
    priority 101
    advert_int 2
    authentication &amp;#123;
        auth_type PASS
        auth_pass K8SHA_KA_AUTH
    &amp;#125;
    virtual_ipaddress &amp;#123;
        192.168.1.70        #VIPåœ°å€
    &amp;#125;
    track_script &amp;#123;
       chk_apiserver
    &amp;#125;
&amp;#125;	
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;Master02 èŠ‚ç‚¹&lt;/mark&gt;çš„é…ç½®ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# vim /etc/keepalived/keepalived.conf 

! Configuration File for keepalived
global_defs &amp;#123;
    router_id LVS_DEVEL
script_user root
    enable_script_security
&amp;#125;
vrrp_script chk_apiserver &amp;#123;
    script &amp;quot;/etc/keepalived/check_apiserver.sh&amp;quot;
   interval 5
    weight -5
    fall 2  
rise 1
&amp;#125;
vrrp_instance VI_1 &amp;#123;
    state BACKUP
    interface ens160                #ç½‘å¡åç§°
    mcast_src_ip 192.168.1.72       #K8s-master02 IPåœ°å€
    virtual_router_id 51
    priority 100
    advert_int 2
    authentication &amp;#123;
        auth_type PASS
        auth_pass K8SHA_KA_AUTH
    &amp;#125;
    virtual_ipaddress &amp;#123;
        192.168.1.70              #VIPåœ°å€
    &amp;#125;
    track_script &amp;#123;
       chk_apiserver
    &amp;#125;
&amp;#125;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;Master03 èŠ‚ç‚¹&lt;/mark&gt;çš„é…ç½®ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# vim /etc/keepalived/keepalived.conf 

! Configuration File for keepalived
global_defs &amp;#123;
    router_id LVS_DEVEL
script_user root
    enable_script_security
&amp;#125;
vrrp_script chk_apiserver &amp;#123;
    script &amp;quot;/etc/keepalived/check_apiserver.sh&amp;quot;
 interval 5
    weight -5
    fall 2  
rise 1
&amp;#125;
vrrp_instance VI_1 &amp;#123;
    state BACKUP
    interface ens160                 #ç½‘å¡åç§°
    mcast_src_ip 192.168.1.73        #K8s-master03 IPåœ°å€
    virtual_router_id 51
    priority 100
    advert_int 2
    authentication &amp;#123;
        auth_type PASS
        auth_pass K8SHA_KA_AUTH
    &amp;#125;
    virtual_ipaddress &amp;#123;
        192.168.1.70          #VIPåœ°å€
    &amp;#125;
    track_script &amp;#123;
       chk_apiserver
    &amp;#125;
&amp;#125;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰ master èŠ‚ç‚¹&lt;/mark&gt;é…ç½® KeepAlived å¥åº·æ£€æŸ¥æ–‡ä»¶ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 keepalived]# vim /etc/keepalived/check_apiserver.sh 
#!/bin/bash

err=0
for k in $(seq 1 3)
do
    check_code=$(pgrep haproxy)
    if [[ $check_code == &amp;quot;&amp;quot; ]]; then
        err=$(expr $err + 1)
        sleep 1
        continue
    else
        err=0
        break
    fi
done

if [[ $err != &amp;quot;0&amp;quot; ]]; then
    echo &amp;quot;systemctl stop keepalived&amp;quot;
    /usr/bin/systemctl stop keepalived
    exit 1
else
    exit 0
fi
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰ master èŠ‚ç‚¹&lt;/mark&gt;é…ç½®å¥åº·æ£€æŸ¥æ–‡ä»¶æ·»åŠ æ‰§è¡Œæƒé™ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;chmod +x /etc/keepalived/check_apiserver.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰ master èŠ‚ç‚¹&lt;/mark&gt;å¯åŠ¨ haproxy å’Œ keepalivedï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 keepalived]# systemctl daemon-reload
[root@k8s-master01 keepalived]# systemctl enable --now haproxy
[root@k8s-master01 keepalived]# systemctl enable --now keepalived
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;é‡è¦ï¼šå¦‚æœå®‰è£…äº† keepalived å’Œ haproxyï¼Œéœ€è¦æµ‹è¯• keepalived æ˜¯å¦æ˜¯æ­£å¸¸çš„&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;æ‰€æœ‰èŠ‚ç‚¹æµ‹è¯•VIP
[root@k8s-master01 ~]# ping 192.168.1.70 -c 4
PING 192.168.1.70 (192.168.1.70) 56(84) bytes of data.
64 bytes from 192.168.1.70: icmp_seq=1 ttl=64 time=0.464 ms
64 bytes from 192.168.1.70: icmp_seq=2 ttl=64 time=0.063 ms
64 bytes from 192.168.1.70: icmp_seq=3 ttl=64 time=0.062 ms
64 bytes from 192.168.1.70: icmp_seq=4 ttl=64 time=0.063 ms

[root@k8s-master01 ~]# telnet 192.168.1.70 16443
Trying 192.168.1.70...
Connected to 192.168.1.70.
Escape character is &#39;^]&#39;.
Connection closed by foreign host.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å¦‚æœ ping ä¸é€šä¸” telnet æ²¡æœ‰å‡ºç° ] ï¼Œåˆ™è®¤ä¸º VIP ä¸å¯ä»¥ï¼Œä¸å¯åœ¨ç»§ç»­å¾€ä¸‹æ‰§è¡Œï¼Œéœ€è¦æ’æŸ¥ keepalived çš„é—®é¢˜ï¼Œæ¯”å¦‚é˜²ç«å¢™å’Œ selinuxï¼Œhaproxy å’Œ keepalived çš„çŠ¶æ€ï¼Œç›‘å¬ç«¯å£ç­‰&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;æ‰€æœ‰èŠ‚ç‚¹æŸ¥çœ‹é˜²ç«å¢™çŠ¶æ€å¿…é¡»ä¸º disable å’Œ inactiveï¼šsystemctl status firewalld&lt;/li&gt;
&lt;li&gt;æ‰€æœ‰èŠ‚ç‚¹æŸ¥çœ‹ selinux çŠ¶æ€ï¼Œå¿…é¡»ä¸º disableï¼šgetenforce&lt;/li&gt;
&lt;li&gt;master èŠ‚ç‚¹æŸ¥çœ‹ haproxy å’Œ keepalived çŠ¶æ€ï¼šsystemctl status keepalived haproxy&lt;/li&gt;
&lt;li&gt;master èŠ‚ç‚¹æŸ¥çœ‹ç›‘å¬ç«¯å£ï¼šnetstat -lntp&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;å¦‚æœä»¥ä¸Šéƒ½æ²¡æœ‰é—®é¢˜ï¼Œéœ€è¦ç¡®è®¤ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;æ˜¯å¦æ˜¯å…¬æœ‰äº‘æœºå™¨&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;æ˜¯å¦æ˜¯ç§æœ‰äº‘æœºå™¨ï¼ˆç±»ä¼¼ OpenStackï¼‰&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ä¸Šè¿°å…¬æœ‰äº‘ä¸€èˆ¬éƒ½æ˜¯ä¸æ”¯æŒ keepalivedï¼Œç§æœ‰äº‘å¯èƒ½ä¹Ÿæœ‰é™åˆ¶ï¼Œéœ€è¦å’Œè‡ªå·±çš„ç§æœ‰äº‘ç®¡ç†å‘˜å’¨è¯¢&lt;/p&gt;
&lt;h4 id=&#34;3-runtimeå®‰è£…&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3-runtimeå®‰è£…&#34;&gt;#&lt;/a&gt; 3. Runtime å®‰è£…&lt;/h4&gt;
&lt;p&gt;å¦‚æœå®‰è£…çš„ç‰ˆæœ¬ä½äº 1.24ï¼Œé€‰æ‹© Docker å’Œ Containerd å‡å¯ï¼Œé«˜äº 1.24 å»ºè®®é€‰æ‹© Containerd ä½œä¸º Runtimeï¼Œä¸å†æ¨èä½¿ç”¨ Docker ä½œä¸º Runtimeã€‚&lt;/p&gt;
&lt;h5 id=&#34;31-å®‰è£…containerd&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#31-å®‰è£…containerd&#34;&gt;#&lt;/a&gt; 3.1 å®‰è£… Containerd&lt;/h5&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;é…ç½®å®‰è£…æºï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yum install wget jq psmisc vim net-tools telnet yum-utils device-mapper-persistent-data lvm2 git -y
yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;å®‰è£… docker-ceï¼ˆå¦‚æœåœ¨ä»¥å‰å·²ç»å®‰è£…è¿‡ï¼Œéœ€è¦é‡æ–°å®‰è£…æ›´æ–°ä¸€ä¸‹ï¼‰ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# yum install docker-ce containerd -y
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;å¯ä»¥æ— éœ€å¯åŠ¨ Dockerï¼Œåªéœ€è¦é…ç½®å’Œå¯åŠ¨ Containerd å³å¯ã€‚&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;é¦–å…ˆé…ç½® Containerd æ‰€éœ€çš„æ¨¡å—ï¼ˆ&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;ï¼‰ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cat &amp;lt;&amp;lt;EOF | sudo tee /etc/modules-load.d/containerd.conf
overlay
br_netfilter
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;åŠ è½½æ¨¡å—ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# modprobe -- overlay
# modprobe -- br_netfilter
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;ï¼Œé…ç½® Containerd æ‰€éœ€çš„å†…æ ¸ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cat &amp;lt;&amp;lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
net.bridge.bridge-nf-call-iptables  = 1
net.ipv4.ip_forward                 = 1
net.bridge.bridge-nf-call-ip6tables = 1
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;åŠ è½½å†…æ ¸ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# sysctl --system
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;ç”Ÿæˆ Containerd çš„é…ç½®æ–‡ä»¶ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# mkdir -p /etc/containerd
# containerd config default | tee /etc/containerd/config.toml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;æ›´æ”¹ Containerd çš„ Cgroup å’Œ Pause é•œåƒé…ç½®ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sed -i &#39;s#SystemdCgroup = false#SystemdCgroup = true#g&#39; /etc/containerd/config.toml
sed -i &#39;s#k8s.gcr.io/pause#registry.cn-hangzhou.aliyuncs.com/google_containers/pause#g&#39;  /etc/containerd/config.toml
sed -i &#39;s#registry.gcr.io/pause#registry.cn-hangzhou.aliyuncs.com/google_containers/pause#g&#39;  /etc/containerd/config.toml
sed -i &#39;s#registry.k8s.io/pause#registry.cn-hangzhou.aliyuncs.com/google_containers/pause#g&#39;  /etc/containerd/config.toml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;å¯åŠ¨ Containerdï¼Œå¹¶é…ç½®å¼€æœºè‡ªå¯åŠ¨ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# systemctl daemon-reload
# systemctl enable --now containerd
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;é…ç½® crictl å®¢æˆ·ç«¯è¿æ¥çš„è¿è¡Œæ—¶ä½ç½®ï¼ˆå¯é€‰ï¼‰ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cat &amp;gt; /etc/crictl.yaml &amp;lt;&amp;lt;EOF
runtime-endpoint: unix:///run/containerd/containerd.sock
image-endpoint: unix:///run/containerd/containerd.sock
timeout: 10
debug: false
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;4-å®‰è£…kubernetesç»„ä»¶&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4-å®‰è£…kubernetesç»„ä»¶&#34;&gt;#&lt;/a&gt; 4 . å®‰è£… Kubernetes ç»„ä»¶&lt;/h4&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;é…ç½®æºï¼ˆæ³¨æ„æ›´æ”¹ç‰ˆæœ¬å·ï¼‰ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt;EOF | tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/rpm/
enabled=1
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/rpm/repodata/repomd.xml.key
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;é¦–å…ˆåœ¨&lt;mark&gt; Master01 èŠ‚ç‚¹&lt;/mark&gt;æŸ¥çœ‹æœ€æ–°çš„ Kubernetes ç‰ˆæœ¬æ˜¯å¤šå°‘ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# yum list kubeadm.x86_64 --showduplicates | sort -r
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;å®‰è£… 1.32 æœ€æ–°ç‰ˆæœ¬ kubeadmã€kubelet å’Œ kubectlï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# yum install kubeadm-1.32* kubelet-1.32* kubectl-1.32* -y
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;è®¾ç½® Kubelet å¼€æœºè‡ªå¯åŠ¨ï¼ˆç”±äºè¿˜æœªåˆå§‹åŒ–ï¼Œæ²¡æœ‰ kubelet çš„é…ç½®æ–‡ä»¶ï¼Œæ­¤æ—¶ kubelet æ— æ³•å¯åŠ¨ï¼Œæ— éœ€å…³å¿ƒï¼‰ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# systemctl daemon-reload
# systemctl enable --now kubelet
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;æ­¤æ—¶ kubelet æ˜¯èµ·ä¸æ¥çš„ï¼Œæ—¥å¿—ä¼šæœ‰æŠ¥é”™ä¸å½±å“ï¼&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&#34;5-é›†ç¾¤åˆå§‹åŒ–&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#5-é›†ç¾¤åˆå§‹åŒ–&#34;&gt;#&lt;/a&gt; 5 . é›†ç¾¤åˆå§‹åŒ–&lt;/h4&gt;
&lt;p&gt;ä»¥ä¸‹æ“ä½œåœ¨&lt;mark&gt; master01&lt;/mark&gt;ï¼ˆæ³¨æ„é»„è‰²éƒ¨åˆ†ï¼‰ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vim kubeadm-config.yaml
apiVersion: kubeadm.k8s.io/v1beta3
bootstrapTokens:
- groups:
  - system:bootstrappers:kubeadm:default-node-token
  token: 7t2weq.bjbawausm0jaxury
  ttl: 24h0m0s
  usages:
  - signing
  - authentication
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.1.71
  bindPort: 6443
nodeRegistration:
  criSocket: unix:///var/run/containerd/containerd.sock
  name: k8s-master01
  taints:
  - effect: NoSchedule
    key: node-role.kubernetes.io/control-plane
---
apiServer:
  certSANs:
  - 192.168.1.70               # å¦‚æœæ­å»ºçš„ä¸æ˜¯é«˜å¯ç”¨é›†ç¾¤ï¼ŒæŠŠæ­¤å¤„æ”¹ä¸ºmasterçš„IP
  timeoutForControlPlane: 4m0s
apiVersion: kubeadm.k8s.io/v1beta3
certificatesDir: /etc/kubernetes/pki
clusterName: kubernetes
controlPlaneEndpoint: 192.168.1.70:16443 # å¦‚æœæ­å»ºçš„ä¸æ˜¯é«˜å¯ç”¨é›†ç¾¤ï¼ŒæŠŠæ­¤å¤„IPæ”¹ä¸ºmasterçš„IPï¼Œç«¯å£æ”¹æˆ6443
controllerManager: &amp;#123;&amp;#125;
etcd:
  local:
    dataDir: /var/lib/etcd
imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers
kind: ClusterConfiguration
kubernetesVersion: v1.32.3    # æ›´æ”¹æ­¤å¤„çš„ç‰ˆæœ¬å·å’Œkubeadm versionä¸€è‡´
networking:
  dnsDomain: cluster.local
  podSubnet: 172.16.0.0/16    # æ³¨æ„æ­¤å¤„çš„ç½‘æ®µï¼Œä¸è¦ä¸serviceå’ŒèŠ‚ç‚¹ç½‘æ®µå†²çª
  serviceSubnet: 10.96.0.0/16 # æ³¨æ„æ­¤å¤„çš„ç½‘æ®µï¼Œä¸è¦ä¸podå’ŒèŠ‚ç‚¹ç½‘æ®µå†²çª
scheduler: &amp;#123;&amp;#125;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;master01 èŠ‚ç‚¹&lt;/mark&gt;æ›´æ–° kubeadm æ–‡ä»¶ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubeadm config migrate --old-config kubeadm-config.yaml --new-config new.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å°† new.yaml æ–‡ä»¶å¤åˆ¶åˆ°&lt;mark&gt;å…¶ä»– master èŠ‚ç‚¹&lt;/mark&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;for i in k8s-master02 k8s-master03; do scp new.yaml $i:/root/; done
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ä¹‹å&lt;mark&gt;æ‰€æœ‰ Master èŠ‚ç‚¹&lt;/mark&gt;æå‰ä¸‹è½½é•œåƒï¼Œå¯ä»¥èŠ‚çœåˆå§‹åŒ–æ—¶é—´ï¼ˆå…¶ä»–èŠ‚ç‚¹ä¸éœ€è¦æ›´æ”¹ä»»ä½•é…ç½®ï¼ŒåŒ…æ‹¬ IP åœ°å€ä¹Ÿä¸éœ€è¦æ›´æ”¹ï¼‰ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubeadm config images pull --config /root/new.yaml 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æ­£ç¡®çš„åé¦ˆä¿¡æ¯å¦‚ä¸‹ï¼ˆ&lt;em&gt;&lt;strong&gt;* ç‰ˆæœ¬å¯èƒ½ä¸ä¸€æ · *&lt;/strong&gt;&lt;/em&gt;ï¼‰ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master02 ~]# kubeadm config images pull --config /root/new.yaml 
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.32.0
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.32.0
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.32.0
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.32.0
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.11.3
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.10
[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.5.16-0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;Master01 èŠ‚ç‚¹&lt;/mark&gt;åˆå§‹åŒ–ï¼Œåˆå§‹åŒ–ä»¥åä¼šåœ¨ /etc/kubernetes ç›®å½•ä¸‹ç”Ÿæˆå¯¹åº”çš„è¯ä¹¦å’Œé…ç½®æ–‡ä»¶ï¼Œä¹‹åå…¶ä»– Master èŠ‚ç‚¹åŠ å…¥ Master01 å³å¯ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubeadm init --config /root/new.yaml  --upload-certs
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;åˆå§‹åŒ–æˆåŠŸä»¥åï¼Œä¼šäº§ç”Ÿ Token å€¼ï¼Œç”¨äºå…¶ä»–èŠ‚ç‚¹åŠ å…¥æ—¶ä½¿ç”¨ï¼Œå› æ­¤è¦è®°å½•ä¸‹åˆå§‹åŒ–æˆåŠŸç”Ÿæˆçš„ token å€¼ï¼ˆä»¤ç‰Œå€¼ï¼‰ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run &amp;quot;kubectl apply -f [podnetwork].yaml&amp;quot; with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of the control-plane node running the following command on each as root:

# ä¸è¦å¤åˆ¶æ–‡æ¡£å½“ä¸­çš„ï¼Œè¦å»ä½¿ç”¨èŠ‚ç‚¹ç”Ÿæˆçš„
  kubeadm join 192.168.1.70:16443 --token 7t2weq.bjbawausm0jaxury \
	--discovery-token-ca-cert-hash sha256:df72788de04bbc2e8fca70becb8a9e8503a962b5d7cd9b1842a0c39930d08c94 \
	--control-plane --certificate-key c595f7f4a7a3beb0d5bdb75d9e4eff0a60b977447e76c1d6885e82c3aa43c94c

Please note that the certificate-key gives access to cluster sensitive data, keep it secret!
As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use
&amp;quot;kubeadm init phase upload-certs --upload-certs&amp;quot; to reload certs afterward.

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 192.168.1.70:16443 --token 7t2weq.bjbawausm0jaxury \
	--discovery-token-ca-cert-hash sha256:df72788de04bbc2e8fca70becb8a9e8503a962b5d7cd9b1842a0c39930d08c94
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;Master01 èŠ‚ç‚¹&lt;/mark&gt;é…ç½®ç¯å¢ƒå˜é‡ï¼Œç”¨äºè®¿é—® Kubernetes é›†ç¾¤ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt;EOF &amp;gt;&amp;gt; /root/.bashrc
export KUBECONFIG=/etc/kubernetes/admin.conf
EOF
source /root/.bashrc
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;Master01 èŠ‚ç‚¹&lt;/mark&gt;æŸ¥çœ‹èŠ‚ç‚¹çŠ¶æ€ï¼šï¼ˆæ˜¾ç¤º NotReady ä¸å½±å“ï¼‰&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# kubectl get node
NAME           STATUS     ROLES           AGE   VERSION
k8s-master01   NotReady   control-plane   24s   v1.32.3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;é‡‡ç”¨åˆå§‹åŒ–å®‰è£…æ–¹å¼ï¼Œæ‰€æœ‰çš„ç³»ç»Ÿç»„ä»¶å‡ä»¥å®¹å™¨çš„æ–¹å¼è¿è¡Œå¹¶ä¸”åœ¨ kube-system å‘½åç©ºé—´å†…ï¼Œæ­¤æ—¶å¯ä»¥æŸ¥çœ‹ Pod çŠ¶æ€ï¼ˆæ˜¾ç¤º pending ä¸å½±å“ï¼‰ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-\&#34;&gt;# kubectl get pods -n kube-system
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;51-åˆå§‹åŒ–å¤±è´¥æ’æŸ¥&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#51-åˆå§‹åŒ–å¤±è´¥æ’æŸ¥&#34;&gt;#&lt;/a&gt; 5.1 åˆå§‹åŒ–å¤±è´¥æ’æŸ¥&lt;/h5&gt;
&lt;p&gt;å¦‚æœåˆå§‹åŒ–å¤±è´¥ï¼Œé‡ç½®åå†æ¬¡åˆå§‹åŒ–ï¼Œå‘½ä»¤å¦‚ä¸‹ï¼ˆæ²¡æœ‰å¤±è´¥ä¸è¦æ‰§è¡Œï¼‰ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubeadm reset -f ; ipvsadm --clear  ; rm -rf ~/.kube
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å¦‚æœå¤šæ¬¡å°è¯•éƒ½æ˜¯åˆå§‹åŒ–å¤±è´¥ï¼Œéœ€è¦çœ‹ç³»ç»Ÿæ—¥å¿—ï¼ŒCentOS/RockyLinux æ—¥å¿—è·¯å¾„:/var/log/messagesï¼ŒUbuntu ç³»åˆ—æ—¥å¿—è·¯å¾„:/var/log/syslogï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tail -f /var/log/messages | grep -v &amp;quot;not found&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ç»å¸¸å‡ºé”™çš„åŸå› ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Containerd çš„é…ç½®æ–‡ä»¶ä¿®æ”¹çš„ä¸å¯¹ï¼Œè‡ªè¡Œå‚è€ƒã€Šå®‰è£… containerdã€‹å°èŠ‚æ ¸å¯¹&lt;/li&gt;
&lt;li&gt;new.yaml é…ç½®é—®é¢˜ï¼Œæ¯”å¦‚éé«˜å¯ç”¨é›†ç¾¤å¿˜è®°ä¿®æ”¹ 16443 ç«¯å£ä¸º 6443&lt;/li&gt;
&lt;li&gt;new.yaml é…ç½®é—®é¢˜ï¼Œä¸‰ä¸ªç½‘æ®µæœ‰äº¤å‰ï¼Œå‡ºç° IP åœ°å€å†²çª&lt;/li&gt;
&lt;li&gt;VIP ä¸é€šå¯¼è‡´æ— æ³•åˆå§‹åŒ–æˆåŠŸï¼Œæ­¤æ—¶ messages æ—¥å¿—ä¼šæœ‰ VIP è¶…æ—¶çš„æŠ¥é”™&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id=&#34;52-é«˜å¯ç”¨master&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#52-é«˜å¯ç”¨master&#34;&gt;#&lt;/a&gt; 5.2 é«˜å¯ç”¨ Master&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;å…¶ä»– master&lt;/strong&gt; åŠ å…¥é›†ç¾¤ï¼Œmaster02 å’Œ master03 åˆ†åˆ«æ‰§è¡Œ (åƒä¸‡ä¸è¦åœ¨ master01 å†æ¬¡æ‰§è¡Œï¼Œä¸èƒ½ç›´æ¥å¤åˆ¶æ–‡æ¡£å½“ä¸­çš„å‘½ä»¤ï¼Œè€Œæ˜¯ä½ è‡ªå·±åˆšæ‰ master01 åˆå§‹åŒ–ä¹‹åäº§ç”Ÿçš„å‘½ä»¤)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubeadm join 192.168.1.70:16443 --token 7t2weq.bjbawausm0jaxury \
	--discovery-token-ca-cert-hash sha256:df72788de04bbc2e8fca70becb8a9e8503a962b5d7cd9b1842a0c39930d08c94 \
	--control-plane --certificate-key c595f7f4a7a3beb0d5bdb75d9e4eff0a60b977447e76c1d6885e82c3aa43c94c
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æŸ¥çœ‹å½“å‰çŠ¶æ€ï¼šï¼ˆå¦‚æœæ˜¾ç¤º NotReady ä¸å½±å“ï¼‰&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# kubectl get node
NAME           STATUS     ROLES           AGE     VERSION
k8s-master01   NotReady   control-plane   4m23s   v1.32.3
k8s-master02   NotReady   control-plane   66s     v1.32.3
k8s-master03   NotReady   control-plane   14s     v1.32.3
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;53-tokenè¿‡æœŸå¤„ç†&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#53-tokenè¿‡æœŸå¤„ç†&#34;&gt;#&lt;/a&gt; 5.3 Token è¿‡æœŸå¤„ç†&lt;/h5&gt;
&lt;p&gt;æ³¨æ„ï¼šä»¥ä¸‹æ­¥éª¤æ˜¯ä¸Šè¿° init å‘½ä»¤äº§ç”Ÿçš„ Token è¿‡æœŸäº†æ‰éœ€è¦æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼Œå¦‚æœæ²¡æœ‰è¿‡æœŸä¸éœ€è¦æ‰§è¡Œï¼Œç›´æ¥ join å³å¯ã€‚&lt;/p&gt;
&lt;p&gt;Token è¿‡æœŸåç”Ÿæˆæ–°çš„ tokenï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubeadm token create --print-join-command
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Master éœ€è¦ç”Ÿæˆ --certificate-keyï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubeadm init phase upload-certs  --upload-certs
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;6-nodeèŠ‚ç‚¹çš„é…ç½®&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#6-nodeèŠ‚ç‚¹çš„é…ç½®&#34;&gt;#&lt;/a&gt; 6. Node èŠ‚ç‚¹çš„é…ç½®&lt;/h4&gt;
&lt;p&gt;Node èŠ‚ç‚¹ä¸Šä¸»è¦éƒ¨ç½²å…¬å¸çš„ä¸€äº›ä¸šåŠ¡åº”ç”¨ï¼Œç”Ÿäº§ç¯å¢ƒä¸­ä¸å»ºè®® Master èŠ‚ç‚¹éƒ¨ç½²ç³»ç»Ÿç»„ä»¶ä¹‹å¤–çš„å…¶ä»– Podï¼Œæµ‹è¯•ç¯å¢ƒå¯ä»¥å…è®¸ Master èŠ‚ç‚¹éƒ¨ç½² Pod ä»¥èŠ‚çœç³»ç»Ÿèµ„æºã€‚&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubeadm join 192.168.1.70:16443 --token 7t2weq.bjbawausm0jaxury \
	--discovery-token-ca-cert-hash sha256:377702f508fe70b9d8ab68beccaa9af1b4609b754e4cc2fcc6185974e1d620b5
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æ‰€æœ‰èŠ‚ç‚¹åˆå§‹åŒ–å®Œæˆåï¼ŒæŸ¥çœ‹é›†ç¾¤çŠ¶æ€ï¼ˆNotReady ä¸å½±å“ï¼‰&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# kubectl get node
NAME           STATUS     ROLES           AGE     VERSION
k8s-master01   NotReady   control-plane   4m23s   v1.32.3
k8s-master02   NotReady   control-plane   66s     v1.32.3
k8s-master03   NotReady   control-plane   14s     v1.32.3
k8s-node01     NotReady   &amp;lt;none&amp;gt;          13s     v1.32.3
k8s-node02     NotReady   &amp;lt;none&amp;gt;          10s     v1.32.3
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;7-calicoç»„ä»¶çš„å®‰è£…&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#7-calicoç»„ä»¶çš„å®‰è£…&#34;&gt;#&lt;/a&gt; 7. Calico ç»„ä»¶çš„å®‰è£…&lt;/h4&gt;
&lt;p&gt;&lt;mark&gt;æ‰€æœ‰èŠ‚ç‚¹&lt;/mark&gt;ç¦æ­¢ NetworkManager ç®¡ç† Calico çš„ç½‘ç»œæ¥å£ï¼Œé˜²æ­¢æœ‰å†²çªæˆ–å¹²æ‰°ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;gt;&amp;gt;/etc/NetworkManager/conf.d/calico.conf&amp;lt;&amp;lt;EOF
[keyfile]
unmanaged-devices=interface-name:cali*;interface-name:tunl*;interface-name:vxlan.calico;interface-name:vxlan-v6.calico;interface-name:wireguard.cali;interface-name:wg-v6.cali
EOF
systemctl daemon-reload
systemctl restart NetworkManager
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ä»¥ä¸‹æ­¥éª¤åªåœ¨&lt;mark&gt; master01&lt;/mark&gt; æ‰§è¡Œï¼ˆ.x ä¸éœ€è¦æ›´æ”¹ï¼‰ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd /root/k8s-ha-install &amp;amp;&amp;amp; git checkout manual-installation-v1.32.x &amp;amp;&amp;amp; cd calico/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ä¿®æ”¹ Pod ç½‘æ®µï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;POD_SUBNET=`cat /etc/kubernetes/manifests/kube-controller-manager.yaml | grep cluster-cidr= | awk -F= &#39;&amp;#123;print $NF&amp;#125;&#39;`

sed -i &amp;quot;s#POD_CIDR#$&amp;#123;POD_SUBNET&amp;#125;#g&amp;quot; calico.yaml
kubectl apply -f calico.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æŸ¥çœ‹å®¹å™¨å’ŒèŠ‚ç‚¹çŠ¶æ€ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# kubectl get pods -n kube-system
NAME                                       READY   STATUS    RESTARTS   AGE
calico-kube-controllers-6f497d8478-v2q8c   1/1     Running   0          24h
calico-node-7mzmb                          1/1     Running   0          24h
calico-node-ljqnl                          1/1     Running   0          24h
calico-node-njqlb                          1/1     Running   0          24h
calico-node-ph4m4                          1/1     Running   0          24h
calico-node-rx8rl                          1/1     Running   0          24h
coredns-76fccbbb6b-76559                   1/1     Running   0          24h
coredns-76fccbbb6b-hkvn7                   1/1     Running   0          24h
etcd-k8s-master01                          1/1     Running   0          24h
etcd-k8s-master02                          1/1     Running   0          24h
etcd-k8s-master03                          1/1     Running   0          24h
kube-apiserver-k8s-master01                1/1     Running   0          24h
kube-apiserver-k8s-master02                1/1     Running   0          24h
kube-apiserver-k8s-master03                1/1     Running   0          24h
kube-controller-manager-k8s-master01       1/1     Running   0          24h
kube-controller-manager-k8s-master02       1/1     Running   0          24h
kube-controller-manager-k8s-master03       1/1     Running   0          24h
kube-proxy-9dtz4                           1/1     Running   0          24h
kube-proxy-jh7rl                           1/1     Running   0          24h
kube-proxy-jvvwt                           1/1     Running   0          24h
kube-proxy-sh89l                           1/1     Running   0          24h
kube-proxy-t2j49                           1/1     Running   0          24h
kube-scheduler-k8s-master01                1/1     Running   0          24h
kube-scheduler-k8s-master02                1/1     Running   0          24h
kube-scheduler-k8s-master03                1/1     Running   0          24h
metrics-server-7d9d8df576-jgnp2            1/1     Running   0          24h
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æ­¤æ—¶èŠ‚ç‚¹å…¨éƒ¨å˜ä¸º Ready çŠ¶æ€ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# kubectl get nodes
NAME           STATUS   ROLES           AGE   VERSION
k8s-master01   Ready    control-plane   24h   v1.32.3
k8s-master02   Ready    control-plane   24h   v1.32.3
k8s-master03   Ready    control-plane   24h   v1.32.3
k8s-node01     Ready    &amp;lt;none&amp;gt;          24h   v1.32.3
k8s-node02     Ready    &amp;lt;none&amp;gt;          24h   v1.32.3
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;8-metricséƒ¨ç½²&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#8-metricséƒ¨ç½²&#34;&gt;#&lt;/a&gt; 8. Metrics éƒ¨ç½²&lt;/h4&gt;
&lt;p&gt;åœ¨æ–°ç‰ˆçš„ Kubernetes ä¸­ç³»ç»Ÿèµ„æºçš„é‡‡é›†å‡ä½¿ç”¨ Metrics-serverï¼Œå¯ä»¥é€šè¿‡ Metrics é‡‡é›†èŠ‚ç‚¹å’Œ Pod çš„å†…å­˜ã€ç£ç›˜ã€CPU å’Œç½‘ç»œçš„ä½¿ç”¨ç‡ã€‚&lt;/p&gt;
&lt;p&gt;å°†&lt;mark&gt; Master01 èŠ‚ç‚¹&lt;/mark&gt;çš„ front-proxy-ca.crt å¤åˆ¶åˆ°æ‰€æœ‰ Node èŠ‚ç‚¹&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;scp /etc/kubernetes/pki/front-proxy-ca.crt k8s-node01:/etc/kubernetes/pki/front-proxy-ca.crt

scp /etc/kubernetes/pki/front-proxy-ca.crt k8s-node(å…¶ä»–èŠ‚ç‚¹è‡ªè¡Œæ‹·è´):/etc/kubernetes/pki/front-proxy-ca.crt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ä»¥ä¸‹æ“ä½œå‡åœ¨&lt;mark&gt; master01 èŠ‚ç‚¹&lt;/mark&gt;æ‰§è¡Œ:&lt;/p&gt;
&lt;p&gt;å®‰è£… metrics server&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd /root/k8s-ha-install/kubeadm-metrics-server

# kubectl  create -f comp.yaml 
serviceaccount/metrics-server created
clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created
clusterrole.rbac.authorization.k8s.io/system:metrics-server created
rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created
clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created
clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created
service/metrics-server created
deployment.apps/metrics-server created
apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æŸ¥çœ‹çŠ¶æ€ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# kubectl get po -n kube-system -l k8s-app=metrics-server
NAME                              READY   STATUS    RESTARTS   AGE
metrics-server-7d9d8df576-jgnp2   1/1     Running   0          24h
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ç­‰ Pod å˜æˆ 1/1   Running åï¼ŒæŸ¥çœ‹èŠ‚ç‚¹å’Œ Pod èµ„æºä½¿ç”¨ç‡ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]#  kubectl top node
NAME           CPU(cores)   CPU(%)   MEMORY(bytes)   MEMORY(%)   
k8s-master01   132m         3%       932Mi           5%          
k8s-master02   131m         3%       845Mi           5%          
k8s-master03   148m         3%       912Mi           5%          
k8s-node01     54m          1%       600Mi           3%          
k8s-node02     49m          1%       602Mi           3%          
[root@k8s-master01 ~]#  kubectl top po -A
NAMESPACE              NAME                                         CPU(cores)   MEMORY(bytes)   
ingress-nginx          ingress-nginx-controller-5v9gl               2m           98Mi            
ingress-nginx          ingress-nginx-controller-r978m               1m           104Mi           
krm                    krm-backend-d7ff675d8-vmt9z                  1m           21Mi            
krm                    krm-frontend-588ffd677b-c2pgj                1m           4Mi             
krm                    nginx-574cf48959-vcfjs                       0m           2Mi             
kube-system            calico-kube-controllers-6f497d8478-v2q8c     6m           17Mi            
kube-system            calico-node-7mzmb                            16m          176Mi           
kube-system            calico-node-ljqnl                            15m          182Mi           
kube-system            calico-node-njqlb                            19m          180Mi           
kube-system            calico-node-ph4m4                            15m          178Mi           
kube-system            calico-node-rx8rl                            17m          180Mi           
kube-system            coredns-76fccbbb6b-76559                     2m           16Mi            
kube-system            coredns-76fccbbb6b-hkvn7                     2m           16Mi            
kube-system            etcd-k8s-master01                            22m          86Mi            
kube-system            etcd-k8s-master02                            27m          84Mi            
kube-system            etcd-k8s-master03                            22m          84Mi            
kube-system            kube-apiserver-k8s-master01                  22m          267Mi           
kube-system            kube-apiserver-k8s-master02                  20m          242Mi           
kube-system            kube-apiserver-k8s-master03                  18m          241Mi           
kube-system            kube-controller-manager-k8s-master01         6m           69Mi            
kube-system            kube-controller-manager-k8s-master02         2m           21Mi            
kube-system            kube-controller-manager-k8s-master03         1m           19Mi            
kube-system            kube-proxy-9dtz4                             11m          30Mi            
kube-system            kube-proxy-jh7rl                             1m           27Mi            
kube-system            kube-proxy-jvvwt                             17m          29Mi            
kube-system            kube-proxy-sh89l                             1m           29Mi            
kube-system            kube-proxy-t2j49                             16m          29Mi            
kube-system            kube-scheduler-k8s-master01                  6m           25Mi            
kube-system            kube-scheduler-k8s-master02                  6m           25Mi            
kube-system            kube-scheduler-k8s-master03                  6m           25Mi            
kube-system            metrics-server-7d9d8df576-jgnp2              2m           26Mi            
kubernetes-dashboard   dashboard-metrics-scraper-69b4796d9b-klnwr   1m           19Mi            
kubernetes-dashboard   kubernetes-dashboard-778584b9dd-pd5ln        1m           31Mi  
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;9-dashboardéƒ¨ç½²&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#9-dashboardéƒ¨ç½²&#34;&gt;#&lt;/a&gt; 9. Dashboard éƒ¨ç½²&lt;/h4&gt;
&lt;h5 id=&#34;91-å®‰è£…dashboard&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#91-å®‰è£…dashboard&#34;&gt;#&lt;/a&gt; 9.1 å®‰è£… Dashboard&lt;/h5&gt;
&lt;p&gt;Dashboard ç”¨äºå±•ç¤ºé›†ç¾¤ä¸­çš„å„ç±»èµ„æºï¼ŒåŒæ—¶ä¹Ÿå¯ä»¥é€šè¿‡ Dashboard å®æ—¶æŸ¥çœ‹ Pod çš„æ—¥å¿—å’Œåœ¨å®¹å™¨ä¸­æ‰§è¡Œä¸€äº›å‘½ä»¤ç­‰ã€‚&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd /root/k8s-ha-install/dashboard/

[root@k8s-master01 dashboard]# kubectl  create -f .
serviceaccount/admin-user created
clusterrolebinding.rbac.authorization.k8s.io/admin-user created
namespace/kubernetes-dashboard created
serviceaccount/kubernetes-dashboard created
service/kubernetes-dashboard created
secret/kubernetes-dashboard-certs created
secret/kubernetes-dashboard-csrf created
secret/kubernetes-dashboard-key-holder created
configmap/kubernetes-dashboard-settings created
role.rbac.authorization.k8s.io/kubernetes-dashboard created
clusterrole.rbac.authorization.k8s.io/kubernetes-dashboard created
rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created
clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created
deployment.apps/kubernetes-dashboard created
service/dashboard-metrics-scraper created
deployment.apps/dashboard-metrics-scraper created
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;92-ç™»å½•dashboard&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#92-ç™»å½•dashboard&#34;&gt;#&lt;/a&gt; 9.2 ç™»å½• dashboard&lt;/h5&gt;
&lt;p&gt;åœ¨è°·æ­Œæµè§ˆå™¨ï¼ˆChromeï¼‰å¯åŠ¨æ–‡ä»¶ä¸­åŠ å…¥å¯åŠ¨å‚æ•°ï¼Œç”¨äºè§£å†³æ— æ³•è®¿é—® Dashboard çš„é—®é¢˜ï¼Œå‚è€ƒä¸‹å›¾ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--test-type --ignore-certificate-errors
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://imgse.com/i/pEgWfHJ&#34;&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://s21.ax1x.com/2025/04/09/pEgWfHJ.png&#34; alt=&#34;pEgWfHJ.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;æ›´æ”¹ dashboard çš„ svc ä¸º NodePort:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl edit svc kubernetes-dashboard -n kubernetes-dashboard
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://imgse.com/i/pEgW5NR&#34;&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://s21.ax1x.com/2025/04/09/pEgW5NR.png&#34; alt=&#34;pEgW5NR.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;å°† ClusterIP æ›´æ”¹ä¸º NodePortï¼ˆå¦‚æœå·²ç»ä¸º NodePort å¿½ç•¥æ­¤æ­¥éª¤ï¼‰&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;æŸ¥çœ‹ç«¯å£å·ï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# kubectl get svc kubernetes-dashboard -n kubernetes-dashboard
NAME                   TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)         AGE
kubernetes-dashboard   NodePort   10.96.139.11   &amp;lt;none&amp;gt;        443:32409/TCP   24h
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æ ¹æ®è‡ªå·±çš„å®ä¾‹ç«¯å£å·ï¼Œé€šè¿‡ä»»æ„å®‰è£…äº† kube-proxy çš„å®¿ä¸»æœºçš„ IP + ç«¯å£å³å¯è®¿é—®åˆ° dashboardï¼š&lt;/p&gt;
&lt;p&gt;è®¿é—® Dashboardï¼š&lt;a href=&#34;https://192.168.181.129:31106&#34;&gt;https://192.168.1.71:32409&lt;/a&gt; ï¼ˆæŠŠ IP åœ°å€å’Œç«¯å£æ”¹æˆä½ è‡ªå·±çš„ï¼‰é€‰æ‹©ç™»å½•æ–¹å¼ä¸ºä»¤ç‰Œï¼ˆå³ token æ–¹å¼ï¼‰ï¼Œå‚è€ƒä¸‹å›¾ï¼š&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://imgse.com/i/pEgW736&#34;&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://s21.ax1x.com/2025/04/09/pEgW736.png&#34; alt=&#34;pEgW736.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;åˆ›å»ºç™»å½• Tokenï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl create token admin-user -n kube-system
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å°† token å€¼è¾“å…¥åˆ°ä»¤ç‰Œåï¼Œå•å‡»ç™»å½•å³å¯è®¿é—® Dashboardï¼Œå‚è€ƒä¸‹å›¾ï¼š&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://imgse.com/i/pEgfPv8&#34;&gt;&lt;img loading=&#34;lazy&#34; data-src=&#34;https://s21.ax1x.com/2025/04/09/pEgfPv8.png&#34; alt=&#34;pEgfPv8.png&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;10å¿…çœ‹ä¸€äº›å¿…é¡»çš„é…ç½®æ›´æ”¹&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#10å¿…çœ‹ä¸€äº›å¿…é¡»çš„é…ç½®æ›´æ”¹&#34;&gt;#&lt;/a&gt; 10.ã€å¿…çœ‹ã€‘ä¸€äº›å¿…é¡»çš„é…ç½®æ›´æ”¹&lt;/h4&gt;
&lt;p&gt;å°† Kube-proxy æ”¹ä¸º ipvs æ¨¡å¼ï¼Œå› ä¸ºåœ¨åˆå§‹åŒ–é›†ç¾¤çš„æ—¶å€™æ³¨é‡Šäº† ipvs é…ç½®ï¼Œæ‰€ä»¥éœ€è¦è‡ªè¡Œä¿®æ”¹ä¸€ä¸‹ï¼š&lt;/p&gt;
&lt;p&gt;åœ¨ master01 èŠ‚ç‚¹æ‰§è¡Œï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl edit cm kube-proxy -n kube-system
mode: ipvs
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æ›´æ–° Kube-Proxy çš„ Podï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl patch daemonset kube-proxy -p &amp;quot;&amp;#123;\&amp;quot;spec\&amp;quot;:&amp;#123;\&amp;quot;template\&amp;quot;:&amp;#123;\&amp;quot;metadata\&amp;quot;:&amp;#123;\&amp;quot;annotations\&amp;quot;:&amp;#123;\&amp;quot;date\&amp;quot;:\&amp;quot;`date +&#39;%s&#39;`\&amp;quot;&amp;#125;&amp;#125;&amp;#125;&amp;#125;&amp;#125;&amp;quot; -n kube-system
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;éªŒè¯ Kube-Proxy æ¨¡å¼:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01]# curl 127.0.0.1:10249/proxyMode
ipvs
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;11å¿…çœ‹æ³¨æ„äº‹é¡¹&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#11å¿…çœ‹æ³¨æ„äº‹é¡¹&#34;&gt;#&lt;/a&gt; 11.ã€å¿…çœ‹ã€‘æ³¨æ„äº‹é¡¹&lt;/h4&gt;
&lt;p&gt;æ³¨æ„ï¼škubeadm å®‰è£…çš„é›†ç¾¤ï¼Œè¯ä¹¦æœ‰æ•ˆæœŸé»˜è®¤æ˜¯ä¸€å¹´ã€‚master èŠ‚ç‚¹çš„ kube-apiserverã€kube-schedulerã€kube-controller-managerã€etcd éƒ½æ˜¯ä»¥å®¹å™¨è¿è¡Œçš„ã€‚å¯ä»¥é€šè¿‡ kubectl get po -n kube-system æŸ¥çœ‹ã€‚&lt;/p&gt;
&lt;p&gt;å¯åŠ¨å’ŒäºŒè¿›åˆ¶ä¸åŒçš„æ˜¯ï¼Œkubelet çš„é…ç½®æ–‡ä»¶åœ¨ /etc/sysconfig/kubelet å’Œ /var/lib/kubelet/config.yamlï¼Œä¿®æ”¹åéœ€è¦é‡å¯ kubelet è¿›ç¨‹ã€‚&lt;/p&gt;
&lt;p&gt;å…¶ä»–ç»„ä»¶çš„é…ç½®æ–‡ä»¶åœ¨ /etc/kubernetes/manifests ç›®å½•ä¸‹ï¼Œæ¯”å¦‚ kube-apiserver.yamlï¼Œè¯¥ yaml æ–‡ä»¶æ›´æ”¹åï¼Œkubelet ä¼šè‡ªåŠ¨åˆ·æ–°é…ç½®ï¼Œä¹Ÿå°±æ˜¯ä¼šé‡å¯ podã€‚ä¸èƒ½å†æ¬¡åˆ›å»ºè¯¥æ–‡ä»¶ã€‚&lt;/p&gt;
&lt;p&gt;kube-proxy çš„é…ç½®åœ¨ kube-system å‘½åç©ºé—´ä¸‹çš„ configmap ä¸­ï¼Œå¯ä»¥é€šè¿‡&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl edit cm kube-proxy -n kube-system
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;è¿›è¡Œæ›´æ”¹ï¼Œæ›´æ”¹å®Œæˆåï¼Œå¯ä»¥é€šè¿‡ patch é‡å¯ kube-proxy&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl patch daemonset kube-proxy -p &amp;quot;&amp;#123;\&amp;quot;spec\&amp;quot;:&amp;#123;\&amp;quot;template\&amp;quot;:&amp;#123;\&amp;quot;metadata\&amp;quot;:&amp;#123;\&amp;quot;annotations\&amp;quot;:&amp;#123;\&amp;quot;date\&amp;quot;:\&amp;quot;`date +&#39;%s&#39;`\&amp;quot;&amp;#125;&amp;#125;&amp;#125;&amp;#125;&amp;#125;&amp;quot; -n kube-system
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Kubeadm å®‰è£…åï¼Œmaster èŠ‚ç‚¹é»˜è®¤ä¸å…è®¸éƒ¨ç½² podï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼åˆ é™¤ Taintï¼Œå³å¯éƒ¨ç½² Podï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@k8s-master01 ~]# kubectl  taint node  -l node-role.kubernetes.io/control-plane node-role.kubernetes.io/control-plane:NoSchedule-
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;12-containerdé…ç½®é•œåƒåŠ é€Ÿ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#12-containerdé…ç½®é•œåƒåŠ é€Ÿ&#34;&gt;#&lt;/a&gt; 12. Containerd é…ç½®é•œåƒåŠ é€Ÿ&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;# vim /etc/containerd/config.toml
#æ·»åŠ ä»¥ä¸‹é…ç½®é•œåƒåŠ é€ŸæœåŠ¡
       [plugins.&amp;quot;io.containerd.grpc.v1.cri&amp;quot;.registry.mirrors.&amp;quot;docker.io&amp;quot;]
        endpoint=[&amp;quot;https://dockerproxy.com&amp;quot;, &amp;quot;https://mirror.baidubce.com&amp;quot;,&amp;quot;https://ccr.ccs.tencentyun.com&amp;quot;,&amp;quot;https://docker.m.daocloud.io&amp;quot;,&amp;quot;https://docker.nju.edu.cn&amp;quot;,&amp;quot;https://docker.mirrors.ustc.edu.cn&amp;quot;,&amp;quot;https://registry-1.docker.io&amp;quot;, &amp;quot;https://hbv0b596.mirror.aliyuncs.com&amp;quot;]
       [plugins.&amp;quot;io.containerd.grpc.v1.cri&amp;quot;.registry.mirrors.&amp;quot;registry.k8s.io&amp;quot;]
        endpoint=[&amp;quot;https://dockerproxy.com&amp;quot;, &amp;quot;https://mirror.baidubce.com&amp;quot;,&amp;quot;https://ccr.ccs.tencentyun.com&amp;quot;,&amp;quot;https://docker.m.daocloud.io&amp;quot;,&amp;quot;https://docker.nju.edu.cn&amp;quot;,&amp;quot;https://docker.mirrors.ustc.edu.cn&amp;quot;,&amp;quot;https://hbv0b596.mirror.aliyuncs.com&amp;quot;, &amp;quot;https://k8s.m.daocloud.io&amp;quot;, &amp;quot;https://docker.mirrors.ustc.edu.cn&amp;quot;,&amp;quot;https://hub-mirror.c.163.com&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æ‰€æœ‰èŠ‚ç‚¹é‡æ–°å¯åŠ¨ Containerdï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# systemctl daemon-reload
# systemctl restart containerd
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;13-dockeré…ç½®é•œåƒåŠ é€Ÿ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#13-dockeré…ç½®é•œåƒåŠ é€Ÿ&#34;&gt;#&lt;/a&gt; 13. Docker é…ç½®é•œåƒåŠ é€Ÿ&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;# sudo mkdir -p /etc/docker
# sudo tee /etc/docker/daemon.json &amp;lt;&amp;lt;-&#39;EOF&#39;
&amp;#123;
  &amp;quot;registry-mirrors&amp;quot;: [
	  &amp;quot;https://docker.credclouds.com&amp;quot;,
	  &amp;quot;https://k8s.credclouds.com&amp;quot;,
	  &amp;quot;https://quay.credclouds.com&amp;quot;,
	  &amp;quot;https://gcr.credclouds.com&amp;quot;,
	  &amp;quot;https://k8s-gcr.credclouds.com&amp;quot;,
	  &amp;quot;https://ghcr.credclouds.com&amp;quot;,
	  &amp;quot;https://do.nark.eu.org&amp;quot;,
	  &amp;quot;https://docker.m.daocloud.io&amp;quot;,
	  &amp;quot;https://docker.nju.edu.cn&amp;quot;,
	  &amp;quot;https://docker.mirrors.sjtug.sjtu.edu.cn&amp;quot;,
	  &amp;quot;https://docker.1panel.live&amp;quot;,
	  &amp;quot;https://docker.rainbond.cc&amp;quot;
  ], 
  &amp;quot;exec-opts&amp;quot;: [&amp;quot;native.cgroupdriver=systemd&amp;quot;] 
&amp;#125;
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æ‰€æœ‰èŠ‚ç‚¹é‡æ–°å¯åŠ¨ Dockerï¼š&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# systemctl daemon-reload
# systemctl enable --now docker
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;æœ¬æ–‡å‡ºè‡ªäºï¼š&lt;a href=&#34;https://edu.51cto.com/course/23845.html&#34;&gt;https://edu.51cto.com/course/23845.html&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</content>
        <category term="Kubernetes" />
        <updated>2025-04-09T10:28:34.000Z</updated>
    </entry>
    <entry>
        <id>http://ixuyong.cn/posts/1922841233.html</id>
        <title>RsyncæœåŠ¡å®è·µ</title>
        <link rel="alternate" href="http://ixuyong.cn/posts/1922841233.html"/>
        <content type="html">&lt;h3 id=&#34;ursyncæœåŠ¡å®è·µu&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#ursyncæœåŠ¡å®è·µu&#34;&gt;#&lt;/a&gt; &lt;u&gt;Rsync æœåŠ¡å®è·µ&lt;/u&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;ç¯å¢ƒå‡†å¤‡&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;ä¸»æœºå&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;strong&gt;IP&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;è§’è‰²&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;server&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;192.168.40.101&lt;/td&gt;
&lt;td&gt;rsync æœåŠ¡ç«¯&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;client&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;192.168.40.102&lt;/td&gt;
&lt;td&gt;rsync å®¢æˆ·&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;1rsyncæœåŠ¡ç«¯&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1rsyncæœåŠ¡ç«¯&#34;&gt;#&lt;/a&gt; 1.rsync æœåŠ¡ç«¯&lt;/h4&gt;
&lt;h5 id=&#34;11-å…³é—­é˜²ç«å¢™-selinux&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#11-å…³é—­é˜²ç«å¢™-selinux&#34;&gt;#&lt;/a&gt; 1.1 å…³é—­é˜²ç«å¢™ã€selinux&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@localhost ~]# hostnamectl set-hostname backup
[root@localhost ~]# bash
[root@backup ~]# hostnamectl set-hostname aizj_lb01
[root@backup ~]# systemctl stop firewalld
[root@backup ~]# systemctl disable firewalld
[root@backup ~]# sed -i &#39;s/^SELINUX=enforcing/SELINUX=disabled/g&#39; /etc/sysconfig/selinux
[root@backup ~]# sed -i &#39;s/^SELINUX=enforcing/SELINUX=disabled/g&#39; /etc/selinux/config
[root@backup ~]# yum install net-tools vim tree lrzsz wget unzip dos2unix bash-completion  lsof ntp ntpdate git -y
[root@backup ~]# yum update -y --exclude=kernel* &amp;amp;&amp;amp; reboot
[root@backup ~]# echo &#39;Asia/Shanghai&#39; &amp;gt;/etc/timezone
[root@backup ~]# ntpdate time2.aliyun.com
[root@backup ~]# crontab -e
*/5 * * * * /usr/sbin/ntpdate time2.aliyun.com &amp;amp;&amp;gt; /dev/nul
[root@backup ~]# mkdir /soft /data /scripts /backup
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;12-å®‰è£…rsync&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#12-å®‰è£…rsync&#34;&gt;#&lt;/a&gt; 1.2 å®‰è£… rsync&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@backup ~]# yum install -y rsync
[root@server ~]# systemctl start rsyncd
[root@server ~]# systemctl enable rsyncd
[root@backup ~]# useradd -M -s /sbin/nologin rsync
[root@backup ~]# mkdir -p /backup/mysql  /backup/file
[root@backup ~]# chown -R rsync.rsync /backup/mysql /backup/file 
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;13-ä¿®æ”¹é…ç½®æ–‡ä»¶&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#13-ä¿®æ”¹é…ç½®æ–‡ä»¶&#34;&gt;#&lt;/a&gt; 1.3 ä¿®æ”¹é…ç½®æ–‡ä»¶&lt;/h5&gt;
&lt;p&gt;&lt;em&gt;&lt;mark&gt;#ç”Ÿäº§ç¯å¢ƒä¸­å–æ¶ˆæ³¨é‡Šï¼Œå¯¼è‡´å¤‡ä»½æ•°æ®æŠ¥é”™&lt;/mark&gt;&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#å¸¦æ³¨é‡Šé…ç½®æ–‡ä»¶
[root@backup ~]# vim /etc/rsyncd.conf
uid = rsync             #è¿è¡ŒæœåŠ¡çš„ç”¨æˆ·
gid = rsync             #è¿è¡ŒæœåŠ¡çš„ç»„
port = 873              #æœåŠ¡ç›‘å¬ç«¯å£
fake super = yes        #æœåŠ¡æ— éœ€ä½¿ç”¨rootç”¨æˆ·èº«ä»½ï¼Œå³å¯æ¥æ”¶æ–‡ä»¶çš„å®Œæ•´å±æ€§
use chroot = no         #ç¦é”¢ç›®å½•,ä¸å…è®¸è·å–rootæƒé™
max connections = 200   #æœ€å¤§è¿æ¥æ•°,æœ€å¤šèƒ½æœ‰å¤šå°‘ä¸ªå®¢æˆ·ç«¯è·ŸæœåŠ¡ç«¯çš„873ç«¯å£å»ºç«‹è¿æ¥
timeout = 600           #è¶…æ—¶æ—¶é—´
ignore errors          #å¿½ç•¥é”™è¯¯
read only = false      #å®¢æˆ·æ˜¯å¦åªè¯»
list = false           #ä¸å…è®¸æŸ¥çœ‹æ¨¡å—ä¿¡æ¯
auth users = rsync_backup         #å®šä¹‰è™šæ‹Ÿç”¨æˆ·ï¼Œç”¨æˆ·æ•°æ®ä¼ è¾“
secrets file = /etc/rsync.passwd  #å®šä¹‰è™šæ‹Ÿç”¨æˆ·å¯†ç è®¤è¯æ–‡ä»¶
log file = /var/log/rsyncd.log    #æ—¥å¿—æ–‡ä»¶å­˜æ”¾çš„ä½ç½®
[backup_mysql]         #æ¨¡å—å
comment = welcome to rsync_backup
path = /backup/mysql   #æ•°æ®å­˜æ”¾ç›®å½•
[backup_file]          #æ¨¡å—å
comment = welcome to rsync_backup
path = /backup/file    #æ•°æ®å­˜æ”¾ç›®å½• 

#ä¸å¸¦æ³¨é‡Šé…ç½®æ–‡ä»¶
[root@backup ~]# cat /etc/rsyncd.conf
uid = rsync        
gid = rsync         
port = 873     
fake super = yes     
use chroot = no        
max connections = 200  
timeout = 600         
ignore errors       
read only = false    
list = false          
auth users = rsync_backup        
secrets file = /etc/rsync.passwd
log file = /var/log/rsyncd.log    
[backup_mysql]       
comment = welcome to rsync_backup
path = /backup/mysql  
[backup_file]         
comment = welcome to rsync_backup
path = /backup/file 
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;4-åˆ›å»ºè™šæ‹Ÿç”¨æˆ·å¯†ç æ–‡ä»¶å¹¶è®¾ç½®æƒé™&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4-åˆ›å»ºè™šæ‹Ÿç”¨æˆ·å¯†ç æ–‡ä»¶å¹¶è®¾ç½®æƒé™&#34;&gt;#&lt;/a&gt; 4. åˆ›å»ºè™šæ‹Ÿç”¨æˆ·å¯†ç æ–‡ä»¶å¹¶è®¾ç½®æƒé™&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@backup ~]# cat /etc/rsync.passwd
rsync_backup:your passwd
[root@backup ~]# chmod 600 /etc/rsync.passwd
[root@backup ~]# systemctl restart rsyncd &amp;amp;&amp;amp; systemctl status rsyncd
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;5-æ£€æŸ¥æœåŠ¡ç«¯å£æ˜¯å¦å¼€å¯&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#5-æ£€æŸ¥æœåŠ¡ç«¯å£æ˜¯å¦å¼€å¯&#34;&gt;#&lt;/a&gt; 5. æ£€æŸ¥æœåŠ¡ç«¯å£æ˜¯å¦å¼€å¯&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@backup ~]# netstat -lntp | grep &amp;quot;rsync&amp;quot;
tcp        0      0 0.0.0.0:873             0.0.0.0:*               LISTEN      20357/rsync         
tcp6       0      0 :::873                  :::*                    LISTEN      20357/rsync 
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2-rsyncå®¢æˆ·ç«¯&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-rsyncå®¢æˆ·ç«¯&#34;&gt;#&lt;/a&gt; 2. rsync å®¢æˆ·ç«¯&lt;/h4&gt;
&lt;h5 id=&#34;21-å®‰è£…rsync&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#21-å®‰è£…rsync&#34;&gt;#&lt;/a&gt; 2.1 å®‰è£… rsync&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@db01 ~]# yum install nfs-utils -y
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;22-é…ç½®ä¼ è¾“å¯†ç &#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#22-é…ç½®ä¼ è¾“å¯†ç &#34;&gt;#&lt;/a&gt; 2.2 é…ç½®ä¼ è¾“å¯†ç &lt;/h5&gt;
&lt;p&gt;æ–¹æ³• 1ï¼šå°†å¯†ç å†™å…¥æ–‡ä»¶&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@db01 ~]#  echo &#39;your passwd&#39; &amp;gt; /etc/rsync.pass
[root@db01 ~]# cat /etc/rsync.pass 
your passwd
[root@db01 ~]# chmod 600 /etc/rsync.pass
--æµ‹è¯•æ”¶å‘æ•°æ®ï¼š
[root@db01 ~]# rsync -avz --password-file=/etc/rsync.pass /root/test rsync_backup@192.168.40.101::backup_file
sending incremental file list

sent 47 bytes  received 20 bytes  134.00 bytes/sec
total size is 0  speedup is 0.00
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æ–¹æ³• 2ï¼šä½¿ç”¨å¯†ç ç¯å¢ƒå˜é‡ RSYNC_PASSWORD&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@db01 ~]# export RSYNC_PASSWORD=&#39;your passwd&#39;
--æµ‹è¯•æ”¶å‘æ•°æ®ï¼š
[root@db01 ~]# rsync -avz /root/test rsync_backup@192.168.40.101::backup_file
sending incremental file list

sent 47 bytes  received 20 bytes  134.00 bytes/sec
total size is 0  speedup is 0.00
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;ursyncä¼ä¸šçº§å¤‡ä»½æ¡ˆä¾‹u&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#ursyncä¼ä¸šçº§å¤‡ä»½æ¡ˆä¾‹u&#34;&gt;#&lt;/a&gt; &lt;u&gt;Rsync ä¼ä¸šçº§å¤‡ä»½æ¡ˆä¾‹&lt;/u&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;ç¯å¢ƒå‡†å¤‡&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;ä¸»æœºå&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;strong&gt;IP&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;è§’è‰²&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;server&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;192.168.40.101&lt;/td&gt;
&lt;td&gt;rsync æœåŠ¡ç«¯&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;client&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;192.168.40.102&lt;/td&gt;
&lt;td&gt;rsync å®¢æˆ·&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;å®¢æˆ·ç«¯éœ€æ±‚&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å®¢æˆ·ç«¯æ¯å¤©å‡Œæ™¨ 3 ç‚¹å¤‡ä»½ MySQL è‡³ /backup ä¸‹ä»¥ &amp;quot;ä¸»æœºå_IP åœ°å€_å½“å‰æ—¶é—´å‘½å&amp;quot; çš„ç›®å½•ä¸­&lt;/li&gt;
&lt;li&gt;å®¢æˆ·ç«¯æ¨é€ /backup ç›®å½•ä¸‹æ•°æ®å¤‡ä»½ç›®å½•è‡³ Rsync å¤‡ä»½æœåŠ¡å™¨&lt;/li&gt;
&lt;li&gt;å®¢æˆ·ç«¯åªä¿ç•™æœ€è¿‘ä¸ƒå¤©çš„å¤‡ä»½æ•°æ®ï¼Œé¿å…æµªè´¹ç£ç›˜ç©ºé—´&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;æœåŠ¡ç«¯éœ€æ±‚&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;æœåŠ¡ç«¯éƒ¨ç½² rsync æœåŠ¡ï¼Œç”¨äºæ¥æ”¶ç”¨æˆ·çš„å¤‡ä»½æ•°æ®&lt;/li&gt;
&lt;li&gt;æœåŠ¡ç«¯æ¯å¤©æ ¡éªŒå®¢æˆ·ç«¯æ¨é€è¿‡æ¥çš„æ•°æ®æ˜¯å¦å®Œæ•´ï¼Œå¹¶å°†ç»“æœä»¥é‚®ä»¶çš„æ–¹å¼å‘é€ç»™ç®¡ç†å‘˜&lt;/li&gt;
&lt;li&gt;æœåŠ¡ç«¯ä»…ä¿ç•™ 6 ä¸ªæœˆçš„å¤‡ä»½æ•°æ®&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;æ³¨æ„&lt;/strong&gt;ï¼šæ‰€æœ‰æœåŠ¡å™¨çš„å¤‡ä»½ç›®å½•å‡ä¸º /backupï¼Œæ‰€æœ‰è„šæœ¬å­˜æ”¾ç›®å½•å‡ä¸º /scriptsã€‚&lt;/p&gt;
&lt;h4 id=&#34;1-æœåŠ¡ç«¯éƒ¨ç½²rsyncæœåŠ¡&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-æœåŠ¡ç«¯éƒ¨ç½²rsyncæœåŠ¡&#34;&gt;#&lt;/a&gt; &lt;strong&gt;1. æœåŠ¡ç«¯éƒ¨ç½² rsync æœåŠ¡&lt;/strong&gt;&lt;/h4&gt;
&lt;h5 id=&#34;11-å…³é—­é˜²ç«å¢™-selinux-2&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#11-å…³é—­é˜²ç«å¢™-selinux-2&#34;&gt;#&lt;/a&gt; 1.1 å…³é—­é˜²ç«å¢™ã€selinux&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@localhost ~]# hostnamectl set-hostname backup
[root@localhost ~]# bash
[root@backup ~]# hostnamectl set-hostname aizj_lb01
[root@backup ~]# systemctl stop firewalld
[root@backup ~]# systemctl disable firewalld
[root@backup ~]# sed -i &#39;s/^SELINUX=enforcing/SELINUX=disabled/g&#39; /etc/sysconfig/selinux
[root@backup ~]# sed -i &#39;s/^SELINUX=enforcing/SELINUX=disabled/g&#39; /etc/selinux/config
[root@backup ~]# yum install net-tools vim tree lrzsz wget unzip dos2unix bash-completion  lsof ntp ntpdate git -y
[root@backup ~]# yum update -y --exclude=kernel* &amp;amp;&amp;amp; reboot
[root@backup ~]# echo &#39;Asia/Shanghai&#39; &amp;gt;/etc/timezone
[root@backup ~]# ntpdate time2.aliyun.com
[root@backup ~]# crontab -e
*/5 * * * * /usr/sbin/ntpdate time2.aliyun.com &amp;amp;&amp;gt; /dev/nul
[root@backup ~]# mkdir /soft /data /scripts /backup
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;12-å®‰è£…rsync-2&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#12-å®‰è£…rsync-2&#34;&gt;#&lt;/a&gt; 1.2 å®‰è£… rsync&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@backup ~]# yum install -y rsync
[root@server ~]# systemctl start rsyncd
[root@server ~]# systemctl enable rsyncd
[root@backup ~]# useradd -M -s /sbin/nologin rsync
[root@backup ~]# mkdir -p /backup/mysql  /backup/file
[root@backup ~]# chown -R rsync.rsync /backup/mysql /backup/file 
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;13-ä¿®æ”¹é…ç½®æ–‡ä»¶-2&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#13-ä¿®æ”¹é…ç½®æ–‡ä»¶-2&#34;&gt;#&lt;/a&gt; 1.3 ä¿®æ”¹é…ç½®æ–‡ä»¶&lt;/h5&gt;
&lt;p&gt;&lt;em&gt;&lt;mark&gt;#ç”Ÿäº§ç¯å¢ƒä¸­å–æ¶ˆæ³¨é‡Šï¼Œå¯¼è‡´å¤‡ä»½æ•°æ®æŠ¥é”™&lt;/mark&gt;&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#å¸¦æ³¨é‡Šé…ç½®æ–‡ä»¶
[root@backup ~]# vim /etc/rsyncd.conf
uid = rsync             #è¿è¡ŒæœåŠ¡çš„ç”¨æˆ·
gid = rsync             #è¿è¡ŒæœåŠ¡çš„ç»„
port = 873              #æœåŠ¡ç›‘å¬ç«¯å£
fake super = yes        #æœåŠ¡æ— éœ€ä½¿ç”¨rootç”¨æˆ·èº«ä»½ï¼Œå³å¯æ¥æ”¶æ–‡ä»¶çš„å®Œæ•´å±æ€§
use chroot = no         #ç¦é”¢ç›®å½•,ä¸å…è®¸è·å–rootæƒé™
max connections = 200   #æœ€å¤§è¿æ¥æ•°,æœ€å¤šèƒ½æœ‰å¤šå°‘ä¸ªå®¢æˆ·ç«¯è·ŸæœåŠ¡ç«¯çš„873ç«¯å£å»ºç«‹è¿æ¥
timeout = 600           #è¶…æ—¶æ—¶é—´
ignore errors          #å¿½ç•¥é”™è¯¯
read only = false      #å®¢æˆ·æ˜¯å¦åªè¯»
list = false           #ä¸å…è®¸æŸ¥çœ‹æ¨¡å—ä¿¡æ¯
auth users = rsync_backup         #å®šä¹‰è™šæ‹Ÿç”¨æˆ·ï¼Œç”¨æˆ·æ•°æ®ä¼ è¾“
secrets file = /etc/rsync.passwd  #å®šä¹‰è™šæ‹Ÿç”¨æˆ·å¯†ç è®¤è¯æ–‡ä»¶
log file = /var/log/rsyncd.log    #æ—¥å¿—æ–‡ä»¶å­˜æ”¾çš„ä½ç½®
[backup_mysql]         #æ¨¡å—å
comment = welcome to rsync_backup
path = /backup/mysql   #æ•°æ®å­˜æ”¾ç›®å½•
[backup_file]          #æ¨¡å—å
comment = welcome to rsync_backup
path = /backup/file    #æ•°æ®å­˜æ”¾ç›®å½• 

#ä¸å¸¦æ³¨é‡Šé…ç½®æ–‡ä»¶
[root@backup ~]# cat /etc/rsyncd.conf
uid = rsync        
gid = rsync         
port = 873     
fake super = yes     
use chroot = no        
max connections = 200  
timeout = 600         
ignore errors       
read only = false    
list = false          
auth users = rsync_backup        
secrets file = /etc/rsync.passwd
log file = /var/log/rsyncd.log    
[backup_mysql]       
comment = welcome to rsync_backup
path = /backup/mysql  
[backup_file]         
comment = welcome to rsync_backup
path = /backup/file 
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;4-åˆ›å»ºè™šæ‹Ÿç”¨æˆ·å¯†ç æ–‡ä»¶å¹¶è®¾ç½®æƒé™-2&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4-åˆ›å»ºè™šæ‹Ÿç”¨æˆ·å¯†ç æ–‡ä»¶å¹¶è®¾ç½®æƒé™-2&#34;&gt;#&lt;/a&gt; 4. åˆ›å»ºè™šæ‹Ÿç”¨æˆ·å¯†ç æ–‡ä»¶å¹¶è®¾ç½®æƒé™&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@backup ~]# cat /etc/rsync.passwd
rsync_backup:your passwd
[root@backup ~]# chmod 600 /etc/rsync.passwd
[root@backup ~]# systemctl restart rsyncd &amp;amp;&amp;amp; systemctl status rsyncd
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;5-æ£€æŸ¥æœåŠ¡ç«¯å£æ˜¯å¦å¼€å¯-2&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#5-æ£€æŸ¥æœåŠ¡ç«¯å£æ˜¯å¦å¼€å¯-2&#34;&gt;#&lt;/a&gt; 5. æ£€æŸ¥æœåŠ¡ç«¯å£æ˜¯å¦å¼€å¯&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@backup ~]# netstat -lntp | grep &amp;quot;rsync&amp;quot;
tcp        0      0 0.0.0.0:873             0.0.0.0:*               LISTEN      20357/rsync         
tcp6       0      0 :::873                  :::*                    LISTEN      20357/rsync 
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2-rsyncå®¢æˆ·ç«¯-2&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-rsyncå®¢æˆ·ç«¯-2&#34;&gt;#&lt;/a&gt; 2. rsync å®¢æˆ·ç«¯&lt;/h4&gt;
&lt;h5 id=&#34;21-å®‰è£…rsync-2&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#21-å®‰è£…rsync-2&#34;&gt;#&lt;/a&gt; 2.1 å®‰è£… rsync&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@db01 ~]# yum install nfs-utils -y
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;22-æµ‹è¯•å®¢æˆ·ç«¯å¤‡ä»½æ•°æ®å¹¶æ¨é€è‡³rsyncæœåŠ¡å™¨&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#22-æµ‹è¯•å®¢æˆ·ç«¯å¤‡ä»½æ•°æ®å¹¶æ¨é€è‡³rsyncæœåŠ¡å™¨&#34;&gt;#&lt;/a&gt; 2.2 æµ‹è¯•å®¢æˆ·ç«¯å¤‡ä»½æ•°æ®å¹¶æ¨é€è‡³ rsync æœåŠ¡å™¨&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@db01 ~]# export RSYNC_PASSWORD=&#39;your passwd&#39;
[root@db01 ~]# rsync -avz /root/test rsync_backup@192.168.40.101::backup_file
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;23-å®¢æˆ·ç«¯å¤‡ä»½æ•°æ®å¹¶æ¨é€è‡³rsyncæœåŠ¡å™¨&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#23-å®¢æˆ·ç«¯å¤‡ä»½æ•°æ®å¹¶æ¨é€è‡³rsyncæœåŠ¡å™¨&#34;&gt;#&lt;/a&gt; &lt;strong&gt;2.3 å®¢æˆ·ç«¯å¤‡ä»½æ•°æ®å¹¶æ¨é€è‡³ rsync æœåŠ¡å™¨&lt;/strong&gt;&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@db01 ~]# mkdir /scripts
[root@db01 ~]# cat /scripts/mysql_backup.sh 
#!/bin/bash
export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin

#1ã€å®šä¹‰å˜é‡
Host=$(hostname)
Ip=$(ifconfig ens192 | awk &#39;NR==2&amp;#123;print $2&amp;#125;&#39;)
Date=$(date +%F)
BackupDir=/backup/mysql
Dest=$&amp;#123;BackupDir&amp;#125;/$&amp;#123;Host&amp;#125;_$&amp;#123;Ip&amp;#125;_$&amp;#123;Date&amp;#125;
FILE_NAME=mysql_backup_`date &#39;+%Y%m%d%H%M%S&#39;`;
OLDBINLOG=/var/lib/mysql/oldbinlog

#2ã€åˆ›å»ºå¤‡ä»½ç›®å½•
if [ ! -d $Dest ];then
  mkdir -p $Dest
fi

#3ã€å¤‡ä»½ç›®å½•
/usr/bin/mysqldump -u&#39;root&#39; -p&#39;your passwd&#39; nf_flms &amp;gt; $Dest/nf-flms_$&amp;#123;FILE_NAME&amp;#125;.sql
tar -czvf $Dest/$&amp;#123;FILE_NAME&amp;#125;.tar.gz $Dest/nf-flms_$&amp;#123;FILE_NAME&amp;#125;.sql
rm -rf $Dest/*$&amp;#123;FILE_NAME&amp;#125;.sql
echo &amp;quot;Your database backup successfully&amp;quot;

#4ã€æ ¡éªŒ
md5sum $Dest/* &amp;gt;$Dest/backup_check_$Date

#5ã€å°†å¤‡ä»½ç›®å½•æ¨åŠ¨åˆ°rsyncæœåŠ¡ç«¯
Rsync_Ip=192.168.1.145
Rsync_user=rsync_backup
Rsync_Module=backup_mysql
export RSYNC_PASSWORD=your passwd
rsync -avz $Dest $Rsync_user@$Rsync_Ip::$Rsync_Module

#6ã€åˆ é™¤15å¤©å¤‡ä»½ç›®å½•
find $Dest -type d -mtime +15 | xargs rm -rf
echo &amp;quot;remove file  successfully&amp;quot;

[root@db01 ~]# chmod +x /scripts/etc_backup.sh
[root@db01 ~]# crontab -e
00 03 * * * /bin/bash /scripts/mysql_backup.sh &amp;amp;&amp;gt; /dev/null
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;24-æœåŠ¡ç«¯æ ¡éªŒæ•°æ®å¹¶å°†ç»“æœä»¥é‚®ä»¶å‘é€ç»™ç®¡ç†å‘˜&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#24-æœåŠ¡ç«¯æ ¡éªŒæ•°æ®å¹¶å°†ç»“æœä»¥é‚®ä»¶å‘é€ç»™ç®¡ç†å‘˜&#34;&gt;#&lt;/a&gt; &lt;strong&gt;2.4 æœåŠ¡ç«¯æ ¡éªŒæ•°æ®å¹¶å°†ç»“æœä»¥é‚®ä»¶å‘é€ç»™ç®¡ç†å‘˜&lt;/strong&gt;&lt;/h5&gt;
&lt;h6 id=&#34;241-é…ç½®é‚®ä»¶æœåŠ¡&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#241-é…ç½®é‚®ä»¶æœåŠ¡&#34;&gt;#&lt;/a&gt; 2.4.1 é…ç½®é‚®ä»¶æœåŠ¡&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;[root@backup ~]# yum -y install mailx
[root@backup ~]# cat /etc/mail.rc      #æœ€åä¸€è¡Œæ’å…¥
set from=373370405@qq.com
set smtp=smtps://smtp.qq.com:465
set smtp-auth-user=373370405@qq.com
set smtp-auth-password=**********   # å‘ä»¶é‚®ç®±çš„æˆæƒç 
set smtp-auth=login
set ssl-verify=ignore
set nss-config-dir=/etc/pki/nssdb
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;242-å‘é€é‚®ä»¶æµ‹è¯•&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#242-å‘é€é‚®ä»¶æµ‹è¯•&#34;&gt;#&lt;/a&gt; 2.4.2 å‘é€é‚®ä»¶æµ‹è¯•&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;[root@backup ~]#  echo Hello World | mail -s test 373370405@qq.com &amp;amp;&amp;gt; /dev/null
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;243-é…ç½®è„šæœ¬æ ¡éªŒæ•°æ®å¹¶å°†ç»“æœå‘é€ç»™ç®¡ç†å‘˜&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#243-é…ç½®è„šæœ¬æ ¡éªŒæ•°æ®å¹¶å°†ç»“æœå‘é€ç»™ç®¡ç†å‘˜&#34;&gt;#&lt;/a&gt; 2.4.3 é…ç½®è„šæœ¬æ ¡éªŒæ•°æ®å¹¶å°†ç»“æœå‘é€ç»™ç®¡ç†å‘˜&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;[root@backup mysql]# cat /scripts/check_backup.sh 
#!/bin/bash
export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin

#1ã€å®šä¹‰å˜é‡
Path=/backup/mysql
Date=$(date +%F)

#2ã€æŸ¥çœ‹flagæ–‡ä»¶ï¼Œå¹¶å¯¹å¯¹æ–‡ä»¶è¿›è¡Œæ ¡éªŒ,ç„¶åå°†æ ¡éªŒçš„ç»“æœä¿å­˜è‡³result_æ—¶é—´
find $Path -type f -name &amp;quot;backup_check_$&amp;#123;Date&amp;#125;*&amp;quot;|xargs md5sum -c &amp;gt;$Path/result_$&amp;#123;Date&amp;#125;

#3ã€å°†æ ¡éªŒç»“æœå‘é€é‚®ä»¶ç»™ç®¡ç†å‘˜
mail -s &amp;quot;Mysql Backup&amp;quot; 373370405@qq.com &amp;lt;$Path/result_$&amp;#123;Date&amp;#125; &amp;amp;&amp;gt; /dev/null

#4ã€åˆ é™¤è¶…è¿‡7å¤©çš„æ ¡éªŒç»“æœæ–‡ä»¶ï¼Œåˆ é™¤è¶…è¿‡180å¤©çš„å¤‡ä»½æ•°æ®æ–‡ä»¶
find $Path -type f -name &amp;quot;result*&amp;quot; -mtime +7 | xargs rm -rf
find $Path -type f -mtime +180 | xargs rm -rf
&lt;/code&gt;&lt;/pre&gt;
&lt;h6 id=&#34;244-å†™è®¡åˆ’ä»»åŠ¡&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#244-å†™è®¡åˆ’ä»»åŠ¡&#34;&gt;#&lt;/a&gt; &lt;strong&gt;2.4.4 å†™è®¡åˆ’ä»»åŠ¡&lt;/strong&gt;&lt;/h6&gt;
&lt;pre&gt;&lt;code&gt;[root@backup ~]# chmod +x /scripts/check_backup.sh 
[root@db01 ~]# crontab -e
00 06 * * * /bin/bash /scripts/mysql_backup.sh &amp;amp;&amp;gt; /dev/null
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;rsyncsersyncå®ç°æ•°æ®å®æ—¶åŒæ­¥&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#rsyncsersyncå®ç°æ•°æ®å®æ—¶åŒæ­¥&#34;&gt;#&lt;/a&gt; Rsync+sersync å®ç°æ•°æ®å®æ—¶åŒæ­¥&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;ç¯å¢ƒå‡†å¤‡&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;ä¸»æœºå&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;strong&gt;IP&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;è§’è‰²&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;server&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;192.168.40.101&lt;/td&gt;
&lt;td&gt;rsync æœåŠ¡ç«¯&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;client&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;192.168.40.102&lt;/td&gt;
&lt;td&gt;rsync å®¢æˆ·&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;1rsyncæœåŠ¡ç«¯-2&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1rsyncæœåŠ¡ç«¯-2&#34;&gt;#&lt;/a&gt; 1.rsync æœåŠ¡ç«¯&lt;/h4&gt;
&lt;h5 id=&#34;11-å…³é—­é˜²ç«å¢™-selinux-3&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#11-å…³é—­é˜²ç«å¢™-selinux-3&#34;&gt;#&lt;/a&gt; 1.1 å…³é—­é˜²ç«å¢™ã€selinux&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@localhost ~]# hostnamectl set-hostname backup
[root@localhost ~]# bash
[root@backup ~]# hostnamectl set-hostname aizj_lb01
[root@backup ~]# systemctl stop firewalld
[root@backup ~]# systemctl disable firewalld
[root@backup ~]# sed -i &#39;s/^SELINUX=enforcing/SELINUX=disabled/g&#39; /etc/sysconfig/selinux
[root@backup ~]# sed -i &#39;s/^SELINUX=enforcing/SELINUX=disabled/g&#39; /etc/selinux/config
[root@backup ~]# yum install net-tools vim tree lrzsz wget unzip dos2unix bash-completion  lsof ntp ntpdate git -y
[root@backup ~]# yum update -y --exclude=kernel* &amp;amp;&amp;amp; reboot
[root@backup ~]# echo &#39;Asia/Shanghai&#39; &amp;gt;/etc/timezone
[root@backup ~]# ntpdate time2.aliyun.com
[root@backup ~]# crontab -e
*/5 * * * * /usr/sbin/ntpdate time2.aliyun.com &amp;amp;&amp;gt; /dev/nul
[root@backup ~]# mkdir /soft /data /scripts /backup
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;12-å®‰è£…rsync-3&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#12-å®‰è£…rsync-3&#34;&gt;#&lt;/a&gt; 1.2 å®‰è£… rsync&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@backup ~]# yum install -y rsync
[root@server ~]# systemctl start rsyncd
[root@server ~]# systemctl enable rsyncd
[root@backup ~]# useradd -M -s /sbin/nologin rsync
[root@backup ~]# mkdir -p /backup/mysql  /backup/file
[root@backup ~]# chown -R rsync.rsync /backup/mysql /backup/file 
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;13-ä¿®æ”¹é…ç½®æ–‡ä»¶-3&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#13-ä¿®æ”¹é…ç½®æ–‡ä»¶-3&#34;&gt;#&lt;/a&gt; 1.3 ä¿®æ”¹é…ç½®æ–‡ä»¶&lt;/h5&gt;
&lt;p&gt;&lt;em&gt;&lt;mark&gt;#ç”Ÿäº§ç¯å¢ƒä¸­å–æ¶ˆæ³¨é‡Šï¼Œå¯¼è‡´å¤‡ä»½æ•°æ®æŠ¥é”™&lt;/mark&gt;&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#å¸¦æ³¨é‡Šé…ç½®æ–‡ä»¶
[root@backup ~]# vim /etc/rsyncd.conf
uid = rsync             #è¿è¡ŒæœåŠ¡çš„ç”¨æˆ·
gid = rsync             #è¿è¡ŒæœåŠ¡çš„ç»„
port = 873              #æœåŠ¡ç›‘å¬ç«¯å£
fake super = yes        #æœåŠ¡æ— éœ€ä½¿ç”¨rootç”¨æˆ·èº«ä»½ï¼Œå³å¯æ¥æ”¶æ–‡ä»¶çš„å®Œæ•´å±æ€§
use chroot = no         #ç¦é”¢ç›®å½•,ä¸å…è®¸è·å–rootæƒé™
max connections = 200   #æœ€å¤§è¿æ¥æ•°,æœ€å¤šèƒ½æœ‰å¤šå°‘ä¸ªå®¢æˆ·ç«¯è·ŸæœåŠ¡ç«¯çš„873ç«¯å£å»ºç«‹è¿æ¥
timeout = 600           #è¶…æ—¶æ—¶é—´
ignore errors          #å¿½ç•¥é”™è¯¯
read only = false      #å®¢æˆ·æ˜¯å¦åªè¯»
list = false           #ä¸å…è®¸æŸ¥çœ‹æ¨¡å—ä¿¡æ¯
auth users = rsync_backup         #å®šä¹‰è™šæ‹Ÿç”¨æˆ·ï¼Œç”¨æˆ·æ•°æ®ä¼ è¾“
secrets file = /etc/rsync.passwd  #å®šä¹‰è™šæ‹Ÿç”¨æˆ·å¯†ç è®¤è¯æ–‡ä»¶
log file = /var/log/rsyncd.log    #æ—¥å¿—æ–‡ä»¶å­˜æ”¾çš„ä½ç½®
[backup_mysql]         #æ¨¡å—å
comment = welcome to rsync_backup
path = /backup/mysql   #æ•°æ®å­˜æ”¾ç›®å½•
[backup_file]          #æ¨¡å—å
comment = welcome to rsync_backup
path = /backup/file    #æ•°æ®å­˜æ”¾ç›®å½• 

#ä¸å¸¦æ³¨é‡Šé…ç½®æ–‡ä»¶
[root@backup ~]# cat /etc/rsyncd.conf
uid = rsync        
gid = rsync         
port = 873     
fake super = yes     
use chroot = no        
max connections = 200  
timeout = 600         
ignore errors       
read only = false    
list = false          
auth users = rsync_backup        
secrets file = /etc/rsync.passwd
log file = /var/log/rsyncd.log    
[backup_mysql]       
comment = welcome to rsync_backup
path = /backup/mysql  
[backup_file]         
comment = welcome to rsync_backup
path = /backup/file 
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;4-åˆ›å»ºè™šæ‹Ÿç”¨æˆ·å¯†ç æ–‡ä»¶å¹¶è®¾ç½®æƒé™-3&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4-åˆ›å»ºè™šæ‹Ÿç”¨æˆ·å¯†ç æ–‡ä»¶å¹¶è®¾ç½®æƒé™-3&#34;&gt;#&lt;/a&gt; 4. åˆ›å»ºè™šæ‹Ÿç”¨æˆ·å¯†ç æ–‡ä»¶å¹¶è®¾ç½®æƒé™&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@backup ~]# cat /etc/rsync.passwd
rsync_backup:your passwd
[root@backup ~]# chmod 600 /etc/rsync.passwd
[root@backup ~]# systemctl restart rsyncd &amp;amp;&amp;amp; systemctl status rsyncd
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;5-æ£€æŸ¥æœåŠ¡ç«¯å£æ˜¯å¦å¼€å¯-3&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#5-æ£€æŸ¥æœåŠ¡ç«¯å£æ˜¯å¦å¼€å¯-3&#34;&gt;#&lt;/a&gt; 5. æ£€æŸ¥æœåŠ¡ç«¯å£æ˜¯å¦å¼€å¯&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@backup ~]# netstat -lntp | grep &amp;quot;rsync&amp;quot;
tcp        0      0 0.0.0.0:873             0.0.0.0:*               LISTEN      20357/rsync         
tcp6       0      0 :::873                  :::*                    LISTEN      20357/rsync 
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2-å®¢æˆ·ç«¯å®‰è£…sersync&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-å®¢æˆ·ç«¯å®‰è£…sersync&#34;&gt;#&lt;/a&gt; 2. å®¢æˆ·ç«¯å®‰è£… sersync&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;2.1 å®‰è£… sercync ä¾èµ–&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@nfs ~]# yum install -y inotify-tools rsync
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;2.2 å®‰è£… sercync&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@nfs ~]# mkdir -p /soft
[root@nfs ~]# cd /soft/
[root@nfs ~]# wget https://down.whsir.com/downloads/sersync2.5.4_64bit_binary_stable_final.tar.gz
[root@nfs soft]# tar -xf sersync2.5.4_64bit_binary_stable_final.tar.gz
[root@nfs soft]# mv GNU-Linux-x86 /usr/local/sersync
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;23-ä¿®æ”¹é…ç½®æ–‡ä»¶&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#23-ä¿®æ”¹é…ç½®æ–‡ä»¶&#34;&gt;#&lt;/a&gt; 2.3 &lt;strong&gt;ä¿®æ”¹é…ç½®æ–‡ä»¶&lt;/strong&gt;&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@nfs soft]# cd /usr/local/sersync/
[root@nfs sersync]# cp confxml.xml confxml.xml.bak
[root@nfs sersync]# vim confxml.xml
...
5    &amp;lt;fileSystem xfs=&amp;quot;true&amp;quot;/&amp;gt;    #ç¬¬5è¡Œ falseæ”¹ä¸ºtrue
13          &amp;lt;delete start=&amp;quot;true&amp;quot;/&amp;gt; #ç¬¬13-20è¡Œ falseæ”¹ä¸ºtrue,#è¯´æ˜ï¼šç›‘æ§ä»¥ä¸Šå˜åŒ–æ¨é€
14        &amp;lt;createFolder start=&amp;quot;true&amp;quot;/&amp;gt;
15        &amp;lt;createFile start=&amp;quot;false&amp;quot;/&amp;gt;
16        &amp;lt;closeWrite start=&amp;quot;true&amp;quot;/&amp;gt;
17        &amp;lt;moveFrom start=&amp;quot;true&amp;quot;/&amp;gt;
18        &amp;lt;moveTo start=&amp;quot;true&amp;quot;/&amp;gt;
19        &amp;lt;attrib start=&amp;quot;true&amp;quot;/&amp;gt;
20        &amp;lt;modify start=&amp;quot;true&amp;quot;/&amp;gt;
24        &amp;lt;localpath watch=&amp;quot;/data&amp;quot;&amp;gt;      #ç›‘æ§çš„æœ¬åœ°ç›®å½•
25             &amp;lt;remote ip=&amp;quot;192.168.1.145&amp;quot; name=&amp;quot;backup_file&amp;quot;/&amp;gt;  #rsyncæœåŠ¡ç«¯IPå’Œæ¨¡å—åbackup_file
30      &amp;lt;commonParams params=&amp;quot;-avz&amp;quot;/&amp;gt;  #rsyncå‘½ä»¤é€‰é¡¹
31      &amp;lt;auth start=&amp;quot;true&amp;quot; users=&amp;quot;rsync_backup&amp;quot; passwordfile=&amp;quot;/etc/rsync.passwd&amp;quot;/&amp;gt; #rsyncè®¤è¯ä¿¡æ¯
...
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;24-ç”Ÿæˆå¯†ç æ–‡ä»¶&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#24-ç”Ÿæˆå¯†ç æ–‡ä»¶&#34;&gt;#&lt;/a&gt; 2.4 ç”Ÿæˆå¯†ç æ–‡ä»¶&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@nfs sersync]# echo &#39;your passwd&#39; &amp;gt; /etc/rsync.passwd
[root@nfs sersync]# chmod 600 /etc/rsync.passwd
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;25-å¯åŠ¨sersync&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#25-å¯åŠ¨sersync&#34;&gt;#&lt;/a&gt; 2.5 å¯åŠ¨ sersync&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;[root@nfs sersync]# ln -s /usr/local/sersync/sersync2 /usr/bin/
[root@nfs sersync]# sersync2 -dro /usr/local/sersync/confxml.xml     #é’ˆå¯¹é…ç½®æ–‡ä»¶confxml.xmlå¯åŠ¨sersync
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;2.5 è®¾ç½® sersync å¼€æœºè‡ªå¯&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@qzj_nfs sersync]# vim /etc/rc.d/rc.local   
/usr/local/sersync/sersync2 -d -r -o  /usr/local/sersync/confxml.xml  #åœ¨æœ€åæ·»åŠ ä¸€è¡Œ
[root@qzj_nfs sersync]# chmod +x /etc/rc.d/rc.local
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;2.6 æµ‹è¯•&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;åœ¨å®¢æˆ·ç«¯ /data ç›®å½•å¢åˆ æ”¹ç›®å½•æ–‡ä»¶ï¼Œrsync æœåŠ¡ç«¯æ•°æ®å­˜æ”¾ç›®å½•å˜åŒ–&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@backup backup]# watch ls
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;2.7 æ·»åŠ è„šæœ¬ç›‘æ§ sersync æ˜¯å¦æ­£å¸¸è¿è¡Œ&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@nfs sersync]# cat /scripts/check_sersync.sh 
#!/bin/sh
sersync=&amp;quot;/usr/local/sersync/sersync2&amp;quot;
confxml=&amp;quot;/usr/local/sersync/confxml.xml&amp;quot;
status=$(ps aux |grep &#39;sersync2&#39;|grep -v &#39;grep&#39;|wc -l)
if [ $status -eq 0 ];
then
$sersync -d -r -o $confxml &amp;amp;
else
exit 0;
fi

[root@nfs sersync]# chmod +x /scripts/check_sersync.sh
[root@nfs sersync]# crontab -l
*/5 * * * * /usr/bin/sh /scripts/check_sersync.sh &amp;amp;&amp;gt; /dev/null
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;è¡¥å……ï¼š å¤šå®ä¾‹æƒ…å†µ&lt;/strong&gt;&lt;/em&gt;&lt;br /&gt;
 1ã€é…ç½®å¤šä¸ª confxml.xml æ–‡ä»¶ï¼ˆæ¯”å¦‚ï¼šwwwã€bbsã€blog.... ç­‰ç­‰ï¼‰&lt;br /&gt;
2ã€ä¿®æ”¹ç«¯å£ã€åŒæ­¥è·¯å¾„ã€æ¨¡å—åç§°&lt;br /&gt;
 3ã€æ ¹æ®ä¸åŒçš„éœ€æ±‚åŒæ­¥å¯¹åº”çš„å®ä¾‹æ–‡ä»¶&lt;br /&gt;
 /usr/local/sersync/sersync2 -dro /usr/local/sersync/www_confxml.xml&lt;br /&gt;
/usr/local/sersync/sersync2 -dro /usr/local/sersync/bbs_confxml.xml&lt;/p&gt;
</content>
        <category term="rsync" />
        <updated>2025-03-30T12:45:48.000Z</updated>
    </entry>
    <entry>
        <id>http://ixuyong.cn/posts/3071070978.html</id>
        <title>ä¼ä¸šçº§ç§æœ‰ä»“åº“Harboræ­å»º</title>
        <link rel="alternate" href="http://ixuyong.cn/posts/3071070978.html"/>
        <content type="html">&lt;h3 id=&#34;ä¼ä¸šçº§ç§æœ‰ä»“åº“harbor&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#ä¼ä¸šçº§ç§æœ‰ä»“åº“harbor&#34;&gt;#&lt;/a&gt; ä¼ä¸šçº§ç§æœ‰ä»“åº“ Harbor&lt;/h3&gt;
&lt;p&gt;ä¼ä¸šéƒ¨ç½² Kuberetes é›†ç¾¤ç¯å¢ƒä¹‹åï¼Œæˆ‘ä»¬å°±å¯ä»¥å°†åŸæ¥åœ¨ä¼ ç»Ÿè™šæ‹Ÿæœºä¸Šè¿è¡Œçš„ä¸šåŠ¡ï¼Œè¿ç§»åˆ° kubernetes ä¸Šï¼Œè®© Kubernetes é€šè¿‡å®¹å™¨çš„æ–¹å¼æ¥ç®¡ç†ã€‚è€Œä¸€æ—¦æˆ‘ä»¬éœ€è¦å°†ä¼ ç»Ÿä¸šåŠ¡ä½¿ç”¨å®¹å™¨çš„æ–¹å¼è¿è¡Œèµ·æ¥ï¼Œå°±éœ€è¦æ„å»ºå¾ˆå¤šé•œåƒï¼Œé‚£ä¹ˆè¿™äº›é•œåƒå°±éœ€è¦æœ‰ä¸€ä¸ªä¸“é—¨çš„ä½ç½®å­˜å‚¨èµ·æ¥ï¼Œä¸ºæˆ‘ä»¬æä¾›é•œåƒä¸Šä¼ å’Œé•œåƒä¸‹è½½ç­‰åŠŸèƒ½ã€‚ä½†æˆ‘ä»¬ä¸èƒ½ä½¿ç”¨é˜¿é‡Œäº‘æˆ–è€… Dockerhub ç­‰ä»“åº“ï¼Œé¦–å…ˆæ‹‰å–é€Ÿåº¦æ¯”è¾ƒæ…¢ï¼Œå…¶æ¬¡é•œåƒçš„å®‰å…¨æ€§æ— æ³•ä¿è¯ï¼Œæ‰€ä»¥å°±éœ€è¦éƒ¨ç½²ä¸€ä¸ªç§æœ‰çš„é•œåƒä»“åº“æ¥ç®¡ç†è¿™äº›å®¹å™¨é•œåƒã€‚åŒæ—¶è¯¥ä»“åº“è¿˜éœ€è¦æä¾›é«˜å¯ç”¨åŠŸèƒ½ï¼Œç¡®ä¿éšæ—¶éƒ½èƒ½ä¸Šä¼ å’Œä¸‹è½½å¯ç”¨çš„å®¹å™¨é•œåƒã€‚&lt;/p&gt;
&lt;h4 id=&#34;1-å…³é—­é˜²ç«å¢™-selinux-ç¯å¢ƒé…ç½®&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#1-å…³é—­é˜²ç«å¢™-selinux-ç¯å¢ƒé…ç½®&#34;&gt;#&lt;/a&gt; 1ã€å…³é—­é˜²ç«å¢™ã€Selinuxã€ç¯å¢ƒé…ç½®&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@harbor ~]# sudo mkdir -p /etc/docker
[root@harbor ~]# hostnamectl set-hostname harbor
[root@harbor ~]# systemctl stop firewalld
[root@harbor ~]# systemctl disable firewalld
[root@harbor ~]# sed -i &#39;s/^SELINUX=enforcing/SELINUX=disabled/g&#39; /etc/sysconfig/selinux
[root@harbor ~]# yum install net-tools vim tree lrzsz wget unzip dos2unix bash-completion  lsof ntp ntpdate -y
[root@harbor ~]# yum update -y
[root@harbor ~]# mkdir /soft /data /scripts /backup
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2-dockerå®‰è£…&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#2-dockerå®‰è£…&#34;&gt;#&lt;/a&gt; 2ã€Docker å®‰è£…&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@harbor ~]# yum install -y yum-utils device-mapper-persistent-data lvm2
[root@harbor ~]# curl -o /etc/yum.repos.d/docker-ce.repo  https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
[root@harbor ~]# yum list docker-ce --showduplicates |sort -r 
[root@harbor ~]# yum install docker-ce docker-compose -y
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;3-é…ç½®dockeråŠ é€Ÿ&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#3-é…ç½®dockeråŠ é€Ÿ&#34;&gt;#&lt;/a&gt; 3ã€é…ç½® Docker åŠ é€Ÿ&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@harbor ~]# sudo mkdir -p /etc/docker
[root@harbor ~]# sudo tee /etc/docker/daemon.json &amp;lt;&amp;lt;-&#39;EOF&#39;
&amp;#123;
  &amp;quot;registry-mirrors&amp;quot;: [
	  &amp;quot;https://docker.credclouds.com&amp;quot;,
	  &amp;quot;https://k8s.credclouds.com&amp;quot;,
	  &amp;quot;https://quay.credclouds.com&amp;quot;,
	  &amp;quot;https://gcr.credclouds.com&amp;quot;,
	  &amp;quot;https://k8s-gcr.credclouds.com&amp;quot;,
	  &amp;quot;https://ghcr.credclouds.com&amp;quot;,
	  &amp;quot;https://do.nark.eu.org&amp;quot;,
	  &amp;quot;https://docker.m.daocloud.io&amp;quot;,
	  &amp;quot;https://docker.nju.edu.cn&amp;quot;,
	  &amp;quot;https://docker.mirrors.sjtug.sjtu.edu.cn&amp;quot;,
	  &amp;quot;https://docker.1panel.live&amp;quot;,
	  &amp;quot;https://docker.rainbond.cc&amp;quot;
  ], 
  &amp;quot;exec-opts&amp;quot;: [&amp;quot;native.cgroupdriver=systemd&amp;quot;] 
&amp;#125;
EOF
[root@harbor ~]# systemctl enable docker --now
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;4-å®‰è£…harbor&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#4-å®‰è£…harbor&#34;&gt;#&lt;/a&gt; 4ã€å®‰è£… Harbor&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@harbor ~]# cd /soft/
[root@harbor ~]# wget https://github.com/goharbor/harbor/releases/download/v2.6.1/harbor-offline-installer-v2.6.1.tgz
[root@harbor soft]# tar xf harbor-offline-installer-v2.6.1.tgz
[root@harbor soft]# cd harbor
[root@harbor harbor]# vim harbor.yml
hostname: 192.168.1.134
...
#https:
#  # https port for harbor, default is 443
#  port: 443
#  # The path of cert and key files for nginx
#  certificate: /your/certificate/path
#  private_key: /your/private/key/path
...
harbor_admin_password: Harbor12345
[root@harbor harbor]#  ./install.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;5-é…ç½®nginxè´Ÿè½½å‡è¡¡è°ƒåº¦&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#5-é…ç½®nginxè´Ÿè½½å‡è¡¡è°ƒåº¦&#34;&gt;#&lt;/a&gt; 5ã€é…ç½® Nginx è´Ÿè½½å‡è¡¡è°ƒåº¦&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@lb ~]# vim s.hmallleasing.com.conf
server &amp;#123;
    listen 443 ssl;
    server_name harbor.hmallleasing.com;
    client_max_body_size 1G; 
    ssl_prefer_server_ciphers on;
    ssl_certificate  /etc/nginx/sslkey/_.hmallleasing.com_chain.crt;
    ssl_certificate_key  /etc/nginx/sslkey/_.hmallleasing.com_key.key;
    location / &amp;#123;
        proxy_pass http://192.168.1.134;
#      include proxy_params;
#        proxy_set_header Host $http_host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        
        proxy_connect_timeout 30;
        proxy_send_timeout 60;
        proxy_read_timeout 60;
        
        proxy_buffering on;
        proxy_buffer_size 32k;
        proxy_buffers 4 128k;
        proxy_temp_file_write_size 10240k;		
        proxy_max_temp_file_size 10240k;
    &amp;#125;
&amp;#125;

server &amp;#123;
    listen 80;
    server_name s.hmallleasing.com;
    return 302 https://$server_name$request_uri;
&amp;#125;
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;6-æ¨é€é•œåƒè‡³harbor&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#6-æ¨é€é•œåƒè‡³harbor&#34;&gt;#&lt;/a&gt; 6ã€æ¨é€é•œåƒè‡³ Harbor&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;[root@harbor harbor]# docker tag beae173ccac6 harbor.hmallleasing.com/ops/busybox.v1
[root@harbor harbor]# docker push harbor.hmallleasing.com/ops/busybox.v1
[root@harbor harbor]# docker login harbor.hmallleasing.com
[root@harbor harbor]# docker push harbor.hmallleasing.com/ops/busybox.v1
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;7-harboråœæ­¢ä¸å¯åŠ¨&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#7-harboråœæ­¢ä¸å¯åŠ¨&#34;&gt;#&lt;/a&gt; 7ã€Harbor åœæ­¢ä¸å¯åŠ¨&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;#åœç”¨Harbor
[root@harbor harbor]# pwd
/soft/harbor
[root@harbor harbor]# docker-compose stop
 #å¯åŠ¨Harbor
[root@harbor harbor]# docker-compose up -d
[root@harbor harbor]# docker-compose start
&lt;/code&gt;&lt;/pre&gt;
</content>
        <category term="Harbor" />
        <updated>2025-03-30T08:17:00.000Z</updated>
    </entry>
</feed>
