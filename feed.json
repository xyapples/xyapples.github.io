{
    "version": "https://jsonfeed.org/version/1",
    "title": "LinuxSreäº‘åŸç”Ÿ",
    "description": "ä¸“æ³¨äº Linux è¿ç»´ã€äº‘è®¡ç®—ã€äº‘åŸâ½£ç­‰æŠ€æœ¯",
    "home_page_url": "http://ixuyong.cn",
    "items": [
        {
            "id": "http://ixuyong.cn/posts/170573601.html",
            "url": "http://ixuyong.cn/posts/170573601.html",
            "title": "K8sæœåŠ¡å‘å¸ƒIngress",
            "date_published": "2025-04-26T08:52:06.000Z",
            "content_html": "<h4 id=\"1-ingress-nginx-controller-å®‰è£…\"><a class=\"anchor\" href=\"#1-ingress-nginx-controller-å®‰è£…\">#</a> 1. Ingress Nginx Controller å®‰è£…</h4>\n<table>\n<thead>\n<tr>\n<th>Supported</th>\n<th>Ingress-NGINX version</th>\n<th>k8s supported version</th>\n<th>Alpine Version</th>\n<th>Nginx Version</th>\n<th>Helm Chart Version</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ğŸ”„</td>\n<td><strong>v1.12.1</strong></td>\n<td>1.32, 1.31, 1.30, 1.29, 1.28</td>\n<td>3.21.3</td>\n<td>1.25.5</td>\n<td>4.12.1</td>\n</tr>\n<tr>\n<td>ğŸ”„</td>\n<td><strong>v1.12.0</strong></td>\n<td>1.32, 1.31, 1.30, 1.29, 1.28</td>\n<td>3.21.0</td>\n<td>1.25.5</td>\n<td>4.12.0</td>\n</tr>\n<tr>\n<td>ğŸ”„</td>\n<td><strong>v1.12.0-beta.0</strong></td>\n<td>1.32, 1.31, 1.30, 1.29, 1.28</td>\n<td>3.20.3</td>\n<td>1.25.5</td>\n<td>4.12.0-beta.0</td>\n</tr>\n<tr>\n<td>ğŸ”„</td>\n<td><strong>v1.11.5</strong></td>\n<td>1.30, 1.29, 1.28, 1.27, 1.26</td>\n<td>3.21.3</td>\n<td>1.25.5</td>\n<td>4.11.5</td>\n</tr>\n<tr>\n<td>ğŸ”„</td>\n<td><strong>v1.11.4</strong></td>\n<td>1.30, 1.29, 1.28, 1.27, 1.26</td>\n<td>3.21.0</td>\n<td>1.25.5</td>\n<td>4.11.4</td>\n</tr>\n<tr>\n<td>ğŸ”„</td>\n<td><strong>v1.11.3</strong></td>\n<td>1.30, 1.29, 1.28, 1.27, 1.26</td>\n<td>3.20.3</td>\n<td>1.25.5</td>\n<td>4.11.3</td>\n</tr>\n<tr>\n<td>ğŸ”„</td>\n<td><strong>v1.11.2</strong></td>\n<td>1.30, 1.29, 1.28, 1.27, 1.26</td>\n<td>3.20.0</td>\n<td>1.25.5</td>\n<td>4.11.2</td>\n</tr>\n<tr>\n<td>ğŸ”„</td>\n<td><strong>v1.11.1</strong></td>\n<td>1.30, 1.29, 1.28, 1.27, 1.26</td>\n<td>3.20.0</td>\n<td>1.25.5</td>\n<td>4.11.1</td>\n</tr>\n<tr>\n<td>ğŸ”„</td>\n<td><strong>v1.11.0</strong></td>\n<td>1.30, 1.29, 1.28, 1.27, 1.26</td>\n<td>3.20.0</td>\n<td>1.25.5</td>\n<td>4.11.0</td>\n</tr>\n<tr>\n<td></td>\n<td><strong>v1.10.6</strong></td>\n<td>1.30, 1.29, 1.28, 1.27, 1.26</td>\n<td>3.21.0</td>\n<td>1.25.5</td>\n<td>4.10.6</td>\n</tr>\n<tr>\n<td></td>\n<td><strong>v1.10.5</strong></td>\n<td>1.30, 1.29, 1.28, 1.27, 1.26</td>\n<td>3.20.3</td>\n<td>1.25.5</td>\n<td>4.10.5</td>\n</tr>\n<tr>\n<td></td>\n<td><strong>v1.10.4</strong></td>\n<td>1.30, 1.29, 1.28, 1.27, 1.26</td>\n<td>3.20.0</td>\n<td>1.25.5</td>\n<td>4.10.4</td>\n</tr>\n<tr>\n<td></td>\n<td><strong>v1.10.3</strong></td>\n<td>1.30, 1.29, 1.28, 1.27, 1.26</td>\n<td>3.20.0</td>\n<td>1.25.5</td>\n<td>4.10.3</td>\n</tr>\n<tr>\n<td></td>\n<td><strong>v1.10.2</strong></td>\n<td>1.30, 1.29, 1.28, 1.27, 1.26</td>\n<td>3.20.0</td>\n<td>1.25.5</td>\n<td>4.10.2</td>\n</tr>\n<tr>\n<td></td>\n<td><strong>v1.10.1</strong></td>\n<td>1.30, 1.29, 1.28, 1.27, 1.26</td>\n<td>3.19.1</td>\n<td>1.25.3</td>\n<td>4.10.1</td>\n</tr>\n<tr>\n<td></td>\n<td><strong>v1.10.0</strong></td>\n<td>1.29, 1.28, 1.27, 1.26</td>\n<td>3.19.1</td>\n<td>1.25.3</td>\n<td>4.10.0</td>\n</tr>\n<tr>\n<td></td>\n<td>v1.9.6</td>\n<td>1.29, 1.28, 1.27, 1.26, 1.25</td>\n<td>3.19.0</td>\n<td>1.21.6</td>\n<td>4.9.1</td>\n</tr>\n<tr>\n<td></td>\n<td>v1.9.5</td>\n<td>1.28, 1.27, 1.26, 1.25</td>\n<td>3.18.4</td>\n<td>1.21.6</td>\n<td>4.9.0</td>\n</tr>\n<tr>\n<td></td>\n<td>v1.9.4</td>\n<td>1.28, 1.27, 1.26, 1.25</td>\n<td>3.18.4</td>\n<td>1.21.6</td>\n<td>4.8.3</td>\n</tr>\n<tr>\n<td></td>\n<td>v1.9.3</td>\n<td>1.28, 1.27, 1.26, 1.25</td>\n<td>3.18.4</td>\n<td>1.21.6</td>\n<td>4.8.*</td>\n</tr>\n<tr>\n<td></td>\n<td>v1.9.1</td>\n<td>1.28, 1.27, 1.26, 1.25</td>\n<td>3.18.4</td>\n<td>1.21.6</td>\n<td>4.8.*</td>\n</tr>\n<tr>\n<td></td>\n<td>v1.9.0</td>\n<td>1.28, 1.27, 1.26, 1.25</td>\n<td>3.18.2</td>\n<td>1.21.6</td>\n<td>4.8.*</td>\n</tr>\n<tr>\n<td></td>\n<td>v1.8.4</td>\n<td>1.27, 1.26, 1.25, 1.24</td>\n<td>3.18.2</td>\n<td>1.21.6</td>\n<td>4.7.*</td>\n</tr>\n<tr>\n<td></td>\n<td>v1.7.1</td>\n<td>1.27, 1.26, 1.25, 1.24</td>\n<td>3.17.2</td>\n<td>1.21.6</td>\n<td>4.6.*</td>\n</tr>\n<tr>\n<td></td>\n<td>v1.6.4</td>\n<td>1.26, 1.25, 1.24, 1.23</td>\n<td>3.17.0</td>\n<td>1.21.6</td>\n<td>4.5.*</td>\n</tr>\n<tr>\n<td></td>\n<td>v1.5.1</td>\n<td>1.25, 1.24, 1.23</td>\n<td>3.16.2</td>\n<td>1.21.6</td>\n<td>4.4.*</td>\n</tr>\n<tr>\n<td></td>\n<td>v1.4.0</td>\n<td>1.25, 1.24, 1.23, 1.22</td>\n<td>3.16.2</td>\n<td>1.19.10â€ </td>\n<td>4.3.0</td>\n</tr>\n<tr>\n<td></td>\n<td>v1.3.1</td>\n<td>1.24, 1.23, 1.22, 1.21, 1.20</td>\n<td>3.16.2</td>\n<td>1.19.10â€ </td>\n<td>4.2.5</td>\n</tr>\n</tbody>\n</table>\n<h5 id=\"11-helmå®‰è£…ingress-nginx-controller\"><a class=\"anchor\" href=\"#11-helmå®‰è£…ingress-nginx-controller\">#</a> 1.1 Helm å®‰è£… Ingress Nginx Controller</h5>\n<ol>\n<li>å®‰è£… Helm</li>\n</ol>\n<pre><code># wget https://get.helm.sh/helm-v3.6.3-linux-amd64.tar.gz\n# tar xf helm-v3.6.3-linux-amd64.tar.gz\n# mv linux-amd64/helm /usr/local/bin/helm\n# helm version\n</code></pre>\n<ol start=\"2\">\n<li>ä¸‹è½½ Ingress Nginx Controller å®‰è£…åŒ…</li>\n</ol>\n<pre><code>å®˜æ–¹æ–‡æ¡£ï¼šhttps://github.com/kubernetes/ingress-nginx/tree/helm-chart-4.8.2         #æ ¹æ®è‡ªå·±k8sç‰ˆæœ¬ä¸‹è½½\n# helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx\n# helm repo update\n# helm repo list\n# helm pull ingress-nginx/ingress-nginx --version 4.8.2\n</code></pre>\n<ol start=\"3\">\n<li>é…ç½® Ingress Nginx Controller</li>\n</ol>\n<pre><code># tar xf ingress-nginx-4.8.2.tgz\n# cd ingress-nginx\n# vim values.yaml\n...\n 16 controller:\n 17   name: controller\n 18   enableAnnotationValidations: false\n 19   image:\n 20     ## Keep false as default for now!\n 21     chroot: false\n 22     registry: registry.cn-hangzhou.aliyuncs.com\n 23     image: kubernetes_public/ingress-nginx-controller\n 24     ## for backwards compatibility consider setting the full image url via the repository value below\n 25     ## use *either* current default registry/image or repository format or installing chart by providing the values.yaml wil    l fail\n 26     ## repository:\n 27     tag: &quot;v1.9.3&quot;\n 28     #digest: sha256:8fd21d59428507671ce0fb47f818b1d859c92d2ad07bb7c947268d433030ba98\n...\n 42   # -- Will add custom configuration options to Nginx https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configurat    ion/configmap/\n 43   config:\n 44     allow-snippet-annotations: true          #å¼€å¯server snippetçš„é…ç½®\n...\n 67   dnsPolicy: ClusterFirstWithHostNet\n...\n 88   hostNetwork: true\n...\n107   ingressClassResource:\n108     # -- Name of the ingressClass\n109     name: nginx\n110     # -- Is this ingressClass enabled or not\n111     enabled: true\n112     # -- Is this the default ingressClass for the cluster\n113     default: true\n...\n184   kind: DaemonSet\n...\n287   nodeSelector:\n288     kubernetes.io/os: linux\n289     ingress: &quot;true&quot;\n...\n638       image:\n639         registry: registry.cn-hangzhou.aliyuncs.com\n640         image: kubernetes_public/kube-webhook-certgen\n641         ## for backwards compatibility consider setting the full image url via the repository value below\n642         ## use *either* current default registry/image or repository format or installing chart by providing the values.yaml     will fail\n643         ## repository:\n644         tag: v20231011-8b53cabe0\n645         #digest: sha256:a7943503b45d552785aa3b5e457f169a5661fb94d82b8a3373bcd9ebaf9aac80\n...\n</code></pre>\n<p>4. ç»™éœ€è¦éƒ¨ç½² ingress çš„èŠ‚ç‚¹ä¸Šæ‰“æ ‡ç­¾</p>\n<pre><code># kubectl label node k8s-node02 ingress=true\n# kubectl label node k8s-node01 ingress=true\n# kubectl create ns ingress-nginx\n# helm install ingress-nginx -n ingress-nginx .     #å®‰è£…\n# helm upgrade ingress-nginx -n ingress-nginx .     #æ›´æ–°\n# kubectl get pods -n ingress-nginx \nNAME                             READY   STATUS    RESTARTS   AGE\ningress-nginx-controller-7nfqn   1/1     Running   0          27s\ningress-nginx-controller-k4p2n   1/1     Running   0          17m\ningress-nginx-controller-kw5jk   1/1     Running   0          24s\n</code></pre>\n<h5 id=\"12-bare-metalå®‰è£…ingress-nginx-controller\"><a class=\"anchor\" href=\"#12-bare-metalå®‰è£…ingress-nginx-controller\">#</a> 1.2 Bare metal å®‰è£… Ingress Nginx Controller</h5>\n<ol>\n<li>ä¸‹è½½ Ingress éƒ¨ç½²æ–‡ä»¶ï¼Œé“¾æ¥åœ°å€ï¼š<a href=\"https://kubernetes.github.io/ingress-nginx/deploy/#bare-metal-clusters\">https://kubernetes.github.io/ingress-nginx/deploy/#bare-metal-clusters</a></li>\n</ol>\n<pre><code>[root@k8s-master01 ~]# wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.12.1/deploy/static/provider/baremetal/deploy.yaml\n</code></pre>\n<ol start=\"2\">\n<li>é…ç½® Ingress</li>\n</ol>\n<pre><code>[root@k8s-master01 ingress-master]# cat deploy.yaml \napiVersion: v1\nkind: Namespace\nmetadata:\n  labels:\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/name: ingress-nginx\n  name: ingress-nginx\n---\napiVersion: v1\nautomountServiceAccountToken: true\nkind: ServiceAccount\nmetadata:\n  labels:\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n    app.kubernetes.io/version: 1.12.1\n  name: ingress-nginx\n  namespace: ingress-nginx\n---\napiVersion: v1\nautomountServiceAccountToken: true\nkind: ServiceAccount\nmetadata:\n  labels:\n    app.kubernetes.io/component: admission-webhook\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n    app.kubernetes.io/version: 1.12.1\n  name: ingress-nginx-admission\n  namespace: ingress-nginx\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  labels:\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n    app.kubernetes.io/version: 1.12.1\n  name: ingress-nginx\n  namespace: ingress-nginx\nrules:\n- apiGroups:\n  - &quot;&quot;\n  resources:\n  - namespaces\n  verbs:\n  - get\n- apiGroups:\n  - &quot;&quot;\n  resources:\n  - configmaps\n  - pods\n  - secrets\n  - endpoints\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - &quot;&quot;\n  resources:\n  - services\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - networking.k8s.io\n  resources:\n  - ingresses\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - networking.k8s.io\n  resources:\n  - ingresses/status\n  verbs:\n  - update\n- apiGroups:\n  - networking.k8s.io\n  resources:\n  - ingressclasses\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - coordination.k8s.io\n  resourceNames:\n  - ingress-nginx-leader\n  resources:\n  - leases\n  verbs:\n  - get\n  - update\n- apiGroups:\n  - coordination.k8s.io\n  resources:\n  - leases\n  verbs:\n  - create\n- apiGroups:\n  - &quot;&quot;\n  resources:\n  - events\n  verbs:\n  - create\n  - patch\n- apiGroups:\n  - discovery.k8s.io\n  resources:\n  - endpointslices\n  verbs:\n  - list\n  - watch\n  - get\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  labels:\n    app.kubernetes.io/component: admission-webhook\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n    app.kubernetes.io/version: 1.12.1\n  name: ingress-nginx-admission\n  namespace: ingress-nginx\nrules:\n- apiGroups:\n  - &quot;&quot;\n  resources:\n  - secrets\n  verbs:\n  - get\n  - create\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  labels:\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n    app.kubernetes.io/version: 1.12.1\n  name: ingress-nginx\nrules:\n- apiGroups:\n  - &quot;&quot;\n  resources:\n  - configmaps\n  - endpoints\n  - nodes\n  - pods\n  - secrets\n  - namespaces\n  verbs:\n  - list\n  - watch\n- apiGroups:\n  - coordination.k8s.io\n  resources:\n  - leases\n  verbs:\n  - list\n  - watch\n- apiGroups:\n  - &quot;&quot;\n  resources:\n  - nodes\n  verbs:\n  - get\n- apiGroups:\n  - &quot;&quot;\n  resources:\n  - services\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - networking.k8s.io\n  resources:\n  - ingresses\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - &quot;&quot;\n  resources:\n  - events\n  verbs:\n  - create\n  - patch\n- apiGroups:\n  - networking.k8s.io\n  resources:\n  - ingresses/status\n  verbs:\n  - update\n- apiGroups:\n  - networking.k8s.io\n  resources:\n  - ingressclasses\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - discovery.k8s.io\n  resources:\n  - endpointslices\n  verbs:\n  - list\n  - watch\n  - get\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  labels:\n    app.kubernetes.io/component: admission-webhook\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n    app.kubernetes.io/version: 1.12.1\n  name: ingress-nginx-admission\nrules:\n- apiGroups:\n  - admissionregistration.k8s.io\n  resources:\n  - validatingwebhookconfigurations\n  verbs:\n  - get\n  - update\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  labels:\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n    app.kubernetes.io/version: 1.12.1\n  name: ingress-nginx\n  namespace: ingress-nginx\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: Role\n  name: ingress-nginx\nsubjects:\n- kind: ServiceAccount\n  name: ingress-nginx\n  namespace: ingress-nginx\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  labels:\n    app.kubernetes.io/component: admission-webhook\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n    app.kubernetes.io/version: 1.12.1\n  name: ingress-nginx-admission\n  namespace: ingress-nginx\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: Role\n  name: ingress-nginx-admission\nsubjects:\n- kind: ServiceAccount\n  name: ingress-nginx-admission\n  namespace: ingress-nginx\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  labels:\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n    app.kubernetes.io/version: 1.12.1\n  name: ingress-nginx\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: ingress-nginx\nsubjects:\n- kind: ServiceAccount\n  name: ingress-nginx\n  namespace: ingress-nginx\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  labels:\n    app.kubernetes.io/component: admission-webhook\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n    app.kubernetes.io/version: 1.12.1\n  name: ingress-nginx-admission\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: ingress-nginx-admission\nsubjects:\n- kind: ServiceAccount\n  name: ingress-nginx-admission\n  namespace: ingress-nginx\n---\napiVersion: v1\ndata: null\nkind: ConfigMap\nmetadata:\n  labels:\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n    app.kubernetes.io/version: 1.12.1\n  name: ingress-nginx-controller\n  namespace: ingress-nginx\n---\napiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n    app.kubernetes.io/version: 1.12.1\n  name: ingress-nginx-controller\n  namespace: ingress-nginx\nspec:\n  ipFamilies:\n  - IPv4\n  ipFamilyPolicy: SingleStack\n  ports:\n  - appProtocol: http\n    name: http\n    port: 80\n    protocol: TCP\n    targetPort: http\n  - appProtocol: https\n    name: https\n    port: 443\n    protocol: TCP\n    targetPort: https\n  selector:\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/name: ingress-nginx\n  #type: NodePort\n  type: ClusterIP\n---\napiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n    app.kubernetes.io/version: 1.12.1\n  name: ingress-nginx-controller-admission\n  namespace: ingress-nginx\nspec:\n  ports:\n  - appProtocol: https\n    name: https-webhook\n    port: 443\n    targetPort: webhook\n  selector:\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/name: ingress-nginx\n  type: ClusterIP\n---\napiVersion: apps/v1\n#kind: Deployment\nkind: DaemonSet\nmetadata:\n  labels:\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n    app.kubernetes.io/version: 1.12.1\n  name: ingress-nginx-controller\n  namespace: ingress-nginx\nspec:\n  minReadySeconds: 0\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: controller\n      app.kubernetes.io/instance: ingress-nginx\n      app.kubernetes.io/name: ingress-nginx\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: controller\n        app.kubernetes.io/instance: ingress-nginx\n        app.kubernetes.io/name: ingress-nginx\n        app.kubernetes.io/part-of: ingress-nginx\n        app.kubernetes.io/version: 1.12.1\n    spec:\n      containers:\n      - args:\n        - /nginx-ingress-controller\n        - --election-id=ingress-nginx-leader\n        - --controller-class=k8s.io/ingress-nginx\n        - --ingress-class=nginx\n        - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller\n        - --validating-webhook=:8443\n        - --validating-webhook-certificate=/usr/local/certificates/cert\n        - --validating-webhook-key=/usr/local/certificates/key\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: LD_PRELOAD\n          value: /usr/local/lib/libmimalloc.so\n        image: registry.cn-hangzhou.aliyuncs.com/kubernetes_public/ingress-nginx-controller-v1.12.1:v1.12.1 \n        imagePullPolicy: IfNotPresent\n        lifecycle:\n          preStop:\n            exec:\n              command:\n              - /wait-shutdown\n        livenessProbe:\n          failureThreshold: 5\n          httpGet:\n            path: /healthz\n            port: 10254\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        name: controller\n        ports:\n        - containerPort: 80\n          name: http\n          protocol: TCP\n        - containerPort: 443\n          name: https\n          protocol: TCP\n        - containerPort: 8443\n          name: webhook\n          protocol: TCP\n        readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 10254\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          successThreshold: 1\n          timeoutSeconds: 1\n        resources:\n          requests:\n            cpu: 100m\n            memory: 90Mi\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            add:\n            - NET_BIND_SERVICE\n            drop:\n            - ALL\n          readOnlyRootFilesystem: false\n          runAsGroup: 82\n          runAsNonRoot: true\n          runAsUser: 101\n          seccompProfile:\n            type: RuntimeDefault\n        volumeMounts:\n        - mountPath: /usr/local/certificates/\n          name: webhook-cert\n          readOnly: true\n      hostNetwork: true                         # ä¸èŠ‚ç‚¹å…±äº«ç½‘ç»œåç§°ç©ºé—´\n      #dnsPolicy: ClusterFirst\n      dnsPolicy: ClusterFirstWithHostNet        # dns ç­–ç•¥\n      nodeSelector:                             # èŠ‚ç‚¹é€‰æ‹©å™¨\n        kubernetes.io/os: linux\n        ingress: &quot;true&quot;\n      serviceAccountName: ingress-nginx\n      terminationGracePeriodSeconds: 300\n      volumes:\n      - name: webhook-cert\n        secret:\n          secretName: ingress-nginx-admission\n---\napiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app.kubernetes.io/component: admission-webhook\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n    app.kubernetes.io/version: 1.12.1\n  name: ingress-nginx-admission-create\n  namespace: ingress-nginx\nspec:\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: admission-webhook\n        app.kubernetes.io/instance: ingress-nginx\n        app.kubernetes.io/name: ingress-nginx\n        app.kubernetes.io/part-of: ingress-nginx\n        app.kubernetes.io/version: 1.12.1\n      name: ingress-nginx-admission-create\n    spec:\n      containers:\n      - args:\n        - create\n        - --host=ingress-nginx-controller-admission,ingress-nginx-controller-admission.$(POD_NAMESPACE).svc\n        - --namespace=$(POD_NAMESPACE)\n        - --secret-name=ingress-nginx-admission\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        image: registry.cn-hangzhou.aliyuncs.com/kubernetes_public/kube-webhook-certgen-v1.5.2:v1.5.2 \n        imagePullPolicy: IfNotPresent\n        name: create\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsGroup: 65532\n          runAsNonRoot: true\n          runAsUser: 65532\n          seccompProfile:\n            type: RuntimeDefault\n      nodeSelector:\n        kubernetes.io/os: linux\n      restartPolicy: OnFailure\n      serviceAccountName: ingress-nginx-admission\n---\napiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    app.kubernetes.io/component: admission-webhook\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n    app.kubernetes.io/version: 1.12.1\n  name: ingress-nginx-admission-patch\n  namespace: ingress-nginx\nspec:\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/component: admission-webhook\n        app.kubernetes.io/instance: ingress-nginx\n        app.kubernetes.io/name: ingress-nginx\n        app.kubernetes.io/part-of: ingress-nginx\n        app.kubernetes.io/version: 1.12.1\n      name: ingress-nginx-admission-patch\n    spec:\n      containers:\n      - args:\n        - patch\n        - --webhook-name=ingress-nginx-admission\n        - --namespace=$(POD_NAMESPACE)\n        - --patch-mutating=false\n        - --secret-name=ingress-nginx-admission\n        - --patch-failure-policy=Fail\n        env:\n        - name: POD_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        image: registry.cn-hangzhou.aliyuncs.com/kubernetes_public/kube-webhook-certgen-v1.5.2:v1.5.2 \n        imagePullPolicy: IfNotPresent\n        name: patch\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          readOnlyRootFilesystem: true\n          runAsGroup: 65532\n          runAsNonRoot: true\n          runAsUser: 65532\n          seccompProfile:\n            type: RuntimeDefault\n      nodeSelector:\n        kubernetes.io/os: linux\n      restartPolicy: OnFailure\n      serviceAccountName: ingress-nginx-admission\n---\napiVersion: networking.k8s.io/v1\nkind: IngressClass\nmetadata:\n  labels:\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n    app.kubernetes.io/version: 1.12.1\n  name: nginx\nspec:\n  controller: k8s.io/ingress-nginx\n---\napiVersion: admissionregistration.k8s.io/v1\nkind: ValidatingWebhookConfiguration\nmetadata:\n  labels:\n    app.kubernetes.io/component: admission-webhook\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n    app.kubernetes.io/version: 1.12.1\n  name: ingress-nginx-admission\nwebhooks:\n- admissionReviewVersions:\n  - v1\n  clientConfig:\n    service:\n      name: ingress-nginx-controller-admission\n      namespace: ingress-nginx\n      path: /networking/v1/ingresses\n      port: 443\n  failurePolicy: Fail\n  matchPolicy: Equivalent\n  name: validate.nginx.ingress.kubernetes.io\n  rules:\n  - apiGroups:\n    - networking.k8s.io\n    apiVersions:\n    - v1\n    operations:\n    - CREATE\n    - UPDATE\n    resources:\n    - ingresses\n  sideEffects: None\n</code></pre>\n<ul>\n<li>type: ClusterIP                                              #service ç±»å‹æ”¹ä¸º ClusterIP</li>\n<li>hostNetwork: true                                      # ä¸èŠ‚ç‚¹å…±äº«ç½‘ç»œåç§°ç©ºé—´</li>\n<li>dnsPolicy: ClusterFirstWithHostNet        # dns ç­–ç•¥</li>\n<li>nodeSelector:                                             # èŠ‚ç‚¹é€‰æ‹©å™¨</li>\n<li>kind: DaemonSet                                        # èµ„æºç±»å‹ DaemonSet</li>\n</ul>\n<ol start=\"3\">\n<li>åœ¨æŒ‡å®šèŠ‚ç‚¹éƒ¨ç½² Ingress-Controller</li>\n</ol>\n<pre><code>[root@k8s-master01 ingress-master]# kubectl apply -f deploy.yaml -n ingress-nginx\n\n[root@k8s-master01 ingress-master]# kubectl label node k8s-node01 ingress=true\n[root@k8s-master01 ingress-master]# kubectl label node k8s-node02 ingress=true\n[root@k8s-master01 ingress-master]# kubectl label node k8s-master03 ingress-     #å–æ¶ˆèŠ‚ç‚¹éƒ¨ç½²\n\n[root@k8s-master01 ingress-master]# kubectl get pods -n ingress-nginx \nNAME                                   READY   STATUS      RESTARTS   AGE\ningress-nginx-admission-create-zp6mh   0/1     Completed   0          12m\ningress-nginx-admission-patch-f2bpd    0/1     Completed   0          12m\ningress-nginx-controller-rgtkc         1/1     Running     0          3m59s\ningress-nginx-controller-trmn8         1/1     Running     0          3m59s\n</code></pre>\n<h4 id=\"2-ingress-nginx-å…¥é—¨ä½¿ç”¨\"><a class=\"anchor\" href=\"#2-ingress-nginx-å…¥é—¨ä½¿ç”¨\">#</a> 2. Ingress Nginx å…¥é—¨ä½¿ç”¨</h4>\n<pre><code># cat web-ingress.yaml \napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: web-ingress\nspec:\n  ingressClassName: &quot;nginx&quot;\n  rules:\n  - host: test.hmallleasing.com\n    http:\n      paths:\n      - backend:\n          service:\n            name: nginx\n            port:\n              number: 80\n        path: /\n        pathType: ImplementationSpecific\n</code></pre>\n<h4 id=\"3-ingress-nginx-åŸŸåé‡å®šå‘-redirect\"><a class=\"anchor\" href=\"#3-ingress-nginx-åŸŸåé‡å®šå‘-redirect\">#</a> 3. Ingress Nginx åŸŸåé‡å®šå‘ Redirect</h4>\n<pre><code># cat redirect-ingress.yaml \napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: redirect-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/permanent-redirect: https://www.baidu.com\nspec:\n  ingressClassName: &quot;nginx&quot;\n  rules:\n  - host: redirect.hmallleasing.com\n    http:\n      paths:\n      - backend:\n          service:\n            name: nginx\n            port:\n              number: 80\n        path: /\n        pathType: ImplementationSpecific\n</code></pre>\n<h4 id=\"4-ingress-nginx-å‰åç«¯åˆ†ç¦»-rewrite\"><a class=\"anchor\" href=\"#4-ingress-nginx-å‰åç«¯åˆ†ç¦»-rewrite\">#</a> 4. Ingress Nginx å‰åç«¯åˆ†ç¦» Rewrite</h4>\n<pre><code># cat rewrite-ingress.yaml \napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: rewrite-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /$2\nspec:\n  ingressClassName: &quot;nginx&quot;\n  rules:\n  - host: rewrite.hmallleasing.com\n    http:\n      paths:\n      - backend:\n          service:\n            name: nginx\n            port:\n              number: 80\n        path: /api(/|$)(.*)\n        pathType: ImplementationSpecif\n</code></pre>\n<h4 id=\"5-ingress-nginx-é”™è¯¯ä»£ç é‡å®šå‘\"><a class=\"anchor\" href=\"#5-ingress-nginx-é”™è¯¯ä»£ç é‡å®šå‘\">#</a> 5. Ingress Nginx é”™è¯¯ä»£ç é‡å®šå‘</h4>\n<pre><code>\n</code></pre>\n<h4 id=\"6-ingress-nginx-ssl\"><a class=\"anchor\" href=\"#6-ingress-nginx-ssl\">#</a> 6. Ingress Nginx SSL</h4>\n<pre><code>1.ç”Ÿæˆè¯ä¹¦\n# openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.cert -subj &quot;/CN=s.hmallleasing.com/O=tls.hmallleasing.com&quot;\n\n2.åˆ›å»ºè¯ä¹¦\n# kubectl create secret tls tls.hmallleasig.com --key tls.key --cert tls.cert\n\n3.ingressé…ç½®\n# kubectl create secret tls tls.hmallleasig.com --cert=tls.crt --key=tls.key\n# cat tls-ingress.yaml \napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: tls-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/ssl-redirect: &quot;false&quot;    #ç¦ç”¨httpså¼ºåˆ¶è·³è½¬\nspec:\n  ingressClassName: &quot;nginx&quot;\n  rules:\n  - host: tls.hmallleasing.com\n    http:\n      paths:\n      - backend:\n          service:\n            name: nginx\n            port:\n              number: 80\n        path: /\n        pathType: ImplementationSpecific\n  tls:                  #https\n  - hosts:\n    - tls.hmallleasing.com\n    secretName: &quot;tls.hmallleasig.com&quot;\t\n</code></pre>\n<h4 id=\"7-ingress-nginx-åŒ¹é…è¯·æ±‚å¤´\"><a class=\"anchor\" href=\"#7-ingress-nginx-åŒ¹é…è¯·æ±‚å¤´\">#</a> 7. Ingress Nginx åŒ¹é…è¯·æ±‚å¤´</h4>\n<pre><code>1.éƒ¨ç½²ç§»åŠ¨ç«¯åº”ç”¨\n# kubectl create deploy phone --image=registry.cn-beijing.aliyuncs.com/dotbalo/nginx:phone\n# kubectl expose deploy phone --port 80\n# vim m-ingress.yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: m-ingress\nspec:\n  ingressClassName: &quot;nginx&quot;\n  rules:\n  - host: m.hmallleasing.com\n    http:\n      paths:\n      - backend:\n          service:\n            name: phone\n            port:\n              number: 80\n        path: /\n        pathType: ImplementationSpecific\n\n2.éƒ¨ç½²PCç«¯åº”ç”¨\t\t\n# kubectl create deploy laptop --image=registry.cn-beijing.aliyuncs.com/dotbalo/nginx:laptop\t\n# kubectl expose deploy laptop --port 80\n# vim laptop-ingress.yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    nginx.ingress.kubernetes.io/server-snippet: |\n      set $agentflag 0;\n          if ($http_user_agent ~* &quot;(Android|iPhone|Windows Phone|UC|Kindle)&quot; )&#123;\n              set $agentflag 1;\n          &#125;\n          if ( $agentflag = 1 ) &#123;\n              return 301 http://m.hmallleaing.com;\n          &#125;\n  name: laptop-ingress\nspec:\n  ingressClassName: &quot;nginx&quot;\n  rules:\n  - host: hmallleasing.com\n    http:\n      paths:\n      - backend:\n          service:\n            name: laptop\n            port:\n              number: 80\n        path: /\n        pathType: ImplementationSpecific\t\n</code></pre>\n<h4 id=\"8ingress-nginx-åŸºæœ¬è®¤è¯\"><a class=\"anchor\" href=\"#8ingress-nginx-åŸºæœ¬è®¤è¯\">#</a> 8.Ingress Nginx åŸºæœ¬è®¤è¯</h4>\n<pre><code># yum install httpd -y\n# htpasswd -c auth superman\n# cat auth \nsuperman:$apr1$AC1pc3dK$RJyWnyDJFNKY6twneGVrA1\t\t\n\n# kubectl create secret generic basic-auth --from-file=auth\n# cat basic-ingress.yaml \napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: basic-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/auth-type: basic  # è®¤è¯ç±»å‹\n    nginx.ingress.kubernetes.io/auth-secret: basic-auth  # åŒ…å«ç”¨æˆ·å’Œå¯†ç çš„ secret èµ„æºåç§°\n    nginx.ingress.kubernetes.io/auth-realm: 'Please User password'  # è¦æ˜¾ç¤ºçš„ä¿¡æ¯\nspec:\n  ingressClassName: &quot;nginx&quot;\n  rules:\n  - host: basic.hmallleasing.com\n    http:\n      paths:\n      - backend:\n          service:\n            name: nginx\n            port:\n              number: 80\n        path: /\n        pathType: ImplementationSpecific\n</code></pre>\n<h4 id=\"9-ingress-nginx-é»‘ç™½åå•\"><a class=\"anchor\" href=\"#9-ingress-nginx-é»‘ç™½åå•\">#</a> 9. Ingress Nginx é»‘ / ç™½åå•</h4>\n<pre><code>å†™æ³•ä¸€ï¼š\n# cat white-ingress.yaml \napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: white-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/whitelist-source-range: &quot;192.168.40.101&quot;\nspec:\n  ingressClassName: &quot;nginx&quot;\n  rules:\n  - host: white.hmallleasing.com\n    http:\n      paths:\n      - backend:\n          service:\n            name: nginx\n            port:\n              number: 80\n        path: /\n        pathType: ImplementationSpecific\t\n\nå†™æ³•äºŒï¼š\t\t\n[root@k8s-master01 ingress]# cat white-ingress.yaml \napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: white-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/whitelist-source-range: &quot;192.168.40.0/24&quot;\nspec:\n  ingressClassName: &quot;nginx&quot;\n  rules:\n  - host: white.hmallleasing.com\n    http:\n      paths:\n      - backend:\n          service:\n            name: nginx\n            port:\n              number: 80\n        path: /\n        pathType: ImplementationSpecific\n\n\nå†™æ³•ä¸‰ï¼š\n# cat white-ingress.yaml \napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: white-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/server-snippet: |\n      allow 192.168.40.0/24;\n      deny all;\nspec:\n  ingressClassName: &quot;nginx&quot;\n  rules:\n  - host: white.hmallleasing.com\n    http:\n      paths:\n      - backend:\n          service:\n            name: nginx\n            port:\n              number: 80\n        path: /\n        pathType: ImplementationSpecific\n\t\t\n\n#Master01æµ‹è¯•\t\t\n# curl -H &quot;Host:white.hmallleasing.com&quot; http://192.168.40.103 -I\nHTTP/1.1 200 OK\nDate: Sat, 14 Oct 2023 13:12:03 GMT\nContent-Type: text/html\nContent-Length: 612\nConnection: keep-alive\nLast-Modified: Tue, 16 Apr 2019 13:08:19 GMT\nETag: &quot;5cb5d3c3-264&quot;\nAccept-Ranges: bytes\t\t\n\n#Master02æµ‹è¯•\n# curl -H &quot;Host:white.hmallleasing.com&quot; http://192.168.40.103 -I\nHTTP/1.1 403 Forbidden\nDate: Sat, 14 Oct 2023 13:13:34 GMT\nContent-Type: text/html\nContent-Length: 146\nConnection: keep-alive\n</code></pre>\n<h4 id=\"10-ingress-nginx-é€Ÿç‡é™åˆ¶\"><a class=\"anchor\" href=\"#10-ingress-nginx-é€Ÿç‡é™åˆ¶\">#</a> 10. Ingress Nginx é€Ÿç‡é™åˆ¶</h4>\n<pre><code>[root@k8s-master01 ingress]# cat limit-rate-ingress.yaml \napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: rate-limit-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/limit-rps: &quot;50&quot;\nspec:\n  ingressClassName: &quot;nginx&quot;\n  rules:\n  - host: rate-limit.hmallleasing.com\n    http:\n      paths:\n      - backend:\n          service:\n            name: nginx\n            port:\n              number: 80\n        path: /\n        pathType: ImplementationSpecific\n\n# ab -c 20 -n 1000 http://rate-limit.hmallleasing.com/ |grep request\nComplete requests:      1000\nFailed requests:        724\nTime per request:       10.301 [ms] (mean)\nTime per request:       0.515 [ms] (mean, across all concurrent requests)\nPercentage of the requests served within a certain time (ms)\n</code></pre>\n<h4 id=\"11ä½¿ç”¨-nginx-å®ç°ç°åº¦é‡‘ä¸é›€å‘å¸ƒ\"><a class=\"anchor\" href=\"#11ä½¿ç”¨-nginx-å®ç°ç°åº¦é‡‘ä¸é›€å‘å¸ƒ\">#</a> 11. ä½¿ç”¨ Nginx å®ç°ç°åº¦ / é‡‘ä¸é›€å‘å¸ƒ</h4>\n<pre><code>1.åˆ›å»º v1 ç‰ˆæœ¬\n# kubectl create deploy canary-v1 --image=registry.cn-beijing.aliyuncs.com/dotbalo/canary:v1\t\n# kubectl expose deploy canary-v1 --port 8080\n# cat canary-v1-ingress.yaml \napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: canary-v1-ingress\nspec:\n  ingressClassName: &quot;nginx&quot;\n  rules:\n  - host: canary.hmallleasing.com\n    http:\n      paths:\n      - backend:\n          service:\n            name: canary-v1\n            port:\n              number: 8080\n        path: /\n        pathType: ImplementationSpecific\n\t\t\n# curl -H &quot;Host:canary.hmallleasing.com&quot; http://192.168.40.103 \t\n\n2.åˆ›å»º v2 ç‰ˆæœ¬\n# kubectl create deploy canary-v2 --image=registry.cn-beijing.aliyuncs.com/dotbalo/canary:v2\n# kubectl expose deploy canary-v2 --port 8080\n# cat canary-v2-ingress.yaml \napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: canary-v2-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/canary: &quot;true&quot;    #å¯åŠ¨ç°åº¦å‘å¸ƒ\n    nginx.ingress.kubernetes.io/canary-weight: &quot;20&quot;  #åŸºäºæƒé‡,50%æµé‡è°ƒåº¦åˆ°è¿™ä¸ªç°åº¦çš„ç‰ˆæœ¬ä¸Š\nspec:\n  ingressClassName: &quot;nginx&quot;\n  rules:\n  - host: canary.hmallleasing.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: canary-v2\n            port:\n              number: 8080\n\n#æµ‹è¯•ç°åº¦å‘å¸ƒ\n[root@k8s-master01 ingress]# cat canary.sh \n#!/bin/bash\n\nwhile true\ndo\n\tcurl -H &quot;Host:canary.hmallleasing.com&quot; http://192.168.40.103\n\tsleep 0.5\ndone\n</code></pre>\n<h4 id=\"12-kubernetes-dashboardé…ç½®è¯ä¹¦\"><a class=\"anchor\" href=\"#12-kubernetes-dashboardé…ç½®è¯ä¹¦\">#</a> 12. kubernetes-dashboard é…ç½®è¯ä¹¦</h4>\n<pre><code>1.åˆ›å»ºè¯ä¹¦\nkubectl create secret tls kubernetes-dashboard-certs --key *.hmallleasing.com_key.key --cert *.hmallleasing.com_chain.crt -n kubernetes-dashboard\n\n2.ä¿®æ”¹kubernetes-dashboardèµ„æºæ¸…å•\nkubectl edit deployment -n kubernetes-dashboard kubernetes-dashboard\n...\n      - args:\n        - --auto-generate-certificates=false\n        - --tls-key-file=_.hmallleasing.com_key.key\n        - --tls-cert-file=_.hmallleasing.com_chain.crt\n        - --token-ttl=21600\n        - --authentication-mode=basic,token\n        - --namespace=kubernetes-dashboard\n...\n\n3.åˆ›å»ºingress\n#cat dashboard-ingress.yaml \napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: dashboard-ingress\n  namespace: kubernetes-dashboard\n  annotations:\n    nginx.ingress.kubernetes.io/ssl-passthrough: &quot;true&quot;    \n    nginx.ingress.kubernetes.io/backend-protocol: &quot;HTTPS&quot;    \nspec:\n  ingressClassName: &quot;nginx&quot;\n  rules:\n  - host: dashboard.hmallleasing.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: kubernetes-dashboard\n            port:\n              number: 443\n\n# kubectl apply -f dashboard-ingress.yaml \n</code></pre>\n<h4 id=\"13-å…¥å£lbé…ç½®\"><a class=\"anchor\" href=\"#13-å…¥å£lbé…ç½®\">#</a> 13. å…¥å£ LB é…ç½®</h4>\n<pre><code>[root@lb nginx]# cat /etc/nginx/conf.d/ingress.conf \nupstream ingress &#123;\n\tserver 192.168.40.103:80 max_conns=2000 max_fails=2 fail_timeout=5s;\n\tserver 192.168.40.104:80 max_conns=2000 max_fails=2 fail_timeout=5s;\n\tserver 192.168.40.105:80 max_conns=2000 max_fails=2 fail_timeout=5s;\n&#125;\n\nserver &#123;\n    listen 443 ssl;\n    server_name test.hmallleasing.com;\n    client_max_body_size 1G; \n    ssl_prefer_server_ciphers on;\n    ssl_certificate  /etc/nginx/sslkey/*.hmallleasing.com_chain.crt;\n    ssl_certificate_key  /etc/nginx/sslkey/*.hmallleasing.com_key.key;\n\n    location / &#123;\n        proxy_pass http://ingress;\n        include proxy_params;\n\t    proxy_next_upstream error timeout http_500 http_502 http_503 http_504;\n\t    proxy_next_upstream_tries 2;\n\t    proxy_next_upstream_timeout 3s;\n    &#125;\n&#125;\n\nserver &#123;\n    listen 80;\n    server_name test.hmallleasing.com;\n    return 302 https://$server_name$request_uri;\n&#125;\n\n[root@lb ~]# mkdir /etc/nginx/sslkey -p\n</code></pre>\n",
            "tags": [
                "é»˜è®¤tags"
            ]
        },
        {
            "id": "http://ixuyong.cn/posts/3364424907.html",
            "url": "http://ixuyong.cn/posts/3364424907.html",
            "title": "é˜¿é‡Œäº‘+Githubæ„å»ºé•œåƒä»“åº“",
            "date_published": "2025-04-26T08:20:14.000Z",
            "content_html": "<h3 id=\"é˜¿é‡Œäº‘githubæ„å»ºé•œåƒä»“åº“è§£å†³-k8sgcrioè®¿é—®\"><a class=\"anchor\" href=\"#é˜¿é‡Œäº‘githubæ„å»ºé•œåƒä»“åº“è§£å†³-k8sgcrioè®¿é—®\">#</a> é˜¿é‡Œäº‘ + github æ„å»ºé•œåƒä»“åº“è§£å†³ k8s.gcr.io è®¿é—®</h3>\n<p><a href=\"http://xn--k8s-xi9d897o.gcr.io/\">ç”±äº k8s.gcr.io/</a> é•œåƒä»“åº“ä½äºå›½å¤–ï¼Œå›½å†…ä½¿ç”¨ kubeadm æ„å»º docker é›†ç¾¤æ—¶æ— æ³•è®¿é—®ç›¸åº”çš„ docker é•œåƒã€‚</p>\n<h4 id=\"1-ç™»å½•githubåˆ›å»ºä»“åº“\"><a class=\"anchor\" href=\"#1-ç™»å½•githubåˆ›å»ºä»“åº“\">#</a> <strong>1.</strong> ç™»å½• Github åˆ›å»ºä»“åº“</h4>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/vgZkKBC.png\" alt=\"1.png\" /></p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/VnJlhBE.png\" alt=\"2.png\" /></p>\n<h4 id=\"2-åˆ›å»ºdockerfile\"><a class=\"anchor\" href=\"#2-åˆ›å»ºdockerfile\">#</a> <strong>2.</strong> åˆ›å»º Dockerfile</h4>\n<p>ä»“åº“ä¸‹é¢åˆ›å»ºä¸€ä¸ª Dockerfileï¼Œä»¥ ingress-nginx-controller ä¸ºä¾‹ä¸‹çš„ dockerfile å†…å®¹å¦‚ä¸‹ï¼š</p>\n<pre><code>[root@manager ~]# mkdir ingress-nginx-controller\n[root@manager ~]# cd ingress-nginx-controller/\n[root@manager ingress-nginx-controller]# cat Dockerfile \nFROM registry.k8s.io/ingress-nginx/controller:v1.12.1 \n</code></pre>\n<h4 id=\"3-sshå…å¯†ç™»å½•github\"><a class=\"anchor\" href=\"#3-sshå…å¯†ç™»å½•github\">#</a> 3. SSH å…å¯†ç™»å½• GitHub</h4>\n<pre><code>[root@manager ingress-nginx-controller]# ssh-keygen\n[root@manager ingress-nginx-controller]# cat ~/.ssh/id_rsa.pub\n</code></pre>\n<p>è¿›å…¥<em> GitHub</em> çš„ä¸ªäººè®¾ç½®ï¼Œæ‰¾åˆ°ã€<em>SSH and GPG keys</em>ã€‘ï¼Œç„¶åç‚¹å‡»æ–°å¢ SSH Keyï¼Œè¿›å…¥å¦‚ä¸‹ç•Œé¢ï¼Œ<em>title</em> è¾“å…¥ä½ å¯¹äºå½“å‰<em> SSH key</em> çš„å¤‡æ³¨ï¼Œä¸‹é¢çš„<em> key</em> å°±ç²˜è´´ä¸Šä¸€æ­¥ç”Ÿæˆçš„<em> id_rsa.pub</em> å†…çš„å†…å®¹</p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/3djSHRS.png\" alt=\"3.png\" /></p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/8gVcVu4.png\" alt=\"5.png\" /></p>\n<h4 id=\"4-æ¨é€dockerfileè‡³github\"><a class=\"anchor\" href=\"#4-æ¨é€dockerfileè‡³github\">#</a> 4. æ¨é€ Dockerfile è‡³ Github</h4>\n<pre><code>[root@manager ingress-nginx-controller]# yum install git -y\n[root@manager ingress-nginx-controller]# git --version\n[root@manager ingress-nginx-controller]# git config --global user.email &quot;373370405@qq.com&quot;\n[root@manager ingress-nginx-controller]# git config --global color.ui true\n[root@manager ingress-nginx-controller]# git init\n[root@manager ingress-nginx-controller]# git add .\n[root@manager ingress-nginx-controller]# git commit -m &quot;first commit&quot;\n[root@manager ingress-nginx-controller]# git branch -M main\n[root@manager ingress-nginx-controller]# git remote add origin git@github.com:xyapples/ingress-nginx-controller.git   #æ·»åŠ è¿œç¨‹ä»“åº“\n[root@manager ingress-nginx-controller]# git remote -v\n[root@manager ingress-nginx-controller]# git push -u origin main\n[root@manager ingress-nginx-controller]# git remote remove origin  #ç§»é™¤è¿œç¨‹ä»“åº“\n</code></pre>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/N3t49eX.png\" alt=\"6.png\" /></p>\n<h4 id=\"5-ç™»å½•é˜¿é‡Œäº‘åˆ›å»ºé•œåƒä»“åº“\"><a class=\"anchor\" href=\"#5-ç™»å½•é˜¿é‡Œäº‘åˆ›å»ºé•œåƒä»“åº“\">#</a> <strong>5.</strong> ç™»å½•é˜¿é‡Œäº‘åˆ›å»ºé•œåƒä»“åº“</h4>\n<p>ç™»å½•é˜¿é‡Œäº‘é•œåƒï¼š<a href=\"https://cr.console.aliyun.com/%EF%BC%8C%E5%88%9B%E5%BB%BA%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93%EF%BC%9A\">https://cr.console.aliyun.com/ï¼Œåˆ›å»ºé•œåƒä»“åº“ï¼š</a></p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/1zFqa35.png\" alt=\"7.png\" /></p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/PhzoeeT.png\" alt=\"1.png\" /></p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/iYAbB0x.png\" alt=\"2.png\" /></p>\n<h4 id=\"6-æ„å»ºé•œåƒ\"><a class=\"anchor\" href=\"#6-æ„å»ºé•œåƒ\">#</a> 6. æ„å»ºé•œåƒ</h4>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/KD3DI7J.png\" alt=\"3.png\" /></p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/WiwNBRK.png\" alt=\"4.png\" /></p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/155pUrE.png\" alt=\"7.png\" /></p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/155pUrE.png\" alt=\"7.png\" /></p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/AU1371X.png\" alt=\"8.png\" /></p>\n",
            "tags": [
                "Docker"
            ]
        },
        {
            "id": "http://ixuyong.cn/posts/0.html",
            "url": "http://ixuyong.cn/posts/0.html",
            "title": "",
            "date_published": "2025-04-26T08:16:16.895Z",
            "content_html": "<h3 id=\"é˜¿é‡Œäº‘githubæ„å»ºé•œåƒä»“åº“è§£å†³-k8sgcrioè®¿é—®\"><a class=\"anchor\" href=\"#é˜¿é‡Œäº‘githubæ„å»ºé•œåƒä»“åº“è§£å†³-k8sgcrioè®¿é—®\">#</a> é˜¿é‡Œäº‘ + github æ„å»ºé•œåƒä»“åº“è§£å†³ k8s.gcr.io è®¿é—®</h3>\n<p>å‚è€ƒé“¾æ¥ï¼š<em><a href=\"https://blog.csdn.net/sinat_35543900/article/details/103290782\">https://blog.csdn.net/sinat_35543900/article/details/103290782</a></em></p>\n<p><a href=\"http://xn--k8s-xi9d897o.gcr.io/\">ç”±äº k8s.gcr.io/</a> é•œåƒä»“åº“ä½äºå›½å¤–ï¼Œå›½å†…ä½¿ç”¨ kubeadm æ„å»º docker é›†ç¾¤æ—¶æ— æ³•è®¿é—®ç›¸åº”çš„ docker é•œåƒã€‚</p>\n<h4 id=\"1-ç™»å½•githubåˆ›å»ºä»“åº“\"><a class=\"anchor\" href=\"#1-ç™»å½•githubåˆ›å»ºä»“åº“\">#</a> <strong>1.</strong> ç™»å½• Github åˆ›å»ºä»“åº“</h4>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/vgZkKBC.png\" alt=\"1.png\" /></p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/VnJlhBE.png\" alt=\"2.png\" /></p>\n<h4 id=\"2-åˆ›å»ºdockerfile\"><a class=\"anchor\" href=\"#2-åˆ›å»ºdockerfile\">#</a> <strong>2.</strong> åˆ›å»º Dockerfile</h4>\n<p>ä»“åº“ä¸‹é¢åˆ›å»ºä¸€ä¸ª Dockerfileï¼Œä»¥ ingress-nginx-controller ä¸ºä¾‹ä¸‹çš„ dockerfile å†…å®¹å¦‚ä¸‹ï¼š</p>\n<pre><code>[root@manager ~]# mkdir ingress-nginx-controller\n[root@manager ~]# cd ingress-nginx-controller/\n[root@manager ingress-nginx-controller]# cat Dockerfile \nFROM registry.k8s.io/ingress-nginx/controller:v1.12.1 \n</code></pre>\n<h4 id=\"3-sshå…å¯†ç™»å½•github\"><a class=\"anchor\" href=\"#3-sshå…å¯†ç™»å½•github\">#</a> 3. SSH å…å¯†ç™»å½• GitHub</h4>\n<pre><code>[root@manager ingress-nginx-controller]# ssh-keygen\n[root@manager ingress-nginx-controller]# cat ~/.ssh/id_rsa.pub\n</code></pre>\n<p>è¿›å…¥<em> GitHub</em> çš„ä¸ªäººè®¾ç½®ï¼Œæ‰¾åˆ°ã€<em>SSH and GPG keys</em>ã€‘ï¼Œç„¶åç‚¹å‡»æ–°å¢ SSH Keyï¼Œè¿›å…¥å¦‚ä¸‹ç•Œé¢ï¼Œ<em>title</em> è¾“å…¥ä½ å¯¹äºå½“å‰<em> SSH key</em> çš„å¤‡æ³¨ï¼Œä¸‹é¢çš„<em> key</em> å°±ç²˜è´´ä¸Šä¸€æ­¥ç”Ÿæˆçš„<em> id_rsa.pub</em> å†…çš„å†…å®¹</p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/3djSHRS.png\" alt=\"3.png\" /></p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/8gVcVu4.png\" alt=\"5.png\" /></p>\n<h4 id=\"4-æ¨é€dockerfileè‡³github\"><a class=\"anchor\" href=\"#4-æ¨é€dockerfileè‡³github\">#</a> 4. æ¨é€ Dockerfile è‡³ Github</h4>\n<pre><code>[root@manager ingress-nginx-controller]# yum install git -y\n[root@manager ingress-nginx-controller]# git --version\n[root@manager ingress-nginx-controller]# git config --global user.email &quot;373370405@qq.com&quot;\n[root@manager ingress-nginx-controller]# git config --global color.ui true\n[root@manager ingress-nginx-controller]# git init\n[root@manager ingress-nginx-controller]# git add .\n[root@manager ingress-nginx-controller]# git commit -m &quot;first commit&quot;\n[root@manager ingress-nginx-controller]# git branch -M main\n[root@manager ingress-nginx-controller]# git remote add origin git@github.com:xyapples/ingress-nginx-controller.git   #æ·»åŠ è¿œç¨‹ä»“åº“\n[root@manager ingress-nginx-controller]# git remote -v\n[root@manager ingress-nginx-controller]# git push -u origin main\n[root@manager ingress-nginx-controller]# git remote remove origin  #ç§»é™¤è¿œç¨‹ä»“åº“\n</code></pre>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/N3t49eX.png\" alt=\"6.png\" /></p>\n<h4 id=\"5-ç™»å½•é˜¿é‡Œäº‘åˆ›å»ºé•œåƒä»“åº“\"><a class=\"anchor\" href=\"#5-ç™»å½•é˜¿é‡Œäº‘åˆ›å»ºé•œåƒä»“åº“\">#</a> <strong>5.</strong> ç™»å½•é˜¿é‡Œäº‘åˆ›å»ºé•œåƒä»“åº“</h4>\n<p>ç™»å½•é˜¿é‡Œäº‘é•œåƒï¼š<a href=\"https://cr.console.aliyun.com/%EF%BC%8C%E5%88%9B%E5%BB%BA%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93%EF%BC%9A\">https://cr.console.aliyun.com/ï¼Œåˆ›å»ºé•œåƒä»“åº“ï¼š</a></p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/1zFqa35.png\" alt=\"7.png\" /></p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/PhzoeeT.png\" alt=\"1.png\" /></p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/iYAbB0x.png\" alt=\"2.png\" /></p>\n<h4 id=\"6-æ„å»ºé•œåƒ\"><a class=\"anchor\" href=\"#6-æ„å»ºé•œåƒ\">#</a> 6. æ„å»ºé•œåƒ</h4>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/KD3DI7J.png\" alt=\"3.png\" /></p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/WiwNBRK.png\" alt=\"4.png\" /></p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/155pUrE.png\" alt=\"7.png\" /></p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/155pUrE.png\" alt=\"7.png\" /></p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/AU1371X.png\" alt=\"8.png\" /></p>\n",
            "tags": []
        },
        {
            "id": "http://ixuyong.cn/posts/3030097036.html",
            "url": "http://ixuyong.cn/posts/3030097036.html",
            "title": "K8Säº‘åŸç”Ÿå­˜å‚¨Rook-Ceph",
            "date_published": "2025-04-24T13:43:19.000Z",
            "content_html": "<h3 id=\"k8säº‘åŸç”Ÿå­˜å‚¨rook-ceph\"><a class=\"anchor\" href=\"#k8säº‘åŸç”Ÿå­˜å‚¨rook-ceph\">#</a> K8S äº‘åŸç”Ÿå­˜å‚¨ Rook-Ceph</h3>\n<p>Rook æ˜¯ä¸€ä¸ªè‡ªæˆ‘ç®¡ç†çš„åˆ†å¸ƒå¼å­˜å‚¨ç¼–æ’ç³»ç»Ÿï¼Œå®ƒæœ¬èº«å¹¶ä¸æ˜¯å­˜å‚¨ç³»ç»Ÿï¼Œåœ¨å­˜å‚¨å’Œ k8s ä¹‹å‰æ­å»ºäº†ä¸€ä¸ªæ¡¥æ¢ï¼Œä½¿å­˜å‚¨ç³»ç»Ÿçš„æ­å»ºæˆ–è€…ç»´æŠ¤å˜å¾—ç‰¹åˆ«ç®€å•ï¼ŒRook å°†åˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿè½¬å˜ä¸ºè‡ªæˆ‘ç®¡ç†ã€è‡ªæˆ‘æ‰©å±•ã€è‡ªæˆ‘ä¿®å¤çš„å­˜å‚¨æœåŠ¡ã€‚å®ƒè®©ä¸€äº›å­˜å‚¨çš„æ“ä½œï¼Œæ¯”å¦‚éƒ¨ç½²ã€é…ç½®ã€æ‰©å®¹ã€å‡çº§ã€è¿ç§»ã€ç¾éš¾æ¢å¤ã€ç›‘è§†å’Œèµ„æºç®¡ç†å˜å¾—è‡ªåŠ¨åŒ–ï¼Œæ— éœ€äººå·¥å¤„ç†ã€‚å¹¶ä¸” Rook æ”¯æŒ CSIï¼Œå¯ä»¥åˆ©ç”¨ CSI åšä¸€äº› PVC çš„å¿«ç…§ã€æ‰©å®¹ã€å…‹éš†ç­‰æ“ä½œã€‚</p>\n<p><em>æœ¬æ–‡å‡ºè‡ªäºï¼š<a href=\"https://edu.51cto.com/course/23845.html\">https://edu.51cto.com/course/23845.html</a></em></p>\n",
            "tags": [
                "Kubernetes"
            ]
        },
        {
            "id": "http://ixuyong.cn/posts/3890389502.html",
            "url": "http://ixuyong.cn/posts/3890389502.html",
            "title": "K8SæŒä¹…åŒ–å­˜å‚¨NFS+StorageClass",
            "date_published": "2025-04-23T12:08:26.000Z",
            "content_html": "<h3 id=\"k8sæŒä¹…åŒ–å­˜å‚¨nfsstorageclass\"><a class=\"anchor\" href=\"#k8sæŒä¹…åŒ–å­˜å‚¨nfsstorageclass\">#</a> K8S æŒä¹…åŒ–å­˜å‚¨ NFS+StorageClass</h3>\n<h4 id=\"1-æ­å»ºnfsæœåŠ¡å™¨\"><a class=\"anchor\" href=\"#1-æ­å»ºnfsæœåŠ¡å™¨\">#</a> 1. æ­å»º NFS æœåŠ¡å™¨</h4>\n<pre><code>#æ‰€æœ‰K8SèŠ‚ç‚¹å®‰è£…nfs-utils\n[root@k8s-node02 ~]# yum install nfs-utils -y    \n\n#K8S-node02èŠ‚ç‚¹é…ç½®nfsæœåŠ¡\n[root@k8s-node02 ~]# mkdir /data/nfs -p\n[root@k8s-node02 ~]# cat /etc/exports\n/data/nfs 192.168.1.0/24(rw,no_root_squash)\n[root@k8s-node02 ~]# exportfs -arv   #NFSé…ç½®ç”Ÿæ•ˆ \n[root@k8s-node02 ~]# systemctl start nfs-server &amp;&amp; systemctl enable nfs-server &amp;&amp; systemctl status nfs-server\n</code></pre>\n<h4 id=\"2-åˆ›å»ºrbac\"><a class=\"anchor\" href=\"#2-åˆ›å»ºrbac\">#</a> 2.  åˆ›å»º RBAC</h4>\n<pre><code>[root@k8s-node02 ~]# cat 01-rbac.yaml \napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: nfs-client-provisioner\n  # replace with namespace where provisioner is deployed\n  namespace: default\n---\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: nfs-client-provisioner-runner\nrules:\n  - apiGroups: [&quot;&quot;]\n    resources: [&quot;nodes&quot;]\n    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]\n  - apiGroups: [&quot;&quot;]\n    resources: [&quot;persistentvolumes&quot;]\n    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;delete&quot;]\n  - apiGroups: [&quot;&quot;]\n    resources: [&quot;persistentvolumeclaims&quot;]\n    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;update&quot;]\n  - apiGroups: [&quot;storage.k8s.io&quot;]\n    resources: [&quot;storageclasses&quot;]\n    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]\n  - apiGroups: [&quot;&quot;]\n    resources: [&quot;events&quot;]\n    verbs: [&quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: run-nfs-client-provisioner\nsubjects:\n  - kind: ServiceAccount\n    name: nfs-client-provisioner\n    # replace with namespace where provisioner is deployed\n    namespace: default\nroleRef:\n  kind: ClusterRole\n  name: nfs-client-provisioner-runner\n  apiGroup: rbac.authorization.k8s.io\n---\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: leader-locking-nfs-client-provisioner\n  # replace with namespace where provisioner is deployed\n  namespace: default\nrules:\n  - apiGroups: [&quot;&quot;]\n    resources: [&quot;endpoints&quot;]\n    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]\n---\nkind: RoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: leader-locking-nfs-client-provisioner\n  # replace with namespace where provisioner is deployed\n  namespace: default\nsubjects:\n  - kind: ServiceAccount\n    name: nfs-client-provisioner\n    # replace with namespace where provisioner is deployed\n    namespace: default\nroleRef:\n  kind: Role\n  name: leader-locking-nfs-client-provisioner\n  apiGroup: rbac.authorization.k8s.io\n  \n  \n[root@k8s-master01 ~]# kubectl apply -f 01-rbac.yaml \nserviceaccount/nfs-client-provisioner created\nclusterrole.rbac.authorization.k8s.io/nfs-client-provisioner-runner created\nclusterrolebinding.rbac.authorization.k8s.io/run-nfs-client-provisioner created\nrole.rbac.authorization.k8s.io/leader-locking-nfs-client-provisioner created\nrolebinding.rbac.authorization.k8s.io/leader-locking-nfs-client-provisioner created\n</code></pre>\n<h4 id=\"3-åˆ›å»ºnfs-provisioner\"><a class=\"anchor\" href=\"#3-åˆ›å»ºnfs-provisioner\">#</a> 3. åˆ›å»º nfs-provisioner</h4>\n<pre><code>[root@k8s-master01 ~]# cat 02-nfs-provisioner.yaml \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nfs-client-provisioner\n  labels:\n    app: nfs-client-provisioner\n  # replace with namespace where provisioner is deployed\n  namespace: default\nspec:\n  replicas: 1\n  strategy:\n    type: Recreate\n  selector:\n    matchLabels:\n      app: nfs-client-provisioner\n  template:\n    metadata:\n      labels:\n        app: nfs-client-provisioner\n    spec:\n      serviceAccountName: nfs-client-provisioner\n      containers:\n        - name: nfs-client-provisioner\n          image: registry.cn-hangzhou.aliyuncs.com/old_xu/nfs-subdir-external-provisioner:v4.0.2\n          volumeMounts:\n            - name: nfs-client-root\n              mountPath: /persistentvolumes\n          env:\n            - name: PROVISIONER_NAME\t# nfs-provisionerçš„åç§°ï¼Œåç»­storageClassè¦ä¸è¯¥åç§°ä¸€è‡´\n              value: nfzl.com/nfs\n            - name: NFS_SERVER\t\t# NFSæœåŠ¡çš„IPåœ°å€\n              value: 192.168.1.75\n            - name: NFS_PATH\t\t# NFSæœåŠ¡å…±äº«çš„è·¯å¾„\n              value: /data/nfs\n      volumes:\n        - name: nfs-client-root\n          nfs:\n            server: 192.168.1.75\n            path: /data/nfs\n\n[root@k8s-master01 ~]# kubectl apply -f 02-nfs-provisioner.yaml \n[root@k8s-master01 ~]# kubectl get pods\nNAME                                      READY   STATUS    RESTARTS   AGE\nnfs-client-provisioner-6bcc4587f8-zp8qc   1/1     Running   0          17s\n</code></pre>\n<h4 id=\"4-åˆ›å»ºstorageclass\"><a class=\"anchor\" href=\"#4-åˆ›å»ºstorageclass\">#</a> 4. åˆ›å»º StorageClass</h4>\n<pre><code>[root@k8s-master01 ~]# cat 03-storageClass.yaml \napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: nfs-storage \t# pvcç”³è¯·æ—¶éœ€æ˜ç¡®æŒ‡å®šçš„storageClassåç§°\nprovisioner: nfzl.com/nfs        # ä¾›åº”å•†åç§°ï¼Œå¿…é¡»å’Œä¸Šé¢åˆ›å»ºçš„&quot;PROVISIONER_NAME&quot;å˜é‡å€¼è‡´\nparameters:\n  archiveOnDelete: &quot;false&quot;     # å¦‚æœå€¼ä¸ºfalseï¼Œåˆ é™¤PVCåä¹Ÿä¼šåˆ é™¤ç›®å½•å†…å®¹, &quot;true&quot;åˆ™ä¼šå¯¹æ•°æ®è¿›è¡Œä¿ç•™\n</code></pre>\n<h4 id=\"5-åˆ›å»ºpvc\"><a class=\"anchor\" href=\"#5-åˆ›å»ºpvc\">#</a> 5. åˆ›å»º PVC</h4>\n<pre><code>[root@k8s-master01 ~]# cat 04-nginx-pvc.yaml \napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: sc-pvc-001\nspec:\n  storageClassName: &quot;nfs-storage&quot;     # æ˜ç¡®æŒ‡å®šä½¿ç”¨å“ªä¸ªscçš„ä¾›åº”å•†æ¥åˆ›å»ºpv\n  accessModes:\n    - ReadWriteMany\n  resources:\n    requests:\n      storage: 1Gi                      # æ ¹æ®ä¸šåŠ¡å®é™…å¤§å°è¿›è¡Œèµ„æºç”³è¯·\n      \n[root@k8s-master01 ~]# kubectl apply -f 04-nginx-pvc.yaml \n</code></pre>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/fgpaP15.png\" alt=\"1.png\" /></p>\n<h4 id=\"6-æŒ‚è½½pvcæµ‹è¯•\"><a class=\"anchor\" href=\"#6-æŒ‚è½½pvcæµ‹è¯•\">#</a> 6. æŒ‚è½½ PVC æµ‹è¯•</h4>\n<pre><code>[root@k8s-master01 ~]# cat 05-nginx-pod.yaml \napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-sc-001\nspec:\n  containers:\n  - name: nginx-sc-001\n    image: nginx\n    volumeMounts:\n    - name: nginx-page\n      mountPath: /usr/share/nginx/html\n  volumes:\n  - name: nginx-page\n    persistentVolumeClaim:      \n      claimName: sc-pvc-001\n\n[root@k8s-master01 ~]# kubectl apply -f 05-nginx-pod.yaml\n[root@k8s-master01 ~]# kubectl get pods -o wide\nNAME                                      READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATES\nnginx-sc-001                              1/1     Running   0          15s   172.16.85.244   k8s-node01   &lt;none&gt;           &lt;none&gt;\n\n[root@k8s-master01 ~]# curl 172.16.85.244\nhello world\n</code></pre>\n",
            "tags": [
                "Kubernetes"
            ]
        },
        {
            "id": "http://ixuyong.cn/posts/722512536.html",
            "url": "http://ixuyong.cn/posts/722512536.html",
            "title": "K8sç»†ç²’åº¦æƒé™æ§åˆ¶RBAC",
            "date_published": "2025-04-23T12:04:03.000Z",
            "content_html": "<h3 id=\"k8sç»†ç²’åº¦æƒé™æ§åˆ¶rbac\"><a class=\"anchor\" href=\"#k8sç»†ç²’åº¦æƒé™æ§åˆ¶rbac\">#</a> K8s ç»†ç²’åº¦æƒé™æ§åˆ¶ RBAC</h3>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/KCZPPkv.jpeg\" alt=\"rbac.jpg\" /></p>\n<h4 id=\"1-åˆ›å»ºä¸åŒæƒé™çš„clusterrole\"><a class=\"anchor\" href=\"#1-åˆ›å»ºä¸åŒæƒé™çš„clusterrole\">#</a> 1. åˆ›å»ºä¸åŒæƒé™çš„ clusterrole</h4>\n<h5 id=\"11-å‘½ä»¤ç©ºé—´åªè¯»namespace-readonly\"><a class=\"anchor\" href=\"#11-å‘½ä»¤ç©ºé—´åªè¯»namespace-readonly\">#</a> 1.1 å‘½ä»¤ç©ºé—´åªè¯» namespace-readonly</h5>\n<pre><code># cat namespace-readonly.yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: namespace-readonly\nrules:\n- apiGroups:\n  - &quot;&quot;\n  resources:\n  - namespaces\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - metrics.k8s.io\n  resources:\n  - pods\n  verbs:\n  - get\n  - list\n  - watch\n</code></pre>\n<h5 id=\"12-èµ„æºæŸ¥çœ‹resource-readonly\"><a class=\"anchor\" href=\"#12-èµ„æºæŸ¥çœ‹resource-readonly\">#</a> 1.2 èµ„æºæŸ¥çœ‹ resource-readonly</h5>\n<pre><code># cat resource-readonly.yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: resource-readonly\nrules:\n- apiGroups:\n  - &quot;&quot;\n  resources:\n  - configmaps\n  - endpoints\n  - persistentvolumeclaims\n  - pods\n  - replicationcontrollers\n  - replicationcontrollers/scale\n  - serviceaccounts\n  - services\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - &quot;&quot;\n  resources:\n  - bindings\n  - events\n  - limitranges\n  - namespaces/status\n  - pods/log\n  - pods/status\n  - replicationcontrollers/status\n  - resourcequotas\n  - resourcequotas/status\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - &quot;&quot;\n  resources:\n  - namespaces\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - apps\n  resources:\n  - controllerrevisions\n  - daemonsets\n  - deployments\n  - deployments/scale\n  - replicasets\n  - replicasets/scale\n  - statefulsets\n  - statefulsets/scale\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - autoscaling\n  resources:\n  - horizontalpodautoscalers\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - batch\n  resources:\n  - cronjobs\n  - jobs\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - extensions\n  resources:\n  - daemonsets\n  - deployments\n  - deployments/scale\n  - ingresses\n  - networkpolicies\n  - replicasets\n  - replicasets/scale\n  - replicationcontrollers/scale\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - policy\n  resources:\n  - poddisruptionbudgets\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - networking.k8s.io\n  resources:\n  - networkpolicies\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - metrics.k8s.io\n  resources:\n  - pods\n  verbs:\n  - get\n  - list\n  - watch\n</code></pre>\n<h5 id=\"13-podæ—¥å¿—æŸ¥çœ‹\"><a class=\"anchor\" href=\"#13-podæ—¥å¿—æŸ¥çœ‹\">#</a> 1.3 pod æ—¥å¿—æŸ¥çœ‹</h5>\n<pre><code># cat pod-log.yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: pod-log\nrules:\n- apiGroups:\n  - &quot;&quot;\n  resources:\n  - pods\n  - pods/log\n  verbs:\n  - get\n  - list\n  - watch\n</code></pre>\n<h5 id=\"14-podåˆ é™¤\"><a class=\"anchor\" href=\"#14-podåˆ é™¤\">#</a> 1.4 Pod åˆ é™¤</h5>\n<pre><code># cat pod-delete.yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: pod-delete\nrules:\n- apiGroups:\n  - &quot;&quot;\n  resources:\n  - pods\n  verbs:\n  - get\n  - list\n  - delete\n</code></pre>\n<h5 id=\"15-podæ‰§è¡Œ\"><a class=\"anchor\" href=\"#15-podæ‰§è¡Œ\">#</a> 1.5 Pod æ‰§è¡Œ</h5>\n<pre><code># cat pod-exec.yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: pod-exec\nrules:\n- apiGroups:\n  - &quot;&quot;\n  resources:\n  - pods\n  verbs:\n  - get\n  - list\n- apiGroups:\n  - &quot;&quot;\n  resources:\n  - pods/exec\n  verbs:\n  - create\n</code></pre>\n<h5 id=\"16-åˆ›å»ºä¸åŒæƒé™çš„clusterrole\"><a class=\"anchor\" href=\"#16-åˆ›å»ºä¸åŒæƒé™çš„clusterrole\">#</a> 1.6 åˆ›å»ºä¸åŒæƒé™çš„ clusterrole</h5>\n<pre><code>[root@k8s-master01 rbac]# kubectl apply -f .\n</code></pre>\n<h4 id=\"2-åˆ›å»ºserviceaccount\"><a class=\"anchor\" href=\"#2-åˆ›å»ºserviceaccount\">#</a> 2. åˆ›å»º serviceaccount</h4>\n<pre><code># kubectl create ns kube-users\n\n# kubectl create sa test -n kube-users   \n# kubectl create sa dev -n kube-users    \n# kubectl create sa ops -n kube-users    \n\n# kubectl create token test -n kube-users\n# kubectl create token dev -n kube-users\n# kubectl create token ops -n kube-users\n</code></pre>\n<h4 id=\"3-åˆ›å»ºclusterrolebinding\"><a class=\"anchor\" href=\"#3-åˆ›å»ºclusterrolebinding\">#</a> 3. åˆ›å»º ClusterRoleBinding</h4>\n<h5 id=\"31-ç»‘å®šå…¨å±€å‘½åç©ºé—´æŸ¥çœ‹æƒé™\"><a class=\"anchor\" href=\"#31-ç»‘å®šå…¨å±€å‘½åç©ºé—´æŸ¥çœ‹æƒé™\">#</a> 3.1 ç»‘å®šå…¨å±€å‘½åç©ºé—´æŸ¥çœ‹æƒé™</h5>\n<pre><code># cat clusterrolebinding-namespace-readonly.yaml \napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: clusterrolebinding-namespace-readonly \nsubjects:\n- kind: Group\n  name: system:serviceaccounts:kube-users\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: ClusterRole\n  name: namespace-readonly\n  apiGroup: rbac.authorization.k8s.io\n  \n# kubectl apply -f clusterrolebinding-namespace-readonly.yaml\n</code></pre>\n<h5 id=\"32-ç»‘å®šæ—¥å¿—æŸ¥çœ‹æƒé™\"><a class=\"anchor\" href=\"#32-ç»‘å®šæ—¥å¿—æŸ¥çœ‹æƒé™\">#</a> 3.2 ç»‘å®šæ—¥å¿—æŸ¥çœ‹æƒé™</h5>\n<pre><code># kubectl create rolebinding ops-pod-log --clusterrole=pod-log --serviceaccount=kube-users:ops --namespace=projectA\n# kubectl create rolebinding ops-pod-log --clusterrole=pod-log --serviceaccount=kube-users:ops --namespace=projectB\n</code></pre>\n<h5 id=\"33-ç»‘å®šèµ„æºæŸ¥çœ‹æƒé™\"><a class=\"anchor\" href=\"#33-ç»‘å®šèµ„æºæŸ¥çœ‹æƒé™\">#</a> 3.3 ç»‘å®šèµ„æºæŸ¥çœ‹æƒé™</h5>\n<pre><code># kubectl create rolebinding ops-resource-readonly --clusterrole=resource-readonly --serviceaccount=kube-users:ops --namespace=projectA\n# kubectl create rolebinding ops-resource-readonly --clusterrole=resource-readonly --serviceaccount=kube-users:ops --namespace=projectB\n</code></pre>\n<h5 id=\"34-ç»‘å®špodæ‰§è¡Œæƒé™\"><a class=\"anchor\" href=\"#34-ç»‘å®špodæ‰§è¡Œæƒé™\">#</a> 3.4 ç»‘å®š Pod æ‰§è¡Œæƒé™</h5>\n<pre><code># kubectl create rolebinding ops-pod-exec --clusterrole=pod-exec --serviceaccount=kube-users:ops --namespace=projectA\n# kubectl create rolebinding ops-pod-exec --clusterrole=pod-exec --serviceaccount=kube-users:ops --namespace=projectB\n</code></pre>\n<h5 id=\"35-ç»‘å®špodåˆ é™¤æƒé™\"><a class=\"anchor\" href=\"#35-ç»‘å®špodåˆ é™¤æƒé™\">#</a> 3.5 ç»‘å®š Pod åˆ é™¤æƒé™</h5>\n<pre><code># kubectl create rolebinding ops-pod-delete --clusterrole=pod-delete --serviceaccount=kube-users:ops --namespace=projectA\n# kubectl create rolebinding ops-pod-delete --clusterrole=pod-delete --serviceaccount=kube-users:ops --namespace=projectB\n</code></pre>\n<p><em>æœ¬æ–‡å‡ºè‡ªäºï¼š<a href=\"https://edu.51cto.com/course/23845.html\">https://edu.51cto.com/course/23845.html</a></em></p>\n",
            "tags": [
                "Kubernetes"
            ]
        },
        {
            "id": "http://ixuyong.cn/posts/176412055.html",
            "url": "http://ixuyong.cn/posts/176412055.html",
            "title": "K8så‡†å…¥æ§åˆ¶ResourceQuotaã€LimitRangeã€QoSæœåŠ¡è´¨é‡",
            "date_published": "2025-04-23T11:55:19.000Z",
            "content_html": "<h3 id=\"k8så‡†å…¥æ§åˆ¶resourcequota-limitrange-qosæœåŠ¡è´¨é‡\"><a class=\"anchor\" href=\"#k8så‡†å…¥æ§åˆ¶resourcequota-limitrange-qosæœåŠ¡è´¨é‡\">#</a> K8s å‡†å…¥æ§åˆ¶ ResourceQuotaã€LimitRangeã€QoS æœåŠ¡è´¨é‡</h3>\n<h4 id=\"1-resourcequotaé…ç½®è§£æ\"><a class=\"anchor\" href=\"#1-resourcequotaé…ç½®è§£æ\">#</a> 1. ResourceQuota é…ç½®è§£æ</h4>\n<p>ResourceQuotas å®ç°èµ„æºé…é¢ï¼Œé¿å…è¿‡åº¦åˆ›å»ºèµ„æºï¼Œé’ˆå¯¹ namespace è¿›è¡Œé™åˆ¶ã€‚cpu å†…å­˜åˆ™æ˜¯æ ¹æ® pod é…ç½®çš„ resources æ€»é¢è¿›è¡Œé™åˆ¶ï¼Œå¦‚æœæ²¡æœ‰é…ç½® resources å‚æ•°åˆ™æ— æ³•é™åˆ¶ã€‚</p>\n<pre><code>apiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: resourcequota-test\n  namespace: test\n  labels:\n    app: resourcequota\nspec:\n  hard:\n    pods: 3\n    requests.cpu: 3\n    requests.memory: 512Mi\n    limits.cpu: 8\n    limits.memory: 16Gi\n    configmaps: 201\n    requests.storage: 40Gi\n    persistentvolumeclaims: 20\n    replicationcontrollers: 20\n    secrets: 20\n    services: 50\n    services.loadbalancers: &quot;2&quot;\n    services.nodeports: &quot;10&quot;\n</code></pre>\n<ul>\n<li>podsï¼šé™åˆ¶æœ€å¤šå¯åŠ¨ Pod çš„ä¸ªæ•°</li>\n<li>requests.cpuï¼šé™åˆ¶æœ€é«˜ CPU è¯·æ±‚æ•°</li>\n<li>requests.memoryï¼šé™åˆ¶æœ€é«˜å†…å­˜çš„è¯·æ±‚æ•°</li>\n<li>limits.cpuï¼šé™åˆ¶æœ€é«˜ CPU çš„ limit ä¸Šé™</li>\n<li>limits.memoryï¼šé™åˆ¶æœ€é«˜å†…å­˜çš„ limit ä¸Šé™</li>\n<li>servicesï¼šé™åˆ¶ services æ•°é‡</li>\n<li>services.nodeportsï¼šé™åˆ¶ services ä¸­ nodeport ç±»å‹ service æ•°é‡</li>\n<li>services.loadbalancersï¼šé™åˆ¶ services ä¸­ loadbalancers ç±»å‹ service æ•°é‡</li>\n</ul>\n<h5 id=\"11-resourcequotaé…ç½®ç¤ºä¾‹\"><a class=\"anchor\" href=\"#11-resourcequotaé…ç½®ç¤ºä¾‹\">#</a> 1.1 ResourceQuota é…ç½®ç¤ºä¾‹</h5>\n<pre><code>#1.é™åˆ¶testå‘½åç©ºé—´podsæ•°é‡é‡ä¸º3ã€configmapæ•°é‡ä¸º2\n[root@k8s-master01 resourcequota]# cat rq-test.yaml\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: resourcequota-test\n  namespace: test\n  labels:\n    app: resourcequota\nspec:\n  hard:\n    pods: 3\n#    requests.cpu: 3\n#    requests.memory: 512Mi\n#    limits.cpu: 8\n#    limits.memory: 16Gi\n    configmaps: 2\n#    requests.storage: 40Gi\n#    persistentvolumeclaims: 20\n#    replicationcontrollers: 20\n#    secrets: 20\n#    services: 50\n#    services.loadbalancers: &quot;2&quot;\n#    services.nodeports: &quot;10&quot;\n\n#2.testå‘½åç©ºé—´å·²åˆ›å»ºconfigmapæ•°é‡ä¸º1,é™åˆ¶æ•°é‡ä¸º2\n[root@k8s-master01 resourcequota]# kubectl get resourcequota -n test\nNAME                 AGE   REQUEST                      LIMIT\nresourcequota-test   61s   configmaps: 1/2, pods: 0/3  \n\n#3.testå‘½åç©ºé—´åˆ›å»ºç¬¬2ä¸ªconfigmapæ—¶æ­£å¸¸ï¼Œåˆ›å»ºç¬¬3ä¸ªconfigmapæ—¶æŠ¥é”™\n[root@k8s-master01 resourcequota]# kubectl create cm rq-cm1 -n test --from-literal=key1=value1\n[root@k8s-master01 resourcequota]# kubectl create cm rq-cm2 -n test --from-literal=key2=value2\nerror: failed to create configmap: configmaps &quot;rq-cm2&quot; is forbidden: exceeded quota: resourcequota-test, requested: configmaps=1, used: configmaps=2, limited: configmaps=2\n</code></pre>\n<h4 id=\"2-limitrangeé…ç½®è§£æ\"><a class=\"anchor\" href=\"#2-limitrangeé…ç½®è§£æ\">#</a> 2. LimitRange é…ç½®è§£æ</h4>\n<p>è™½ç„¶ ResourceQuota å¯ä»¥å®ç°èµ„æºé…é¢ï¼Œå¯ä»¥é™åˆ¶æŸä¸ªå‘½åç©ºé—´å†…å­˜å’Œ CPUï¼Œä½†æ˜¯å¦‚æœåˆ›å»ºçš„ Pod éƒ½æ²¡æœ‰é…ç½® resources å‚æ•°åˆ™æ— æ³•é™åˆ¶ã€‚å¦‚æœé…ç½® LimitRangeï¼ŒPod æ²¡æœ‰é…ç½® resources æƒ…å†µä¸‹ï¼Œåˆ›å»ºçš„ Pod ä¼šæ ¹æ® LimitRange é…ç½®è‡ªåŠ¨æ·»åŠ  CPU å†…å­˜é…ç½®ï¼Œå¹¶ä¸”å¯ä»¥é™åˆ¶ resources å‚æ•°æœ€å¤§é…ç½®å’Œæœ€å°é…ç½®ï¼ŒLimitRange é’ˆå¯¹ Pod è¿›è¡Œé™åˆ¶ã€‚</p>\n<pre><code>apiVersion: v1\nkind: LimitRange\nmetadata:\n  name: cpu-mem-limit-range\n  namespace: test\nspec:\n  limits:\n  - default:         #é™åˆ¶CPUå†…å­˜é»˜è®¤limitsé…ç½®\n      cpu: 1\n      memory: 512Mi\n    defaultRequest:  #é™åˆ¶CPUå†…å­˜é»˜è®¤requesté…ç½®\n      cpu: 0.5\n      memory: 256Mi\n    max:                #é™åˆ¶CPUå†…å­˜æœ€å¤§é…ç½® \n      cpu: &quot;4000m&quot;\n      memory: 4Gi\n    min:                #é™åˆ¶CPUå†…å­˜æœ€å°é…ç½®\n      cpu: &quot;100m&quot;\n      memory: 100Mi\n    type: Container\n  - type: PersistentVolumeClaim    #é™åˆ¶pvcå¤§å°\n    max:\n      storage: 2Gi\n    min:\n      storage: 1Gi\n</code></pre>\n<ul>\n<li>defaultï¼šé»˜è®¤ limits é…ç½®</li>\n<li>defaultRequestï¼šé»˜è®¤ requests é…ç½®</li>\n</ul>\n<h5 id=\"21-é…ç½®é»˜è®¤çš„requestså’Œlimits\"><a class=\"anchor\" href=\"#21-é…ç½®é»˜è®¤çš„requestså’Œlimits\">#</a> 2.1 é…ç½®é»˜è®¤çš„ requests å’Œ limits</h5>\n<p>Pod æ²¡æœ‰é…ç½® resources æƒ…å†µä¸‹ï¼Œåˆ›å»ºçš„ Pod ä¼šæ ¹æ® LimitRange é…ç½®è‡ªåŠ¨æ·»åŠ  CPU å†…å­˜é…ç½®ã€‚</p>\n<pre><code>#1.åˆ›å»ºLimitRange\n[root@k8s-master01 resourcequota]# cat limitrange.yaml \napiVersion: v1\nkind: LimitRange\nmetadata:\n  name: cpu-mem-limit-range\n  namespace: test\nspec:\n  limits:\n  - default:         #é™åˆ¶CPUå†…å­˜é»˜è®¤limitsé…ç½®\n      cpu: 1\n      memory: 512Mi\n    defaultRequest:  #é™åˆ¶CPUå†…å­˜é»˜è®¤requesté…ç½®\n      cpu: 0.5\n      memory: 256Mi\n    max:                #é™åˆ¶CPUå†…å­˜æœ€å¤§é…ç½® \n      cpu: &quot;4000m&quot;\n      memory: 4Gi\n    min:                #é™åˆ¶CPUå†…å­˜æœ€å°é…ç½®\n      cpu: &quot;100m&quot;\n      memory: 100Mi\n    type: Container\n  - type: PersistentVolumeClaim    #é™åˆ¶pvcå¤§å°\n    max:\n      storage: 2Gi\n    min:\n      storage: 1Gi  \n      \n[root@k8s-master01 resourcequota]# kubectl apply -f limitrange.yaml\n[root@k8s-master01 resourcequota]# kubectl get limitrange -n test\nNAME                  CREATED AT\ncpu-mem-limit-range   2025-04-23T07:55:03Z\n\n#2.åˆ›å»ºdeployment, æŸ¥çœ‹æ˜¯å¦ä¼šæ ¹æ®LimitRangeè‡ªåŠ¨æ·»åŠ CPUå†…å­˜é…ç½®\n[root@k8s-master01 resourcequota]# cat deploy-limitrange.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: deploy-limirange\n  labels:\n    app: deploy-limirange\n  namespace: test\nspec:\n  selector:\n    matchLabels:\n      app: deploy-limirange\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: deploy-limirange\n    spec:\n      restartPolicy: Always\n      containers:\n        - name: deploy-limirange\n          image: nginx\n          imagePullPolicy: IfNotPresent\n\n[root@k8s-master01 resourcequota]# kubectl get pod -n test\nNAME                                READY   STATUS    RESTARTS   AGE\ndeploy-limirange-854c9545ff-grpxr   1/1     Running   0          39s\n[root@k8s-master01 resourcequota]# kubectl get pod -n test -oyaml\n...\n  spec:\n    containers:\n    - image: nginx\n      imagePullPolicy: IfNotPresent\n      name: deploy-limirange\n      resources:\n        limits:\n          cpu: &quot;1&quot;\n          memory: 512Mi\n        requests:\n          cpu: 500m\n          memory: 256Mi\n...\n</code></pre>\n<h5 id=\"22-é™åˆ¶requestså’ŒlimitsèŒƒå›´\"><a class=\"anchor\" href=\"#22-é™åˆ¶requestså’ŒlimitsèŒƒå›´\">#</a> 2.2 é™åˆ¶ requests å’Œ limits èŒƒå›´</h5>\n<pre><code>#1.åˆ›å»ºLimitRange\n[root@k8s-master01 resourcequota]# cat limitrange.yaml \napiVersion: v1\nkind: LimitRange\nmetadata:\n  name: cpu-mem-limit-range\n  namespace: test\nspec:\n  limits:\n  - default:         #é™åˆ¶CPUå†…å­˜é»˜è®¤limitsé…ç½®\n      cpu: 1\n      memory: 512Mi\n    defaultRequest:  #é™åˆ¶CPUå†…å­˜é»˜è®¤requesté…ç½®\n      cpu: 0.5\n      memory: 256Mi\n    max:                #é™åˆ¶CPUå†…å­˜æœ€å¤§é…ç½® \n      cpu: &quot;4000m&quot;\n      memory: 4Gi\n    min:                #é™åˆ¶CPUå†…å­˜æœ€å°é…ç½®\n      cpu: &quot;100m&quot;\n      memory: 100Mi\n    type: Container\n  - type: PersistentVolumeClaim    #é™åˆ¶pvcå¤§å°\n    max:\n      storage: 2Gi\n    min:\n      storage: 1Gi  \n\n#2.åˆ›å»ºdeployment, CPUå†…å­˜limitså’Œrequestsé«˜äº/ä½äºLimitRangeCPUå†…å­˜maxã€miné…ç½®\n[root@k8s-master01 resourcequota]# cat deploy-limitrange.yaml \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: deploy-limirange\n  labels:\n    app: deploy-limirange\n  namespace: test\nspec:\n  selector:\n    matchLabels:\n      app: deploy-limirange\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: deploy-limirange\n    spec:\n      restartPolicy: Always\n      containers:\n        - name: deploy-limirange\n          image: nginx\n          imagePullPolicy: IfNotPresent\n          resources:\n            limits:\n              memory: 8096Mi\n              cpu: 5\n            requests:\n              memory: 64Mi\n              cpu: 10m\n\n#3.ç”±äºåˆ›å»ºdeployment, CPUå†…å­˜limitså’Œrequestsé«˜äº/ä½äºLimitRangeCPUå†…å­˜maxã€miné…ç½®ï¼Œpodæ²¡æœ‰åˆ›å»º\n[root@k8s-master01 resourcequota]# kubectl create -f deploy-limitrange.yaml \n\n[root@k8s-master01 resourcequota]# kubectl get deploy deploy-limirange -n test\nNAME               READY   UP-TO-DATE   AVAILABLE   AGE\ndeploy-limirange   0/1     0            0           2m7s\n[root@k8s-master01 resourcequota]# kubectl get pods -n test\n\n[root@k8s-master01 resourcequota]# kubectl describe rs deploy-limirange-54c5d69b4b -n test\nName:           deploy-limirange-54c5d69b4b\nNamespace:      test\nSelector:       app=deploy-limirange,pod-template-hash=54c5d69b4b\nLabels:         app=deploy-limirange\n                pod-template-hash=54c5d69b4b\nAnnotations:    deployment.kubernetes.io/desired-replicas: 1\n                deployment.kubernetes.io/max-replicas: 2\n                deployment.kubernetes.io/revision: 1\nControlled By:  Deployment/deploy-limirange\nReplicas:       0 current / 1 desired\nPods Status:    0 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=deploy-limirange\n           pod-template-hash=54c5d69b4b\n  Containers:\n   deploy-limirange:\n    Image:      nginx\n    Port:       &lt;none&gt;\n    Host Port:  &lt;none&gt;\n    Limits:\n      cpu:     5\n      memory:  8096Mi\n    Requests:\n      cpu:         10m\n      memory:      64Mi\n    Environment:   &lt;none&gt;\n    Mounts:        &lt;none&gt;\n  Volumes:         &lt;none&gt;\n  Node-Selectors:  &lt;none&gt;\n  Tolerations:     &lt;none&gt;\nConditions:\n  Type             Status  Reason\n  ----             ------  ------\n  ReplicaFailure   True    FailedCreate\nEvents:\n  Type     Reason        Age                 From                   Message\n  ----     ------        ----                ----                   -------\n  Warning  FailedCreate  3m8s                replicaset-controller  Error creating: pods &quot;deploy-limirange-54c5d69b4b-zxhzk&quot; is forbidden: [minimum cpu usage per Container is 100m, but request is 10m, minimum memory usage per Container is 100Mi, but request is 64Mi, maximum cpu usage per Container is 4, but limit is 5, maximum memory usage per Container is 4Gi, but limit is 8096Mi]\n</code></pre>\n<h5 id=\"23-é™åˆ¶å­˜å‚¨ç©ºé—´å¤§å°\"><a class=\"anchor\" href=\"#23-é™åˆ¶å­˜å‚¨ç©ºé—´å¤§å°\">#</a> 2.3 é™åˆ¶å­˜å‚¨ç©ºé—´å¤§å°</h5>\n<pre><code>#1.åˆ›å»ºLimitRange\n[root@k8s-master01 resourcequota]# cat limitrange.yaml \napiVersion: v1\nkind: LimitRange\nmetadata:\n  name: cpu-mem-limit-range\n  namespace: test\nspec:\n  limits:\n  - default:         #é™åˆ¶CPUå†…å­˜é»˜è®¤limitsé…ç½®\n      cpu: 1\n      memory: 512Mi\n    defaultRequest:  #é™åˆ¶CPUå†…å­˜é»˜è®¤requesté…ç½®\n      cpu: 0.5\n      memory: 256Mi\n    max:                #é™åˆ¶CPUå†…å­˜æœ€å¤§é…ç½® \n      cpu: &quot;4000m&quot;\n      memory: 4Gi\n    min:                #é™åˆ¶CPUå†…å­˜æœ€å°é…ç½®\n      cpu: &quot;100m&quot;\n      memory: 100Mi\n    type: Container\n  - type: PersistentVolumeClaim    #é™åˆ¶pvcå¤§å°\n    max:\n      storage: 2Gi\n    min:\n      storage: 1Gi  \n  \n#2.ç”±äºåˆ›å»ºçš„pvcå¤§äº2Gï¼Œæ‰€ä»¥æŠ¥é”™  \n[root@k8s-master01 ~]# cat pvc.yaml \napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: sc-pvc-001\nspec:\n  storageClassName: &quot;nfs-storage&quot;     # æ˜ç¡®æŒ‡å®šä½¿ç”¨å“ªä¸ªscçš„ä¾›åº”å•†æ¥åˆ›å»ºpv\n  accessModes:\n    - ReadWriteMany\n  resources:\n    requests:\n      storage: 3Gi                      # æ ¹æ®ä¸šåŠ¡å®é™…å¤§å°è¿›è¡Œèµ„æºç”³è¯·  \n[root@k8s-master01 ~]# kubectl create -f pvc.yaml -n test\nError from server (Forbidden): error when creating &quot;pvc.yaml&quot;: persistentvolumeclaims &quot;sc-pvc-001&quot; is forbidden: maximum storage usage per PersistentVolumeClaim is 2Gi, but request is 3Gi\n</code></pre>\n<h4 id=\"3-æœåŠ¡è´¨é‡-qos\"><a class=\"anchor\" href=\"#3-æœåŠ¡è´¨é‡-qos\">#</a> 3. æœåŠ¡è´¨é‡ QoS</h4>\n<ul>\n<li>Guaranteedï¼šæœ€é«˜æœåŠ¡è´¨é‡ï¼Œå½“å®¿ä¸»æœºå†…å­˜ä¸å¤Ÿæ—¶ï¼Œä¼šå…ˆ kill æ‰ QoS ä¸º BestEffort å’Œ Burstable çš„ Podï¼Œå¦‚æœå†…å­˜è¿˜æ˜¯ä¸å¤Ÿï¼Œæ‰ä¼š kill æ‰ QoS ä¸º Guaranteedï¼Œè¯¥çº§åˆ« Pod çš„èµ„æºå ç”¨é‡ä¸€èˆ¬æ¯”è¾ƒæ˜ç¡®ï¼Œå³ requests çš„ cpu å’Œ memory å’Œ limits çš„ cpu å’Œ memory é…ç½®çš„ä¸€è‡´ã€‚</li>\n<li>Burstableï¼š æœåŠ¡è´¨é‡ä½äº Guaranteedï¼Œå½“å®¿ä¸»æœºå†…å­˜ä¸å¤Ÿæ—¶ï¼Œä¼šå…ˆ kill æ‰ QoS ä¸º BestEffort çš„ Podï¼Œå¦‚æœå†…å­˜è¿˜æ˜¯ä¸å¤Ÿä¹‹åå°±ä¼š kill æ‰ QoS çº§åˆ«ä¸º Burstable çš„ Podï¼Œç”¨æ¥ä¿è¯ QoS è´¨é‡ä¸º Guaranteed çš„ Podï¼Œè¯¥çº§åˆ« Pod ä¸€èˆ¬çŸ¥é“æœ€å°èµ„æºä½¿ç”¨é‡ï¼Œä½†æ˜¯å½“æœºå™¨èµ„æºå……è¶³æ—¶ï¼Œè¿˜æ˜¯æƒ³å°½å¯èƒ½çš„ä½¿ç”¨æ›´å¤šçš„èµ„æºï¼Œå³ limits å­—æ®µçš„ cpu å’Œ memory å¤§äº requests çš„ cpu å’Œ memory çš„é…ç½®ã€‚</li>\n<li>BestEffortï¼šå°½åŠ›è€Œä¸ºï¼Œå½“å®¿ä¸»æœºå†…å­˜ä¸å¤Ÿæ—¶ï¼Œé¦–å…ˆ kill çš„å°±æ˜¯è¯¥ QoS çš„ Podï¼Œç”¨ä»¥ä¿è¯ Burstable å’Œ Guaranteed çº§åˆ«çš„ Pod æ­£å¸¸è¿è¡Œã€‚</li>\n</ul>\n<h5 id=\"31-å®ç°qosä¸ºguaranteedçš„pod\"><a class=\"anchor\" href=\"#31-å®ç°qosä¸ºguaranteedçš„pod\">#</a> 3.1 å®ç° QoS ä¸º Guaranteed çš„ Pod</h5>\n<ol>\n<li>\n<p>Pod ä¸­çš„æ¯ä¸ªå®¹å™¨å¿…é¡»æŒ‡å®š limits.memory å’Œ requests.memoryï¼Œå¹¶ä¸”ä¸¤è€…éœ€è¦ç›¸ç­‰ï¼›</p>\n</li>\n<li>\n<p>Pod ä¸­çš„æ¯ä¸ªå®¹å™¨å¿…é¡»æŒ‡å®š limits.cpu å’Œ limits.memoryï¼Œå¹¶ä¸”ä¸¤è€…éœ€è¦ç›¸ç­‰ã€‚</p>\n</li>\n</ol>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deploy\n  labels:\n    app: nginx-deploy\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n    spec:\n      restartPolicy: Always\n      containers:\n        - name: nginx-deploy\n          image: nginx\n          imagePullPolicy: IfNotPresent\n          resources:\n            limits:\n              memory: 1024Mi\n              cpu: 1\n            requests:\n              memory: 1024Mi\n              cpu: 1\n</code></pre>\n<h5 id=\"32-å®ç°qosä¸ºburstableçš„pod\"><a class=\"anchor\" href=\"#32-å®ç°qosä¸ºburstableçš„pod\">#</a> 3.2 å®ç° QoS ä¸º Burstable çš„ Pod</h5>\n<ol>\n<li>\n<p>Pod ä¸ç¬¦åˆ Guaranteed çš„é…ç½®è¦æ±‚ï¼›</p>\n</li>\n<li>\n<p>Pod ä¸­è‡³å°‘æœ‰ä¸€ä¸ªå®¹å™¨é…ç½®äº† requests.cpu æˆ– requests.memoryã€‚</p>\n</li>\n</ol>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deploy\n  labels:\n    app: nginx-deploy\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n    spec:\n      restartPolicy: Always\n      containers:\n        - name: nginx-deploy\n          image: nginx\n          imagePullPolicy: IfNotPresent\n          resources:\n            limits:\n              memory: 1024Mi\n              cpu: 1\n            requests:\n              memory: 128Mi\n              cpu: 100m\n</code></pre>\n<h5 id=\"33-å®ç°qosä¸ºbesteffortçš„pod\"><a class=\"anchor\" href=\"#33-å®ç°qosä¸ºbesteffortçš„pod\">#</a> 3.3 å®ç° QoS ä¸º BestEffort çš„ Pod</h5>\n<ol>\n<li>ä¸è®¾ç½® resources å‚æ•°</li>\n</ol>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deploy\n  labels:\n    app: nginx-deploy\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n    spec:\n      restartPolicy: Always\n      containers:\n        - name: nginx-deploy\n          image: nginx\n          imagePullPolicy: IfNotPresent\n</code></pre>\n<p><em>æœ¬æ–‡å‡ºè‡ªäºï¼š<a href=\"https://edu.51cto.com/course/23845.html\">https://edu.51cto.com/course/23845.html</a></em></p>\n",
            "tags": [
                "Kubernetes"
            ]
        },
        {
            "id": "http://ixuyong.cn/posts/312010518.html",
            "url": "http://ixuyong.cn/posts/312010518.html",
            "title": "K8säº²å’ŒåŠ›Affinity",
            "date_published": "2025-04-20T09:59:58.000Z",
            "content_html": "<h3 id=\"k8säº²å’ŒåŠ›affinity\"><a class=\"anchor\" href=\"#k8säº²å’ŒåŠ›affinity\">#</a> K8s äº²å’ŒåŠ› Affinity</h3>\n<p>Pod å’ŒèŠ‚ç‚¹ä¹‹é—´çš„å…³ç³»ï¼š</p>\n<ul>\n<li>æŸäº› Pod ä¼˜å…ˆé€‰æ‹©æœ‰ ssd=true æ ‡ç­¾çš„èŠ‚ç‚¹ï¼Œå¦‚æœæ²¡æœ‰åœ¨è€ƒè™‘éƒ¨ç½²åˆ°å…¶å®ƒèŠ‚ç‚¹ï¼›</li>\n<li>æŸäº› Pod éœ€è¦éƒ¨ç½²åœ¨ ssd=true å’Œ type=physical çš„èŠ‚ç‚¹ä¸Šï¼Œä½†æ˜¯ä¼˜å…ˆéƒ¨ç½²åœ¨ ssd=true çš„èŠ‚ç‚¹ä¸Šã€‚</li>\n</ul>\n<p>Pod å’Œ Pod ä¹‹é—´çš„å…³ç³»ï¼š</p>\n<ul>\n<li>åŒä¸€ä¸ªåº”ç”¨çš„ Pod ä¸åŒçš„å‰¯æœ¬æˆ–è€…åŒä¸€ä¸ªé¡¹ç›®çš„åº”ç”¨å°½é‡æˆ–å¿…é¡»ä¸éƒ¨ç½²åœ¨åŒä¸€ä¸ªèŠ‚ç‚¹æˆ–è€…ç¬¦åˆæŸä¸ªæ ‡ç­¾çš„ä¸€ç±»èŠ‚ç‚¹ä¸Šæˆ–è€…ä¸åŒçš„åŒºåŸŸï¼›</li>\n<li>ç›¸äº’ä¾èµ–çš„ä¸¤ä¸ª Pod å°½é‡æˆ–å¿…é¡»éƒ¨ç½²åœ¨åŒä¸€ä¸ªèŠ‚ç‚¹ä¸Šæˆ–è€…åŒä¸€ä¸ªåŸŸå†…ã€‚</li>\n</ul>\n<h4 id=\"1-affinityåˆ†ç±»\"><a class=\"anchor\" href=\"#1-affinityåˆ†ç±»\">#</a> 1. Affinity åˆ†ç±»</h4>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/hTd0wmD.png\" alt=\"1.png\" /></p>\n<h4 id=\"2-èŠ‚ç‚¹äº²å’ŒåŠ›é…ç½®è¯¦è§£\"><a class=\"anchor\" href=\"#2-èŠ‚ç‚¹äº²å’ŒåŠ›é…ç½®è¯¦è§£\">#</a> 2. èŠ‚ç‚¹äº²å’ŒåŠ›é…ç½®è¯¦è§£</h4>\n<h5 id=\"21-ç¡¬äº²å’ŒåŠ›required\"><a class=\"anchor\" href=\"#21-ç¡¬äº²å’ŒåŠ›required\">#</a> 2.1 ç¡¬äº²å’ŒåŠ› required</h5>\n<pre><code># cat nginx-deploy.yaml \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deploy\n  labels:\n    app: nginx-deploy\n  annotations:\n    app: nginx-deploy\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  replicas: 5\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n              - matchExpressions:\n                  - key: kubernetes.io/hostname\n                    operator: In\n                    values:\n                      - k8s-node01\n                      - k8s-node02\n      restartPolicy: Always\n      containers:\n        - name: nginx-deploy\n          image: nginx:latest\n          imagePullPolicy: IfNotPresent\n          resources:\n            limits:\n              memory: 1024Mi\n              cpu: 1\n            requests:\n              memory: 128Mi\n              cpu: 100m\n</code></pre>\n<ul>\n<li>requiredDuringSchedulingIgnoredDuringExecutionï¼šç¡¬äº²å’ŒåŠ›é…ç½®</li>\n<li>nodeSelectorTermsï¼šèŠ‚ç‚¹é€‰æ‹©å™¨é…ç½®ï¼Œå¯ä»¥é…ç½®å¤šä¸ª matchExpressionsï¼ˆæ»¡è¶³å…¶ä¸€å³å¯ï¼‰</li>\n<li>matchExpressionsï¼šmatchExpressions ä¸‹å¯ä»¥é…ç½®å¤šä¸ª keyã€valuesï¼ˆéƒ½éœ€è¦æ»¡è¶³ï¼‰ï¼Œå…¶ä¸­ values å¯ä»¥é…ç½®å¤šä¸ªï¼ˆæ»¡è¶³å…¶ä¸€å³å¯ï¼‰</li>\n<li>operatorï¼š\n<ul>\n<li>IN ç›¸å½“äº key = value çš„å½¢å¼ï¼Œ<strong>NotIn ç›¸å½“äº key!=value çš„å½¢å¼ (åäº²å’ŒåŠ›)</strong></li>\n<li>Exists: èŠ‚ç‚¹å­˜åœ¨ label çš„ key ä¸ºæŒ‡å®šçš„å€¼å³å¯ï¼Œä¸èƒ½é…ç½® values å­—æ®µ</li>\n<li>DoesNotExist: èŠ‚ç‚¹ä¸å­˜åœ¨ label çš„ key ä¸ºæŒ‡å®šçš„å€¼å³å¯ï¼Œä¸èƒ½é…ç½® values å­—æ®µ</li>\n<li>Gtï¼šå¤§äº value æŒ‡å®šçš„å€¼</li>\n<li>Ltï¼šå°äº value æŒ‡å®šçš„å€¼</li>\n</ul>\n</li>\n</ul>\n<h5 id=\"22-è½¯äº²å’ŒåŠ›preferred\"><a class=\"anchor\" href=\"#22-è½¯äº²å’ŒåŠ›preferred\">#</a> 2.2 è½¯äº²å’ŒåŠ› preferred</h5>\n<pre><code># cat nginx-deploy.yaml \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deploy\n  labels:\n    app: nginx-deploy\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  replicas: 6\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n            - weight: 100\n              preference:\n                matchExpressions:\n                  - key: ssd\n                    operator: In\n                    values:\n                      - 'true'\n            - weight: 50\n              preference:\n                matchExpressions:\n                  - key: kubernetes.io/hostname\n                    operator: In\n                    values:\n                      - k8s-master01\n      restartPolicy: Always\n      containers:\n        - name: nginx-deploy\n          image: nginx\n          imagePullPolicy: IfNotPresent\n          resources:\n            limits:\n              memory: 1024Mi\n              cpu: 1\n            requests:\n              memory: 128Mi\n              cpu: 100m\n</code></pre>\n<ul>\n<li>preferredDuringSchedulingIgnoredDuringExecutionï¼šè½¯äº²å’ŒåŠ›é…ç½®</li>\n<li>weightï¼šè½¯äº²å’ŒåŠ›çš„æƒé‡ï¼Œæƒé‡è¶Šé«˜ä¼˜å…ˆçº§è¶Šå¤§ï¼ŒèŒƒå›´ 1-100</li>\n<li>matchExpressionsï¼šmatchExpressions ä¸‹å¯ä»¥é…ç½®å¤šä¸ª keyã€valuesï¼ˆéƒ½éœ€è¦æ»¡è¶³ï¼‰ï¼Œå…¶ä¸­ values å¯ä»¥é…ç½®å¤šä¸ªï¼ˆæ»¡è¶³å…¶ä¸€å³å¯ï¼‰</li>\n<li>operatorï¼š\n<ul>\n<li>IN ç›¸å½“äº key = value çš„å½¢å¼ï¼Œ<strong>NotIn ç›¸å½“äº key!=value çš„å½¢å¼ (åäº²å’ŒåŠ›)</strong></li>\n<li>Exists: èŠ‚ç‚¹å­˜åœ¨ label çš„ key ä¸ºæŒ‡å®šçš„å€¼å³å¯ï¼Œä¸èƒ½é…ç½® values å­—æ®µ</li>\n<li>DoesNotExist: èŠ‚ç‚¹ä¸å­˜åœ¨ label çš„ key ä¸ºæŒ‡å®šçš„å€¼å³å¯ï¼Œä¸èƒ½é…ç½® values å­—æ®µ</li>\n<li>Gtï¼šå¤§äº value æŒ‡å®šçš„å€¼</li>\n<li>Ltï¼šå°äº value æŒ‡å®šçš„å€¼</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"3-podäº²å’ŒåŠ›è¯¦è§£\"><a class=\"anchor\" href=\"#3-podäº²å’ŒåŠ›è¯¦è§£\">#</a> 3. Pod äº²å’ŒåŠ›è¯¦è§£</h4>\n<pre><code>[root@k8s-master01 ~]# cat nginx-deploy.yaml \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: nginx-deploy\n  name: nginx-deploy\nspec:\n  replicas: 4\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n    spec:\n      affinity:              \n        podAntiAffinity:   #podç¡¬åäº²å’ŒåŠ›\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: app\n                operator: In\n                values:\n                - nginx-deploy\n            topologyKey: kubernetes.io/hostname\n        podAntiAffinity:       #podè½¯åäº²å’ŒåŠ›\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - nginx-deploy\n              namespaces:     #å’Œå“ªä¸ªå‘½åç©ºé—´çš„Podè¿›è¡ŒåŒ¹é…ï¼Œä¸ºç©ºä¸ºå½“å‰å‘½åç©ºé—´\n              - default\n              topologyKey: kubernetes.io/hostname\n</code></pre>\n<ul>\n<li>\n<p>labelSelectorï¼šPod é€‰æ‹©å™¨é…ç½®ï¼Œå¯ä»¥é…ç½®å¤šä¸ª</p>\n</li>\n<li>\n<p>matchExpressionsï¼šmatchExpressions ä¸‹å¯ä»¥é…ç½®å¤šä¸ª keyã€valuesï¼ˆéƒ½éœ€è¦æ»¡è¶³ï¼‰ï¼Œå…¶ä¸­ values å¯ä»¥é…ç½®å¤šä¸ªï¼ˆæ»¡è¶³å…¶ä¸€å³å¯ï¼‰</p>\n</li>\n<li>\n<p>topologyKeyï¼šåŒ¹é…çš„æ‹“æ‰‘åŸŸçš„ keyï¼Œä¹Ÿå°±æ˜¯èŠ‚ç‚¹ä¸Š label çš„ keyï¼Œkey å’Œ value ç›¸åŒçš„ä¸ºåŒä¸€ä¸ªåŸŸï¼Œå¯ä»¥ç”¨äºæ ‡æ³¨ä¸åŒçš„æœºæˆ¿å’Œåœ°åŒº</p>\n</li>\n<li>\n<p>Namespaces: å’Œå“ªä¸ªå‘½åç©ºé—´çš„ Pod è¿›è¡ŒåŒ¹é…ï¼Œä¸ºç©ºä¸ºå½“å‰å‘½åç©ºé—´</p>\n</li>\n<li>\n<p>operatorï¼šé…ç½®å’ŒèŠ‚ç‚¹äº²å’ŒåŠ›ä¸€è‡´ï¼Œä½†æ˜¯æ²¡æœ‰ Gt å’Œ Lt</p>\n<ul>\n<li>\n<p>IN ç›¸å½“äº key = value çš„å½¢å¼ï¼›</p>\n</li>\n<li>\n<p>Exists: èŠ‚ç‚¹å­˜åœ¨ label çš„ key ä¸ºæŒ‡å®šçš„å€¼å³å¯ï¼Œä¸èƒ½é…ç½® values å­—æ®µï¼›</p>\n</li>\n<li>\n<p>DoesNotExist: èŠ‚ç‚¹ä¸å­˜åœ¨ label çš„ key ä¸ºæŒ‡å®šçš„å€¼å³å¯ï¼Œä¸èƒ½é…ç½® values å­—æ®µ</p>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"4-èŠ‚ç‚¹äº²å’ŒåŠ›é…ç½®ç¤ºä¾‹\"><a class=\"anchor\" href=\"#4-èŠ‚ç‚¹äº²å’ŒåŠ›é…ç½®ç¤ºä¾‹\">#</a> 4. èŠ‚ç‚¹äº²å’ŒåŠ›é…ç½®ç¤ºä¾‹</h4>\n<p>Pod å°½é‡éƒ¨ç½²åœ¨ ssd=true å’Œ type=physical çš„èŠ‚ç‚¹ä¸Šï¼Œä½†æ˜¯ä¼˜å…ˆéƒ¨ç½²åœ¨ ssd=true çš„èŠ‚ç‚¹ä¸Šï¼Œä¸èƒ½éƒ¨ç½² label ä¸º gpu=true çš„èŠ‚ç‚¹ã€‚</p>\n<pre><code>[root@k8s-master01 ~]# kubectl label nodes k8s-node01 ssd=true\n[root@k8s-master01 ~]# kubectl label nodes k8s-master01 ssd=true\n[root@k8s-master01 ~]# kubectl label nodes k8s-master01 gpu=true\n[root@k8s-master01 ~]# kubectl label nodes k8s-node02 type=physical\n\n[root@k8s-master01 ~]# cat nginx-deploy.yaml \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deploy\n  labels:\n    app: nginx-deploy\n  annotations:\n    app: nginx-deploy\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  replicas: 5\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n      annotations:\n        app: nginx-deploy\n    spec:\n      affinity:\n        nodeAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n            - weight: 100\n              preference:\n                matchExpressions:\n                  - key: ssd\n                    operator: In\n                    values:\n                      - 'true'\n                  - key: gpu\n                    operator: NotIn\n                    values:\n                      - 'true'\n            - weight: 50\n              preference:\n                matchExpressions:\n                  - key: type\n                    operator: In\n                    values:\n                      - physical\n      restartPolicy: Always\n      containers:\n        - name: nginx-deploy\n          image: nginx\n          imagePullPolicy: IfNotPresent\n          resources:\n            limits:\n              memory: 1024Mi\n              cpu: 1\n            requests:\n              memory: 128Mi\n              cpu: 100m\n          volumeMounts:\n          - name: tz-config\n            mountPath: /usr/share/zoneinfo/Asia/Shanghai\n          - name: tz-config\n            mountPath: /etc/localtime\n          - name: timezone\n            mountPath: /etc/timezone\n      volumes:\n      - name: tz-config\n        hostPath:\n          path: /usr/share/zoneinfo/Asia/Shanghai\n          type: &quot;&quot;\n      - name: timezone\n        hostPath:\n          path: /etc/timezone\n          type: &quot;&quot;\n\n\n[root@k8s-master01 ~]# kubectl apply -f nginx-deploy.yaml \n[root@k8s-master01 ~]# kubectl get pods -o wide\nNAME                          READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATES\nnginx-deploy-7d65fbdf-2b4jr   1/1     Running   0          5s    172.16.85.236   k8s-node01   &lt;none&gt;           &lt;none&gt;\nnginx-deploy-7d65fbdf-jjzwr   1/1     Running   0          5s    172.16.58.251   k8s-node02   &lt;none&gt;           &lt;none&gt;\nnginx-deploy-7d65fbdf-kx5lm   1/1     Running   0          5s    172.16.85.237   k8s-node01   &lt;none&gt;           &lt;none&gt;\nnginx-deploy-7d65fbdf-lrmcg   1/1     Running   0          5s    172.16.85.238   k8s-node01   &lt;none&gt;           &lt;none&gt;\nnginx-deploy-7d65fbdf-n6mlp   1/1     Running   0          5s    172.16.58.250   k8s-node02   &lt;none&gt;           &lt;none&gt;\n</code></pre>\n<h4 id=\"5-podäº²å’ŒåŠ›-åäº²å’ŒåŠ›é…ç½®ç¤ºä¾‹\"><a class=\"anchor\" href=\"#5-podäº²å’ŒåŠ›-åäº²å’ŒåŠ›é…ç½®ç¤ºä¾‹\">#</a> 5. Pod äº²å’ŒåŠ›ã€åäº²å’ŒåŠ›é…ç½®ç¤ºä¾‹</h4>\n<h5 id=\"51-podåäº²å’ŒåŠ›required\"><a class=\"anchor\" href=\"#51-podåäº²å’ŒåŠ›required\">#</a> 5.1 Pod åäº²å’ŒåŠ› required</h5>\n<p>åŒä¸€ä¸ªåº”ç”¨éƒ¨ç½²åœ¨ä¸åŒçš„å®¿ä¸»æœº</p>\n<pre><code>#1.èŠ‚ç‚¹å­˜åœ¨æ±¡ç‚¹podæ— æ³•è°ƒåº¦è‡³è¯¥èŠ‚ç‚¹\n# kubectl describe nodes|grep -i taint\nTaints:             &lt;none&gt;\nTaints:             &lt;none&gt;\nTaints:             &lt;none&gt;\nTaints:             &lt;none&gt;\nTaints:             &lt;none&gt;\n\n#2.podåäº²å’ŒåŠ›required\n# cat nginx-deploy.yaml \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deploy\n  labels:\n    app: nginx-deploy\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  replicas: 5\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            - labelSelector:\n                matchExpressions:\n                  - key: app\n                    operator: In\n                    values:\n                      - nginx-deploy\n              topologyKey: kubernetes.io/hostname\n      restartPolicy: Always\n      containers:\n        - name: nginx-deploy\n          image: nginx\n          imagePullPolicy: IfNotPresent\n          resources:\n            limits:\n              memory: 1024Mi\n              cpu: 1\n            requests:\n              memory: 128Mi\n              cpu: 100m\n          volumeMounts:\n          - name: tz-config\n            mountPath: /usr/share/zoneinfo/Asia/Shanghai\n          - name: tz-config\n            mountPath: /etc/localtime\n          - name: timezone\n            mountPath: /etc/timezone\n      volumes:\n      - name: tz-config\n        hostPath:\n          path: /usr/share/zoneinfo/Asia/Shanghai\n          type: &quot;&quot;\n      - name: timezone\n        hostPath:\n          path: /etc/timezone\n          type: &quot;&quot;\n\n#3.éƒ¨ç½²deployment\n[root@k8s-master01 ~]# kubectl apply -f nginx-deploy.yaml \n[root@k8s-master01 ~]# kubectl get pods -o wide\nNAME                            READY   STATUS    RESTARTS   AGE   IP               NODE           NOMINATED NODE   READINESS GATES\nnginx-deploy-5787887b6f-4654b   1/1     Running   0          4s    172.16.85.234    k8s-node01     &lt;none&gt;           &lt;none&gt;\nnginx-deploy-5787887b6f-8mq7s   1/1     Running   0          4s    172.16.122.152   k8s-master02   &lt;none&gt;           &lt;none&gt;\nnginx-deploy-5787887b6f-fdkft   1/1     Running   0          4s    172.16.58.247    k8s-node02     &lt;none&gt;           &lt;none&gt;\nnginx-deploy-5787887b6f-jzcmd   1/1     Running   0          4s    172.16.32.152    k8s-master01   &lt;none&gt;           &lt;none&gt;\nnginx-deploy-5787887b6f-qdq9g   1/1     Running   0          4s    172.16.195.14    k8s-master03   &lt;none&gt;           &lt;none&gt;\n\n#4.å°†å‰¯æœ¬æ‰©æˆ6ä¸ªï¼Œç”±äºK8sé›†ç¾¤åªæœ‰5ä¸ªèŠ‚ç‚¹ï¼Œå³5ä¸ªtopologyKeyï¼ˆæ‹“æ‰‘åŸŸï¼‰ï¼Œæ¯ä¸ªåŸŸåªèƒ½æœ‰ä¸€ä¸ªå‰¯æœ¬ï¼Œæ‰€ä»¥æœ‰ä¸€ä¸ªpodä¼špending\n[root@k8s-master01 ~]# kubectl scale deploy nginx-deploy --replicas=6 \n[root@k8s-master01 ~]# kubectl get pods -o wide\nNAME                            READY   STATUS    RESTARTS   AGE     IP               NODE           NOMINATED NODE   READINESS GATES\nnginx-deploy-5787887b6f-4654b   1/1     Running   0          4m44s   172.16.85.234    k8s-node01     &lt;none&gt;           &lt;none&gt;\nnginx-deploy-5787887b6f-8mq7s   1/1     Running   0          4m44s   172.16.122.152   k8s-master02   &lt;none&gt;           &lt;none&gt;\nnginx-deploy-5787887b6f-fdkft   1/1     Running   0          4m44s   172.16.58.247    k8s-node02     &lt;none&gt;           &lt;none&gt;\nnginx-deploy-5787887b6f-jzcmd   1/1     Running   0          4m44s   172.16.32.152    k8s-master01   &lt;none&gt;           &lt;none&gt;\nnginx-deploy-5787887b6f-qdq9g   1/1     Running   0          4m44s   172.16.195.14    k8s-master03   &lt;none&gt;           &lt;none&gt;\nnginx-deploy-5787887b6f-sztm7   0/1     Pending   0          9s      &lt;none&gt;           &lt;none&gt;         &lt;none&gt;           &lt;none&gt;\n\n[root@k8s-master01 ~]# kubectl describe pods nginx-deploy-5787887b6f-sztm7\n...\nEvents:\n  Type     Reason            Age   From               Message\n  ----     ------            ----  ----               -------\n  Warning  FailedScheduling  102s  default-scheduler  0/5 nodes are available: 5 node(s) didn't match pod anti-affinity rules. preemption: 0/5 nodes are available: 5 No preemption victims found for incoming pod.\n</code></pre>\n<p><strong>å°†å‰¯æœ¬æ‰©æˆ 6 ä¸ªï¼Œæœ‰ä¸€ä¸ªä¼š pending çŠ¶æ€ï¼ŒåŸå›  K8s é›†ç¾¤åªæœ‰ 5 ä¸ªèŠ‚ç‚¹ï¼Œå³ 5 ä¸ª topologyKeyï¼ˆæ‹“æ‰‘åŸŸï¼‰ï¼Œæ¯ä¸ªæ‹“æ‰‘åŸŸåªèƒ½æœ‰ä¸€ä¸ªå‰¯æœ¬ï¼Œæ‰€ä»¥æœ‰ä¸€ä¸ª pod ä¼š pendingã€‚</strong></p>\n<p><strong>topologyKeyï¼šåŒ¹é…çš„æ‹“æ‰‘åŸŸçš„ keyï¼Œä¹Ÿå°±æ˜¯èŠ‚ç‚¹ä¸Š label çš„ keyï¼Œkey å’Œ value ç›¸åŒçš„ä¸ºåŒä¸€ä¸ªåŸŸï¼Œå¯ä»¥ç”¨äºæ ‡æ³¨ä¸åŒçš„æœºæˆ¿å’Œåœ°åŒº</strong>ã€‚</p>\n<h5 id=\"52-podåäº²å’ŒåŠ›preferred\"><a class=\"anchor\" href=\"#52-podåäº²å’ŒåŠ›preferred\">#</a> 5.2 Pod åäº²å’ŒåŠ› preferred</h5>\n<p>åŒä¸€ä¸ªåº”ç”¨å°½é‡éƒ¨ç½²åœ¨ä¸åŒçš„å®¿ä¸»æœº</p>\n<pre><code>#1.èŠ‚ç‚¹å­˜åœ¨æ±¡ç‚¹podæ— æ³•è°ƒåº¦è‡³è¯¥èŠ‚ç‚¹\n# kubectl describe nodes|grep -i taint\nTaints:             &lt;none&gt;\nTaints:             &lt;none&gt;\nTaints:             &lt;none&gt;\nTaints:             &lt;none&gt;\nTaints:             &lt;none&gt;\n\n#2.podåäº²å’ŒåŠ›preferred\n# cat nginx-deploy.yaml \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deploy\n  labels:\n    app: nginx-deploy\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  replicas: 6\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n            - podAffinityTerm:\n                labelSelector:\n                  matchExpressions:\n                    - key: app\n                      operator: In\n                      values:\n                        - nginx-deploy\n                topologyKey: kubernetes.io/hostname\n              weight: 100\n      restartPolicy: Always\n      containers:\n        - name: nginx-deploy\n          image: nginx\n          imagePullPolicy: IfNotPresent\n          resources:\n            limits:\n              memory: 1024Mi\n              cpu: 1\n            requests:\n              memory: 128Mi\n              cpu: 100m\n          volumeMounts:\n          - name: tz-config\n            mountPath: /usr/share/zoneinfo/Asia/Shanghai\n          - name: tz-config\n            mountPath: /etc/localtime\n          - name: timezone\n            mountPath: /etc/timezone\n      volumes:\n      - name: tz-config\n        hostPath:\n          path: /usr/share/zoneinfo/Asia/Shanghai\n          type: &quot;&quot;\n      - name: timezone\n        hostPath:\n          path: /etc/timezone\n          type: &quot;&quot;\n\n#3.éƒ¨ç½²deployment\n[root@k8s-master01 ~]# kubectl apply -f nginx-deploy.yaml \n[root@k8s-master01 ~]# kubectl get pods -o wide\nNAME                            READY   STATUS    RESTARTS   AGE   IP               NODE           NOMINATED NODE   READINESS GATES\nnginx-deploy-7c47567b79-97qs5   1/1     Running   0          6s    172.16.122.153   k8s-master02   &lt;none&gt;           &lt;none&gt;\nnginx-deploy-7c47567b79-g49h4   1/1     Running   0          6s    172.16.85.235    k8s-node01     &lt;none&gt;           &lt;none&gt;\nnginx-deploy-7c47567b79-g5n2s   1/1     Running   0          6s    172.16.58.248    k8s-node02     &lt;none&gt;           &lt;none&gt;\nnginx-deploy-7c47567b79-g5v5b   1/1     Running   0          6s    172.16.195.15    k8s-master03   &lt;none&gt;           &lt;none&gt;\nnginx-deploy-7c47567b79-pjwws   1/1     Running   0          6s    172.16.58.249    k8s-node02     &lt;none&gt;           &lt;none&gt;\nnginx-deploy-7c47567b79-q2hn5   1/1     Running   0          6s    172.16.32.153    k8s-master01   &lt;none&gt;           &lt;none&gt;\n</code></pre>\n<h5 id=\"53-podäº²å’ŒåŠ›required\"><a class=\"anchor\" href=\"#53-podäº²å’ŒåŠ›required\">#</a> 5.3 Pod äº²å’ŒåŠ› required</h5>\n<p>åŒä¸€ä¸ªåº”ç”¨å¿…é¡»éƒ¨ç½²åœ¨åŒä¸€ä¸ªå®¿ä¸»æœº</p>\n<pre><code>[root@k8s-master01 ~]# cat nginx-deploy.yaml \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: nginx-deploy\n  name: nginx-deploy\nspec:\n  replicas: 8\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n    spec:\n      affinity:              \n        podAffinity:   #podç¡¬äº²å’ŒåŠ›\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchExpressions:\n              - key: app\n                operator: In\n                values:\n                - nginx-deploy\n            topologyKey: kubernetes.io/hostname\n      containers:\n      - image: nginx\n        name: nginx\n        volumeMounts:\n        - name: timezone\n          mountPath: /etc/timezone\n        - name: tz-config\n          mountPath: /usr/share/zoneinfo/Asia/Shanghai\n        - name: tz-config\n          mountPath: /etc/localtime\n      volumes:\n      - name: timezone\n        hostPath:\n          path: /etc/timezone\n          type: File\n      - name: tz-config\n        hostPath:\n          path: /usr/share/zoneinfo/Asia/Shanghai\n          type: File\n\n[root@k8s-master01 ~]# kubectl apply -f nginx-deploy.yaml \n[root@k8s-master01 ~]# kubectl get pods -o wide\nNAME                           READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATES\nnginx-deploy-dbcc4d65c-2sthn   1/1     Running   0          12s   172.16.58.255   k8s-node02   &lt;none&gt;           &lt;none&gt;\nnginx-deploy-dbcc4d65c-78nxf   1/1     Running   0          12s   172.16.58.197   k8s-node02   &lt;none&gt;           &lt;none&gt;\nnginx-deploy-dbcc4d65c-82ssq   1/1     Running   0          12s   172.16.58.194   k8s-node02   &lt;none&gt;           &lt;none&gt;\nnginx-deploy-dbcc4d65c-986cb   1/1     Running   0          12s   172.16.58.254   k8s-node02   &lt;none&gt;           &lt;none&gt;\nnginx-deploy-dbcc4d65c-9rnt7   1/1     Running   0          12s   172.16.58.252   k8s-node02   &lt;none&gt;           &lt;none&gt;\nnginx-deploy-dbcc4d65c-knm8q   1/1     Running   0          12s   172.16.58.195   k8s-node02   &lt;none&gt;           &lt;none&gt;\nnginx-deploy-dbcc4d65c-kx56f   1/1     Running   0          12s   172.16.58.253   k8s-node02   &lt;none&gt;           &lt;none&gt;\nnginx-deploy-dbcc4d65c-sqlhf   1/1     Running   0          12s   172.16.58.198   k8s-node02   &lt;none&gt;           &lt;none&gt;\n</code></pre>\n<h5 id=\"54-podäº²å’ŒåŠ›preferre\"><a class=\"anchor\" href=\"#54-podäº²å’ŒåŠ›preferre\">#</a> 5.4 Pod äº²å’ŒåŠ› preferre</h5>\n<p>åŒä¸€ä¸ªåº”ç”¨å°½é‡éƒ¨ç½²åœ¨åŒä¸€ä¸ªå®¿ä¸»æœº</p>\n<pre><code># cat nginx-deploy.yaml \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: nginx-deploy\n  name: nginx-deploy\nspec:\n  replicas: 20\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n    spec:\n      affinity:              \n        podAffinity:       #podè½¯äº²å’ŒåŠ›\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - nginx-deploy\n              namespaces:     #å’Œå“ªä¸ªå‘½åç©ºé—´çš„Podè¿›è¡ŒåŒ¹é…ï¼Œä¸ºç©ºä¸ºå½“å‰å‘½åç©ºé—´\n              - default\n              topologyKey: kubernetes.io/hostname\n      containers:\n      - image: nginx\n        name: nginx\n        volumeMounts:\n        - name: timezone\n          mountPath: /etc/timezone\n        - name: tz-config\n          mountPath: /usr/share/zoneinfo/Asia/Shanghai\n        - name: tz-config\n          mountPath: /etc/localtime\n      volumes:\n      - name: timezone\n        hostPath:\n          path: /etc/timezone\n          type: File\n      - name: tz-config\n        hostPath:\n          path: /usr/share/zoneinfo/Asia/Shanghai\n          type: File\n</code></pre>\n<p><em>æœ¬æ–‡å‡ºè‡ªäºï¼š<a href=\"https://edu.51cto.com/course/23845.html\">https://edu.51cto.com/course/23845.html</a></em></p>\n",
            "tags": [
                "Kubernetes"
            ]
        },
        {
            "id": "http://ixuyong.cn/posts/3254599477.html",
            "url": "http://ixuyong.cn/posts/3254599477.html",
            "title": "K8så®¹å¿å’Œæ±¡ç‚¹",
            "date_published": "2025-04-20T07:51:58.000Z",
            "content_html": "<h3 id=\"k8så®¹å¿å’Œæ±¡ç‚¹\"><a class=\"anchor\" href=\"#k8så®¹å¿å’Œæ±¡ç‚¹\">#</a> K8s å®¹å¿å’Œæ±¡ç‚¹</h3>\n<p>Taint æŒ‡å®šæœåŠ¡å™¨ä¸Šæ‰“ä¸Šæ±¡ç‚¹ï¼Œè®©ä¸èƒ½å®¹å¿è¿™ä¸ªæ±¡ç‚¹çš„ Pod ä¸èƒ½éƒ¨ç½²åœ¨æ‰“äº†æ±¡ç‚¹çš„æœåŠ¡å™¨ä¸Šã€‚Toleration æ˜¯è®© Pod å®¹å¿èŠ‚ç‚¹ä¸Šé…ç½®çš„æ±¡ç‚¹ï¼Œå¯ä»¥è®©ä¸€äº›éœ€è¦ç‰¹æ®Šé…ç½®çš„ Pod èƒ½å¤Ÿè°ƒç”¨åˆ°å…·æœ‰æ±¡ç‚¹å’Œç‰¹æ®Šé…ç½®çš„èŠ‚ç‚¹ä¸Šã€‚</p>\n<h4 id=\"1-tainté…ç½®è§£æ\"><a class=\"anchor\" href=\"#1-tainté…ç½®è§£æ\">#</a> 1. Taint é…ç½®è§£æ</h4>\n<pre><code>#1.Taintè¯­æ³•\n# kubectl taint nodes NODE_NAME TAINT_KEY=TAINT_VALUE:EFFECT\n\n#2.åˆ›å»ºTaintç¤ºä¾‹\n# kubectl taint nodes k8s-node01 ssd=true:PreferNoSchedule\n\n#3.æŸ¥çœ‹æ±¡ç‚¹\n# kubectl describe node k8s-node01 | grep Taints -A 10\n\n#4.åˆ é™¤æ±¡ç‚¹\n# kubectl taint nodes k8s-node01 ssd-                   #åŸºäºKeyåˆ é™¤\n# kubectl taint nodes k8s-node01 ssd:PreferNoSchedule-  #åŸºäºKey+Effectåˆ é™¤\n\n#5.ä¿®æ”¹æ±¡ç‚¹ï¼ˆKeyå’ŒEffectç›¸åŒï¼‰\n# kubectl taint nodes k8s-node01 ssd=true:PreferNoSchedule --overwrite\n</code></pre>\n<p>EFFECT æ’æ–¥ç­‰çº§ï¼š</p>\n<ul>\n<li>NoScheduleï¼šç¦æ­¢è°ƒåº¦åˆ°è¯¥èŠ‚ç‚¹ï¼Œå·²ç»åœ¨è¯¥èŠ‚ç‚¹ä¸Šçš„ Pod ä¸å—å½±å“</li>\n<li>NoExecuteï¼šç¦æ­¢è°ƒåº¦åˆ°è¯¥èŠ‚ç‚¹ï¼Œå¦‚æœä¸ç¬¦åˆè¿™ä¸ªæ±¡ç‚¹ï¼Œä¼šç«‹é©¬è¢«é©±é€ï¼ˆæˆ–åœ¨ä¸€æ®µæ—¶é—´åï¼‰</li>\n<li>PreferNoScheduleï¼šå°½é‡é¿å…å°† Pod è°ƒåº¦åˆ°æŒ‡å®šçš„èŠ‚ç‚¹ä¸Šï¼Œå¦‚æœæ²¡æœ‰æ›´åˆé€‚çš„èŠ‚ç‚¹ï¼Œå¯ä»¥éƒ¨ç½²åˆ°è¯¥èŠ‚ç‚¹</li>\n</ul>\n<h4 id=\"2tolerationé…ç½®è§£æ\"><a class=\"anchor\" href=\"#2tolerationé…ç½®è§£æ\">#</a> 2.Toleration é…ç½®è§£æ</h4>\n<pre><code>#1.å®Œå…¨åŒ¹é…\ntolerations:\n- key: &quot;taintKey&quot;\n  operator: &quot;Equal&quot;\n  value: &quot;taintValue&quot;\n  effect: &quot;NoSchedule\n \n#2.ä¸å®Œå…¨åŒ¹é… \ntolerations:\n- key: &quot;taintKey&quot;\n  operator: &quot;Exists&quot;\n  effect: &quot;NoSchedule&quot;\n  \n#3.å¤§èŒƒå›´åŒ¹é…ï¼ˆä¸æ¨èkeyä¸ºå†…ç½®Taintï¼Œä¼šå¯¼è‡´èŠ‚ç‚¹æ•…éšœpodæ— æ³•æ¼‚ç§»ï¼‰\ntolerations:\n- key: &quot;taintKey&quot;\n  operator: &quot;Exists\n  \n#4.å®¹å¿æ—¶é—´é…ç½®\ntolerations:\n- key: &quot;key1&quot;\n  operator: &quot;Equal&quot;\n  value: &quot;value1&quot;\n  effect: &quot;NoExecute&quot;\n  tolerationSeconds: 3600\n</code></pre>\n<h4 id=\"3-taint-tolerationé…ç½®ç¤ºä¾‹\"><a class=\"anchor\" href=\"#3-taint-tolerationé…ç½®ç¤ºä¾‹\">#</a> 3. Taintã€Toleration é…ç½®ç¤ºä¾‹</h4>\n<p>æœ‰ä¸€ä¸ª K8s èŠ‚ç‚¹æ˜¯çº¯ SSD ç¡¬ç›˜çš„èŠ‚ç‚¹ï¼Œç°éœ€è¦åªæœ‰ä¸€äº›éœ€è¦é«˜æ€§èƒ½å­˜å‚¨çš„ Pod æ‰èƒ½è°ƒåº¦åˆ°è¯¥èŠ‚ç‚¹ä¸Šã€‚</p>\n<pre><code>#1.ç»™èŠ‚ç‚¹æ‰“ä¸Šæ±¡ç‚¹å’Œæ ‡ç­¾\n# kubectl taint nodes k8s-node01 ssd=true:PreferNoSchedule\n# kubectl label node k8s-node01 ssd=true\n\n#2.é…ç½®Tolerationï¼š\n# cat nginx-deploy.yaml \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deploy\n  labels:\n    app: nginx-deploy\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  replicas: 5\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n    spec:\n      containers:\n        - name: nginx-deploy\n          image: nginx\n          imagePullPolicy: IfNotPresent\n          resources:\n            limits:\n              memory: 1024Mi\n              cpu: 1\n            requests:\n              memory: 128Mi\n              cpu: 100m\n      nodeSelector:\n        ssd: 'true'\n      tolerations:\n        - key: ssd\n          operator: Exists\n          effect: NoSchedule\n</code></pre>\n<h4 id=\"4-k8så†…ç½®æ±¡ç‚¹\"><a class=\"anchor\" href=\"#4-k8så†…ç½®æ±¡ç‚¹\">#</a> 4. K8s å†…ç½®æ±¡ç‚¹</h4>\n<ul>\n<li><a href=\"http://node.kubernetes.io/not-ready%EF%BC%9A%E8%8A%82%E7%82%B9%E6%9C%AA%E5%87%86%E5%A4%87%E5%A5%BD%EF%BC%8C%E7%9B%B8%E5%BD%93%E4%BA%8E%E8%8A%82%E7%82%B9%E7%8A%B6%E6%80%81Ready%E7%9A%84%E5%80%BC%E4%B8%BAFalse%E3%80%82\">node.kubernetes.io/not-readyï¼šèŠ‚ç‚¹æœªå‡†å¤‡å¥½ï¼Œç›¸å½“äºèŠ‚ç‚¹çŠ¶æ€ Ready çš„å€¼ä¸º Falseã€‚</a></li>\n<li><a href=\"http://node.kubernetes.io/unreachable%EF%BC%9ANode\">node.kubernetes.io/unreachableï¼šNode</a> Controller è®¿é—®ä¸åˆ°èŠ‚ç‚¹ï¼Œç›¸å½“äºèŠ‚ç‚¹çŠ¶æ€ Ready çš„å€¼ä¸º Unknownã€‚</li>\n<li><a href=\"http://node.kubernetes.io/out-of-disk%EF%BC%9A%E8%8A%82%E7%82%B9%E7%A3%81%E7%9B%98%E8%80%97%E5%B0%BD%E3%80%82\">node.kubernetes.io/out-of-diskï¼šèŠ‚ç‚¹ç£ç›˜è€—å°½ã€‚</a></li>\n<li><a href=\"http://node.kubernetes.io/memory-pressure%EF%BC%9A%E8%8A%82%E7%82%B9%E5%AD%98%E5%9C%A8%E5%86%85%E5%AD%98%E5%8E%8B%E5%8A%9B%E3%80%82\">node.kubernetes.io/memory-pressureï¼šèŠ‚ç‚¹å­˜åœ¨å†…å­˜å‹åŠ›ã€‚</a></li>\n<li><a href=\"http://node.kubernetes.io/disk-pressure%EF%BC%9A%E8%8A%82%E7%82%B9%E5%AD%98%E5%9C%A8%E7%A3%81%E7%9B%98%E5%8E%8B%E5%8A%9B%E3%80%82\">node.kubernetes.io/disk-pressureï¼šèŠ‚ç‚¹å­˜åœ¨ç£ç›˜å‹åŠ›ã€‚</a></li>\n<li><a href=\"http://node.kubernetes.io/network-unavailable%EF%BC%9A%E8%8A%82%E7%82%B9%E7%BD%91%E7%BB%9C%E4%B8%8D%E5%8F%AF%E8%BE%BE%E3%80%82\">node.kubernetes.io/network-unavailableï¼šèŠ‚ç‚¹ç½‘ç»œä¸å¯è¾¾ã€‚</a></li>\n<li><a href=\"http://node.kubernetes.io/unschedulable%EF%BC%9A%E8%8A%82%E7%82%B9%E4%B8%8D%E5%8F%AF%E8%B0%83%E5%BA%A6%E3%80%82\">node.kubernetes.io/unschedulableï¼šèŠ‚ç‚¹ä¸å¯è°ƒåº¦ã€‚</a></li>\n<li><a href=\"http://node.cloudprovider.kubernetes.io/uninitialized%EF%BC%9A%E5%A6%82%E6%9E%9CKubelet%E5%90%AF%E5%8A%A8%E6%97%B6%E6%8C%87%E5%AE%9A%E4%BA%86%E4%B8%80%E4%B8%AA%E5%A4%96%E9%83%A8%E7%9A%84cloudprovider%EF%BC%8C%E5%AE%83%E5%B0%86%E7%BB%99%E5%BD%93%E5%89%8D%E8%8A%82%E7%82%B9%E6%B7%BB%E5%8A%A0%E4%B8%80%E4%B8%AATaint%E5%B0%86%E5%85%B6%E6%A0%87%E8%AE%B0%E4%B8%BA%E4%B8%8D%E5%8F%AF%E7%94%A8%E3%80%82%E5%9C%A8cloud-controller-manager%E7%9A%84%E4%B8%80%E4%B8%AAcontroller%E5%88%9D%E5%A7%8B%E5%8C%96%E8%BF%99%E4%B8%AA%E8%8A%82%E7%82%B9%E5%90%8E%EF%BC%8CKubelet%E5%B0%86%E5%88%A0%E9%99%A4%E8%BF%99%E4%B8%AATaint%E3%80%82\">node.cloudprovider.kubernetes.io/uninitializedï¼šå¦‚æœ Kubelet å¯åŠ¨æ—¶æŒ‡å®šäº†ä¸€ä¸ªå¤–éƒ¨çš„ cloudproviderï¼Œå®ƒå°†ç»™å½“å‰èŠ‚ç‚¹æ·»åŠ ä¸€ä¸ª Taint å°†å…¶æ ‡è®°ä¸ºä¸å¯ç”¨ã€‚åœ¨ cloud-controller-manager çš„ä¸€ä¸ª controller åˆå§‹åŒ–è¿™ä¸ªèŠ‚ç‚¹åï¼ŒKubelet å°†åˆ é™¤è¿™ä¸ª Taintã€‚</a></li>\n</ul>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/vO7kURL.png\" alt=\"1.png\" /></p>\n<p>Deployment åˆ›å»ºå K8s é»˜è®¤ä¸º Pod æ·»åŠ å®¹å¿ï¼Œå½“ Pod æ‰€åœ¨çš„èŠ‚ç‚¹å®•æœºï¼Œ300 ç§’å pod ä¼šæ¼‚ç§»ï¼Œé»˜è®¤å®¹å¿æ—¶é—´ 300 ç§’ã€‚</p>\n<h4 id=\"5èŠ‚ç‚¹å®•æœºå¿«é€Ÿæ¢å¤ä¸šåŠ¡åº”ç”¨\"><a class=\"anchor\" href=\"#5èŠ‚ç‚¹å®•æœºå¿«é€Ÿæ¢å¤ä¸šåŠ¡åº”ç”¨\">#</a> 5. èŠ‚ç‚¹å®•æœºå¿«é€Ÿæ¢å¤ä¸šåŠ¡åº”ç”¨</h4>\n<p>èŠ‚ç‚¹ä¸å¥åº·ï¼Œ180 ç§’åå†é©±é€ï¼ˆé»˜è®¤æ˜¯ 300 ç§’ï¼‰</p>\n<pre><code># cat nginx-deploy.yaml \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deploy\n  labels:\n    app: nginx-deploy\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  replicas: 5\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n    spec:\n      containers:\n        - name: nginx-deploy\n          image: nginx\n          imagePullPolicy: IfNotPresent\n          resources:\n            limits:\n              memory: 1024Mi\n              cpu: 1\n            requests:\n              memory: 128Mi\n              cpu: 100m\n      tolerations:\n        - key: node.kubernetes.io/unreachable\n          operator: Exists\n          effect: NoExecute\n          tolerationSeconds: 180\n        - key: node.kubernetes.io/not-ready\n          operator: Exists\n          effect: NoExecute\n          tolerationSeconds: 180\n</code></pre>\n<p><em>æœ¬æ–‡å‡ºè‡ªäºï¼š<a href=\"https://edu.51cto.com/course/23845.html\">https://edu.51cto.com/course/23845.html</a></em></p>\n",
            "tags": [
                "Kubernetes"
            ]
        },
        {
            "id": "http://ixuyong.cn/posts/3142072607.html",
            "url": "http://ixuyong.cn/posts/3142072607.html",
            "title": "K8såˆå§‹åŒ–å®¹å™¨ã€ä¸´æ—¶å®¹å™¨",
            "date_published": "2025-04-19T13:07:20.000Z",
            "content_html": "<h3 id=\"k8såˆå§‹åŒ–å®¹å™¨-ä¸´æ—¶å®¹å™¨\"><a class=\"anchor\" href=\"#k8såˆå§‹åŒ–å®¹å™¨-ä¸´æ—¶å®¹å™¨\">#</a> K8s åˆå§‹åŒ–å®¹å™¨ã€ä¸´æ—¶å®¹å™¨</h3>\n<h4 id=\"1-åˆå§‹åŒ–å®¹å™¨\"><a class=\"anchor\" href=\"#1-åˆå§‹åŒ–å®¹å™¨\">#</a> 1. åˆå§‹åŒ–å®¹å™¨</h4>\n<h5 id=\"1-1-åˆå§‹åŒ–å®¹å™¨çš„ç”¨é€”\"><a class=\"anchor\" href=\"#1-1-åˆå§‹åŒ–å®¹å™¨çš„ç”¨é€”\">#</a> 1. 1 åˆå§‹åŒ–å®¹å™¨çš„ç”¨é€”</h5>\n<p>åˆå§‹åŒ–å®¹å™¨ä¸»è¦æ˜¯åœ¨ä¸»åº”ç”¨å¯åŠ¨ä¹‹å‰ï¼Œåšä¸€äº›åˆå§‹åŒ–çš„æ“ä½œï¼Œæ¯”å¦‚åˆ›å»ºæ–‡ä»¶ã€ä¿®æ”¹å†…æ ¸å‚æ•°ã€ç­‰å¾…ä¾èµ–ç¨‹åºå¯åŠ¨æˆ–å…¶ä»–éœ€è¦åœ¨ä¸»ç¨‹åºå¯åŠ¨ä¹‹å‰éœ€è¦åšçš„å·¥ä½œã€‚</p>\n<ul>\n<li>Init å®¹å™¨å¯ä»¥åŒ…å«ä¸€äº›å®‰è£…è¿‡ç¨‹ä¸­åº”ç”¨å®¹å™¨ä¸­ä¸å­˜åœ¨çš„å®ç”¨å·¥å…·æˆ–ä¸ªæ€§åŒ–ä»£ç ï¼›</li>\n<li>Init å®¹å™¨å¯ä»¥å®‰å…¨åœ°è¿è¡Œè¿™äº›å·¥å…·ï¼Œé¿å…è¿™äº›å·¥å…·å¯¼è‡´åº”ç”¨é•œåƒçš„å®‰å…¨æ€§é™ä½ï¼›</li>\n<li>Init å®¹å™¨å¯ä»¥ä»¥ root èº«ä»½è¿è¡Œï¼Œæ‰§è¡Œä¸€äº›é«˜æƒé™å‘½ä»¤ï¼›</li>\n<li>Init å®¹å™¨ç›¸å…³æ“ä½œæ‰§è¡Œå®Œæˆä»¥åå³é€€å‡ºï¼Œä¸ä¼šç»™ä¸šåŠ¡å®¹å™¨å¸¦æ¥å®‰å…¨éšæ‚£ã€‚</li>\n</ul>\n<h5 id=\"12-åˆå§‹åŒ–å®¹å™¨å’ŒpoststartåŒºåˆ«\"><a class=\"anchor\" href=\"#12-åˆå§‹åŒ–å®¹å™¨å’ŒpoststartåŒºåˆ«\">#</a> 1.2 åˆå§‹åŒ–å®¹å™¨å’Œ PostStart åŒºåˆ«</h5>\n<p>PostStartï¼šä¾èµ–ä¸»åº”ç”¨çš„ç¯å¢ƒï¼Œè€Œä¸”å¹¶ä¸ä¸€å®šå…ˆäº Command è¿è¡Œã€‚</p>\n<p>InitContainerï¼šä¸ä¾èµ–ä¸»åº”ç”¨çš„ç¯å¢ƒï¼Œå¯ä»¥æœ‰æ›´é«˜çš„æƒé™å’Œæ›´å¤šçš„å·¥å…·ï¼Œä¸€å®šä¼šåœ¨ä¸»åº”ç”¨å¯åŠ¨ä¹‹å‰å®Œæˆ</p>\n<h5 id=\"13-åˆå§‹åŒ–å®¹å™¨å’Œæ™®é€šå®¹å™¨çš„åŒºåˆ«\"><a class=\"anchor\" href=\"#13-åˆå§‹åŒ–å®¹å™¨å’Œæ™®é€šå®¹å™¨çš„åŒºåˆ«\">#</a> 1.3 åˆå§‹åŒ–å®¹å™¨å’Œæ™®é€šå®¹å™¨çš„åŒºåˆ«</h5>\n<p>Init å®¹å™¨ä¸æ™®é€šçš„å®¹å™¨éå¸¸åƒï¼Œé™¤äº†å¦‚ä¸‹å‡ ç‚¹ï¼š</p>\n<ul>\n<li>\n<p>ç¬¬ä¸€ä¸ª Init å®¹å™¨è¿è¡ŒæˆåŠŸåæ‰ä¼šè¿è¡Œä¸‹ä¸€ä¸ª Init å®¹å™¨ï¼›</p>\n</li>\n<li>\n<p>æ‰€æœ‰çš„ Init å®¹å™¨è¿è¡ŒæˆåŠŸåæ‰ä¼šè¿è¡Œä¸»å®¹å™¨ï¼›</p>\n</li>\n<li>\n<p>å¦‚æœ Pod çš„ Init å®¹å™¨å¤±è´¥ï¼ŒKubernetes ä¼šä¸æ–­åœ°é‡å¯è¯¥ Podï¼Œç›´åˆ° Init å®¹å™¨æˆåŠŸä¸ºæ­¢ï¼Œä½†æ˜¯ Pod å¯¹åº”çš„ restartPolicy å€¼ä¸º Neverï¼ŒKubernetes ä¸ä¼šé‡æ–°å¯åŠ¨ Podã€‚</p>\n</li>\n<li>\n<p>Init å®¹å™¨ä¸æ”¯æŒ lifecycleã€livenessProbeã€readinessProbe å’Œ startupProbe</p>\n</li>\n</ul>\n<h5 id=\"14-åˆå§‹åŒ–å®¹å™¨ç¤ºä¾‹\"><a class=\"anchor\" href=\"#14-åˆå§‹åŒ–å®¹å™¨ç¤ºä¾‹\">#</a> 1.4 åˆå§‹åŒ–å®¹å™¨ç¤ºä¾‹</h5>\n<pre><code>[root@k8s-master01 ~]# cat init.yaml \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: nginx-deploy\n  name: nginx-deploy\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n    spec:\n      initContainers:           # åˆå§‹åŒ–å®¹å™¨è®¾å®š\n      - name: fix-permissions\n        image: busybox\n        command: [&quot;sh&quot;,&quot;-c&quot;,&quot;echo hello kubernetes&gt;/usr/share/nginx/html/index.html&quot;]\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: share-volume\n          mountPath: /usr/share/nginx/html\n      containers:\n      - image: nginx\n        name: nginx\n        volumeMounts:\n        - name: timezone\n          mountPath: /etc/timezone\n        - name: tz-config\n          mountPath: /usr/share/zoneinfo/Asia/Shanghai\n        - name: tz-config\n          mountPath: /etc/localtime\n        - name: share-volume\n          mountPath: /usr/share/nginx/html\n      volumes:\n      - name: share-volume\n        emptyDir: &#123;&#125;\n      - name: timezone\n        hostPath:\n          path: /etc/timezone\n          type: File\n      - name: tz-config\n        hostPath:\n          path: /usr/share/zoneinfo/Asia/Shanghai\n          type: File\n\n[root@k8s-master01 ~]# kubectl create -f init.yaml\n\n[root@k8s-master01 ~]# curl 172.16.32.145\nhello kubernetes\n</code></pre>\n<h4 id=\"2-ä¸´æ—¶å®¹å™¨\"><a class=\"anchor\" href=\"#2-ä¸´æ—¶å®¹å™¨\">#</a> 2. ä¸´æ—¶å®¹å™¨</h4>\n<h5 id=\"21-æ³¨å…¥ä¸´æ—¶å®¹å™¨åˆ°pod\"><a class=\"anchor\" href=\"#21-æ³¨å…¥ä¸´æ—¶å®¹å™¨åˆ°pod\">#</a> 2.1 æ³¨å…¥ä¸´æ—¶å®¹å™¨åˆ° Pod</h5>\n<pre><code>[root@k8s-master01 ~]# kubectl get pods\nNAME                            READY   STATUS    RESTARTS      AGE\nnginx-deploy-7dd6cd4b44-ktw5k   1/1     Running   1             16h\nnginx-deploy-7dd6cd4b44-mjcgq   1/1     Running   1 (28m ago)   16h\nnginx-deploy-7dd6cd4b44-wdm6p   1/1     Running   1 (28m ago)   16h\n\n#1.è¿›å…¥å®¹å™¨å‘ç°podæ²¡æœ‰pså’Œnetstatå‘½ä»¤\n[root@k8s-master01 ~]# kubectl exec -it nginx-deploy-7dd6cd4b44-ktw5k  -- bash\nroot@nginx-deploy-7dd6cd4b44-ktw5k:/# ps aux\nroot@nginx-deploy-7dd6cd4b44-ktw5k:/# netstat -lntp\n\n#2.æ³¨å…¥ä¸´æ—¶å®¹å™¨è‡³è¯¥Pod\n[root@k8s-master01 ~]# kubectl debug nginx-deploy-7dd6cd4b44-wdm6p -ti --image=registry.cn-hangzhou.aliyuncs.com/old_xu/debug-tools\n</code></pre>\n<h5 id=\"21-æ³¨å…¥ä¸´æ—¶å®¹å™¨åˆ°èŠ‚ç‚¹\"><a class=\"anchor\" href=\"#21-æ³¨å…¥ä¸´æ—¶å®¹å™¨åˆ°èŠ‚ç‚¹\">#</a> 2.1 æ³¨å…¥ä¸´æ—¶å®¹å™¨åˆ°èŠ‚ç‚¹</h5>\n<pre><code>kubectl debug node k8s-node01 -it --image=registry.cn-hangzhou.aliyuncs.com/old_xu/debug-tools\n</code></pre>\n<p><em>æœ¬æ–‡å‡ºè‡ªäºï¼š<a href=\"https://edu.51cto.com/course/23845.html\">https://edu.51cto.com/course/23845.html</a></em></p>\n",
            "tags": [
                "Kubernetes"
            ]
        },
        {
            "id": "http://ixuyong.cn/posts/3833778957.html",
            "url": "http://ixuyong.cn/posts/3833778957.html",
            "title": "K8sè®¡åˆ’ä»»åŠ¡Jobã€Cronjob",
            "date_published": "2025-04-19T13:00:21.000Z",
            "content_html": "<h3 id=\"k8sè®¡åˆ’ä»»åŠ¡job-cronjob\"><a class=\"anchor\" href=\"#k8sè®¡åˆ’ä»»åŠ¡job-cronjob\">#</a> K8s è®¡åˆ’ä»»åŠ¡ Jobã€Cronjob</h3>\n<h4 id=\"1-jobé…ç½®å‚æ•°è¯¦è§£\"><a class=\"anchor\" href=\"#1-jobé…ç½®å‚æ•°è¯¦è§£\">#</a> 1. Job é…ç½®å‚æ•°è¯¦è§£</h4>\n<pre><code># cat job.yaml \napiVersion: batch/v1\nkind: Job\nmetadata:\n  labels:\n    job-name: echo\n  name: echo\n  namespace: default\nspec:\n  #suspend: true # 1.21+\n  #ttlSecondsAfterFinished: 100\n  backoffLimit: 4\n  completions: 1\n  parallelism: 1\n  template:\n    spec:\n      containers:\n      - name: echo\n        image: busybox\n        imagePullPolicy: IfNotPresent\n        command:\n        - sh\n        - -c\n        - echo &quot;Hello Job&quot;\n      restartPolicy: Never\n      \n[root@k8s-master01 ~]# kubectl get jobs\nNAME   STATUS     COMPLETIONS   DURATION   AGE\necho   Complete   1/1           70s        2m5s\n\n[root@k8s-master01 ~]# kubectl get pods\nNAME          READY   STATUS      RESTARTS      AGE\necho-564c8    0/1     Completed   0             2m10s\n\n[root@k8s-master01 ~]# kubectl logs echo-564c8\nHello Job\n</code></pre>\n<ul>\n<li>backoffLimit:ï¼šå¦‚æœä»»åŠ¡æ‰§è¡Œå¤±è´¥ï¼Œå¤±è´¥å¤šå°‘æ¬¡åä¸å†æ‰§è¡Œ</li>\n<li>completionsï¼šæœ‰å¤šå°‘ä¸ª Pod æ‰§è¡ŒæˆåŠŸï¼Œè®¤ä¸ºä»»åŠ¡æ˜¯æˆåŠŸçš„ï¼Œé»˜è®¤ä¸ºç©ºå’Œ parallelism æ•°å€¼ä¸€æ ·</li>\n<li>parallelismï¼šå¹¶è¡Œæ‰§è¡Œä»»åŠ¡çš„æ•°é‡ï¼Œå¦‚æœ parallelism æ•°å€¼å¤§äº completions æ•°å€¼ï¼Œåªä¼šåˆ›å»º completions çš„æ•°é‡ï¼›å¦‚æœ completions æ˜¯ 4ï¼Œå¹¶å‘æ˜¯ 3ï¼Œç¬¬ä¸€æ¬¡ä¼šåˆ›å»º 3 ä¸ª Pod æ‰§è¡Œä»»åŠ¡ï¼Œç¬¬äºŒæ¬¡åªä¼šåˆ›å»ºä¸€ä¸ª Pod æ‰§è¡Œä»»åŠ¡</li>\n<li>ttlSecondsAfterFinishedï¼šJob åœ¨æ‰§è¡Œç»“æŸä¹‹åï¼ˆçŠ¶æ€ä¸º completed æˆ– Failedï¼‰è‡ªåŠ¨æ¸…ç†ã€‚è®¾ç½®ä¸º 0 è¡¨ç¤ºæ‰§è¡Œç»“æŸç«‹å³åˆ é™¤ï¼Œä¸è®¾ç½®åˆ™ä¸ä¼šæ¸…é™¤ï¼Œéœ€è¦å¼€å¯ TTLAfterFinished ç‰¹æ€§</li>\n</ul>\n<h4 id=\"2-cronjobé…ç½®å‚æ•°è¯¦è§£\"><a class=\"anchor\" href=\"#2-cronjobé…ç½®å‚æ•°è¯¦è§£\">#</a> 2. CronJob é…ç½®å‚æ•°è¯¦è§£</h4>\n<pre><code># cat cronjob.yaml \napiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: hello\nspec:\n  schedule: &quot;*/1 * * * *&quot;\n  concurrencyPolicy: Allow   #å…è®¸åŒæ—¶è¿è¡Œå¤šä¸ªä»»åŠ¡\n  failedJobsHistoryLimit: 10  #ä¿ç•™å¤šå°‘å¤±è´¥çš„ä»»åŠ¡\n  successfulJobsHistoryLimit: 10  #ä¿ç•™å¤šå°‘å·²å®Œæˆçš„ä»»åŠ¡\n  #suspend: true             #å¦‚æœtrueåˆ™å–æ¶ˆå‘¨æœŸæ€§æ‰§è¡Œä»»åŠ¡\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n          - name: hello\n            image: busybox\n            command:\n            - sh\n            - -c\n            - date; echo Hello from the Kubernetes cluster\n          restartPolicy: OnFailure \n          \n[root@k8s-master01 ~]# kubectl get  cj\nNAME    SCHEDULE      TIMEZONE   SUSPEND   ACTIVE   LAST SCHEDULE   AGE\nhello   */1 * * * *   &lt;none&gt;     False     0        6s              81s\n\n[root@k8s-master01 ~]# kubectl get  jobs\nNAME             STATUS     COMPLETIONS   DURATION   AGE\nhello-29084454   Complete   1/1           4s         72s\nhello-29084455   Complete   1/1           5s         12s\n\n[root@k8s-master01 ~]# kubectl get  pods\nNAME                   READY   STATUS      RESTARTS   AGE\nhello-29084454-hwv7p   0/1     Completed   0          78s\nhello-29084455-vf99w   0/1     Completed   0          18s\n\n[root@k8s-master01 ~]# kubectl logs -f hello-29084455-vf99w\nSat Apr 19 12:55:02 UTC 2025\nHello from the Kubernetes cluster\n</code></pre>\n<ul>\n<li>apiVersion: batch/v1beta1   #1.21+ batch/v1</li>\n<li>scheduleï¼šè°ƒåº¦å‘¨æœŸï¼Œå’Œ Linux ä¸€è‡´ï¼Œåˆ†åˆ«æ˜¯åˆ†æ—¶æ—¥æœˆå‘¨ã€‚</li>\n<li>restartPolicyï¼šé‡å¯ç­–ç•¥ï¼Œå’Œ Pod ä¸€è‡´ã€‚</li>\n<li>concurrencyPolicyï¼šå¹¶å‘è°ƒåº¦ç­–ç•¥ã€‚å¯é€‰å‚æ•°å¦‚ä¸‹ï¼š\n<ul>\n<li>Allowï¼šå…è®¸åŒæ—¶è¿è¡Œå¤šä¸ªä»»åŠ¡ã€‚</li>\n<li>Forbidï¼šä¸å…è®¸å¹¶å‘è¿è¡Œï¼Œå¦‚æœä¹‹å‰çš„ä»»åŠ¡å°šæœªå®Œæˆï¼Œæ–°çš„ä»»åŠ¡ä¸ä¼šè¢«åˆ›å»ºã€‚</li>\n<li>Replaceï¼šå¦‚æœä¹‹å‰çš„ä»»åŠ¡å°šæœªå®Œæˆï¼Œæ–°çš„ä»»åŠ¡ä¼šæ›¿æ¢çš„ä¹‹å‰çš„ä»»åŠ¡ã€‚</li>\n</ul>\n</li>\n<li>suspendï¼šå¦‚æœè®¾ç½®ä¸º trueï¼Œåˆ™æš‚åœåç»­çš„ä»»åŠ¡ï¼Œé»˜è®¤ä¸º falseã€‚</li>\n<li>successfulJobsHistoryLimitï¼šä¿ç•™å¤šå°‘å·²å®Œæˆçš„ä»»åŠ¡ï¼ŒæŒ‰éœ€é…ç½®ã€‚</li>\n<li>failedJobsHistoryLimitï¼šä¿ç•™å¤šå°‘å¤±è´¥çš„ä»»åŠ¡ã€‚</li>\n</ul>\n<p><em>æœ¬æ–‡å‡ºè‡ªäºï¼š<a href=\"https://edu.51cto.com/course/23845.html\">https://edu.51cto.com/course/23845.html</a></em></p>\n",
            "tags": [
                "Kubernetes"
            ]
        },
        {
            "id": "http://ixuyong.cn/posts/169153047.html",
            "url": "http://ixuyong.cn/posts/169153047.html",
            "title": "K8sæŒä¹…åŒ–å­˜å‚¨",
            "date_published": "2025-04-18T14:25:17.000Z",
            "content_html": "<h3 id=\"k8sæŒä¹…åŒ–å­˜å‚¨\"><a class=\"anchor\" href=\"#k8sæŒä¹…åŒ–å­˜å‚¨\">#</a> K8s æŒä¹…åŒ–å­˜å‚¨</h3>\n<h4 id=\"1-volume\"><a class=\"anchor\" href=\"#1-volume\">#</a> 1. Volume</h4>\n<p>Containerï¼ˆå®¹å™¨ï¼‰ä¸­çš„ç£ç›˜æ–‡ä»¶æ˜¯çŸ­æš‚çš„ï¼Œå½“å®¹å™¨å´©æºƒæ—¶ï¼Œkubelet ä¼šé‡æ–°å¯åŠ¨å®¹å™¨ï¼ŒContainer ä¼šä»¥æœ€å¹²å‡€çš„çŠ¶æ€å¯åŠ¨ï¼Œæœ€åˆçš„æ–‡ä»¶å°†ä¸¢å¤±ã€‚å¦å¤–ï¼Œå½“ä¸€ä¸ª Pod è¿è¡Œå¤šä¸ª Container æ—¶ï¼Œå„ä¸ªå®¹å™¨å¯èƒ½éœ€è¦å…±äº«ä¸€äº›æ–‡ä»¶ã€‚Kubernetes Volume å¯ä»¥è§£å†³è¿™ä¸¤ä¸ªé—®é¢˜ã€‚</p>\n<ul>\n<li>ä¸€äº›éœ€è¦æŒä¹…åŒ–æ•°æ®çš„ç¨‹åºæ‰ä¼šç”¨åˆ° Volumesï¼Œæˆ–è€…ä¸€äº›éœ€è¦å…±äº«æ•°æ®çš„å®¹å™¨éœ€è¦ volumesã€‚</li>\n<li>æ—¥å¿—æ”¶é›†çš„éœ€æ±‚éœ€è¦åœ¨åº”ç”¨ç¨‹åºçš„å®¹å™¨é‡Œé¢åŠ ä¸€ä¸ª sidecarï¼Œè¿™ä¸ªå®¹å™¨æ˜¯ä¸€ä¸ªæ”¶é›†æ—¥å¿—çš„å®¹å™¨ï¼Œæ¯”å¦‚ filebeatï¼Œå®ƒé€šè¿‡ volumes å…±äº«åº”ç”¨ç¨‹åºçš„æ—¥å¿—æ–‡ä»¶ç›®å½•ã€‚</li>\n</ul>\n<h5 id=\"11-emptydirå®ç°æ•°æ®å…±äº«\"><a class=\"anchor\" href=\"#11-emptydirå®ç°æ•°æ®å…±äº«\">#</a> 1.1 EmptyDir å®ç°æ•°æ®å…±äº«</h5>\n<p>å’Œä¸Šè¿° volume ä¸åŒçš„æ˜¯ï¼Œå¦‚æœåˆ é™¤ Podï¼ŒemptyDir å·ä¸­çš„æ•°æ®ä¹Ÿå°†è¢«åˆ é™¤ï¼Œä¸€èˆ¬ emptyDir å·ç”¨äº Pod ä¸­çš„ä¸åŒ Container å…±äº«æ•°æ®ã€‚</p>\n<pre><code># cat nginx-deploy.yaml \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deploy\n  labels:\n    app: nginx-deploy\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n    spec:\n      restartPolicy: Always\n      volumes:\n        - name: share-volume\n          emptyDir: &#123;&#125;\n      containers:\n        - name: nginx\n          image: nginx:latest\n          imagePullPolicy: IfNotPresent\n          resources:\n            limits:\n              memory: 1024Mi\n              cpu: 1\n            requests:\n              memory: 128Mi\n              cpu: 100m\n          volumeMounts:\n            - name: share-volume\n              mountPath: /opt\n        - name: nginx2\n          image: nginx:latest\n          imagePullPolicy: IfNotPresent\n          resources:\n            limits:\n              memory: 1024Mi\n              cpu: 1\n            requests:\n              memory: 128Mi\n              cpu: 100m\n          command:\n            - sh\n            - '-c'\n            - sleep 3600\n          volumeMounts:\n            - name: share-volume\n              mountPath: /mnt\n</code></pre>\n<h5 id=\"12-volumes-hostpathæŒ‚è½½å®¿ä¸»æœºè·¯å¾„\"><a class=\"anchor\" href=\"#12-volumes-hostpathæŒ‚è½½å®¿ä¸»æœºè·¯å¾„\">#</a> 1.2 Volumes HostPath æŒ‚è½½å®¿ä¸»æœºè·¯å¾„</h5>\n<p>hostPath å·å¯å°†èŠ‚ç‚¹ä¸Šçš„æ–‡ä»¶æˆ–ç›®å½•æŒ‚è½½åˆ° Pod ä¸Šï¼Œç”¨äº Pod è‡ªå®šä¹‰æ—¥å¿—è¾“å‡ºæˆ–è®¿é—® Docker å†…éƒ¨çš„å®¹å™¨ç­‰ã€‚</p>\n<pre><code>[root@k8s-master01 ~]# cat nginx-deploy.yaml \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deploy\n  labels:\n    app: nginx-deploy\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n    spec:\n      restartPolicy: Always\n      volumes:\n      - name: share-volume\n        emptyDir: &#123;&#125;\n      - name: tz-config\n        hostPath:\n          path: /usr/share/zoneinfo/Asia/Shanghai\n          type: &quot;&quot;\n      - name: timezone\n        hostPath:\n          path: /etc/timezone\n          type: &quot;&quot;\n      containers:\n        - name: nginx\n          image: nginx:latest\n          imagePullPolicy: IfNotPresent\n          resources:\n            limits:\n              memory: 1024Mi\n              cpu: 1\n            requests:\n              memory: 128Mi\n              cpu: 100m\n          volumeMounts:\n          - name: share-volume\n            mountPath: /opt\n          - name: tz-config\n            mountPath: /usr/share/zoneinfo/Asia/Shanghai\n          - name: tz-config\n            mountPath: /etc/localtime\n          - name: timezone\n            mountPath: /etc/timezone\n        - name: nginx2\n          image: nginx:latest\n          imagePullPolicy: IfNotPresent\n          resources:\n            limits:\n              memory: 1024Mi\n              cpu: 1\n            requests:\n              memory: 128Mi\n              cpu: 100m\n          command:\n            - sh\n            - '-c'\n            - sleep 3600\n          volumeMounts:\n          - name: share-volume\n            mountPath: /mnt\n</code></pre>\n<p>hostPath å·å¸¸ç”¨çš„ typeï¼ˆç±»å‹ï¼‰å¦‚ä¸‹ï¼š</p>\n<ul>\n<li>type ä¸ºç©ºå­—ç¬¦ä¸²ï¼šé»˜è®¤é€‰é¡¹ï¼Œæ„å‘³ç€æŒ‚è½½ hostPath å·ä¹‹å‰ä¸ä¼šæ‰§è¡Œä»»ä½•æ£€æŸ¥ã€‚</li>\n<li>DirectoryOrCreateï¼šå¦‚æœç»™å®šçš„ path ä¸å­˜åœ¨ä»»ä½•ä¸œè¥¿ï¼Œé‚£ä¹ˆå°†æ ¹æ®éœ€è¦åˆ›å»ºä¸€ä¸ªæƒé™ä¸º 0755 çš„ç©ºç›®å½•ï¼Œå’Œ Kubelet å…·æœ‰ç›¸åŒçš„ç»„å’Œæƒé™ã€‚</li>\n<li>Directoryï¼šç›®å½•å¿…é¡»å­˜åœ¨äºç»™å®šçš„è·¯å¾„ä¸‹ã€‚</li>\n<li>FileOrCreateï¼šå¦‚æœç»™å®šçš„è·¯å¾„ä¸å­˜å‚¨ä»»ä½•å†…å®¹ï¼Œåˆ™ä¼šæ ¹æ®éœ€è¦åˆ›å»ºä¸€ä¸ªç©ºæ–‡ä»¶ï¼Œæƒé™è®¾ç½®ä¸º 0644ï¼Œå’Œ Kubelet å…·æœ‰ç›¸åŒçš„ç»„å’Œæ‰€æœ‰æƒã€‚</li>\n<li>Fileï¼šæ–‡ä»¶ï¼Œå¿…é¡»å­˜åœ¨äºç»™å®šè·¯å¾„ä¸­ã€‚</li>\n<li>Socketï¼šUNIX å¥—æ¥å­—ï¼Œå¿…é¡»å­˜åœ¨äºç»™å®šè·¯å¾„ä¸­ã€‚</li>\n<li>CharDeviceï¼šå­—ç¬¦è®¾å¤‡ï¼Œå¿…é¡»å­˜åœ¨äºç»™å®šè·¯å¾„ä¸­ã€‚</li>\n<li>BlockDeviceï¼šå—è®¾å¤‡ï¼Œå¿…é¡»å­˜åœ¨äºç»™å®šè·¯å¾„ä¸­ã€‚</li>\n</ul>\n<h5 id=\"13-æŒ‚è½½nfsè‡³å®¹å™¨\"><a class=\"anchor\" href=\"#13-æŒ‚è½½nfsè‡³å®¹å™¨\">#</a> 1.3 æŒ‚è½½ NFS è‡³å®¹å™¨</h5>\n<pre><code>#1.å®‰è£…nfs\n# yum install nfs-utils -y       \n# mkdir /data/nfs -p\n# vim /etc/exports \n/data 192.168.1.0/24(rw,no_root_squash)\n# exportfs -arv   \n# systemctl start nfs-server &amp;&amp; systemctl enable nfs-server &amp;&amp; systemctl status nfs-server \n\n#2.æµ‹è¯•å®¢æˆ·ç«¯æŒ‚è½½\n# showmount -e 192.168.1.75\n# mount -t nfs 192.168.1.75:/data/nfs /mnt\n\n#3.DeployæŒ‚è½½NFS\n[root@k8s-master01 ~]# cat nginx-deploy-nfs.yaml \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deploy\n  labels:\n    app: nginx-deploy\n  annotations:\n    app: nginx-deploy\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n      annotations:\n        app: nginx-deploy\n    spec:\n      restartPolicy: Always\n      volumes:\n      - name: nfs-volume\n        nfs:\n          server: 192.168.1.75\n          path: /data/nfs\n      - name: tz-config\n        hostPath:\n          path: /usr/share/zoneinfo/Asia/Shanghai\n          type: &quot;&quot;\n      - name: timezone\n        hostPath:\n          path: /etc/timezone\n          type: &quot;&quot;\n      containers:\n        - name: nginx-deploy\n          image: nginx:latest\n          imagePullPolicy: IfNotPresent\n          resources:\n            limits:\n              memory: 1024Mi\n              cpu: 1\n            requests:\n              memory: 128Mi\n              cpu: 100m\n          volumeMounts:\n          - name: nfs-volume\n            mountPath: /usr/share/nginx/html\n          - name: tz-config\n            mountPath: /usr/share/zoneinfo/Asia/Shanghai\n          - name: tz-config\n            mountPath: /etc/localtime\n          - name: timezone\n            mountPath: /etc/timezone\n</code></pre>\n<h4 id=\"2-pv-pvc\"><a class=\"anchor\" href=\"#2-pv-pvc\">#</a> 2. PVã€PVC</h4>\n<p>PersistentVolumeï¼šç®€ç§° PVï¼Œæ˜¯ç”± Kubernetes ç®¡ç†å‘˜è®¾ç½®çš„å­˜å‚¨ï¼Œå¯ä»¥é…ç½® Cephã€NFSã€GlusterFS ç­‰å¸¸ç”¨å­˜å‚¨é…ç½®ï¼Œç›¸å¯¹äº Volume é…ç½®ï¼Œæä¾›äº†æ›´å¤šçš„åŠŸèƒ½ï¼Œæ¯”å¦‚ç”Ÿå‘½å‘¨æœŸçš„ç®¡ç†ã€å¤§å°çš„é™åˆ¶ã€‚PV åˆ†ä¸ºé™æ€å’ŒåŠ¨æ€ã€‚</p>\n<p>PersistentVolumeClaimï¼šç®€ç§° PVCï¼Œæ˜¯å¯¹å­˜å‚¨ PV çš„è¯·æ±‚ï¼Œè¡¨ç¤ºéœ€è¦ä»€ä¹ˆç±»å‹çš„ PVï¼Œéœ€è¦å­˜å‚¨çš„æŠ€æœ¯äººå‘˜åªéœ€è¦é…ç½® PVC å³å¯ä½¿ç”¨å­˜å‚¨ï¼Œæˆ–è€… Volume é…ç½® PVC çš„åç§°å³å¯ã€‚</p>\n<h5 id=\"21-pvå›æ”¶ç­–ç•¥\"><a class=\"anchor\" href=\"#21-pvå›æ”¶ç­–ç•¥\">#</a> 2.1 PV å›æ”¶ç­–ç•¥</h5>\n<ul>\n<li>Retainï¼šä¿ç•™ï¼Œè¯¥ç­–ç•¥å…è®¸æ‰‹åŠ¨å›æ”¶èµ„æºï¼Œå½“åˆ é™¤ PVC æ—¶ï¼ŒPV ä»ç„¶å­˜åœ¨ï¼ŒPV è¢«è§†ä¸ºå·²é‡Šæ”¾ï¼Œç®¡ç†å‘˜å¯ä»¥æ‰‹åŠ¨å›æ”¶å·ã€‚</li>\n<li>Recycleï¼šå›æ”¶ï¼Œå¦‚æœ Volume æ’ä»¶æ”¯æŒï¼ŒRecycle ç­–ç•¥ä¼šå¯¹å·æ‰§è¡Œ rm -rf æ¸…ç†è¯¥ PVï¼Œå¹¶ä½¿å…¶å¯ç”¨äºä¸‹ä¸€ä¸ªæ–°çš„ PVCï¼Œä½†æ˜¯æœ¬ç­–ç•¥å°†æ¥ä¼šè¢«å¼ƒç”¨ï¼Œç›®å‰åªæœ‰ NFS å’Œ HostPath æ”¯æŒè¯¥ç­–ç•¥ã€‚</li>\n<li>Deleteï¼šåˆ é™¤ï¼Œå¦‚æœ Volume æ’ä»¶æ”¯æŒï¼Œåˆ é™¤ PVC æ—¶ä¼šåŒæ—¶åˆ é™¤ PVï¼ŒåŠ¨æ€å·é»˜è®¤ä¸º Deleteï¼Œç›®å‰æ”¯æŒ Delete çš„å­˜å‚¨åç«¯åŒ…æ‹¬ AWS EBS, GCE PD, Azure Disk, or OpenStack Cinder ç­‰ã€‚</li>\n<li>å¯ä»¥é€šè¿‡ persistentVolumeReclaimPolicy: Recycle å­—æ®µé…ç½®</li>\n</ul>\n<h5 id=\"22-pvè®¿é—®ç­–ç•¥\"><a class=\"anchor\" href=\"#22-pvè®¿é—®ç­–ç•¥\">#</a> 2.2 PV è®¿é—®ç­–ç•¥</h5>\n<ul>\n<li>ReadWriteOnceï¼šå¯ä»¥è¢«å•èŠ‚ç‚¹ä»¥è¯»å†™æ¨¡å¼æŒ‚è½½ï¼Œå‘½ä»¤è¡Œä¸­å¯ä»¥è¢«ç¼©å†™ä¸º RWOã€‚</li>\n<li>ReadOnlyManyï¼šå¯ä»¥è¢«å¤šä¸ªèŠ‚ç‚¹ä»¥åªè¯»æ¨¡å¼æŒ‚è½½ï¼Œå‘½ä»¤è¡Œä¸­å¯ä»¥è¢«ç¼©å†™ä¸º ROXã€‚</li>\n<li>ReadWriteManyï¼šå¯ä»¥è¢«å¤šä¸ªèŠ‚ç‚¹ä»¥è¯»å†™æ¨¡å¼æŒ‚è½½ï¼Œå‘½ä»¤è¡Œä¸­å¯ä»¥è¢«ç¼©å†™ä¸º RWXã€‚</li>\n<li>ReadWriteOncePod ï¼šåªå…è®¸è¢«å•ä¸ª Pod è®¿é—®ï¼Œéœ€è¦ K8s 1.22 + ä»¥ä¸Šç‰ˆæœ¬ï¼Œå¹¶ä¸”æ˜¯ CSI åˆ›å»ºçš„ PV æ‰å¯ä½¿ç”¨ï¼Œç¼©å†™ä¸º RWOP</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">Volume Plugin</th>\n<th style=\"text-align:center\">ReadWriteOnce</th>\n<th style=\"text-align:center\">ReadOnlyMany</th>\n<th style=\"text-align:center\">ReadWriteMany</th>\n<th style=\"text-align:center\">ReadWriteOncePod</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">AzureFile</td>\n<td style=\"text-align:center\">âœ“</td>\n<td style=\"text-align:center\">âœ“</td>\n<td style=\"text-align:center\">âœ“</td>\n<td style=\"text-align:center\">-</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">CephFS</td>\n<td style=\"text-align:center\">âœ“</td>\n<td style=\"text-align:center\">âœ“</td>\n<td style=\"text-align:center\">âœ“</td>\n<td style=\"text-align:center\">-</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">CSI</td>\n<td style=\"text-align:center\">depends on the driver</td>\n<td style=\"text-align:center\">depends on the driver</td>\n<td style=\"text-align:center\">depends on the driver</td>\n<td style=\"text-align:center\">depends on the driver</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">FC</td>\n<td style=\"text-align:center\">âœ“</td>\n<td style=\"text-align:center\">âœ“</td>\n<td style=\"text-align:center\">-</td>\n<td style=\"text-align:center\">-</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">FlexVolume</td>\n<td style=\"text-align:center\">âœ“</td>\n<td style=\"text-align:center\">âœ“</td>\n<td style=\"text-align:center\">depends on the driver</td>\n<td style=\"text-align:center\">-</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">HostPath</td>\n<td style=\"text-align:center\">âœ“</td>\n<td style=\"text-align:center\">-</td>\n<td style=\"text-align:center\">-</td>\n<td style=\"text-align:center\">-</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">iSCSI</td>\n<td style=\"text-align:center\">âœ“</td>\n<td style=\"text-align:center\">âœ“</td>\n<td style=\"text-align:center\">-</td>\n<td style=\"text-align:center\">-</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">NFS</td>\n<td style=\"text-align:center\">âœ“</td>\n<td style=\"text-align:center\">âœ“</td>\n<td style=\"text-align:center\">âœ“</td>\n<td style=\"text-align:center\">-</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">RBD</td>\n<td style=\"text-align:center\">âœ“</td>\n<td style=\"text-align:center\">âœ“</td>\n<td style=\"text-align:center\">-</td>\n<td style=\"text-align:center\">-</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">VsphereVolume</td>\n<td style=\"text-align:center\">âœ“</td>\n<td style=\"text-align:center\">-</td>\n<td style=\"text-align:center\">- (works when Pods are collocated)</td>\n<td style=\"text-align:center\">-</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">PortworxVolume</td>\n<td style=\"text-align:center\">âœ“</td>\n<td style=\"text-align:center\">-</td>\n<td style=\"text-align:center\">âœ“</td>\n<td style=\"text-align:center\">-</td>\n</tr>\n</tbody>\n</table>\n<h5 id=\"23-å­˜å‚¨åˆ†ç±»\"><a class=\"anchor\" href=\"#23-å­˜å‚¨åˆ†ç±»\">#</a> 2.3 å­˜å‚¨åˆ†ç±»</h5>\n<ul>\n<li>æ–‡ä»¶å­˜å‚¨ï¼šä¸€äº›æ•°æ®å¯èƒ½éœ€è¦è¢«å¤šä¸ªèŠ‚ç‚¹ä½¿ç”¨ï¼Œæ¯”å¦‚ç”¨æˆ·çš„å¤´åƒã€ç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶ç­‰ï¼Œå®ç°æ–¹å¼ï¼šNFSã€NASã€FTPã€CephFS ç­‰ã€‚</li>\n<li>å—å­˜å‚¨ï¼šä¸€äº›æ•°æ®åªèƒ½è¢«ä¸€ä¸ªèŠ‚ç‚¹ä½¿ç”¨ï¼Œæˆ–è€…æ˜¯éœ€è¦å°†ä¸€å—è£¸ç›˜æ•´ä¸ªæŒ‚è½½ä½¿ç”¨ï¼Œæ¯”å¦‚æ•°æ®åº“ã€Redis ç­‰ï¼Œå®ç°æ–¹å¼ï¼šCephã€GlusterFSã€å…¬æœ‰äº‘ã€‚</li>\n<li>å¯¹è±¡å­˜å‚¨ï¼šç”±ç¨‹åºä»£ç ç›´æ¥å®ç°çš„ä¸€ç§å­˜å‚¨æ–¹å¼ï¼Œäº‘åŸç”Ÿåº”ç”¨æ— çŠ¶æ€åŒ–å¸¸ç”¨çš„å®ç°æ–¹å¼ï¼Œå®ç°æ–¹å¼ï¼šä¸€èˆ¬æ˜¯ç¬¦åˆ S3 åè®®çš„äº‘å­˜å‚¨ï¼Œæ¯”å¦‚ AWS çš„ S3 å­˜å‚¨ã€Minioã€ä¸ƒç‰›äº‘ç­‰ã€‚</li>\n</ul>\n<h5 id=\"24-pvé…ç½®ç¤ºä¾‹nfs\"><a class=\"anchor\" href=\"#24-pvé…ç½®ç¤ºä¾‹nfs\">#</a> 2.4 PV é…ç½®ç¤ºä¾‹ NFS</h5>\n<pre><code>apiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: nfs-pv1\nspec:\n  capacity:\n    storage: 5Gi\n  volumeMode: Filesystem\n  accessModes:\n    - ReadWriteOnce\n  persistentVolumeReclaimPolicy: Retain\n  storageClassName: nfs-slow\n  nfs:\n    path: /data/pv1\n    server: 192.168.1.75\n</code></pre>\n<p>capacityï¼šå®¹é‡é…ç½®</p>\n<p>volumeModeï¼šå·çš„æ¨¡å¼ï¼Œç›®å‰æ”¯æŒ Filesystemï¼ˆæ–‡ä»¶ç³»ç»Ÿï¼‰ å’Œ Blockï¼ˆå—ï¼‰ï¼Œå…¶ä¸­ Block ç±»å‹éœ€è¦åç«¯å­˜å‚¨æ”¯æŒï¼Œé»˜è®¤ä¸ºæ–‡ä»¶ç³»ç»Ÿ</p>\n<p>accessModesï¼šè¯¥ PV çš„è®¿é—®æ¨¡å¼</p>\n<p>storageClassNameï¼šPV çš„ç±»ï¼Œä¸€ä¸ªç‰¹å®šç±»å‹çš„ PV åªèƒ½ç»‘å®šåˆ°ç‰¹å®šç±»åˆ«çš„ PVCï¼›</p>\n<p>persistentVolumeReclaimPolicyï¼šå›æ”¶ç­–ç•¥</p>\n<p>mountOptionsï¼šéå¿…é¡»ï¼Œæ–°ç‰ˆæœ¬ä¸­å·²å¼ƒç”¨</p>\n<p>nfsï¼šNFS æœåŠ¡é…ç½®ï¼ŒåŒ…æ‹¬ä»¥ä¸‹ä¸¤ä¸ªé€‰é¡¹</p>\n<ul>\n<li>pathï¼šNFS ä¸Šçš„å…±äº«ç›®å½•</li>\n<li>serverï¼šNFS çš„ IP åœ°å€</li>\n</ul>\n<h5 id=\"25-pvé…ç½®ç¤ºä¾‹hostpath\"><a class=\"anchor\" href=\"#25-pvé…ç½®ç¤ºä¾‹hostpath\">#</a> 2.5 PV é…ç½®ç¤ºä¾‹ HostPath</h5>\n<pre><code>apiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: hostpath\nspec:\n  capacity:\n    storage: 5Gi\n  volumeMode: Filesystem\n  accessModes:\n    - ReadWriteOnce\n  persistentVolumeReclaimPolicy: Retain\n  storageClassName: hostpath\n  hostPath:\n    path: &quot;/mnt/data&quot;\n</code></pre>\n<p>hostPathï¼šhostPath æœåŠ¡é…ç½®</p>\n<ul>\n<li>pathï¼šå®¿ä¸»æœºè·¯å¾„</li>\n</ul>\n<h5 id=\"26-pvçš„çŠ¶æ€\"><a class=\"anchor\" href=\"#26-pvçš„çŠ¶æ€\">#</a> 2.6 PV çš„çŠ¶æ€</h5>\n<ul>\n<li>Availableï¼šå¯ç”¨ï¼Œæ²¡æœ‰è¢« PVC ç»‘å®šçš„ç©ºé—²èµ„æºã€‚</li>\n<li>Boundï¼šå·²ç»‘å®šï¼Œå·²ç»è¢« PVC ç»‘å®šã€‚</li>\n<li>Releasedï¼šå·²é‡Šæ”¾ï¼ŒPVC è¢«åˆ é™¤ï¼Œä½†æ˜¯èµ„æºè¿˜æœªè¢«é‡æ–°ä½¿ç”¨ã€‚</li>\n<li>Failedï¼šå¤±è´¥ï¼Œè‡ªåŠ¨å›æ”¶å¤±è´¥ã€‚</li>\n</ul>\n<h5 id=\"27-pvcç»‘å®špv\"><a class=\"anchor\" href=\"#27-pvcç»‘å®špv\">#</a> 2.7 PVC ç»‘å®š PV</h5>\n<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: nfs-pvc\nspec:\n  storageClassName: nfs-slow\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 5Gi      \n</code></pre>\n<ul>\n<li>PVC çš„ç©ºé—´ç”³è¯·å¤§å°â‰¤PV çš„å¤§å°</li>\n<li>PVC çš„ StorageClassName å’Œ PV çš„ä¸€è‡´</li>\n<li>PVC çš„ accessModes å’Œ PV çš„ä¸€è‡´</li>\n</ul>\n<h5 id=\"28-depoymentæŒ‚è½½pvc\"><a class=\"anchor\" href=\"#28-depoymentæŒ‚è½½pvc\">#</a> 2.8 Depoyment æŒ‚è½½ PVC</h5>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: nginx-deploy\n  name: nginx-deploy\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n    spec:\n      volumes:\n      - name: nfs-pvc-storage  #volumeåç§°\n        persistentVolumeClaim:\n          claimName: nfs-pvc   #PVCåç§°\n      containers:\n      - image: nginx\n        name: nginx\n        volumeMounts:\n         - name: nfs-pvc-storage\n          mountPath: /usr/share/nginx/html\n</code></pre>\n<p>æŒ‚è½½ PVC çš„ Pod ä¸€ç›´å¤„äº Pendingï¼š</p>\n<ul>\n<li>PVC æ²¡æœ‰åˆ›å»ºæˆåŠŸæˆ– PVC ä¸å­˜åœ¨</li>\n<li>PVC å’Œ Pod ä¸åœ¨åŒä¸€ä¸ª Namespace</li>\n</ul>\n<p><em>æœ¬æ–‡å‡ºè‡ªäºï¼š<a href=\"https://edu.51cto.com/course/23845.html\">https://edu.51cto.com/course/23845.html</a></em></p>\n",
            "tags": [
                "Kubernetes"
            ]
        },
        {
            "id": "http://ixuyong.cn/posts/3992668367.html",
            "url": "http://ixuyong.cn/posts/3992668367.html",
            "title": "K8sé…ç½®ç®¡ç†Configmap",
            "date_published": "2025-04-14T13:47:47.000Z",
            "content_html": "<h3 id=\"k8sé…ç½®ç®¡ç†configmap\"><a class=\"anchor\" href=\"#k8sé…ç½®ç®¡ç†configmap\">#</a> K8s é…ç½®ç®¡ç† Configmap</h3>\n<h4 id=\"1-configmap\"><a class=\"anchor\" href=\"#1-configmap\">#</a> 1. Configmap</h4>\n<h5 id=\"1-1-åŸºäºfrom-env-fileåˆ›å»ºconfigmap\"><a class=\"anchor\" href=\"#1-1-åŸºäºfrom-env-fileåˆ›å»ºconfigmap\">#</a> 1. 1 åŸºäº from-env-file åˆ›å»º Configmap</h5>\n<pre><code># cat cm_env.conf \npodname=nf-flms-system\npodip=192.168.1.100\nenv=prod\nnacosaddr=nacos.svc.cluster.local\n\n#kubectl create cm cmenv --from-env-file=./cm_env.conf \n</code></pre>\n<h5 id=\"12-åŸºäºfrom-literalåˆ›å»ºconfigmap\"><a class=\"anchor\" href=\"#12-åŸºäºfrom-literalåˆ›å»ºconfigmap\">#</a> 1.2 åŸºäº from-literal åˆ›å»º Configmap</h5>\n<pre><code># kubectl create cm cmliteral --from-literal=level=INFO --from-literal=passwd=Superman*2023\n</code></pre>\n<h5 id=\"13-åŸºäºfrom-fileåˆ›å»ºconfigmap\"><a class=\"anchor\" href=\"#13-åŸºäºfrom-fileåˆ›å»ºconfigmap\">#</a> 1.3 åŸºäº from-file åˆ›å»º Configmap</h5>\n<pre><code># cat s.hmallleasing.com.conf \nserver &#123;\n    listen 80;\n    server_name s.hmallleasing.com;\n    client_max_body_size 1G; \n    location / &#123;\n        proxy_pass http://192.168.1.134;\n        proxy_set_header Host $http_host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        \n        proxy_connect_timeout 30;\n        proxy_send_timeout 60;\n        proxy_read_timeout 60;\n        \n        proxy_buffering on;\n        proxy_buffer_size 32k;\n        proxy_buffers 4 128k;\n        proxy_temp_file_write_size 10240k;\t\t\n        proxy_max_temp_file_size 10240k;\n    &#125;\n&#125;\n\nserver &#123;\n    listen 80;\n    server_name s.hmallleasing.com;\n    return 302 https://$server_name$request_uri;\n&#125;\n\n# kubectl create cm nginxconfig --from-file=./s.hmallleasing.com.conf\n</code></pre>\n<h5 id=\"14-deploymentæŒ‚è½½configmapç¤ºä¾‹\"><a class=\"anchor\" href=\"#14-deploymentæŒ‚è½½configmapç¤ºä¾‹\">#</a> 1.4 Deployment æŒ‚è½½ configmap ç¤ºä¾‹</h5>\n<pre><code>[root@k8s-master01 cm]# cat deploy.yaml \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: nginx-deploy\n  name: nginx-deploy\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n    spec:\n      imagePullSecrets:        \n      - name: harboradmin\n      containers:\n      - image: nginx\n        name: nginx\n        ports:\n        - name: http\n          containerPort: 80\n          protocol: TCP\n        envFrom:         # 1.æ‰¹é‡æŒ‚è½½ConfigMapç”Ÿæˆç¯å¢ƒå˜é‡\n        - configMapRef:\n            name: cmenv\n        env:\n        - name: MYSQL_ADDR     # 2.è‡ªå®šä¹‰ç¯å¢ƒå˜é‡\n          value: &quot;192.168.40.150&quot;\n        - name: MYSQL_PASSWD\n          value: Superman*2022\n        - name: LOG_LEVEL           # 3.æŒ‚è½½å•ä¸ªConfigMapç”Ÿæˆç¯å¢ƒå˜é‡ï¼Œè¿™é‡Œå’ŒConfigMapä¸­çš„é”®åæ˜¯ä¸ä¸€æ ·çš„     \n          valueFrom:\n            configMapKeyRef:\n              name: cmliteral       # è¿™ä¸ªå€¼æ¥è‡ªConfigMap\n              key: level            # æ¥è‡ªConfigMapçš„key\n        volumeMounts:              \n        - name: nginx-config\n          mountPath: &quot;/etc/nginx/conf.d&quot;\n          readOnly: true\n      volumes:\n      - name: nginx-config\n        configMap:\n          name: nginxconfig      # æä¾›ä½ æƒ³è¦æŒ‚è½½çš„ ConfigMap çš„åå­—\n</code></pre>\n<h5 id=\"15-é‡å‘½åæŒ‚è½½çš„configmaq-keyçš„åç§°\"><a class=\"anchor\" href=\"#15-é‡å‘½åæŒ‚è½½çš„configmaq-keyçš„åç§°\">#</a> 1.5 é‡å‘½åæŒ‚è½½çš„ configmaq key çš„åç§°</h5>\n<pre><code>[root@k8s-master01 cm]# cat deploy.yaml \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: nginx-deploy\n  name: nginx-deploy\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n    spec:\n      imagePullSecrets:        \n      - name: harboradmin\n      containers:\n      - image: nginx\n        name: nginx\n        ports:\n        - name: http\n          containerPort: 80\n          protocol: TCP\n        envFrom:         # 1.æ‰¹é‡æŒ‚è½½ConfigMapç”Ÿæˆç¯å¢ƒå˜é‡\n        - configMapRef:\n            name: cmenv\n        env:\n        - name: MYSQL_ADDR     # 2.è‡ªå®šä¹‰ç¯å¢ƒå˜é‡\n          value: &quot;192.168.40.150&quot;\n        - name: MYSQL_PASSWD\n          value: Superman*2022\n        - name: LOG_LEVEL           # 3.æŒ‚è½½å•ä¸ªConfigMapç”Ÿæˆç¯å¢ƒå˜é‡ï¼Œè¿™é‡Œå’ŒConfigMapä¸­çš„é”®åæ˜¯ä¸ä¸€æ ·çš„     \n          valueFrom:\n            configMapKeyRef:\n              name: cmliteral       # è¿™ä¸ªå€¼æ¥è‡ªConfigMap\n              key: level            # æ¥è‡ªConfigMapçš„key\n        volumeMounts:              \n        - name: nginx-config\n          mountPath: &quot;/etc/nginx/conf.d&quot;\n          readOnly: true\n      volumes:\n      - name: nginx-config\n        configMap:\n          name: nginxconfig      # æä¾›ä½ æƒ³è¦æŒ‚è½½çš„ ConfigMap çš„åå­—\n          items:                # é‡å‘½åæŒ‚è½½çš„configmaq keyçš„åç§°ä¸ºnginx.conf\n          - key: s.hmallleasing.com.conf  \n            path: nginx.conf\n \n#æŸ¥çœ‹æŒ‚è½½çš„configmaq keyçš„åç§°é‡å‘½åä¸ºnginx.conf\n[root@k8s-master01 cm]# kubectl get pods\nNAME                           READY   STATUS    RESTARTS   AGE\nnginx-deploy-bc476bc56-flln4   1/1     Running   0          10h\nnginx-deploy-bc476bc56-jhsh6   1/1     Running   0          10h\nnginx-deploy-bc476bc56-splv9   1/1     Running   0          10h\n[root@k8s-master01 cm]# kubectl exec -it nginx-deploy-bc476bc56-flln4 -- bash\nroot@nginx-deploy-bc476bc56-flln4:/# ls /etc/nginx/conf.d/\nnginx.conf\n</code></pre>\n<h5 id=\"16-ä¿®æ”¹æŒ‚è½½çš„configmaq-æƒé™\"><a class=\"anchor\" href=\"#16-ä¿®æ”¹æŒ‚è½½çš„configmaq-æƒé™\">#</a> 1.6 ä¿®æ”¹æŒ‚è½½çš„ configmaq æƒé™</h5>\n<pre><code>[root@k8s-master01 cm]# cat deploy.yaml \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: nginx-deploy\n  name: nginx-deploy\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n    spec:\n      imagePullSecrets:        \n      - name: harboradmin\n      containers:\n      - image: nginx\n        name: nginx\n        ports:\n        - name: http\n          containerPort: 80\n          protocol: TCP\n        envFrom:         # 1.æ‰¹é‡æŒ‚è½½ConfigMapç”Ÿæˆç¯å¢ƒå˜é‡\n        - configMapRef:\n            name: cmenv\n        env:\n        - name: MYSQL_ADDR     # 2.è‡ªå®šä¹‰ç¯å¢ƒå˜é‡\n          value: &quot;192.168.40.150&quot;\n        - name: MYSQL_PASSWD\n          value: Superman*2022\n        - name: LOG_LEVEL           # 3.æŒ‚è½½å•ä¸ªConfigMapç”Ÿæˆç¯å¢ƒå˜é‡ï¼Œè¿™é‡Œå’ŒConfigMapä¸­çš„é”®åæ˜¯ä¸ä¸€æ ·çš„     \n          valueFrom:\n            configMapKeyRef:\n              name: cmliteral       # è¿™ä¸ªå€¼æ¥è‡ªConfigMap\n              key: level            # æ¥è‡ªConfigMapçš„key\n        volumeMounts:              \n        - name: nginx-config\n          mountPath: &quot;/etc/nginx/conf.d&quot;\n          readOnly: true\n      volumes:\n      - name: nginx-config\n        configMap:\n          name: nginxconfig      # æä¾›ä½ æƒ³è¦æŒ‚è½½çš„ ConfigMap çš„åå­—\n          items:                # é‡å‘½åæŒ‚è½½çš„configmaq keyçš„åç§°ä¸ºnginx.conf\n          - key: s.hmallleasing.com.conf  \n            path: nginx.conf\n            mode: 0644        # é…ç½®æŒ‚è½½æƒé™ï¼Œé’ˆå¯¹å•ä¸ªkeyç”Ÿæ•ˆ\n          defaultMode: 0666   # é…ç½®æŒ‚è½½æƒé™ï¼Œé’ˆå¯¹æ•´ä¸ªkeyç”Ÿæ•ˆ\n    \n#æŸ¥çœ‹æŒ‚è½½æƒé™\nroot@nginx-deploy-7657fbffc7-k75l5:/# ls -l /etc/nginx/conf.d/nginx.conf \nlrwxrwxrwx 1 root root 17 Apr 16 13:37 /etc/nginx/conf.d/nginx.conf -&gt; ..data/nginx.conf\nroot@nginx-deploy-7657fbffc7-k75l5:/# ls -l /etc/nginx/conf.d/..data/nginx.conf \n-rw-rw-rw- 1 root root 722 Apr 16 13:37 /etc/nginx/conf.d/..data/nginx.conf\n</code></pre>\n<h5 id=\"17-subpathè§£å†³æŒ‚è½½è¦†ç›–é—®é¢˜\"><a class=\"anchor\" href=\"#17-subpathè§£å†³æŒ‚è½½è¦†ç›–é—®é¢˜\">#</a> 1.7 subpath è§£å†³æŒ‚è½½è¦†ç›–é—®é¢˜</h5>\n<pre><code>#1.åˆ›å»ºconfigmap\n[root@k8s-master01 cm]# cat nginx.conf \n\nuser  nginx;\nworker_processes  1;\n\nerror_log  /var/log/nginx/error.log warn;\npid        /var/run/nginx.pid;\n\n\nevents &#123;\n    worker_connections  512;\n&#125;\n\n\nhttp &#123;\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    log_format  main  '$remote_addr - $remote_user [$time_local] &quot;$request&quot; '\n                      '$status $body_bytes_sent &quot;$http_referer&quot; '\n                      '&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;';\n\n    access_log  /var/log/nginx/access.log  main;\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    keepalive_timeout  65;\n\n    #gzip  on;\n\n    include /etc/nginx/conf.d/*.conf;\n&#125;\n\n[root@k8s-master01 cm]# kubectl create cm nginx-config --from-file=./nginx.conf\n\n#subpathè§£å†³æŒ‚è½½è¦†ç›–é—®é¢˜\n[root@k8s-master01 study]# cat cm-deploy.yaml \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: nginx-deploy\n  name: nginx-deploy\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n    spec:\n      imagePullSecrets:        \n      - name: harboradmin\n      containers:\n      - image: nginx\n        name: nginx\n        ports:\n        - name: http\n          containerPort: 80\n          protocol: TCP\n        envFrom:         # â‘ æ‰¹é‡æŒ‚è½½ConfigMapç”Ÿæˆç¯å¢ƒå˜é‡\n        - configMapRef:\n            name: cmenv\n        env:\n        - name: MYSQL_ADDR     # â‘¡è‡ªå®šä¹‰ç¯å¢ƒå˜é‡\n          value: &quot;192.168.40.150&quot;\n        - name: MYSQL_PASSWD\n          value: Superman*2022\n        - name: LOG_LEVEL           # â‘¢æŒ‚è½½å•ä¸ªConfigMapç”Ÿæˆç¯å¢ƒå˜é‡ï¼Œè¿™é‡Œå’ŒConfigMapä¸­çš„é”®åæ˜¯ä¸ä¸€æ ·çš„     \n          valueFrom:\n            configMapKeyRef:\n              name: cmliteral       # è¿™ä¸ªå€¼æ¥è‡ªConfigMap\n              key: level            # æ¥è‡ªConfigMapçš„key\n        volumeMounts:\n        - name: config\n          mountPath: &quot;/etc/nginx/nginx.conf&quot;   #åªæŒ‚åœ¨nginx.confä¸€ä¸ªæ–‡ä»¶,ä¸è¦†ç›–ç›®å½•\n          subPath: nginx.conf      \n      volumes:\n      - name: config\n        configMap:\n          name: nginx-config      # æä¾›ä½ æƒ³è¦æŒ‚è½½çš„ConfigMapçš„åå­—\n</code></pre>\n<h4 id=\"2-secret\"><a class=\"anchor\" href=\"#2-secret\">#</a> 2. Secret</h4>\n<h5 id=\"21-secretæ‹‰å–ç§æœ‰ä»“åº“é•œåƒ\"><a class=\"anchor\" href=\"#21-secretæ‹‰å–ç§æœ‰ä»“åº“é•œåƒ\">#</a> 2.1 Secret æ‹‰å–ç§æœ‰ä»“åº“é•œåƒ</h5>\n<pre><code># kubectl create secret docker-registry harboradmin \\\n--docker-server=s.hmallleasing.com \\\n--docker-username=admin \\\n--docker-password=Superman*2023 \n</code></pre>\n<h5 id=\"22-åˆ›å»ºssl-secret\"><a class=\"anchor\" href=\"#22-åˆ›å»ºssl-secret\">#</a> 2.2 åˆ›å»º ssl Secret</h5>\n<pre><code># kubectl create secret tls dev.hmallleasig.com --key *.hmallleasing.com_key.key --cert *.hmallleasing.com_chain.crt -n dev\n</code></pre>\n<h5 id=\"23-åŸºäºå‘½ä»¤åˆ›å»ºgeneric-secret\"><a class=\"anchor\" href=\"#23-åŸºäºå‘½ä»¤åˆ›å»ºgeneric-secret\">#</a> 2.3 åŸºäºå‘½ä»¤åˆ›å»º generic Secret</h5>\n<pre><code>#1.é€šè¿‡from-env-fileåˆ›å»º\n# cat db.conf \nusername=xuyong\npasswd=Superman*2023\n\n# kubectl create secret generic dbconf --from-env-file=./db.conf\n\n#2.é€šè¿‡from-literalåˆ›å»º\nkubectl create secret generic db-user-pass \\\n    --from-literal=username=admin \\\n    --from-literal=password='S!B\\*d$zDsb='\n</code></pre>\n<h5 id=\"24-secretåŠ å¯†-è§£å¯†\"><a class=\"anchor\" href=\"#24-secretåŠ å¯†-è§£å¯†\">#</a> 2.4 Secret åŠ å¯†ã€è§£å¯†</h5>\n<pre><code>1.åŠ å¯†\n# echo -n &quot;Superman*2023&quot; | base64\nU3VwZXJtYW4qMjAyMw==\n\n2.è§£å¯†\n# echo &quot;U3VwZXJtYW4qMjAyMw==&quot; | base64 --decode\n</code></pre>\n<h5 id=\"25-åŸºäºæ–‡ä»¶åˆ›å»ºéåŠ å¯†generic-secret\"><a class=\"anchor\" href=\"#25-åŸºäºæ–‡ä»¶åˆ›å»ºéåŠ å¯†generic-secret\">#</a> 2.5 åŸºäºæ–‡ä»¶åˆ›å»ºéåŠ å¯† generic Secret</h5>\n<pre><code># kubectl get secret dbconf -oyaml\napiVersion: v1\ndata:\n  passwd: U3VwZXJtYW4qMjAyMw==\n  username: eHV5b25n\nkind: Secret\nmetadata:\n  name: dbconf\n  namespace: default\ntype: Opaque\n</code></pre>\n<h5 id=\"2-6-åŸºäºyamlåˆ›å»ºåŠ å¯†generic-secret\"><a class=\"anchor\" href=\"#2-6-åŸºäºyamlåˆ›å»ºåŠ å¯†generic-secret\">#</a> 2. 6 åŸºäº yaml åˆ›å»ºåŠ å¯† generic Secret</h5>\n<pre><code># cat mysql-secret.yaml \napiVersion: v1\nkind: Secret\nmetadata:\n  name: mysql-secret\n  namespace: dev\nstringData:\n  MYSQL_ROOT_PASSWORD: Superman*2023\ntype: Opaque\n</code></pre>\n<h5 id=\"27-deploymentæŒ‚è½½secretç¤ºä¾‹\"><a class=\"anchor\" href=\"#27-deploymentæŒ‚è½½secretç¤ºä¾‹\">#</a> 2.7 Deployment æŒ‚è½½ Secret ç¤ºä¾‹</h5>\n<pre><code>[root@k8s-master01 study]# cat cm-deploy.yaml \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: nginx-deploy\n  name: nginx-deploy\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n    spec:\n      imagePullSecrets:        \n      - name: harboradmin\n      containers:\n      - image: nginx\n        name: nginx\n        ports:\n        - name: http\n          containerPort: 80\n          protocol: TCP\n        - name: MYSQL_ROOT_PASSWORD  \n          valueFrom:\n            secretKeyRef:\n              name: mysql-secret\n              key: MYSQL_ROOT_PASSWORD\n</code></pre>\n<h4 id=\"3-configmapsecretçƒ­æ›´æ–°\"><a class=\"anchor\" href=\"#3-configmapsecretçƒ­æ›´æ–°\">#</a> 3. ConfigMap&amp;Secret çƒ­æ›´æ–°</h4>\n<pre><code># kubectl create cm nginxconfig --from-file=nginx.conf --dry-run=client -oyaml | kubectl replace -f -\n</code></pre>\n<p><em>æœ¬æ–‡å‡ºè‡ªäºï¼š<a href=\"https://edu.51cto.com/course/23845.html\">https://edu.51cto.com/course/23845.html</a></em></p>\n",
            "tags": [
                "Kubernetes"
            ]
        },
        {
            "id": "http://ixuyong.cn/posts/858611107.html",
            "url": "http://ixuyong.cn/posts/858611107.html",
            "title": "K8sæœåŠ¡å‘å¸ƒService",
            "date_published": "2025-04-14T11:25:51.000Z",
            "content_html": "<h3 id=\"k8sæœåŠ¡å‘å¸ƒservice\"><a class=\"anchor\" href=\"#k8sæœåŠ¡å‘å¸ƒservice\">#</a> K8s æœåŠ¡å‘å¸ƒ Service</h3>\n<h4 id=\"1-serviceç±»å‹\"><a class=\"anchor\" href=\"#1-serviceç±»å‹\">#</a> 1. Service ç±»å‹</h4>\n<p>Kubernetes Service Typeï¼ˆæœåŠ¡ç±»å‹ï¼‰ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ç§ï¼š</p>\n<ul>\n<li>ClusterIPï¼šåœ¨é›†ç¾¤å†…éƒ¨ä½¿ç”¨ï¼Œé»˜è®¤å€¼ï¼Œåªèƒ½ä»é›†ç¾¤ä¸­è®¿é—®ã€‚</li>\n<li>NodePortï¼šåœ¨æ‰€æœ‰å®‰è£…äº† Kube-Proxy çš„èŠ‚ç‚¹ä¸Šæ‰“å¼€ä¸€ä¸ªç«¯å£ï¼Œæ­¤ç«¯å£å¯ä»¥ä»£ç†è‡³åç«¯ Podï¼Œå¯ä»¥é€šè¿‡ NodePort ä»é›†ç¾¤å¤–éƒ¨è®¿é—®é›†ç¾¤å†…çš„æœåŠ¡ï¼Œæ ¼å¼ä¸º NodeIP:NodePortã€‚</li>\n<li>LoadBalancerï¼šä½¿ç”¨äº‘æä¾›å•†çš„è´Ÿè½½å‡è¡¡å™¨å…¬å¼€æœåŠ¡ï¼Œæˆæœ¬è¾ƒé«˜ã€‚</li>\n<li>ExternalNameï¼šé€šè¿‡è¿”å›å®šä¹‰çš„ CNAME åˆ«åï¼Œæ²¡æœ‰è®¾ç½®ä»»ä½•ç±»å‹çš„ä»£ç†ï¼Œéœ€è¦ 1.7 æˆ–æ›´é«˜ç‰ˆæœ¬ kube-dns æ”¯æŒã€‚</li>\n</ul>\n<h5 id=\"11-nodeportç±»å‹\"><a class=\"anchor\" href=\"#11-nodeportç±»å‹\">#</a> 1.1 NodePort ç±»å‹</h5>\n<p>å¦‚æœå°† Service çš„ type å­—æ®µè®¾ç½®ä¸º NodePortï¼Œåˆ™ Kubernetes å°†ä» --service-node-port-range å‚æ•°æŒ‡å®šçš„èŒƒå›´ï¼ˆé»˜è®¤ä¸º 30000-32767ï¼‰ä¸­è‡ªåŠ¨åˆ†é…ç«¯å£ï¼Œä¹Ÿå¯ä»¥æ‰‹åŠ¨æŒ‡å®š NodePortï¼Œåˆ›å»ºè¯¥ Service åï¼Œé›†ç¾¤æ¯ä¸ªèŠ‚ç‚¹éƒ½å°†æš´éœ²ä¸€ä¸ªç«¯å£ï¼Œé€šè¿‡æŸä¸ªå®¿ä¸»æœºçš„ IP + ç«¯å£å³å¯è®¿é—®åˆ°åç«¯çš„åº”ç”¨ã€‚</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: nginx-svc\n  namespace: default\n  labels:\n    app: nginx-svc\nspec:\n  ports:\n    - port: 80\n      targetPort: 80\n      protocol: TCP\n      name: http\n  selector:\n    app: nginx\n  type: NodePort\n</code></pre>\n<h5 id=\"12-clusteripç±»å‹\"><a class=\"anchor\" href=\"#12-clusteripç±»å‹\">#</a> 1.2 ClusterIP ç±»å‹</h5>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: nginx-svc\n  namespace: default\n  labels:\n    app: nginx-svc\nspec:\n  ports:\n    - port: 80\n      targetPort: 80\n      protocol: TCP\n      name: http\n  selector:\n    app: nginx\n  type: ClusterIP\n</code></pre>\n<h5 id=\"13-ä½¿ç”¨serviceä»£ç†k8så¤–éƒ¨æœåŠ¡\"><a class=\"anchor\" href=\"#13-ä½¿ç”¨serviceä»£ç†k8så¤–éƒ¨æœåŠ¡\">#</a> 1.3 ä½¿ç”¨ Service ä»£ç† K8s å¤–éƒ¨æœåŠ¡</h5>\n<p>ä½¿ç”¨åœºæ™¯ï¼š</p>\n<ul>\n<li>å¸Œæœ›åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨æŸä¸ªå›ºå®šçš„åç§°è€Œé IP åœ°å€è®¿é—®å¤–éƒ¨çš„ä¸­é—´ä»¶æœåŠ¡ï¼›</li>\n<li>å¸Œæœ› Service æŒ‡å‘å¦ä¸€ä¸ª Namespace ä¸­æˆ–å…¶ä»–é›†ç¾¤ä¸­çš„æœåŠ¡ï¼›</li>\n<li>æ­£åœ¨å°†å·¥ä½œè´Ÿè½½è½¬ç§»åˆ° Kubernetes é›†ç¾¤ï¼Œä½†æ˜¯ä¸€éƒ¨åˆ†æœåŠ¡ä»è¿è¡Œåœ¨ Kubernetes é›†ç¾¤ä¹‹å¤–çš„ backendã€‚</li>\n</ul>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app: mysql-svc-external\n  name: mysql-svc-external\nspec:\n  clusterIP: None\n  ports:\n  - name: mysql\n    port: 3306 \n    protocol: TCP\n    targetPort: 3306\n  type: ClusterIP\n---\napiVersion: v1\nkind: Endpoints\nmetadata:\n  labels:\n    app: mysql-svc-external\n  name: mysql-svc-external\nsubsets:\n- addresses:\n  - ip: 192.168.40.150\n  ports:\n  - name: mysql\n    port: 3306\n    protocol: TCP\n</code></pre>\n<h5 id=\"14-externalname-service\"><a class=\"anchor\" href=\"#14-externalname-service\">#</a> 1.4 ExternalName Service</h5>\n<p>ExternalName Service æ˜¯ Service çš„ç‰¹ä¾‹ï¼Œå®ƒæ²¡æœ‰ Selectorï¼Œä¹Ÿæ²¡æœ‰å®šä¹‰ä»»ä½•ç«¯å£å’Œ Endpointï¼Œå®ƒé€šè¿‡è¿”å›è¯¥å¤–éƒ¨æœåŠ¡çš„åˆ«åæ¥æä¾›æœåŠ¡ã€‚</p>\n<p>æ¯”å¦‚å¯ä»¥å®šä¹‰ä¸€ä¸ª Serviceï¼Œåç«¯è®¾ç½®ä¸ºä¸€ä¸ªå¤–éƒ¨åŸŸåï¼Œè¿™æ ·é€šè¿‡ Service çš„åç§°å³å¯è®¿é—®åˆ°è¯¥åŸŸåã€‚ä½¿ç”¨ nslookup è§£æä»¥ä¸‹æ–‡ä»¶å®šä¹‰çš„ Serviceï¼Œé›†ç¾¤çš„ DNS <a href=\"http://xn--my-uu2cmg2cx7mswf9rko5lsx1a5n3h.database.example.com\">æœåŠ¡å°†è¿”å›ä¸€ä¸ªå€¼ä¸º my.database.example.com</a> çš„ CNAME è®°å½•ï¼š</p>\n<pre><code>kind: Service\napiVersion: v1\nmetadata:\n  name: my-service\n  namespace: prod\nspec:\n  type: ExternalName\n  externalName: my.database.example.com\n</code></pre>\n<h5 id=\"15-å¤šç«¯å£-service\"><a class=\"anchor\" href=\"#15-å¤šç«¯å£-service\">#</a> 1.5 å¤šç«¯å£ Service</h5>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: nginx-svc\n  namespace: default\n  labels:\n    app: nginx-svc\nspec:\n  ports:\n    - port: 80\n      targetPort: 80\n      protocol: TCP\n      name: http\n    - port: 443\n      targetPort: 443\n      protocol: TCP\n      name: https\n  selector:\n    app: nginx\n  type: ClusterIP\n</code></pre>\n<p><em>æœ¬æ–‡å‡ºè‡ªäºï¼š<a href=\"https://edu.51cto.com/course/23845.html\">https://edu.51cto.com/course/23845.html</a></em></p>\n",
            "tags": [
                "Kubernetes"
            ]
        },
        {
            "id": "http://ixuyong.cn/posts/108692210.html",
            "url": "http://ixuyong.cn/posts/108692210.html",
            "title": "K8sèµ„æºè°ƒåº¦deploymentã€statefulsetã€daemonset",
            "date_published": "2025-04-14T11:25:00.000Z",
            "content_html": "<h3 id=\"k8sèµ„æºè°ƒåº¦deployment-statefulset-daemonset\"><a class=\"anchor\" href=\"#k8sèµ„æºè°ƒåº¦deployment-statefulset-daemonset\">#</a> K8s èµ„æºè°ƒåº¦ deploymentã€statefulsetã€daemonset</h3>\n<h4 id=\"1-æ— çŠ¶æ€åº”ç”¨ç®¡ç†-deployment\"><a class=\"anchor\" href=\"#1-æ— çŠ¶æ€åº”ç”¨ç®¡ç†-deployment\">#</a> 1. æ— çŠ¶æ€åº”ç”¨ç®¡ç† Deployment</h4>\n<pre><code>[root@k8s-master01 ~]# cat nginx-deploy.yaml \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deploy\n  labels:\n    app: nginx-deploy\n  annotations:\n    app: nginx-deploy\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n    spec:\n      containers:\n        - name: nginx-deploy\n          image: nginx:1.21.0\n          imagePullPolicy: IfNotPresent\n      restartPolicy: Always\n</code></pre>\n<p>ç¤ºä¾‹è§£æï¼š</p>\n<ol>\n<li>\n<p>nginx-deployï¼šDeployment çš„åç§°ï¼›</p>\n</li>\n<li>\n<p>replicasï¼š åˆ›å»º Pod çš„å‰¯æœ¬æ•°ï¼›</p>\n</li>\n<li>\n<p>selectorï¼šå®šä¹‰ Deployment å¦‚ä½•æ‰¾åˆ°è¦ç®¡ç†çš„ Podï¼Œä¸ template çš„ labelï¼ˆæ ‡ç­¾ï¼‰å¯¹åº”ï¼ŒapiVersion ä¸º apps/v1 å¿…é¡»æŒ‡å®šè¯¥å­—æ®µï¼›</p>\n</li>\n<li>\n<p>template å­—æ®µåŒ…å«ä»¥ä¸‹å­—æ®µï¼š</p>\n<ul>\n<li>\n<p>app: nginx-deploy ä½¿ç”¨ labelï¼ˆæ ‡ç­¾ï¼‰æ ‡è®° Podï¼›</p>\n</li>\n<li>\n<p>specï¼šè¡¨ç¤º Pod è¿è¡Œä¸€ä¸ªåå­—ä¸º nginx çš„å®¹å™¨ï¼›</p>\n</li>\n<li>\n<p>imageï¼šè¿è¡Œæ­¤ Pod ä½¿ç”¨çš„é•œåƒï¼›</p>\n</li>\n<li>\n<p>Portï¼šå®¹å™¨ç”¨äºå‘é€å’Œæ¥æ”¶æµé‡çš„ç«¯å£ã€‚</p>\n</li>\n</ul>\n</li>\n</ol>\n<h5 id=\"11-æ›´æ–°-deployment\"><a class=\"anchor\" href=\"#11-æ›´æ–°-deployment\">#</a> 1.1 æ›´æ–° Deployment</h5>\n<p>å‡å¦‚æ›´æ–° Nginx Pod çš„ image ä½¿ç”¨ nginx:latestï¼Œå¹¶ä½¿ç”¨ --record è®°å½•å½“å‰æ›´æ”¹çš„å‚æ•°ï¼ŒåæœŸå›æ»šæ—¶å¯ä»¥æŸ¥çœ‹åˆ°å¯¹åº”çš„ä¿¡æ¯ï¼š</p>\n<pre><code>[root@k8s-master01 ~]# kubectl set image deployment nginx-deploy nginx-deploy=nginx:latest --record\n</code></pre>\n<p>æ›´æ–°è¿‡ç¨‹ä¸ºæ–°æ—§äº¤æ›¿æ›´æ–°ï¼Œé¦–å…ˆæ–°å»ºä¸€ä¸ª Podï¼Œå½“ Pod çŠ¶æ€ä¸º Running æ—¶ï¼Œåˆ é™¤ä¸€ä¸ªæ—§çš„ Podï¼ŒåŒæ—¶å†åˆ›å»ºä¸€ä¸ªæ–°çš„ Podã€‚å½“è§¦å‘ä¸€ä¸ªæ›´æ–°åï¼Œä¼šæœ‰æ–°çš„ ReplicaSet äº§ç”Ÿï¼Œæ—§çš„ ReplicaSet ä¼šè¢«ä¿å­˜ï¼ŒæŸ¥çœ‹æ­¤æ—¶ ReplicaSetï¼Œå¯ä»¥ä» AGE æˆ– READY çœ‹å‡ºæ¥æ–°æ—§ ReplicaSetï¼š</p>\n<pre><code>[root@k8s-master01 ~]# kubectl get rs\nNAME                      DESIRED   CURRENT   READY   AGE\nnginx-deploy-65bfb77869   0         0         0       50s\nnginx-deploy-85b94dddb4   3         3         3       8s\n</code></pre>\n<p>é€šè¿‡ describe æŸ¥çœ‹ Deployment çš„è¯¦ç»†ä¿¡æ¯ï¼š</p>\n<pre><code>[root@k8s-master01 ~]#  kubectl describe deploy nginx-deploy\nName:                   nginx-deploy\nNamespace:              default\nCreationTimestamp:      Mon, 14 Apr 2025 11:28:03 +0800\nLabels:                 app=nginx-deploy\nAnnotations:            app: nginx-deploy\n                        deployment.kubernetes.io/revision: 2\n                        kubernetes.io/change-cause: kubectl set image deployment nginx-deploy nginx-deploy=nginx:latest --record=true\nSelector:               app=nginx-deploy\nReplicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable\nStrategyType:           RollingUpdate\nMinReadySeconds:        0\nRollingUpdateStrategy:  25% max unavailable, 25% max surge\nPod Template:\n  Labels:  app=nginx-deploy\n  Containers:\n   nginx-deploy:\n    Image:         nginx:latest\n    Port:          &lt;none&gt;\n    Host Port:     &lt;none&gt;\n    Environment:   &lt;none&gt;\n    Mounts:        &lt;none&gt;\n  Volumes:         &lt;none&gt;\n  Node-Selectors:  &lt;none&gt;\n  Tolerations:     &lt;none&gt;\nConditions:\n  Type           Status  Reason\n  ----           ------  ------\n  Available      True    MinimumReplicasAvailable\n  Progressing    True    NewReplicaSetAvailable\nOldReplicaSets:  nginx-deploy-65bfb77869 (0/0 replicas created)\nNewReplicaSet:   nginx-deploy-85b94dddb4 (3/3 replicas created)\nEvents:\n  Type    Reason             Age   From                   Message\n  ----    ------             ----  ----                   -------\n  Normal  ScalingReplicaSet  71s   deployment-controller  Scaled up replica set nginx-deploy-65bfb77869 from 0 to 3\n  Normal  ScalingReplicaSet  29s   deployment-controller  Scaled up replica set nginx-deploy-85b94dddb4 from 0 to 1\n  Normal  ScalingReplicaSet  28s   deployment-controller  Scaled down replica set nginx-deploy-65bfb77869 from 3 to 2\n  Normal  ScalingReplicaSet  28s   deployment-controller  Scaled up replica set nginx-deploy-85b94dddb4 from 1 to 2\n  Normal  ScalingReplicaSet  27s   deployment-controller  Scaled down replica set nginx-deploy-65bfb77869 from 2 to 1\n  Normal  ScalingReplicaSet  27s   deployment-controller  Scaled up replica set nginx-deploy-85b94dddb4 from 2 to 3\n  Normal  ScalingReplicaSet  26s   deployment-controller  Scaled down replica set nginx-deploy-65bfb77869 from 1 to 0\n</code></pre>\n<p>åœ¨ describe ä¸­å¯ä»¥çœ‹å‡ºï¼Œç¬¬ä¸€æ¬¡åˆ›å»ºæ—¶ï¼Œå®ƒåˆ›å»ºäº†ä¸€ä¸ªåä¸º nginx-deploy-65bfb77869 çš„ ReplicaSetï¼Œå¹¶ç›´æ¥å°†å…¶æ‰©å±•ä¸º 3 ä¸ªå‰¯æœ¬ã€‚æ›´æ–°éƒ¨ç½²æ—¶ï¼Œå®ƒåˆ›å»ºäº†ä¸€ä¸ªæ–°çš„ ReplicaSetï¼Œå‘½åä¸º nginx-deploy-85b94dddb4ï¼Œå¹¶å°†å…¶å‰¯æœ¬æ•°æ‰©å±•ä¸º 1ï¼Œç„¶åå°†æ—§çš„ ReplicaSet ç¼©å°ä¸º 2ï¼Œè¿™æ ·è‡³å°‘å¯ä»¥æœ‰ 2 ä¸ª Pod å¯ç”¨ï¼Œæœ€å¤šåˆ›å»ºäº† 4 ä¸ª Podã€‚ä»¥æ­¤ç±»æ¨ï¼Œä½¿ç”¨ç›¸åŒçš„æ»šåŠ¨æ›´æ–°ç­–ç•¥å‘ä¸Šå’Œå‘ä¸‹æ‰©å±•æ–°æ—§ ReplicaSetï¼Œæœ€ç»ˆæ–°çš„ ReplicaSet å¯ä»¥æ‹¥æœ‰ 3 ä¸ªå‰¯æœ¬ï¼Œå¹¶å°†æ—§çš„ ReplicaSet ç¼©å°ä¸º 0ã€‚</p>\n<h5 id=\"12-å›æ»š-deployment\"><a class=\"anchor\" href=\"#12-å›æ»š-deployment\">#</a> 1.2 å›æ»š Deployment</h5>\n<p>å½“æ›´æ–°äº†ç‰ˆæœ¬ä¸ç¨³å®šæˆ–é…ç½®ä¸åˆç†æ—¶ï¼Œå¯ä»¥å¯¹å…¶è¿›è¡Œå›æ»šæ“ä½œï¼Œå‡è®¾æˆ‘ä»¬åˆè¿›è¡Œäº†å‡ æ¬¡æ›´æ–°ï¼ˆæ­¤å¤„ä»¥æ›´æ–°é•œåƒç‰ˆæœ¬è§¦å‘æ›´æ–°ï¼Œæ›´æ”¹é…ç½®æ•ˆæœç±»ä¼¼ï¼‰ï¼š</p>\n<pre><code># kubectl set image deployment nginx-deploy nginx-deploy=nginx:1.21.1 --record\n# kubectl set image deployment nginx-deploy nginx-deploy=nginx:1.21.2 --record\n</code></pre>\n<p>ä½¿ç”¨ kubectl rollout history æŸ¥çœ‹æ›´æ–°å†å²ï¼š</p>\n<pre><code>[root@k8s-master01 ~]# kubectl rollout history deployment nginx-deploy\ndeployment.apps/nginx-deploy \nREVISION  CHANGE-CAUSE\n1         &lt;none&gt;\n2         kubectl set image deployment nginx-deploy nginx-deploy=nginx:latest --record=true\n3         kubectl set image deployment nginx-deploy nginx-deploy=nginx:1.21.1 --record=true\n4         kubectl set image deployment nginx-deploy nginx-deploy=nginx:1.21.2 --record=true\n</code></pre>\n<p>æŸ¥çœ‹ Deployment æŸæ¬¡æ›´æ–°çš„è¯¦ç»†ä¿¡æ¯ï¼Œä½¿ç”¨ --revision æŒ‡å®šæŸæ¬¡æ›´æ–°ç‰ˆæœ¬å·ï¼š</p>\n<pre><code># kubectl rollout history deployment nginx-deploy --revision=4\ndeployment.apps/nginx-deploy with revision #4\nPod Template:\n  Labels:\tapp=nginx-deploy\n\tpod-template-hash=65b576b795\n  Annotations:\tkubernetes.io/change-cause: kubectl set image deployment nginx-deploy nginx-deploy=nginx:1.21.2 --record=true\n  Containers:\n   nginx-deploy:\n    Image:\tnginx:1.21.2\n    Port:\t&lt;none&gt;\n    Host Port:\t&lt;none&gt;\n    Environment:\t&lt;none&gt;\n    Mounts:\t&lt;none&gt;\n  Volumes:\t&lt;none&gt;\n  Node-Selectors:\t&lt;none&gt;\n  Tolerations:\t&lt;none&gt;\n</code></pre>\n<p>å¦‚æœåªéœ€è¦å›æ»šåˆ°ä¸Šä¸€ä¸ªç¨³å®šç‰ˆæœ¬ï¼Œä½¿ç”¨ kubectl rollout undo å³å¯ï¼š</p>\n<pre><code># kubectl rollout undo deployment nginx-deploy\n</code></pre>\n<p>å†æ¬¡æŸ¥çœ‹æ›´æ–°å†å²ï¼Œå‘ç° REVISION3 å›åˆ°äº† nginx:1.21.1ï¼š</p>\n<pre><code># kubectl rollout history deployment nginx-deploy\ndeployment.apps/nginx-deploy \nREVISION  CHANGE-CAUSE\n1         &lt;none&gt;\n2         kubectl set image deployment nginx-deploy nginx-deploy=nginx:latest --record=true\n4         kubectl set image deployment nginx-deploy nginx-deploy=nginx:1.21.2 --record=true\n5         kubectl set image deployment nginx-deploy nginx-deploy=nginx:1.21.1 --record=true\n</code></pre>\n<p>å¦‚æœè¦å›æ»šåˆ°æŒ‡å®šç‰ˆæœ¬ï¼Œä½¿ç”¨ --to-revision å‚æ•°ï¼š</p>\n<pre><code># kubectl rollout undo deployment nginx-deploy --to-revision=2\n</code></pre>\n<h5 id=\"13-æ‰©å®¹-deployment\"><a class=\"anchor\" href=\"#13-æ‰©å®¹-deployment\">#</a> 1.3 æ‰©å®¹ Deployment</h5>\n<p>å½“å…¬å¸è®¿é—®é‡å˜å¤§ï¼Œæˆ–è€…æœ‰é¢„æœŸå†…çš„æ´»åŠ¨æ—¶ï¼Œä¸‰ä¸ª Pod å¯èƒ½å·²æ— æ³•æ”¯æ’‘ä¸šåŠ¡æ—¶ï¼Œå¯ä»¥æå‰å¯¹å…¶è¿›è¡Œæ‰©å±•ã€‚</p>\n<p>ä½¿ç”¨ kubectl scale åŠ¨æ€è°ƒæ•´ Pod çš„å‰¯æœ¬æ•°ï¼Œæ¯”å¦‚å¢åŠ  Pod ä¸º 5 ä¸ªï¼š</p>\n<pre><code># kubectl scale deployment nginx-deploy --replicas=5\n</code></pre>\n<p>æŸ¥çœ‹ Podï¼Œæ­¤æ—¶ Pod å·²ç»å˜æˆäº† 5 ä¸ªï¼š</p>\n<pre><code># kubectl get pods\nNAME                            READY   STATUS    RESTARTS   AGE\nnginx-deploy-85b94dddb4-2qrh6   1/1     Running   0          2m9s\nnginx-deploy-85b94dddb4-gvkqj   1/1     Running   0          2m10s\nnginx-deploy-85b94dddb4-mdfjs   1/1     Running   0          22s\nnginx-deploy-85b94dddb4-rhgpr   1/1     Running   0          2m8s\nnginx-deploy-85b94dddb4-vwjhl   1/1     Running   0          22s\n</code></pre>\n<h5 id=\"14-æš‚åœå’Œæ¢å¤-deployment-æ›´æ–°\"><a class=\"anchor\" href=\"#14-æš‚åœå’Œæ¢å¤-deployment-æ›´æ–°\">#</a> 1.4 æš‚åœå’Œæ¢å¤ Deployment æ›´æ–°</h5>\n<p>ä¸Šè¿°æ¼”ç¤ºçš„å‡ä¸ºæ›´æ”¹æŸä¸€å¤„çš„é…ç½®ï¼Œæ›´æ”¹åç«‹å³è§¦å‘æ›´æ–°ï¼Œå¤§å¤šæ•°æƒ…å†µä¸‹å¯èƒ½éœ€è¦é’ˆå¯¹ä¸€ä¸ªèµ„æºæ–‡ä»¶æ›´æ”¹å¤šå¤„åœ°æ–¹ï¼Œè€Œå¹¶ä¸éœ€è¦å¤šæ¬¡è§¦å‘æ›´æ–°ï¼Œæ­¤æ—¶å¯ä»¥ä½¿ç”¨ Deployment æš‚åœåŠŸèƒ½ï¼Œä¸´æ—¶ç¦ç”¨æ›´æ–°æ“ä½œï¼Œå¯¹ Deployment è¿›è¡Œå¤šæ¬¡ä¿®æ”¹ååœ¨è¿›è¡Œæ›´æ–°ã€‚</p>\n<p>ä½¿ç”¨ kubectl rollout pause å‘½ä»¤å³å¯æš‚åœ Deployment æ›´æ–°ï¼š</p>\n<pre><code># kubectl rollout pause deployment nginx-deploy\n</code></pre>\n<p>ç„¶åå¯¹ Deployment è¿›è¡Œç›¸å…³æ›´æ–°æ“ä½œï¼Œæ¯”å¦‚å…ˆæ›´æ–°é•œåƒï¼Œç„¶åå¯¹å…¶èµ„æºè¿›è¡Œé™åˆ¶ï¼ˆå¦‚æœä½¿ç”¨çš„æ˜¯ kubectl edit å‘½ä»¤ï¼Œå¯ä»¥ç›´æ¥è¿›è¡Œå¤šæ¬¡ä¿®æ”¹ï¼Œæ— éœ€æš‚åœæ›´æ–°ï¼Œkubectlset å‘½ä»¤ä¸€èˆ¬ä¼šé›†æˆåœ¨ CICD æµæ°´çº¿ä¸­ï¼‰ï¼š</p>\n<pre><code># kubectl set image deployment nginx-deploy nginx-deploy=nginx:1.21.3\n# kubectl set resources deployment nginx-deploy -c=nginx-deploy --limits=cpu=200m,memory=512Mi\n</code></pre>\n<p>é€šè¿‡ rollout history å¯ä»¥çœ‹åˆ°æ²¡æœ‰æ–°çš„æ›´æ–°ï¼š</p>\n<pre><code>#  kubectl rollout history deployment nginx-deploy\n</code></pre>\n<p>è¿›è¡Œå®Œæœ€åä¸€å¤„é…ç½®æ›´æ”¹åï¼Œä½¿ç”¨ kubectl rollout resume æ¢å¤ Deployment æ›´æ–°ï¼š</p>\n<pre><code># kubectl rollout resume deployment nginx-deploy\n</code></pre>\n<p>å¯ä»¥æŸ¥çœ‹åˆ°æ¢å¤æ›´æ–°çš„ Deployment åˆ›å»ºäº†ä¸€ä¸ªæ–°çš„ RSï¼ˆReplicaSet ç¼©å†™ï¼‰ï¼š</p>\n<pre><code># kubectl get rs\n</code></pre>\n<p>å¯ä»¥æŸ¥çœ‹ Deployment çš„ imageï¼ˆé•œåƒï¼‰å·²ç»å˜ä¸º nginx:1.21.3</p>\n<pre><code>[root@k8s-master01 ~]# kubectl get pods -oyaml|grep image\n    - image: nginx:1.21.3\n      imagePullPolicy: IfNotPresent\n      image: docker.io/library/nginx:1.21.3\n      imageID: docker.io/library/nginx@sha256:644a70516a26004c97d0d85c7fe1d0c3a67ea8ab7ddf4aff193d9f301670cf36\n    - image: nginx:1.21.3\n      imagePullPolicy: IfNotPresent\n      image: docker.io/library/nginx:1.21.3\n      imageID: docker.io/library/nginx@sha256:644a70516a26004c97d0d85c7fe1d0c3a67ea8ab7ddf4aff193d9f301670cf36\n    - image: nginx:1.21.3\n      imagePullPolicy: IfNotPresent\n      image: docker.io/library/nginx:1.21.3\n      imageID: docker.io/library/nginx@sha256:644a70516a26004c97d0d85c7fe1d0c3a67ea8ab7ddf4aff193d9f301670cf36\n    - image: nginx:1.21.3\n      imagePullPolicy: IfNotPresent\n      image: docker.io/library/nginx:1.21.3\n      imageID: docker.io/library/nginx@sha256:644a70516a26004c97d0d85c7fe1d0c3a67ea8ab7ddf4aff193d9f301670cf36\n    - image: nginx:1.21.3\n      imagePullPolicy: IfNotPresent\n      image: docker.io/library/nginx:1.21.3\n      imageID: docker.io/library/nginx@sha256:644a70516a26004c97d0d85c7fe1d0c3a67ea8ab7ddf4aff193d9f301670cf36\n</code></pre>\n<h5 id=\"15-æ›´æ–°-deployment-çš„æ³¨æ„äº‹é¡¹\"><a class=\"anchor\" href=\"#15-æ›´æ–°-deployment-çš„æ³¨æ„äº‹é¡¹\">#</a> 1.5 æ›´æ–° Deployment çš„æ³¨æ„äº‹é¡¹</h5>\n<p>åœ¨é»˜è®¤æƒ…å†µä¸‹ï¼Œrevision ä¿ç•™ 10 ä¸ªæ—§çš„ ReplicaSetï¼Œå…¶ä½™çš„å°†åœ¨åå°è¿›è¡Œåƒåœ¾å›æ”¶ï¼Œå¯ä»¥åœ¨.spec.revisionHistoryLimit è®¾ç½®ä¿ç•™ ReplicaSet çš„ä¸ªæ•°ã€‚å½“è®¾ç½®ä¸º 0 æ—¶ï¼Œä¸ä¿ç•™å†å²è®°å½•ã€‚</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deploy\n  namespace: default\n  labels:\n    app: nginx-deploy\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n    spec:\n      containers:\n        - name: nginx-deploy\n          image: nginx:1.21.3\n          resources:\n            limits:\n              cpu: 200m\n              memory: 512Mi\n          imagePullPolicy: IfNotPresent\n      restartPolicy: Always\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 25%\n      maxSurge: 25%\n  revisionHistoryLimit: 10\n</code></pre>\n<p>æ›´æ–°ç­–ç•¥ï¼š</p>\n<ul>\n<li>spec.strategy.type==Recreateï¼Œè¡¨ç¤ºé‡å»ºï¼Œå…ˆåˆ æ‰æ—§çš„ Pod å†åˆ›å»ºæ–°çš„ Podï¼›</li>\n</ul>\n<pre><code>  strategy:\n    type: Recreate\n</code></pre>\n<ul>\n<li>\n<p>spec.strategy.type==RollingUpdateï¼Œè¡¨ç¤ºæ»šåŠ¨æ›´æ–°ï¼Œå¯ä»¥æŒ‡å®š maxUnavailable å’Œ maxSurge æ¥æ§åˆ¶æ»šåŠ¨æ›´æ–°è¿‡ç¨‹ï¼›</p>\n<ul>\n<li>\n<p>spec.strategy.rollingUpdate.maxUnavailableï¼ŒæŒ‡å®šåœ¨å›æ»šæ›´æ–°æ—¶æœ€å¤§ä¸å¯ç”¨çš„ Pod æ•°é‡ï¼Œå¯é€‰å­—æ®µï¼Œé»˜è®¤ä¸º 25%ï¼Œå¯ä»¥è®¾ç½®ä¸ºæ•°å­—æˆ–ç™¾åˆ†æ¯”ï¼Œå¦‚æœ maxSurge ä¸º 0ï¼Œåˆ™è¯¥å€¼ä¸èƒ½ä¸º 0ï¼›</p>\n</li>\n<li>\n<p>spec.strategy.rollingUpdate.maxSurge å¯ä»¥è¶…è¿‡æœŸæœ›å€¼çš„æœ€å¤§ Pod æ•°ï¼Œå¯é€‰å­—æ®µï¼Œé»˜è®¤ä¸º 25%ï¼Œå¯ä»¥è®¾ç½®æˆæ•°å­—æˆ–ç™¾åˆ†æ¯”ï¼Œå¦‚æœ maxUnavailable ä¸º 0ï¼Œåˆ™è¯¥å€¼ä¸èƒ½ä¸º 0ã€‚</p>\n</li>\n</ul>\n</li>\n</ul>\n<pre><code>  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 25%\n      maxSurge: 25%\n</code></pre>\n<h4 id=\"2-æœ‰çŠ¶æ€åº”ç”¨ç®¡ç†-statefulset\"><a class=\"anchor\" href=\"#2-æœ‰çŠ¶æ€åº”ç”¨ç®¡ç†-statefulset\">#</a> 2. æœ‰çŠ¶æ€åº”ç”¨ç®¡ç† StatefulSet</h4>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: web\n  namespace: default\nspec:\n  ports:\n    - port: 80\n      targetPort: 80\n      protocol: TCP\n      name: http\n  selector:\n    app: nginx\n  type: ClusterIP\n  clusterIP: None\n---\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: nginx\n  namespace: default\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n        - name: nginx\n          image: nginx:latest\n          resources:\n            limits:\n              cpu: '1'\n              memory: 1Gi\n            requests:\n              cpu: 100m\n              memory: 128Mi\n      restartPolicy: Always\n  serviceName: web\n</code></pre>\n<ul>\n<li>kind: Service å®šä¹‰äº†ä¸€ä¸ªåå­—ä¸º web çš„ Headless Serviceï¼Œåˆ›å»ºçš„ Service æ ¼å¼ä¸º nginx-0.web.default.svc.cluster.localï¼Œå…¶ä»–çš„ç±»ä¼¼ï¼Œå› ä¸ºæ²¡æœ‰æŒ‡å®š Namespaceï¼ˆå‘½åç©ºé—´ï¼‰ï¼Œæ‰€ä»¥é»˜è®¤éƒ¨ç½²åœ¨ defaultï¼›</li>\n<li>kind: StatefulSet å®šä¹‰äº†ä¸€ä¸ªåå­—ä¸º nginx çš„ StatefulSetï¼Œreplicas è¡¨ç¤ºéƒ¨ç½² Pod çš„å‰¯æœ¬æ•°ï¼Œæœ¬å®ä¾‹ä¸º 3ã€‚</li>\n</ul>\n<h5 id=\"21-åˆ›å»º-statefulset\"><a class=\"anchor\" href=\"#21-åˆ›å»º-statefulset\">#</a> 2.1 åˆ›å»º StatefulSet</h5>\n<pre><code>[root@k8s-master01 ~]# kubectl get pods\nNAME      READY   STATUS    RESTARTS   AGE\nnginx-0   1/1     Running   0          8m51s\nnginx-1   1/1     Running   0          8m50s\nnginx-2   1/1     Running   0          8m48s\n[root@k8s-master01 ~]# kubectl get svc\nNAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE\nkubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   6d1h\nweb          ClusterIP   None         &lt;none&gt;        80/TCP    9m28s\n[root@k8s-master01 ~]# kubectl get sts\nNAME    READY   AGE\nnginx   3/3     8m58s\n</code></pre>\n<h5 id=\"22-statefulsetåˆ›å»ºpodæµç¨‹\"><a class=\"anchor\" href=\"#22-statefulsetåˆ›å»ºpodæµç¨‹\">#</a> 2.2 StatefulSet åˆ›å»º Pod æµç¨‹</h5>\n<p>StatefulSet ç®¡ç†çš„ Pod éƒ¨ç½²å’Œæ‰©å±•è§„åˆ™å¦‚ä¸‹ï¼š</p>\n<ul>\n<li>å¯¹äºå…·æœ‰ N ä¸ªå‰¯æœ¬çš„ StatefulSetï¼Œå°†æŒ‰é¡ºåºä» 0 åˆ° N-1 å¼€å§‹åˆ›å»º Podï¼›</li>\n<li>å½“åˆ é™¤ Pod æ—¶ï¼Œå°†æŒ‰ç…§ N-1 åˆ° 0 çš„åé¡ºåºç»ˆæ­¢ï¼›</li>\n<li>åœ¨ç¼©æ”¾ Pod ä¹‹å‰ï¼Œå¿…é¡»ä¿è¯å½“å‰çš„ Pod æ˜¯ Runningï¼ˆè¿è¡Œä¸­ï¼‰æˆ–è€… Readyï¼ˆå°±ç»ªï¼‰ï¼›</li>\n<li>åœ¨ç»ˆæ­¢ Pod ä¹‹å‰ï¼Œå®ƒæ‰€æœ‰çš„ç»§ä»»è€…å¿…é¡»æ˜¯å®Œå…¨å…³é—­çŠ¶æ€ã€‚</li>\n</ul>\n<p>StatefulSet çš„ pod.Spec.TerminationGracePeriodSecondsï¼ˆç»ˆæ­¢ Pod çš„ç­‰å¾…æ—¶é—´ï¼‰ä¸åº”è¯¥æŒ‡å®šä¸º 0ï¼Œè®¾ç½®ä¸º 0 å¯¹ StatefulSet çš„ Pod æ˜¯æå…¶ä¸å®‰å…¨çš„åšæ³•ï¼Œä¼˜é›…åœ°åˆ é™¤ StatefulSet çš„ Pod æ˜¯éå¸¸æœ‰å¿…è¦çš„ï¼Œè€Œä¸”æ˜¯å®‰å…¨çš„ï¼Œå› ä¸ºå®ƒå¯ä»¥ç¡®ä¿åœ¨ Kubelet ä» APIServer åˆ é™¤ä¹‹å‰ï¼Œè®© Pod æ­£å¸¸å…³é—­ã€‚</p>\n<p>å½“åˆ›å»ºä¸Šé¢çš„ Nginx å®ä¾‹æ—¶ï¼ŒPod å°†æŒ‰ nginx-0ã€nginx-1ã€nginx-2 çš„é¡ºåºéƒ¨ç½² 3 ä¸ª Podã€‚åœ¨ nginx-0 å¤„äº Running æˆ–è€… Ready ä¹‹å‰ï¼Œnginx-1 ä¸ä¼šè¢«éƒ¨ç½²ï¼Œç›¸åŒçš„ï¼Œnginx-2 åœ¨ web-1 æœªå¤„äº Running å’Œ Ready ä¹‹å‰ä¹Ÿä¸ä¼šè¢«éƒ¨ç½²ã€‚å¦‚æœåœ¨ nginx-1 å¤„äº Running å’Œ Ready çŠ¶æ€æ—¶ï¼Œnginx-0 å˜æˆ Failed å¤±è´¥ï¼‰çŠ¶æ€ï¼Œé‚£ä¹ˆ nginx-2 å°†ä¸ä¼šè¢«å¯åŠ¨ï¼Œç›´åˆ° nginx-0 æ¢å¤ä¸º Running å’Œ Ready çŠ¶æ€ã€‚</p>\n<p>å¦‚æœç”¨æˆ·å°† StatefulSet çš„ replicas è®¾ç½®ä¸º 1ï¼Œé‚£ä¹ˆ nginx-2 å°†é¦–å…ˆè¢«ç»ˆæ­¢ï¼Œåœ¨å®Œå…¨å…³é—­å¹¶åˆ é™¤ nginx-2 ä¹‹å‰ï¼Œä¸ä¼šåˆ é™¤ nginx-1ã€‚å¦‚æœ nginx-2 ç»ˆæ­¢å¹¶ä¸”å®Œå…¨å…³é—­åï¼Œnginx-0 çªç„¶å¤±è´¥ï¼Œé‚£ä¹ˆåœ¨ nginx-0 æœªæ¢å¤æˆ Running æˆ–è€… Ready æ—¶ï¼Œnginx-1 ä¸ä¼šè¢«åˆ é™¤ã€‚</p>\n<h5 id=\"23-tatefulset-æ‰©å®¹å’Œç¼©å®¹\"><a class=\"anchor\" href=\"#23-tatefulset-æ‰©å®¹å’Œç¼©å®¹\">#</a> 2.3 tatefulSet æ‰©å®¹å’Œç¼©å®¹</h5>\n<p>å’Œ Deployment ç±»ä¼¼ï¼Œå¯ä»¥é€šè¿‡æ›´æ–° replicas å­—æ®µæ‰©å®¹ / ç¼©å®¹ StatefulSetï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ kubectlscaleã€kubectl edit å’Œ kubectl patch æ¥æ‰©å®¹ / ç¼©å®¹ä¸€ä¸ª StatefulSetã€‚</p>\n<pre><code># kubectl scale sts nginx --replicas=5\n</code></pre>\n<h5 id=\"24-statefulset-æ›´æ–°ç­–ç•¥\"><a class=\"anchor\" href=\"#24-statefulset-æ›´æ–°ç­–ç•¥\">#</a> 2.4 StatefulSet æ›´æ–°ç­–ç•¥</h5>\n<p><strong>On Delete ç­–ç•¥</strong></p>\n<p>OnDelete æ›´æ–°ç­–ç•¥å®ç°äº†ä¼ ç»Ÿï¼ˆ1.7 ç‰ˆæœ¬ä¹‹å‰ï¼‰çš„è¡Œä¸ºï¼Œå®ƒä¹Ÿæ˜¯é»˜è®¤çš„æ›´æ–°ç­–ç•¥ã€‚å½“æˆ‘ä»¬é€‰æ‹©è¿™ä¸ªæ›´æ–°ç­–ç•¥å¹¶ä¿®æ”¹ StatefulSet çš„.spec.template å­—æ®µæ—¶ï¼ŒStatefulSet æ§åˆ¶å™¨ä¸ä¼šè‡ªåŠ¨æ›´æ–° Podï¼Œå¿…é¡»æ‰‹åŠ¨åˆ é™¤ Pod æ‰èƒ½ä½¿æ§åˆ¶å™¨åˆ›å»ºæ–°çš„ Podã€‚</p>\n<pre><code>  updateStrategy:\n    type: OnDelete\n</code></pre>\n<p><strong>RollingUpdate ç­–ç•¥</strong></p>\n<p>RollingUpdateï¼ˆæ»šåŠ¨æ›´æ–°ï¼‰æ›´æ–°ç­–ç•¥ä¼šè‡ªåŠ¨æ›´æ–°ä¸€ä¸ª StatefulSet ä¸­æ‰€æœ‰çš„ Podï¼Œé‡‡ç”¨ä¸åºå·ç´¢å¼•ç›¸åçš„é¡ºåºè¿›è¡Œæ»šåŠ¨æ›´æ–°ã€‚</p>\n<pre><code>  updateStrategy:\n    type: RollingUpdate\n    rollingUpdate:\n      partition: 0\n</code></pre>\n<h5 id=\"25-åˆ†æ®µæ›´æ–°\"><a class=\"anchor\" href=\"#25-åˆ†æ®µæ›´æ–°\">#</a> 2.5 åˆ†æ®µæ›´æ–°</h5>\n<p>å°†åˆ†åŒºæ”¹ä¸º 2ï¼Œæ­¤æ—¶ä¼šè‡ªåŠ¨æ›´æ–° nginx-2ã€nginx-3ã€nginx-4ï¼ˆå› ä¸ºä¹‹å‰æ›´æ”¹äº†æ›´æ–°ç­–ç•¥ï¼‰ï¼Œä½†æ˜¯ä¸ä¼šæ›´æ–° nginx-0 å’Œ nginx-1ï¼š</p>\n<pre><code>  updateStrategy:\n    type: RollingUpdate\n    rollingUpdate:\n      partition: 2\n</code></pre>\n<p>å°† sts é•œåƒä¸º nginx:1.21.1</p>\n<pre><code># kubectl set image sts nginx nginx=nginx:1.21.1\n</code></pre>\n<p>æŒ‰ç…§ä¸Šè¿°æ–¹å¼ï¼Œå¯ä»¥å®ç°åˆ†é˜¶æ®µæ›´æ–°ï¼Œç±»ä¼¼äºç°åº¦ / é‡‘ä¸é›€å‘å¸ƒã€‚æŸ¥çœ‹æœ€ç»ˆçš„ç»“æœå¦‚ä¸‹ï¼š</p>\n<pre><code>[root@k8s-master01 ~]# kubectl get pods -oyaml|grep image\n    - image: nginx:latest\n      imagePullPolicy: IfNotPresent\n      image: docker.io/library/nginx:latest\n      imageID: docker.io/library/nginx@sha256:fad8e1cd52e24bce7b72cd7cb674a2efad671647b917055f5bd8a1f7ac9b1af8\n    - image: nginx:latest\n      imagePullPolicy: IfNotPresent\n      image: docker.io/library/nginx:latest\n      imageID: docker.io/library/nginx@sha256:fad8e1cd52e24bce7b72cd7cb674a2efad671647b917055f5bd8a1f7ac9b1af8\n    - image: nginx:1.21.1\n      imagePullPolicy: IfNotPresent\n      image: docker.io/library/nginx:1.21.1\n      imageID: docker.io/library/nginx@sha256:a05b0cdd4fc1be3b224ba9662ebdf98fe44c09c0c9215b45f84344c12867002e\n    - image: nginx:1.21.1\n      imagePullPolicy: IfNotPresent\n      image: docker.io/library/nginx:1.21.1\n      imageID: docker.io/library/nginx@sha256:a05b0cdd4fc1be3b224ba9662ebdf98fe44c09c0c9215b45f84344c12867002e\n    - image: nginx:1.21.1\n      imagePullPolicy: IfNotPresent\n      image: docker.io/library/nginx:1.21.1\n      imageID: docker.io/library/nginx@sha256:a05b0cdd4fc1be3b224ba9662ebdf98fe44c09c0c9215b45f84344c12867002e\n</code></pre>\n<h5 id=\"26-statefulset-æŒ‚è½½åŠ¨æ€å­˜å‚¨\"><a class=\"anchor\" href=\"#26-statefulset-æŒ‚è½½åŠ¨æ€å­˜å‚¨\">#</a> 2.6 StatefulSet æŒ‚è½½åŠ¨æ€å­˜å‚¨</h5>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: nginx\n  labels:\n    app: nginx\nspec:\n  ports:\n  - port: 80\n    name: web\n  clusterIP: None\n  selector:\n    app: nginx\n---\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: web\nspec:\n  selector:\n    matchLabels:\n      app: nginx \n  serviceName: &quot;nginx&quot;\n  replicas: 3 1\n  template:\n    metadata:\n      labels:\n        app: nginx \n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.20\n        ports:\n        - containerPort: 80\n          name: web\n        volumeMounts:\n        - name: www\n          mountPath: /usr/share/nginx/html\n  volumeClaimTemplates:\n  - metadata:\n      name: www\n    spec:\n      accessModes: [ &quot;ReadWriteOnce&quot; ]\n      storageClassName: &quot;rook-ceph-block&quot;\n      resources:\n        requests:\n          storage: 10Gi\n</code></pre>\n<h4 id=\"3å®ˆæŠ¤è¿›ç¨‹é›†-daemonset\"><a class=\"anchor\" href=\"#3å®ˆæŠ¤è¿›ç¨‹é›†-daemonset\">#</a> 3. å®ˆæŠ¤è¿›ç¨‹é›† DaemonSet</h4>\n<pre><code>apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: nginx-ds\n  labels:\n    app: nginx-ds\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: nginx-ds\n  template:\n    metadata:\n      labels:\n        app: nginx-ds\n    spec:\n      containers:\n        - name: nginx-ds\n          image: nginx:latest\n          imagePullPolicy: IfNotPresent\n          resources:\n            limits:\n              memory: 1024Mi\n              cpu: 1\n            requests:\n              memory: 128Mi\n              cpu: 100m\n</code></pre>\n<p>æ­¤æ—¶ä¼šåœ¨æ¯ä¸ªèŠ‚ç‚¹åˆ›å»ºä¸€ä¸ª Podï¼š</p>\n<pre><code>[root@k8s-master01 ~]# kubectl get pods -o wide\nNAME             READY   STATUS    RESTARTS   AGE   IP               NODE           NOMINATED NODE   READINESS GATES\nnginx-ds-47dxc   1/1     Running   0          56s   172.16.85.213    k8s-node01     &lt;none&gt;           &lt;none&gt;\nnginx-ds-4m89f   1/1     Running   0          56s   172.16.32.143    k8s-master01   &lt;none&gt;           &lt;none&gt;\nnginx-ds-mtpc2   1/1     Running   0          56s   172.16.195.12    k8s-master03   &lt;none&gt;           &lt;none&gt;\nnginx-ds-t5rxc   1/1     Running   0          56s   172.16.122.142   k8s-master02   &lt;none&gt;           &lt;none&gt;\nnginx-ds-x86kc   1/1     Running   0          56s   172.16.58.222    k8s-node02     &lt;none&gt;           &lt;none&gt;\n</code></pre>\n<p>æŒ‡å®šèŠ‚ç‚¹éƒ¨ç½² Pod</p>\n<pre><code>      nodeSelector:\n        ingress: 'true'\n</code></pre>\n<p>æ›´æ–°å’Œå›æ»š DaemonSet</p>\n<pre><code># kubectl set image ds nginx-ds nginx-ds=1.21.0 --record=true\n# kubectl rollout undo daemonset &lt;daemonset-name&gt; --to-revision=&lt;revision&gt;\n</code></pre>\n<p>DaemonSet çš„æ›´æ–°å’Œå›æ»šä¸ Deployment ç±»ä¼¼ï¼Œæ­¤å¤„ä¸å†æ¼”ç¤ºã€‚</p>\n<h4 id=\"4-hpa\"><a class=\"anchor\" href=\"#4-hpa\">#</a> 4. HPA</h4>\n<p>åˆ›å»º deploymentã€service</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: nginx-hpa-svc\n  namespace: default\nspec:\n  ports:\n    - port: 80\n      targetPort: 80\n      protocol: TCP\n      name: http\n  selector:\n    app: nginx-hpa\n  type: ClusterIP\n\n---\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-hpa\n  labels:\n    app: nginx-hpa\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: nginx-hpa\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: nginx-hpa\n    spec:\n      restartPolicy: Always\n      containers:\n        - name: nginx-hpa\n          image: nginx:latest\n          imagePullPolicy: IfNotPresent\n          resources:\n            limits:\n              memory: 1024Mi\n              cpu: 1\n            requests:\n              memory: 128Mi\n              cpu: 100m\n</code></pre>\n<p>åˆ›å»º HPA</p>\n<pre><code># kubectl autoscale deployment nginx-hpa --cpu-percent=10 --min=1 --max=10\n# kubectl get hpa\nNAME        REFERENCE              TARGETS       MINPODS   MAXPODS   REPLICAS   AGE\nnginx-hpa   Deployment/nginx-hpa   cpu: 0%/10%   1         10        1          16s\n\n</code></pre>\n<p>æµ‹è¯•è‡ªåŠ¨æ‰©ç¼©å®¹</p>\n<pre><code>while true; do wget -q -O- http://10.96.18.221 &gt; /dev/null; done\n[root@k8s-master01 ~]# kubectl get pods\nNAME                        READY   STATUS    RESTARTS   AGE\nnginx-hpa-d8bcbdf7d-4mkxp   1/1     Running   0          66s\nnginx-hpa-d8bcbdf7d-974q5   1/1     Running   0          6m36s\nnginx-hpa-d8bcbdf7d-g6p2h   1/1     Running   0          66s\nnginx-hpa-d8bcbdf7d-lvvsq   1/1     Running   0          111s\nnginx-hpa-d8bcbdf7d-tgqmr   1/1     Running   0          111s\nnginx-hpa-d8bcbdf7d-tzfbs   1/1     Running   0          21s\n</code></pre>\n<p><em>æœ¬æ–‡å‡ºè‡ªäºï¼š<a href=\"https://edu.51cto.com/course/23845.html\">https://edu.51cto.com/course/23845.html</a></em></p>\n",
            "tags": [
                "Kubernetes"
            ]
        },
        {
            "id": "http://ixuyong.cn/posts/1771242682.html",
            "url": "http://ixuyong.cn/posts/1771242682.html",
            "title": "K8sé›¶å®•æœºæœåŠ¡å‘å¸ƒ-æ¢é’ˆ",
            "date_published": "2025-04-14T11:23:48.000Z",
            "content_html": "<h3 id=\"k8sé›¶å®•æœºæœåŠ¡å‘å¸ƒ-æ¢é’ˆ\"><a class=\"anchor\" href=\"#k8sé›¶å®•æœºæœåŠ¡å‘å¸ƒ-æ¢é’ˆ\">#</a> K8s é›¶å®•æœºæœåŠ¡å‘å¸ƒ - æ¢é’ˆ</h3>\n<h4 id=\"1-podçŠ¶æ€åŠ-pod-æ•…éšœæ’æŸ¥å‘½ä»¤\"><a class=\"anchor\" href=\"#1-podçŠ¶æ€åŠ-pod-æ•…éšœæ’æŸ¥å‘½ä»¤\">#</a> 1. Pod çŠ¶æ€åŠ Pod æ•…éšœæ’æŸ¥å‘½ä»¤</h4>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">çŠ¶æ€</th>\n<th style=\"text-align:left\">è¯´æ˜</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">Pendingï¼ˆæŒ‚èµ·ï¼‰</td>\n<td style=\"text-align:left\">Pod å·²è¢« Kubernetes ç³»ç»Ÿæ¥æ”¶ï¼Œä½†ä»æœ‰ä¸€ä¸ªæˆ–å¤šä¸ªå®¹å™¨æœªè¢«åˆ›å»ºï¼Œå¯ä»¥é€šè¿‡ kubectl describe æŸ¥çœ‹å¤„äº Pending çŠ¶æ€çš„åŸå› </td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Runningï¼ˆè¿è¡Œä¸­ï¼‰</td>\n<td style=\"text-align:left\">Pod å·²ç»è¢«ç»‘å®šåˆ°ä¸€ä¸ªèŠ‚ç‚¹ä¸Šï¼Œå¹¶ä¸”æ‰€æœ‰çš„å®¹å™¨éƒ½å·²ç»è¢«åˆ›å»ºï¼Œè€Œä¸”è‡³å°‘æœ‰ä¸€ä¸ªæ˜¯è¿è¡ŒçŠ¶æ€ï¼Œæˆ–è€…æ˜¯æ­£åœ¨å¯åŠ¨æˆ–è€…é‡å¯ï¼Œå¯ä»¥é€šè¿‡ kubectl logs æŸ¥çœ‹ Pod çš„æ—¥å¿—</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Succeededï¼ˆæˆåŠŸï¼‰</td>\n<td style=\"text-align:left\">æ‰€æœ‰å®¹å™¨æ‰§è¡ŒæˆåŠŸå¹¶ç»ˆæ­¢ï¼Œå¹¶ä¸”ä¸ä¼šå†æ¬¡é‡å¯ï¼Œå¯ä»¥é€šè¿‡ kubectl logs æŸ¥çœ‹ Pod æ—¥å¿—</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Failedï¼ˆå¤±è´¥ï¼‰</td>\n<td style=\"text-align:left\">æ‰€æœ‰å®¹å™¨éƒ½å·²ç»ˆæ­¢ï¼Œå¹¶ä¸”è‡³å°‘æœ‰ä¸€ä¸ªå®¹å™¨ä»¥å¤±è´¥çš„æ–¹å¼ç»ˆæ­¢ï¼Œä¹Ÿå°±æ˜¯è¯´è¿™ä¸ªå®¹å™¨è¦ä¹ˆä»¥éé›¶çŠ¶æ€é€€å‡ºï¼Œè¦ä¹ˆè¢«ç³»ç»Ÿç»ˆæ­¢ï¼Œå¯ä»¥é€šè¿‡ logs å’Œ describe æŸ¥çœ‹ Pod æ—¥å¿—å’ŒçŠ¶æ€</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Unknownï¼ˆæœªçŸ¥ï¼‰</td>\n<td style=\"text-align:left\">é€šå¸¸æ˜¯ç”±äºé€šä¿¡é—®é¢˜é€ æˆçš„æ— æ³•è·å¾— Pod çš„çŠ¶æ€</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">ImagePullBackOff ErrImagePull</td>\n<td style=\"text-align:left\">é•œåƒæ‹‰å–å¤±è´¥ï¼Œä¸€èˆ¬æ˜¯ç”±äºé•œåƒä¸å­˜åœ¨ã€ç½‘ç»œä¸é€šæˆ–è€…éœ€è¦ç™»å½•è®¤è¯å¼•èµ·çš„ï¼Œå¯ä»¥ä½¿ç”¨ describe å‘½ä»¤æŸ¥çœ‹å…·ä½“åŸå› </td>\n</tr>\n<tr>\n<td style=\"text-align:left\">CrashLoopBackOff</td>\n<td style=\"text-align:left\">å®¹å™¨å¯åŠ¨å¤±è´¥ï¼Œå¯ä»¥é€šè¿‡ logs å‘½ä»¤æŸ¥çœ‹å…·ä½“åŸå› ï¼Œä¸€èˆ¬ä¸ºå¯åŠ¨å‘½ä»¤ä¸æ­£ç¡®ï¼Œå¥åº·æ£€æŸ¥ä¸é€šè¿‡ç­‰</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">OOMKilled</td>\n<td style=\"text-align:left\">å®¹å™¨å†…å­˜æº¢å‡ºï¼Œä¸€èˆ¬æ˜¯å®¹å™¨çš„å†…å­˜ Limit è®¾ç½®çš„è¿‡å°ï¼Œæˆ–è€…ç¨‹åºæœ¬èº«æœ‰å†…å­˜æº¢å‡ºï¼Œå¯ä»¥é€šè¿‡ logs æŸ¥çœ‹ç¨‹åºå¯åŠ¨æ—¥å¿—</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Terminating</td>\n<td style=\"text-align:left\">Pod æ­£åœ¨è¢«åˆ é™¤ï¼Œå¯ä»¥é€šè¿‡ describe æŸ¥çœ‹çŠ¶æ€</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">SysctlForbidden</td>\n<td style=\"text-align:left\">Pod è‡ªå®šä¹‰äº†å†…æ ¸é…ç½®ï¼Œä½† kubelet æ²¡æœ‰æ·»åŠ å†…æ ¸é…ç½®æˆ–é…ç½®çš„å†…æ ¸å‚æ•°ä¸æ”¯æŒï¼Œå¯ä»¥é€šè¿‡ describe æŸ¥çœ‹å…·ä½“åŸå› </td>\n</tr>\n<tr>\n<td style=\"text-align:left\">Completed</td>\n<td style=\"text-align:left\">å®¹å™¨å†…éƒ¨ä¸»è¿›ç¨‹é€€å‡ºï¼Œä¸€èˆ¬è®¡åˆ’ä»»åŠ¡æ‰§è¡Œç»“æŸä¼šæ˜¾ç¤ºè¯¥çŠ¶æ€ï¼Œæ­¤æ—¶å¯ä»¥é€šè¿‡ logs æŸ¥çœ‹å®¹å™¨æ—¥å¿—</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">ContainerCreating</td>\n<td style=\"text-align:left\">Pod æ­£åœ¨åˆ›å»ºï¼Œä¸€èˆ¬ä¸ºæ­£åœ¨ä¸‹è½½é•œåƒï¼Œæˆ–è€…æœ‰é…ç½®ä¸å½“çš„åœ°æ–¹ï¼Œå¯ä»¥é€šè¿‡ describe æŸ¥çœ‹å…·ä½“åŸå› </td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"2-podé•œåƒæ‹‰å–ç­–ç•¥\"><a class=\"anchor\" href=\"#2-podé•œåƒæ‹‰å–ç­–ç•¥\">#</a> 2. Pod é•œåƒæ‹‰å–ç­–ç•¥</h4>\n<p>é€šè¿‡ spec.containers [].imagePullPolicy å‚æ•°å¯ä»¥æŒ‡å®šé•œåƒçš„æ‹‰å–ç­–ç•¥ï¼Œç›®å‰æ”¯æŒçš„ç­–ç•¥å¦‚ä¸‹ï¼š</p>\n<table>\n<thead>\n<tr>\n<th>æ“ä½œæ–¹å¼</th>\n<th>è¯´æ˜</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Always</td>\n<td>æ€»æ˜¯æ‹‰å–ï¼Œå½“é•œåƒ tag ä¸º latest æ—¶ï¼Œä¸” imagePullPolicy æœªé…ç½®ï¼Œé»˜è®¤ä¸º Always</td>\n</tr>\n<tr>\n<td>Never</td>\n<td>ä¸ç®¡æ˜¯å¦å­˜åœ¨éƒ½ä¸ä¼šæ‹‰å–</td>\n</tr>\n<tr>\n<td>IfNotPresent</td>\n<td>é•œåƒä¸å­˜åœ¨æ—¶æ‹‰å–é•œåƒï¼Œå¦‚æœ tag ä¸ºé latestï¼Œä¸” imagePullPolicy æœªé…ç½®ï¼Œé»˜è®¤ä¸º IfNotPresent</td>\n</tr>\n</tbody>\n</table>\n<p>æ›´æ”¹é•œåƒæ‹‰å–ç­–ç•¥ä¸º IfNotPresentï¼š</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deploy\n  labels:\n    app: nginx-deploy\n  annotations:\n    app: nginx-deploy\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n    spec:\n      containers:\n        - name: nginx-deploy\n          image: nginx:latest\n          imagePullPolicy: IfNotPresent\n</code></pre>\n<h4 id=\"3-pod-é‡å¯ç­–ç•¥\"><a class=\"anchor\" href=\"#3-pod-é‡å¯ç­–ç•¥\">#</a> 3. <strong>Pod</strong> é‡å¯ç­–ç•¥</h4>\n<table>\n<thead>\n<tr>\n<th>æ“ä½œæ–¹å¼</th>\n<th>è¯´æ˜</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Always</td>\n<td>é»˜è®¤ç­–ç•¥ã€‚å®¹å™¨å¤±æ•ˆæ—¶ï¼Œè‡ªåŠ¨é‡å¯è¯¥å®¹å™¨</td>\n</tr>\n<tr>\n<td>OnFailure</td>\n<td>å®¹å™¨ä»¥ä¸ä¸º 0 çš„çŠ¶æ€ç ç»ˆæ­¢ï¼Œè‡ªåŠ¨é‡å¯è¯¥å®¹å™¨</td>\n</tr>\n<tr>\n<td>Never</td>\n<td>æ— è®ºä½•ç§çŠ¶æ€ï¼Œéƒ½ä¸ä¼šé‡å¯</td>\n</tr>\n</tbody>\n</table>\n<p>æŒ‡å®šé‡å¯ç­–ç•¥ä¸º Always ï¼š</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deploy\n  labels:\n    app: nginx-deploy\n  annotations:\n    app: nginx-deploy\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n    spec:\n      containers:\n        - name: nginx-deploy\n          image: nginx:latest\n          imagePullPolicy: IfNotPresent\n      restartPolicy: Always\n</code></pre>\n<h4 id=\"4-podçš„ä¸‰ç§æ¢é’ˆ\"><a class=\"anchor\" href=\"#4-podçš„ä¸‰ç§æ¢é’ˆ\">#</a> 4. Pod çš„ä¸‰ç§æ¢é’ˆ</h4>\n<table>\n<thead>\n<tr>\n<th>ç§ç±»</th>\n<th>è¯´æ˜</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>startupProbe</td>\n<td>Kubernetes1.16 æ–°åŠ çš„æ¢æµ‹æ–¹å¼ï¼Œç”¨äºåˆ¤æ–­å®¹å™¨å†…çš„åº”ç”¨ç¨‹åºæ˜¯å¦å·²ç»å¯åŠ¨ã€‚å¦‚æœé…ç½®äº† startupProbeï¼Œå°±ä¼šå…ˆç¦ç”¨å…¶ä»–æ¢æµ‹ï¼Œç›´åˆ°å®ƒæˆåŠŸä¸ºæ­¢ã€‚å¦‚æœæ¢æµ‹å¤±è´¥ï¼ŒKubelet ä¼šæ€æ­»å®¹å™¨ï¼Œä¹‹åæ ¹æ®é‡å¯ç­–ç•¥è¿›è¡Œå¤„ç†ï¼Œå¦‚æœæ¢æµ‹æˆåŠŸï¼Œæˆ–æ²¡æœ‰é…ç½® startupProbeï¼Œåˆ™çŠ¶æ€ä¸ºæˆåŠŸï¼Œä¹‹åå°±ä¸å†æ¢æµ‹ã€‚</td>\n</tr>\n<tr>\n<td>livenessProbe</td>\n<td>ç”¨äºæ¢æµ‹å®¹å™¨æ˜¯å¦åœ¨è¿è¡Œï¼Œå¦‚æœæ¢æµ‹å¤±è´¥ï¼Œkubelet ä¼š â€œæ€æ­»â€ å®¹å™¨å¹¶æ ¹æ®é‡å¯ç­–ç•¥è¿›è¡Œç›¸åº”çš„å¤„ç†ã€‚å¦‚æœæœªæŒ‡å®šè¯¥æ¢é’ˆï¼Œå°†é»˜è®¤ä¸º Success</td>\n</tr>\n<tr>\n<td>readinessProbe</td>\n<td>ä¸€èˆ¬ç”¨äºæ¢æµ‹å®¹å™¨å†…çš„ç¨‹åºæ˜¯å¦å¥åº·ï¼Œå³åˆ¤æ–­å®¹å™¨æ˜¯å¦ä¸ºå°±ç»ªï¼ˆReadyï¼‰çŠ¶æ€ã€‚å¦‚æœæ˜¯ï¼Œåˆ™å¯ä»¥å¤„ç†è¯·æ±‚ï¼Œåä¹‹ Endpoints Controller å°†ä»æ‰€æœ‰çš„ Service çš„ Endpoints ä¸­åˆ é™¤æ­¤å®¹å™¨æ‰€åœ¨ Pod çš„ IP åœ°å€ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†é»˜è®¤ä¸º Success</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"5-podæ¢é’ˆçš„å®ç°æ–¹å¼\"><a class=\"anchor\" href=\"#5-podæ¢é’ˆçš„å®ç°æ–¹å¼\">#</a> 5. Pod æ¢é’ˆçš„å®ç°æ–¹å¼</h4>\n<table>\n<thead>\n<tr>\n<th>å®ç°æ–¹å¼</th>\n<th>è¯´æ˜</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ExecAction</td>\n<td>åœ¨å®¹å™¨å†…æ‰§è¡Œä¸€ä¸ªæŒ‡å®šçš„å‘½ä»¤ï¼Œå¦‚æœå‘½ä»¤è¿”å›å€¼ä¸º 0ï¼Œåˆ™è®¤ä¸ºå®¹å™¨å¥åº·</td>\n</tr>\n<tr>\n<td>TCPSocketAction</td>\n<td>é€šè¿‡ TCP è¿æ¥æ£€æŸ¥å®¹å™¨æŒ‡å®šçš„ç«¯å£ï¼Œå¦‚æœç«¯å£å¼€æ”¾ï¼Œåˆ™è®¤ä¸ºå®¹å™¨å¥åº·</td>\n</tr>\n<tr>\n<td>HTTPGetAction</td>\n<td>å¯¹æŒ‡å®šçš„ URL è¿›è¡Œ Get è¯·æ±‚ï¼Œå¦‚æœçŠ¶æ€ç åœ¨ 200~400 ä¹‹é—´ï¼Œåˆ™è®¤ä¸ºå®¹å™¨å¥åº·</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"6-å¥åº·æ£€æŸ¥é…ç½®\"><a class=\"anchor\" href=\"#6-å¥åº·æ£€æŸ¥é…ç½®\">#</a> 6. å¥åº·æ£€æŸ¥é…ç½®</h4>\n<p>é…ç½®å¥åº·æ£€æŸ¥ï¼š</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deploy\n  labels:\n    app: nginx-deploy\n  annotations:\n    app: nginx-deploy\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n    spec:\n      containers:\n        - name: nginx-deploy\n          image: nginx:latest\n          imagePullPolicy: IfNotPresent\n          startupProbe:\n            initialDelaySeconds: 30\n            timeoutSeconds: 2\n            periodSeconds: 30\n            successThreshold: 1\n            failureThreshold: 2\n            tcpSocket:\n              port: 80\n          livenessProbe:\n            initialDelaySeconds: 30\n            timeoutSeconds: 2\n            periodSeconds: 30\n            successThreshold: 1\n            failureThreshold: 2\n            tcpSocket:\n              port: 80\n          readinessProbe:\n            initialDelaySeconds: 30\n            timeoutSeconds: 2\n            periodSeconds: 30\n            successThreshold: 1\n            failureThreshold: 2\n            httpGet:\n              path: /index.html\n              port: 80\n              scheme: HTTP\n      restartPolicy: Always\n</code></pre>\n<h4 id=\"7-prestopå’Œ-poststarté…ç½®\"><a class=\"anchor\" href=\"#7-prestopå’Œ-poststarté…ç½®\">#</a> 7. PreStop å’Œ PostStart é…ç½®</h4>\n<pre><code>[root@k8s-master01 ~]# cat nginx-deploy.yaml \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deploy\n  labels:\n    app: nginx-deploy\n  annotations:\n    app: nginx-deploy\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: nginx-deploy\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: nginx-deploy\n    spec:\n      containers:\n        - name: nginx-deploy\n          image: nginx:latest\n          imagePullPolicy: IfNotPresent\n          startupProbe:\n            initialDelaySeconds: 30\n            timeoutSeconds: 2\n            periodSeconds: 30\n            successThreshold: 1\n            failureThreshold: 2\n            tcpSocket:\n              port: 80\n          livenessProbe:\n            initialDelaySeconds: 30\n            timeoutSeconds: 2\n            periodSeconds: 30\n            successThreshold: 1\n            failureThreshold: 2\n            tcpSocket:\n              port: 80\n          readinessProbe:\n            initialDelaySeconds: 30\n            timeoutSeconds: 2\n            periodSeconds: 30\n            successThreshold: 1\n            failureThreshold: 2\n            httpGet:\n              path: /index.html\n              port: 80\n              scheme: HTTP\n          lifecycle:\n            postStart:\n              exec:\n                command:\n                  - sh\n                  - '-c'\n                  - mkdir /data\n            preStop:\n              exec:\n                command:\n                  - sh\n                  - '-c'\n                  - sleep 30\n      restartPolicy: Always\n</code></pre>\n<p><em>æœ¬æ–‡å‡ºè‡ªäºï¼š<a href=\"https://edu.51cto.com/course/23845.html\">https://edu.51cto.com/course/23845.html</a></em></p>\n",
            "tags": [
                "Kubernetes"
            ]
        },
        {
            "id": "http://ixuyong.cn/posts/3071070979.html",
            "url": "http://ixuyong.cn/posts/3071070979.html",
            "title": "ä¸€é”®æ°¸ä¹…æ¿€æ´»Windowã€officeæ•™ç¨‹",
            "date_published": "2025-04-10T13:32:09.000Z",
            "content_html": "<h3 id=\"ä¸€é”®æ°¸ä¹…æ¿€æ´»window-officeæ•™ç¨‹\"><a class=\"anchor\" href=\"#ä¸€é”®æ°¸ä¹…æ¿€æ´»window-officeæ•™ç¨‹\">#</a> ä¸€é”®æ°¸ä¹…æ¿€æ´» Windowã€office æ•™ç¨‹</h3>\n<p>1ã€æŒ‰ä¸‹ Win é”® + Rï¼Œè°ƒå‡ºè¿è¡Œå¯¹è¯æ¡†ï¼Œè¾“å…¥ powershell å¹¶å›è½¦ï¼Œå¯åŠ¨å‘½ä»¤æç¤ºç¬¦çª—å£ã€‚æ¥ç€è¾“å…¥ä»¥ä¸‹æŒ‡ä»¤æ‰§è¡Œæ¿€æ´»ï¼š</p>\n<pre><code>irmÂ https://get.activated.win | iex\n</code></pre>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/ilMT403.png\" alt=\"1.png\" /></p>\n<p>è¯¥è„šæœ¬åŒ…å«å››ä¸ªåŠŸèƒ½ï¼šé¦–ä¸ªå‘½ä»¤ç”¨äº Windows ç³»ç»Ÿæ°¸ä¹…æ¿€æ´»ï¼Œç¬¬äºŒä¸ªç”¨äº Office æ°¸ä¹…æ¿€æ´»ï¼Œç¬¬ä¸‰ä¸ªå°†ç³»ç»Ÿæœ‰æ•ˆæœŸå»¶é•¿è‡³ 2038 å¹´ï¼Œç¬¬å››ä¸ªåˆ™å®ç°æ¯ 180 å¤©è‡ªåŠ¨å¾ªç¯æ¿€æ´»ã€‚</p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/taJbKQr.png\" alt=\"2.png\" /></p>\n<p>2. æˆ‘ä»¬å†æ¬¡ä½¿ç”¨ Windows å¾½æ ‡ + R å¿«æ·é”®æ‰“å¼€è¿è¡Œæ¡†ï¼Œè¾“å…¥ slmgr.vbs/xpr å°±å¯ä»¥çœ‹åˆ°ç³»ç»Ÿå·²ç»æ°¸ä¹…æ¿€æ´»äº†ã€‚</p>\n<pre><code>slmgr.vbs /xpr\n</code></pre>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/JMWlUpc.png\" alt=\"3.png\" /></p>\n<p>ä»¥ä¸Šï¼Œæ—¢ç„¶çœ‹åˆ°è¿™é‡Œäº†ï¼Œå¦‚æœè§‰å¾—ä¸é”™ï¼Œéšæ‰‹ç‚¹ä¸ªèµã€æ‰“èµä¸€ä¸‹å§ï¼Œâ­ï½è°¢è°¢ä½ çœ‹æˆ‘çš„æ–‡ç« ï¼Œæˆ‘ä»¬ä¸‹æ¬¡å†è§ã€‚</p>\n",
            "tags": [
                "Windows"
            ]
        },
        {
            "id": "http://ixuyong.cn/posts/985149017.html",
            "url": "http://ixuyong.cn/posts/985149017.html",
            "title": "äºŒè¿›åˆ¶é«˜å¯ç”¨å®‰è£…K8Sé›†ç¾¤",
            "date_published": "2025-04-10T12:58:40.000Z",
            "content_html": "<h2 id=\"äºŒè¿›åˆ¶é«˜å¯ç”¨å®‰è£…k8sé›†ç¾¤\"><a class=\"anchor\" href=\"#äºŒè¿›åˆ¶é«˜å¯ç”¨å®‰è£…k8sé›†ç¾¤\">#</a> äºŒè¿›åˆ¶é«˜å¯ç”¨å®‰è£… K8s é›†ç¾¤</h2>\n<h4 id=\"1-åŸºæœ¬é…ç½®\"><a class=\"anchor\" href=\"#1-åŸºæœ¬é…ç½®\">#</a> 1. åŸºæœ¬é…ç½®</h4>\n<h5 id=\"11-åŸºæœ¬ç¯å¢ƒé…ç½®\"><a class=\"anchor\" href=\"#11-åŸºæœ¬ç¯å¢ƒé…ç½®\">#</a> 1.1 åŸºæœ¬ç¯å¢ƒé…ç½®</h5>\n<table>\n<thead>\n<tr>\n<th>ä¸»æœºå</th>\n<th>IP åœ°å€</th>\n<th>è¯´æ˜</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>k8s-master01 ~ 03</td>\n<td>192.168.1.71 ~ 73</td>\n<td>master èŠ‚ç‚¹ * 3</td>\n</tr>\n<tr>\n<td>/</td>\n<td>192.168.1.70</td>\n<td>keepalived è™šæ‹Ÿ IPï¼ˆä¸å ç”¨æœºå™¨ï¼‰</td>\n</tr>\n<tr>\n<td>k8s-node01 ~ 02</td>\n<td>192.168.1.74/75</td>\n<td>worker èŠ‚ç‚¹ * 2</td>\n</tr>\n</tbody>\n</table>\n<p><em>è¯·ç»Ÿä¸€æ›¿æ¢è¿™äº›ç½‘æ®µï¼ŒPod ç½‘æ®µå’Œ service å’Œå®¿ä¸»æœºç½‘æ®µä¸è¦é‡å¤ï¼ï¼ï¼</em></p>\n<table>\n<thead>\n<tr>\n<th><em><strong>* é…ç½®ä¿¡æ¯ *</strong></em></th>\n<th>å¤‡æ³¨</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ç³»ç»Ÿç‰ˆæœ¬</td>\n<td>Rocky Linux 8/9</td>\n</tr>\n<tr>\n<td>Containerd</td>\n<td>latest</td>\n</tr>\n<tr>\n<td>Pod ç½‘æ®µ</td>\n<td>172.16.0.0/16</td>\n</tr>\n<tr>\n<td>Service ç½‘æ®µ</td>\n<td>10.96.0.0/16</td>\n</tr>\n</tbody>\n</table>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>æ›´æ”¹ä¸»æœºåï¼ˆå…¶å®ƒèŠ‚ç‚¹æŒ‰éœ€ä¿®æ”¹ï¼‰ï¼š</p>\n<pre><code>hostnamectl set-hostname k8s-master01 \n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>é…ç½® hostsï¼Œä¿®æ”¹ /etc/hosts å¦‚ä¸‹ï¼š</p>\n<pre><code>[root@k8s-master01 ~]# cat /etc/hosts\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.1.71 k8s-master01\n192.168.1.72 k8s-master02\n192.168.1.73 k8s-master03\n192.168.1.74 k8s-node01\n192.168.1.75 k8s-node02\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>é…ç½® yum æºï¼š</p>\n<pre><code># é…ç½®åŸºç¡€æº\nsed -e 's|^mirrorlist=|#mirrorlist=|g' \\\n    -e 's|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g' \\\n    -i.bak \\\n    /etc/yum.repos.d/*.repo\n\nyum makecache\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>å¿…å¤‡å·¥å…·å®‰è£…ï¼š</p>\n<pre><code>yum install wget jq psmisc vim net-tools telnet yum-utils device-mapper-persistent-data lvm2 git rsyslog -y\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>å…³é—­é˜²ç«å¢™ã€selinuxã€dnsmasqã€swapã€å¼€å¯ rsyslogã€‚æœåŠ¡å™¨é…ç½®å¦‚ä¸‹ï¼š</p>\n<pre><code>systemctl disable --now firewalld \nsystemctl disable --now dnsmasq\nsetenforce 0\nsed -i 's#SELINUX=enforcing#SELINUX=disabled#g' /etc/sysconfig/selinux\nsed -i 's#SELINUX=enforcing#SELINUX=disabled#g' /etc/selinux/config\nsystemctl enable --now rsyslog\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>å…³é—­ swap åˆ†åŒºï¼š</p>\n<pre><code>swapoff -a &amp;&amp; sysctl -w vm.swappiness=0\nsed -ri '/^[^#]*swap/s@^@#@' /etc/fstab\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>å®‰è£… ntpdateï¼š</p>\n<pre><code>sudo dnf install epel-release -y\nsudo dnf config-manager --set-enabled epel\nsudo dnf install ntpsec\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>åŒæ­¥æ—¶é—´å¹¶é…ç½®ä¸Šæµ·æ—¶åŒºï¼š</p>\n<pre><code>ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime\necho 'Asia/Shanghai' &gt;/etc/timezone\nntpdate time2.aliyun.com\n# åŠ å…¥åˆ°crontab\ncrontab -e\n*/5 * * * * /usr/sbin/ntpdate time2.aliyun.com\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>é…ç½® limitï¼š</p>\n<pre><code>ulimit -SHn 65535\nvim /etc/security/limits.conf\n# æœ«å°¾æ·»åŠ å¦‚ä¸‹å†…å®¹\n* soft nofile 65536\n* hard nofile 131072\n* soft nproc 65535\n* hard nproc 655350\n* soft memlock unlimited\n* hard memlock unlimited\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>å‡çº§ç³»ç»Ÿï¼š</p>\n<pre><code>yum update -y\n</code></pre>\n<p><mark>Master01 èŠ‚ç‚¹</mark>å…å¯†é’¥ç™»å½•å…¶ä»–èŠ‚ç‚¹ï¼Œå®‰è£…è¿‡ç¨‹ä¸­ç”Ÿæˆé…ç½®æ–‡ä»¶å’Œè¯ä¹¦å‡åœ¨ Master01 ä¸Šæ“ä½œï¼Œé›†ç¾¤ç®¡ç†ä¹Ÿåœ¨ Master01 ä¸Šæ“ä½œï¼š</p>\n<pre><code>ssh-keygen -t rsa\nfor i in k8s-master01 k8s-master02 k8s-master03 k8s-node01 k8s-node02;do ssh-copy-id -i .ssh/id_rsa.pub $i;done\n</code></pre>\n<p><em>æ³¨æ„ï¼šå…¬æœ‰äº‘ç¯å¢ƒï¼Œå¯èƒ½éœ€è¦æŠŠ kubectl æ”¾åœ¨ä¸€ä¸ªé Master èŠ‚ç‚¹ä¸Š</em></p>\n<p><mark>Master01 èŠ‚ç‚¹</mark>ä¸‹è½½å®‰è£…æ‰€æœ‰çš„æºç æ–‡ä»¶ï¼š</p>\n<pre><code>cd /root/ ; git clone https://gitee.com/chinagei/k8s-ha-install\n</code></pre>\n<h5 id=\"12-å†…æ ¸é…ç½®\"><a class=\"anchor\" href=\"#12-å†…æ ¸é…ç½®\">#</a> 1.2 å†…æ ¸é…ç½®</h5>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>å®‰è£… ipvsadmï¼š</p>\n<pre><code>yum install ipvsadm ipset sysstat conntrack libseccomp -y\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>é…ç½® ipvs æ¨¡å—ï¼š</p>\n<pre><code>modprobe -- ip_vs\nmodprobe -- ip_vs_rr\nmodprobe -- ip_vs_wrr\nmodprobe -- ip_vs_sh\nmodprobe -- nf_conntrack\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>åˆ›å»º ipvs.confï¼Œå¹¶é…ç½®å¼€æœºè‡ªåŠ¨åŠ è½½ï¼š</p>\n<pre><code>vim /etc/modules-load.d/ipvs.conf \n# åŠ å…¥ä»¥ä¸‹å†…å®¹\nip_vs\nip_vs_lc\nip_vs_wlc\nip_vs_rr\nip_vs_wrr\nip_vs_lblc\nip_vs_lblcr\nip_vs_dh\nip_vs_sh\nip_vs_fo\nip_vs_nq\nip_vs_sed\nip_vs_ftp\nip_vs_sh\nnf_conntrack\nip_tables\nip_set\nxt_set\nipt_set\nipt_rpfilter\nipt_REJECT\nipip\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>ç„¶åæ‰§è¡Œ systemctl enable --now systemd-modules-load.service å³å¯ï¼ˆæŠ¥é”™ä¸ç”¨ç®¡ï¼‰</p>\n<pre><code>systemctl enable --now systemd-modules-load.service\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>å†…æ ¸ä¼˜åŒ–é…ç½®ï¼š</p>\n<pre><code>cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.conf\nnet.ipv4.ip_forward = 1\nnet.bridge.bridge-nf-call-iptables = 1\nnet.bridge.bridge-nf-call-ip6tables = 1\nfs.may_detach_mounts = 1\nnet.ipv4.conf.all.route_localnet = 1\nvm.overcommit_memory=1\nvm.panic_on_oom=0\nfs.inotify.max_user_watches=89100\nfs.file-max=52706963\nfs.nr_open=52706963\nnet.netfilter.nf_conntrack_max=2310720\n\nnet.ipv4.tcp_keepalive_time = 600\nnet.ipv4.tcp_keepalive_probes = 3\nnet.ipv4.tcp_keepalive_intvl =15\nnet.ipv4.tcp_max_tw_buckets = 36000\nnet.ipv4.tcp_tw_reuse = 1\nnet.ipv4.tcp_max_orphans = 327680\nnet.ipv4.tcp_orphan_retries = 3\nnet.ipv4.tcp_syncookies = 1\nnet.ipv4.tcp_max_syn_backlog = 16384\nnet.ipv4.ip_conntrack_max = 65536\nnet.ipv4.tcp_max_syn_backlog = 16384\nnet.ipv4.tcp_timestamps = 0\nnet.core.somaxconn = 16384\nEOF\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>åº”ç”¨é…ç½®ï¼š</p>\n<pre><code>sysctl --system\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>é…ç½®å®Œå†…æ ¸åï¼Œé‡å¯æœºå™¨ï¼Œä¹‹åæŸ¥çœ‹å†…æ ¸æ¨¡å—æ˜¯å¦å·²è‡ªåŠ¨åŠ è½½ï¼š</p>\n<pre><code>reboot\nlsmod | grep --color=auto -e ip_vs -e nf_conntrack\n</code></pre>\n<h4 id=\"2-é«˜å¯ç”¨ç»„ä»¶å®‰è£…\"><a class=\"anchor\" href=\"#2-é«˜å¯ç”¨ç»„ä»¶å®‰è£…\">#</a> 2. é«˜å¯ç”¨ç»„ä»¶å®‰è£…</h4>\n<p><em>æ³¨æ„ï¼šå¦‚æœå®‰è£…çš„ä¸æ˜¯é«˜å¯ç”¨é›†ç¾¤ï¼Œhaproxy å’Œ keepalived æ— éœ€å®‰è£…</em></p>\n<p><em>æ³¨æ„ï¼šå…¬æœ‰äº‘è¦ç”¨å…¬æœ‰äº‘è‡ªå¸¦çš„è´Ÿè½½å‡è¡¡ï¼Œæ¯”å¦‚é˜¿é‡Œäº‘çš„ SLBã€NLBï¼Œè…¾è®¯äº‘çš„ ELBï¼Œç”¨æ¥æ›¿ä»£ haproxy å’Œ keepalivedï¼Œå› ä¸ºå…¬æœ‰äº‘å¤§éƒ¨åˆ†éƒ½æ˜¯ä¸æ”¯æŒ keepalived çš„ã€‚</em></p>\n<p><mark>æ‰€æœ‰ Master èŠ‚ç‚¹</mark>é€šè¿‡ yum å®‰è£… HAProxy å’Œ KeepAlivedï¼š</p>\n<pre><code>yum install keepalived haproxy -y\n</code></pre>\n<p><mark>æ‰€æœ‰ Master èŠ‚ç‚¹</mark>é…ç½® HAProxyï¼Œéœ€è¦æ³¨æ„é»„è‰²éƒ¨åˆ†çš„ IPï¼š</p>\n<pre><code>[root@k8s-master01 etc]# mkdir /etc/haproxy\n[root@k8s-master01 etc]# vim /etc/haproxy/haproxy.cfg \nglobal\n  maxconn  2000\n  ulimit-n  16384\n  log  127.0.0.1 local0 err\n  stats timeout 30s\n\ndefaults\n  log global\n  mode  http\n  option  httplog\n  timeout connect 5000\n  timeout client  50000\n  timeout server  50000\n  timeout http-request 15s\n  timeout http-keep-alive 15s\n\nfrontend monitor-in\n  bind *:33305\n  mode http\n  option httplog\n  monitor-uri /monitor\n\nfrontend k8s-master\n  bind 0.0.0.0:8443       #HAProxyç›‘å¬ç«¯å£\n  bind 127.0.0.1:8443     #HAProxyç›‘å¬ç«¯å£\n  mode tcp\n  option tcplog\n  tcp-request inspect-delay 5s\n  default_backend k8s-master\n\nbackend k8s-master\n  mode tcp\n  option tcplog\n  option tcp-check\n  balance roundrobin\n  default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100\n  server k8s-master01\t192.168.1.71:6443  check       #API Server IPåœ°å€\n  server k8s-master02\t192.168.1.72:6443  check       #API Server IPåœ°å€\n  server k8s-master03\t192.168.1.73:6443  check       #API Server IPåœ°å€\n</code></pre>\n<p><mark>æ‰€æœ‰ Master èŠ‚ç‚¹</mark>é…ç½® KeepAlivedï¼Œéœ€è¦æ³¨æ„é»„è‰²éƒ¨åˆ†çš„é…ç½®ã€‚</p>\n<p><mark>Master01 èŠ‚ç‚¹</mark>çš„é…ç½®ï¼š</p>\n<pre><code>[root@k8s-master01 etc]# mkdir /etc/keepalived\n\n[root@k8s-master01 ~]# vim /etc/keepalived/keepalived.conf \n! Configuration File for keepalived\nglobal_defs &#123;\n    router_id LVS_DEVEL\nscript_user root\n    enable_script_security\n&#125;\nvrrp_script chk_apiserver &#123;\n    script &quot;/etc/keepalived/check_apiserver.sh&quot;\n    interval 5\n    weight -5\n    fall 2  \nrise 1\n&#125;\nvrrp_instance VI_1 &#123;\n    state MASTER\n    interface ens160               #ç½‘å¡åç§°\n    mcast_src_ip 192.168.1.71      #K8s-master01 IPåœ°å€\n    virtual_router_id 51\n    priority 101\n    advert_int 2\n    authentication &#123;\n        auth_type PASS\n        auth_pass K8SHA_KA_AUTH\n    &#125;\n    virtual_ipaddress &#123;\n        192.168.1.70        #VIPåœ°å€\n    &#125;\n    track_script &#123;\n       chk_apiserver\n    &#125;\n&#125;\t\n</code></pre>\n<p><mark>Master02 èŠ‚ç‚¹</mark>çš„é…ç½®ï¼š</p>\n<pre><code># vim /etc/keepalived/keepalived.conf \n\n! Configuration File for keepalived\nglobal_defs &#123;\n    router_id LVS_DEVEL\nscript_user root\n    enable_script_security\n&#125;\nvrrp_script chk_apiserver &#123;\n    script &quot;/etc/keepalived/check_apiserver.sh&quot;\n   interval 5\n    weight -5\n    fall 2  \nrise 1\n&#125;\nvrrp_instance VI_1 &#123;\n    state BACKUP\n    interface ens160                #ç½‘å¡åç§°\n    mcast_src_ip 192.168.1.72       #K8s-master02 IPåœ°å€\n    virtual_router_id 51\n    priority 100\n    advert_int 2\n    authentication &#123;\n        auth_type PASS\n        auth_pass K8SHA_KA_AUTH\n    &#125;\n    virtual_ipaddress &#123;\n        192.168.1.70              #VIPåœ°å€\n    &#125;\n    track_script &#123;\n       chk_apiserver\n    &#125;\n&#125;\n</code></pre>\n<p><mark>Master03 èŠ‚ç‚¹</mark>çš„é…ç½®ï¼š</p>\n<pre><code># vim /etc/keepalived/keepalived.conf \n\n! Configuration File for keepalived\nglobal_defs &#123;\n    router_id LVS_DEVEL\nscript_user root\n    enable_script_security\n&#125;\nvrrp_script chk_apiserver &#123;\n    script &quot;/etc/keepalived/check_apiserver.sh&quot;\n interval 5\n    weight -5\n    fall 2  \nrise 1\n&#125;\nvrrp_instance VI_1 &#123;\n    state BACKUP\n    interface ens160                 #ç½‘å¡åç§°\n    mcast_src_ip 192.168.1.73        #K8s-master03 IPåœ°å€\n    virtual_router_id 51\n    priority 100\n    advert_int 2\n    authentication &#123;\n        auth_type PASS\n        auth_pass K8SHA_KA_AUTH\n    &#125;\n    virtual_ipaddress &#123;\n        192.168.1.70          #VIPåœ°å€\n    &#125;\n    track_script &#123;\n       chk_apiserver\n    &#125;\n&#125;\n</code></pre>\n<p><mark>æ‰€æœ‰ master èŠ‚ç‚¹</mark>é…ç½® KeepAlived å¥åº·æ£€æŸ¥æ–‡ä»¶ï¼š</p>\n<pre><code>[root@k8s-master01 keepalived]# vim /etc/keepalived/check_apiserver.sh \n#!/bin/bash\n\nerr=0\nfor k in $(seq 1 3)\ndo\n    check_code=$(pgrep haproxy)\n    if [[ $check_code == &quot;&quot; ]]; then\n        err=$(expr $err + 1)\n        sleep 1\n        continue\n    else\n        err=0\n        break\n    fi\ndone\n\nif [[ $err != &quot;0&quot; ]]; then\n    echo &quot;systemctl stop keepalived&quot;\n    /usr/bin/systemctl stop keepalived\n    exit 1\nelse\n    exit 0\nfi\n</code></pre>\n<p><mark>æ‰€æœ‰ master èŠ‚ç‚¹</mark>é…ç½®å¥åº·æ£€æŸ¥æ–‡ä»¶æ·»åŠ æ‰§è¡Œæƒé™ï¼š</p>\n<pre><code>chmod +x /etc/keepalived/check_apiserver.sh\n</code></pre>\n<p><mark>æ‰€æœ‰ master èŠ‚ç‚¹</mark>å¯åŠ¨ haproxy å’Œ keepalivedï¼š</p>\n<pre><code>[root@k8s-master01 keepalived]# systemctl daemon-reload\n[root@k8s-master01 keepalived]# systemctl enable --now haproxy\n[root@k8s-master01 keepalived]# systemctl enable --now keepalived\n</code></pre>\n<p>é‡è¦ï¼šå¦‚æœå®‰è£…äº† keepalived å’Œ haproxyï¼Œéœ€è¦æµ‹è¯• keepalived æ˜¯å¦æ˜¯æ­£å¸¸çš„</p>\n<pre><code>æ‰€æœ‰èŠ‚ç‚¹æµ‹è¯•VIP\n[root@k8s-master01 ~]# ping 192.168.1.70 -c 4\nPING 192.168.1.70 (192.168.1.70) 56(84) bytes of data.\n64 bytes from 192.168.1.70: icmp_seq=1 ttl=64 time=0.464 ms\n64 bytes from 192.168.1.70: icmp_seq=2 ttl=64 time=0.063 ms\n64 bytes from 192.168.1.70: icmp_seq=3 ttl=64 time=0.062 ms\n64 bytes from 192.168.1.70: icmp_seq=4 ttl=64 time=0.063 ms\n\n[root@k8s-master01 ~]# telnet 192.168.1.70 16443\nTrying 192.168.1.70...\nConnected to 192.168.1.70.\nEscape character is '^]'.\nConnection closed by foreign host.\n</code></pre>\n<p>å¦‚æœ ping ä¸é€šä¸” telnet æ²¡æœ‰å‡ºç° ] ï¼Œåˆ™è®¤ä¸º VIP ä¸å¯ä»¥ï¼Œä¸å¯åœ¨ç»§ç»­å¾€ä¸‹æ‰§è¡Œï¼Œéœ€è¦æ’æŸ¥ keepalived çš„é—®é¢˜ï¼Œæ¯”å¦‚é˜²ç«å¢™å’Œ selinuxï¼Œhaproxy å’Œ keepalived çš„çŠ¶æ€ï¼Œç›‘å¬ç«¯å£ç­‰</p>\n<ul>\n<li>æ‰€æœ‰èŠ‚ç‚¹æŸ¥çœ‹é˜²ç«å¢™çŠ¶æ€å¿…é¡»ä¸º disable å’Œ inactiveï¼šsystemctl status firewalld</li>\n<li>æ‰€æœ‰èŠ‚ç‚¹æŸ¥çœ‹ selinux çŠ¶æ€ï¼Œå¿…é¡»ä¸º disableï¼šgetenforce</li>\n<li>master èŠ‚ç‚¹æŸ¥çœ‹ haproxy å’Œ keepalived çŠ¶æ€ï¼šsystemctl status keepalived haproxy</li>\n<li>master èŠ‚ç‚¹æŸ¥çœ‹ç›‘å¬ç«¯å£ï¼šnetstat -lntp</li>\n</ul>\n<p>å¦‚æœä»¥ä¸Šéƒ½æ²¡æœ‰é—®é¢˜ï¼Œéœ€è¦ç¡®è®¤ï¼š</p>\n<ol>\n<li>\n<p>æ˜¯å¦æ˜¯å…¬æœ‰äº‘æœºå™¨</p>\n</li>\n<li>\n<p>æ˜¯å¦æ˜¯ç§æœ‰äº‘æœºå™¨ï¼ˆç±»ä¼¼ OpenStackï¼‰</p>\n</li>\n</ol>\n<p>ä¸Šè¿°å…¬æœ‰äº‘ä¸€èˆ¬éƒ½æ˜¯ä¸æ”¯æŒ keepalivedï¼Œç§æœ‰äº‘å¯èƒ½ä¹Ÿæœ‰é™åˆ¶ï¼Œéœ€è¦å’Œè‡ªå·±çš„ç§æœ‰äº‘ç®¡ç†å‘˜å’¨è¯¢</p>\n<h4 id=\"3-runtimeå®‰è£…\"><a class=\"anchor\" href=\"#3-runtimeå®‰è£…\">#</a> 3. Runtime å®‰è£…</h4>\n<p>å¦‚æœå®‰è£…çš„ç‰ˆæœ¬ä½äº 1.24ï¼Œé€‰æ‹© Docker å’Œ Containerd å‡å¯ï¼Œé«˜äº 1.24 å»ºè®®é€‰æ‹© Containerd ä½œä¸º Runtimeï¼Œä¸å†æ¨èä½¿ç”¨ Docker ä½œä¸º Runtimeã€‚</p>\n<h5 id=\"31-å®‰è£…containerd\"><a class=\"anchor\" href=\"#31-å®‰è£…containerd\">#</a> 3.1 å®‰è£… Containerd</h5>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>é…ç½®å®‰è£…æºï¼š</p>\n<pre><code>yum install wget jq psmisc vim net-tools telnet yum-utils device-mapper-persistent-data lvm2 git -y\nyum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>å®‰è£… docker-ceï¼ˆå¦‚æœåœ¨ä»¥å‰å·²ç»å®‰è£…è¿‡ï¼Œéœ€è¦é‡æ–°å®‰è£…æ›´æ–°ä¸€ä¸‹ï¼‰ï¼š</p>\n<pre><code># yum install docker-ce containerd -y\n</code></pre>\n<p><em>å¯ä»¥æ— éœ€å¯åŠ¨ Dockerï¼Œåªéœ€è¦é…ç½®å’Œå¯åŠ¨ Containerd å³å¯ã€‚</em></p>\n<p>é¦–å…ˆé…ç½® Containerd æ‰€éœ€çš„æ¨¡å—ï¼ˆ<mark>æ‰€æœ‰èŠ‚ç‚¹</mark>ï¼‰ï¼š</p>\n<pre><code># cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf\noverlay\nbr_netfilter\nEOF\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>åŠ è½½æ¨¡å—ï¼š</p>\n<pre><code># modprobe -- overlay\n# modprobe -- br_netfilter\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>ï¼Œé…ç½® Containerd æ‰€éœ€çš„å†…æ ¸ï¼š</p>\n<pre><code># cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf\nnet.bridge.bridge-nf-call-iptables  = 1\nnet.ipv4.ip_forward                 = 1\nnet.bridge.bridge-nf-call-ip6tables = 1\nEOF\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>åŠ è½½å†…æ ¸ï¼š</p>\n<pre><code># sysctl --system\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>ç”Ÿæˆ Containerd çš„é…ç½®æ–‡ä»¶ï¼š</p>\n<pre><code># mkdir -p /etc/containerd\n# containerd config default | tee /etc/containerd/config.toml\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>æ›´æ”¹ Containerd çš„ Cgroup å’Œ Pause é•œåƒé…ç½®ï¼š</p>\n<pre><code>sed -i 's#SystemdCgroup = false#SystemdCgroup = true#g' /etc/containerd/config.toml\nsed -i 's#k8s.gcr.io/pause#registry.cn-hangzhou.aliyuncs.com/google_containers/pause#g'  /etc/containerd/config.toml\nsed -i 's#registry.gcr.io/pause#registry.cn-hangzhou.aliyuncs.com/google_containers/pause#g'  /etc/containerd/config.toml\nsed -i 's#registry.k8s.io/pause#registry.cn-hangzhou.aliyuncs.com/google_containers/pause#g'  /etc/containerd/config.toml\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>å¯åŠ¨ Containerdï¼Œå¹¶é…ç½®å¼€æœºè‡ªå¯åŠ¨ï¼š</p>\n<pre><code># systemctl daemon-reload\n# systemctl enable --now containerd\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>é…ç½® crictl å®¢æˆ·ç«¯è¿æ¥çš„è¿è¡Œæ—¶ä½ç½®ï¼ˆå¯é€‰ï¼‰ï¼š</p>\n<pre><code># cat &gt; /etc/crictl.yaml &lt;&lt;EOF\nruntime-endpoint: unix:///run/containerd/containerd.sock\nimage-endpoint: unix:///run/containerd/containerd.sock\ntimeout: 10\ndebug: false\nEOF\n</code></pre>\n<h4 id=\"4-k8såŠetcdå®‰è£…\"><a class=\"anchor\" href=\"#4-k8såŠetcdå®‰è£…\">#</a> 4 . K8S åŠ etcd å®‰è£…</h4>\n<p><mark>Master01</mark> ä¸‹è½½ kubernetes å®‰è£…åŒ…ï¼ˆ1.32.3 éœ€è¦æ›´æ”¹ä¸ºä½ çœ‹åˆ°çš„æœ€æ–°ç‰ˆæœ¬ï¼‰ï¼š</p>\n<pre><code>[root@k8s-master01 ~]# wget https://dl.k8s.io/v1.32.0/kubernetes-server-linux-amd64.tar.gz\n</code></pre>\n<p>æœ€æ–°ç‰ˆè·å–åœ°å€ï¼š<a href=\"https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.31.md\">https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/</a></p>\n<p><mark>ä»¥ä¸‹æ“ä½œéƒ½åœ¨ master01 æ‰§è¡Œ</mark></p>\n<p>ä¸‹è½½ etcd å®‰è£…åŒ…ï¼š<a href=\"https://github.com/etcd-io/etcd/releases/\">https://github.com/etcd-io/etcd/releases/</a></p>\n<pre><code>[root@k8s-master01 ~]# wget https://github.com/etcd-io/etcd/releases/download/v3.5.16/etcd-v3.5.16-linux-amd64.tar.gz\n</code></pre>\n<p>è§£å‹ kubernetes å®‰è£…æ–‡ä»¶ï¼š</p>\n<pre><code>[root@k8s-master01 ~]# tar -xf kubernetes-server-linux-amd64.tar.gz  --strip-components=3 -C /usr/local/bin kubernetes/server/bin/kube&#123;let,ctl,-apiserver,-controller-manager,-scheduler,-proxy&#125;\n</code></pre>\n<p>è§£å‹ etcd å®‰è£…æ–‡ä»¶ï¼š</p>\n<pre><code>[root@k8s-master01 ~]#  tar -zxvf etcd-v3.5.16-linux-amd64.tar.gz --strip-components=1 -C /usr/local/bin etcd-v3.5.16-linux-amd64/etcd&#123;,ctl&#125;\n</code></pre>\n<p>ç‰ˆæœ¬æŸ¥çœ‹ï¼š</p>\n<pre><code>[root@k8s-master01 ~]# kubelet --version\nKubernetes v1.32.3\n[root@k8s-master01 ~]# etcdctl version\netcdctl version: 3.5.16\nAPI version: 3.5\n</code></pre>\n<p>å°†ç»„ä»¶å‘é€åˆ°å…¶ä»–èŠ‚ç‚¹</p>\n<pre><code>MasterNodes='k8s-master02 k8s-master03'\nWorkNodes='k8s-node01 k8s-node02'\nfor NODE in $MasterNodes; do echo $NODE; scp /usr/local/bin/kube&#123;let,ctl,-apiserver,-controller-manager,-scheduler,-proxy&#125; $NODE:/usr/local/bin/; scp /usr/local/bin/etcd* $NODE:/usr/local/bin/; done\nfor NODE in $WorkNodes; do     scp /usr/local/bin/kube&#123;let,-proxy&#125; $NODE:/usr/local/bin/ ; done\n</code></pre>\n<p><mark>Master01 èŠ‚ç‚¹</mark>åˆ‡æ¢åˆ° 1.32.x åˆ†æ”¯ï¼ˆå…¶ä»–ç‰ˆæœ¬å¯ä»¥åˆ‡æ¢åˆ°å…¶ä»–åˆ†æ”¯ï¼Œ.x å³å¯ï¼Œä¸éœ€è¦æ›´æ”¹ä¸ºå…·ä½“çš„å°ç‰ˆæœ¬ï¼‰ï¼š</p>\n<pre><code>cd /root/k8s-ha-install &amp;&amp; git checkout manual-installation-v1.32.x\n</code></pre>\n<h4 id=\"5-ç”Ÿæˆè¯ä¹¦\"><a class=\"anchor\" href=\"#5-ç”Ÿæˆè¯ä¹¦\">#</a> 5 . ç”Ÿæˆè¯ä¹¦</h4>\n<p><em><mark>äºŒè¿›åˆ¶å®‰è£…æœ€å…³é”®æ­¥éª¤ï¼Œä¸€æ­¥é”™è¯¯å…¨ç›˜çš†è¾“ï¼Œä¸€å®šè¦æ³¨æ„æ¯ä¸ªæ­¥éª¤éƒ½è¦æ˜¯æ­£ç¡®çš„</mark></em></p>\n<p><mark>Master01</mark> ä¸‹è½½ç”Ÿæˆè¯ä¹¦å·¥å…·ï¼ˆä¸‹è½½ä¸æˆåŠŸå¯ä»¥å»ç™¾åº¦ç½‘ç›˜ï¼‰</p>\n<pre><code>wget &quot;https://pkg.cfssl.org/R1.2/cfssl_linux-amd64&quot; -O /usr/local/bin/cfssl\nwget &quot;https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64&quot; -O /usr/local/bin/cfssljson\nchmod +x /usr/local/bin/cfssl /usr/local/bin/cfssljson\n</code></pre>\n<h5 id=\"51-etcdè¯ä¹¦\"><a class=\"anchor\" href=\"#51-etcdè¯ä¹¦\">#</a> 5.1 Etcd è¯ä¹¦</h5>\n<p><mark>æ‰€æœ‰ Master èŠ‚ç‚¹</mark>åˆ›å»º etcd è¯ä¹¦ç›®å½•ï¼š</p>\n<pre><code>mkdir /etc/etcd/ssl -p\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>åˆ›å»º kubernetes ç›¸å…³ç›®å½•ï¼š</p>\n<pre><code>mkdir -p /etc/kubernetes/pki\n</code></pre>\n<p><mark>Master01 èŠ‚ç‚¹</mark>ç”Ÿæˆ etcd è¯ä¹¦</p>\n<p>ç”Ÿæˆè¯ä¹¦çš„ CSRï¼ˆè¯ä¹¦ç­¾åè¯·æ±‚æ–‡ä»¶ï¼Œé…ç½®äº†ä¸€äº›åŸŸåã€å…¬å¸ã€å•ä½ï¼‰æ–‡ä»¶ï¼š</p>\n<pre><code>[root@k8s-master01 pki]# cd /root/k8s-ha-install/pki\n\n# ç”Ÿæˆetcd CAè¯ä¹¦å’ŒCAè¯ä¹¦çš„key\ncfssl gencert -initca etcd-ca-csr.json | cfssljson -bare /etc/etcd/ssl/etcd-ca\n\n\ncfssl gencert \\\n   -ca=/etc/etcd/ssl/etcd-ca.pem \\\n   -ca-key=/etc/etcd/ssl/etcd-ca-key.pem \\\n   -config=ca-config.json \\\n   -hostname=127.0.0.1,k8s-master01,k8s-master02,k8s-master03,192.168.1.71,192.168.1.72,192.168.1.73 \\\n   -profile=kubernetes \\\n   etcd-csr.json | cfssljson -bare /etc/etcd/ssl/etcd\n\næ‰§è¡Œç»“æœ\n[INFO] generate received request\n \t[INFO] received CSR\n     [INFO] generating key: rsa-2048\n     [INFO] encoded CSR\n     [INFO] signed certificate with serial number     250230878926052708909595617022917808304837732033\n</code></pre>\n<p>å°†è¯ä¹¦å¤åˆ¶åˆ°å…¶ä»– master èŠ‚ç‚¹</p>\n<pre><code>MasterNodes='k8s-master02 k8s-master03'\n\nfor NODE in $MasterNodes; do\n     ssh $NODE &quot;mkdir -p /etc/etcd/ssl&quot;\n     for FILE in etcd-ca-key.pem  etcd-ca.pem  etcd-key.pem  etcd.pem; do\n       scp /etc/etcd/ssl/$&#123;FILE&#125; $NODE:/etc/etcd/ssl/$&#123;FILE&#125;\n     done\n done\n</code></pre>\n<h5 id=\"52-k8sç»„ä»¶è¯ä¹¦\"><a class=\"anchor\" href=\"#52-k8sç»„ä»¶è¯ä¹¦\">#</a> 5.2 K8s ç»„ä»¶è¯ä¹¦</h5>\n<p><mark>Master01</mark> ç”Ÿæˆ kubernetes CA è¯ä¹¦ï¼š</p>\n<pre><code>[root@k8s-master01 pki]# cd /root/k8s-ha-install/pki\n\ncfssl gencert -initca ca-csr.json | cfssljson -bare /etc/kubernetes/pki/ca\n</code></pre>\n<h6 id=\"521-apiserverè¯ä¹¦\"><a class=\"anchor\" href=\"#521-apiserverè¯ä¹¦\">#</a> 5.2.1 APIServer è¯ä¹¦</h6>\n<p>æ³¨æ„ï¼š10.96.0. æ˜¯ k8s service çš„ç½‘æ®µï¼Œå¦‚æœè¯´éœ€è¦æ›´æ”¹ k8s service ç½‘æ®µï¼Œé‚£å°±éœ€è¦æ›´æ”¹ 10.96.0.1</p>\n<pre><code>cfssl gencert   -ca=/etc/kubernetes/pki/ca.pem   -ca-key=/etc/kubernetes/pki/ca-key.pem   -config=ca-config.json   -hostname=10.96.0.1,192.168.1.70,127.0.0.1,kubernetes,kubernetes.default,kubernetes.default.svc,kubernetes.default.svc.cluster,kubernetes.default.svc.cluster.local,192.168.1.71,192.168.1.72,192.168.1.73   -profile=kubernetes   apiserver-csr.json | cfssljson -bare /etc/kubernetes/pki/apiserver\n</code></pre>\n<p>ç”Ÿæˆ apiserver çš„èšåˆè¯ä¹¦ï¼šï¼š</p>\n<pre><code>cfssl gencert   -initca front-proxy-ca-csr.json | cfssljson -bare /etc/kubernetes/pki/front-proxy-ca \n\ncfssl gencert   -ca=/etc/kubernetes/pki/front-proxy-ca.pem   -ca-key=/etc/kubernetes/pki/front-proxy-ca-key.pem   -config=ca-config.json   -profile=kubernetes   front-proxy-client-csr.json | cfssljson -bare /etc/kubernetes/pki/front-proxy-client\n</code></pre>\n<p>è¿”å›ç»“æœï¼ˆå¿½ç•¥è­¦å‘Šï¼‰ï¼š</p>\n<pre><code>2020/12/11 18:15:28 [INFO] generate received request\n2020/12/11 18:15:28 [INFO] received CSR\n2020/12/11 18:15:28 [INFO] generating key: rsa-2048\n\n2020/12/11 18:15:28 [INFO] encoded CSR\n2020/12/11 18:15:28 [INFO] signed certificate with serial number 597484897564859295955894546063479154194995827845\n2020/12/11 18:15:28 [WARNING] This certificate lacks a &quot;hosts&quot; field. This makes it unsuitable for\nwebsites. For more information see the Baseline Requirements for the Issuance and Management\nof Publicly-Trusted Certificates, v.1.1.6, from the CA/Browser Forum (https://cabforum.org);\nspecifically, section 10.2.3 (&quot;Information Requirements&quot;).\n</code></pre>\n<h6 id=\"522-controllermanager\"><a class=\"anchor\" href=\"#522-controllermanager\">#</a> 5.2.2 ControllerManager</h6>\n<p>ç”Ÿæˆ controller-manage çš„è¯ä¹¦ï¼š</p>\n<pre><code class=\"language-\\\">cfssl gencert \\\n   -ca=/etc/kubernetes/pki/ca.pem \\\n   -ca-key=/etc/kubernetes/pki/ca-key.pem \\\n   -config=ca-config.json \\\n   -profile=kubernetes \\\n   manager-csr.json | cfssljson -bare /etc/kubernetes/pki/controller-manager\n\næ³¨æ„ï¼šä¿®æ”¹é»„è‰²éƒ¨åˆ†çš„IPåœ°å€\n# set-clusterï¼šè®¾ç½®ä¸€ä¸ªé›†ç¾¤é¡¹ï¼Œ\n\nkubectl config set-cluster kubernetes \\\n     --certificate-authority=/etc/kubernetes/pki/ca.pem \\\n     --embed-certs=true \\\n     --server=https://192.168.1.70:8443 \\\n     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig\n\n# è®¾ç½®ä¸€ä¸ªç¯å¢ƒé¡¹ï¼Œä¸€ä¸ªä¸Šä¸‹æ–‡\nkubectl config set-context system:kube-controller-manager@kubernetes \\\n    --cluster=kubernetes \\\n    --user=system:kube-controller-manager \\\n    --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig\n\n# set-credentials è®¾ç½®ä¸€ä¸ªç”¨æˆ·é¡¹\n\nkubectl config set-credentials system:kube-controller-manager \\\n     --client-certificate=/etc/kubernetes/pki/controller-manager.pem \\\n     --client-key=/etc/kubernetes/pki/controller-manager-key.pem \\\n     --embed-certs=true \\\n     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig\n\n\n# ä½¿ç”¨æŸä¸ªç¯å¢ƒå½“åšé»˜è®¤ç¯å¢ƒ\n\nkubectl config use-context system:kube-controller-manager@kubernetes \\\n     --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig\n</code></pre>\n<h6 id=\"523-schedulerè¯ä¹¦\"><a class=\"anchor\" href=\"#523-schedulerè¯ä¹¦\">#</a> 5.2.3 Scheduler è¯ä¹¦</h6>\n<pre><code>cfssl gencert \\\n   -ca=/etc/kubernetes/pki/ca.pem \\\n   -ca-key=/etc/kubernetes/pki/ca-key.pem \\\n   -config=ca-config.json \\\n   -profile=kubernetes \\\n   scheduler-csr.json | cfssljson -bare /etc/kubernetes/pki/scheduler\n\næ³¨æ„ï¼šä¿®æ”¹é»„è‰²éƒ¨åˆ†çš„IPåœ°å€\n\nkubectl config set-cluster kubernetes \\\n     --certificate-authority=/etc/kubernetes/pki/ca.pem \\\n     --embed-certs=true \\\n     --server=https://192.168.1.70:8443 \\\n     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig\n\n\nkubectl config set-credentials system:kube-scheduler \\\n     --client-certificate=/etc/kubernetes/pki/scheduler.pem \\\n     --client-key=/etc/kubernetes/pki/scheduler-key.pem \\\n     --embed-certs=true \\\n     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig\n\nkubectl config set-context system:kube-scheduler@kubernetes \\\n     --cluster=kubernetes \\\n     --user=system:kube-scheduler \\\n     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig\n\nkubectl config use-context system:kube-scheduler@kubernetes \\\n     --kubeconfig=/etc/kubernetes/scheduler.kubeconfig\n</code></pre>\n<h6 id=\"524-ç”Ÿæˆç®¡ç†å‘˜è¯ä¹¦\"><a class=\"anchor\" href=\"#524-ç”Ÿæˆç®¡ç†å‘˜è¯ä¹¦\">#</a> 5.2.4 ç”Ÿæˆç®¡ç†å‘˜è¯ä¹¦</h6>\n<p>Kubectl /etc/Kubernetes/admin.conf ~/.kube/config</p>\n<pre><code>cfssl gencert \\\n   -ca=/etc/kubernetes/pki/ca.pem \\\n   -ca-key=/etc/kubernetes/pki/ca-key.pem \\\n   -config=ca-config.json \\\n   -profile=kubernetes \\\n   admin-csr.json | cfssljson -bare /etc/kubernetes/pki/admin\n\næ³¨æ„ï¼šä¿®æ”¹é»„è‰²éƒ¨åˆ†çš„IP\n\nkubectl config set-cluster kubernetes     --certificate-authority=/etc/kubernetes/pki/ca.pem     --embed-certs=true     --server=https://192.168.1.70:8443     --kubeconfig=/etc/kubernetes/admin.kubeconfig\nkubectl config set-credentials kubernetes-admin     --client-certificate=/etc/kubernetes/pki/admin.pem     --client-key=/etc/kubernetes/pki/admin-key.pem     --embed-certs=true     --kubeconfig=/etc/kubernetes/admin.kubeconfig\n\nkubectl config set-context kubernetes-admin@kubernetes     --cluster=kubernetes     --user=kubernetes-admin     --kubeconfig=/etc/kubernetes/admin.kubeconfig\n\nkubectl config use-context kubernetes-admin@kubernetes     --kubeconfig=/etc/kubernetes/admin.kubeconfig\n</code></pre>\n<h6 id=\"525-åˆ›å»ºserviceaccountè¯ä¹¦\"><a class=\"anchor\" href=\"#525-åˆ›å»ºserviceaccountè¯ä¹¦\">#</a> 5.2.5 åˆ›å»º ServiceAccount è¯ä¹¦</h6>\n<p>åˆ›å»ºä¸€å¯¹å…¬é’¥ï¼Œç”¨æ¥ç­¾å‘ ServiceAccount çš„ Tokenï¼š</p>\n<pre><code>openssl genrsa -out /etc/kubernetes/pki/sa.key 2048\n</code></pre>\n<p>è¿”å›ç»“æœï¼š</p>\n<pre><code>Generating RSA private key, 2048 bit long modulus (2 primes)\n...................................................................................+++++\n...............+++++\ne is 65537 (0x010001)\n</code></pre>\n<pre><code> openssl rsa -in /etc/kubernetes/pki/sa.key -pubout -out /etc/kubernetes/pki/sa.pub\n</code></pre>\n<p>å‘é€è¯ä¹¦è‡³å…¶ä»–èŠ‚ç‚¹ï¼š</p>\n<pre><code>for NODE in k8s-master02 k8s-master03; do \n  for FILE in $(ls /etc/kubernetes/pki | grep -v etcd); do \n    scp /etc/kubernetes/pki/$&#123;FILE&#125; $NODE:/etc/kubernetes/pki/$&#123;FILE&#125;;\n  done; \n  for FILE in admin.kubeconfig controller-manager.kubeconfig scheduler.kubeconfig; do \n    scp /etc/kubernetes/$&#123;FILE&#125; $NODE:/etc/kubernetes/$&#123;FILE&#125;;\n  done;\ndone\n</code></pre>\n<p>æŸ¥çœ‹è¯ä¹¦æ–‡ä»¶ï¼š</p>\n<pre><code>[root@k8s-master01 pki]# ls /etc/kubernetes/pki/\nadmin.csr      apiserver.csr      ca.csr      controller-manager.csr      front-proxy-ca.csr      front-proxy-client.csr      sa.key         scheduler-key.pem\nadmin-key.pem  apiserver-key.pem  ca-key.pem  controller-manager-key.pem  front-proxy-ca-key.pem  front-proxy-client-key.pem  sa.pub         scheduler.pem\nadmin.pem      apiserver.pem      ca.pem      controller-manager.pem      front-proxy-ca.pem      front-proxy-client.pem      scheduler.csr\n[root@k8s-master01 pki]# ls /etc/kubernetes/pki/ |wc -l\n23\n</code></pre>\n<h4 id=\"6-kubernetesç»„ä»¶é…ç½®\"><a class=\"anchor\" href=\"#6-kubernetesç»„ä»¶é…ç½®\">#</a> 6. Kubernetes ç»„ä»¶é…ç½®</h4>\n<h5 id=\"61-ecdé…ç½®\"><a class=\"anchor\" href=\"#61-ecdé…ç½®\">#</a> 6.1 Ecd é…ç½®</h5>\n<p>Etcd é…ç½®å¤§è‡´ç›¸åŒï¼Œæ³¨æ„ä¿®æ”¹æ¯ä¸ª Master èŠ‚ç‚¹çš„ etcd é…ç½®çš„ä¸»æœºåå’Œ IP åœ°å€</p>\n<h6 id=\"611-master01\"><a class=\"anchor\" href=\"#611-master01\">#</a> 6.1.1 Master01</h6>\n<pre><code># vim /etc/etcd/etcd.config.yml\nname: 'k8s-master01'     # k8s-master01åç§°\ndata-dir: /var/lib/etcd\nwal-dir: /var/lib/etcd/wal\nsnapshot-count: 5000\nheartbeat-interval: 100\nelection-timeout: 1000\nquota-backend-bytes: 0\nlisten-peer-urls: 'https://192.168.1.71:2380'            # k8s-master01 IP\nlisten-client-urls: 'https://192.168.1.71:2379,http://127.0.0.1:2379'   # k8s-master01 IP\nmax-snapshots: 3\nmax-wals: 5\ncors:\ninitial-advertise-peer-urls: 'https://192.168.1.71:2380'  # k8s-master01 IP\nadvertise-client-urls: 'https://192.168.1.71:2379'        # k8s-master01 IP\ndiscovery:\ndiscovery-fallback: 'proxy'\ndiscovery-proxy:\ndiscovery-srv:\ninitial-cluster: 'k8s-master01=https://192.168.1.71:2380,k8s-master02=https://192.168.1.72:2380,k8s-master03=https://192.168.1.73:2380'     # k8s-master01ã€k8s-master02ã€k8s-master03 IP \ninitial-cluster-token: 'etcd-k8s-cluster'\ninitial-cluster-state: 'new'\nstrict-reconfig-check: false\nenable-v2: true\nenable-pprof: true\nproxy: 'off'\nproxy-failure-wait: 5000\nproxy-refresh-interval: 30000\nproxy-dial-timeout: 1000\nproxy-write-timeout: 5000\nproxy-read-timeout: 0\nclient-transport-security:\n  cert-file: '/etc/kubernetes/pki/etcd/etcd.pem'\n  key-file: '/etc/kubernetes/pki/etcd/etcd-key.pem'\n  client-cert-auth: true\n  trusted-ca-file: '/etc/kubernetes/pki/etcd/etcd-ca.pem'\n  auto-tls: true\npeer-transport-security:\n  cert-file: '/etc/kubernetes/pki/etcd/etcd.pem'\n  key-file: '/etc/kubernetes/pki/etcd/etcd-key.pem'\n  peer-client-cert-auth: true\n  trusted-ca-file: '/etc/kubernetes/pki/etcd/etcd-ca.pem'\n  auto-tls: true\ndebug: false\nlog-package-levels:\nlog-outputs: [default]\nforce-new-cluster: false\n</code></pre>\n<h6 id=\"612-master02\"><a class=\"anchor\" href=\"#612-master02\">#</a> 6.1.2 Master02</h6>\n<pre><code># vim /etc/etcd/etcd.config.yml\t\nname: 'k8s-master02'   # k8s-master02åç§°\ndata-dir: /var/lib/etcd\nwal-dir: /var/lib/etcd/wal\nsnapshot-count: 5000\nheartbeat-interval: 100\nelection-timeout: 1000\nquota-backend-bytes: 0\nlisten-peer-urls: 'https://192.168.1.72:2380'      # k8s-master02 IP\nlisten-client-urls: 'https://192.168.1.72:2379,http://127.0.0.1:2379'    # k8s-master02 IP\nmax-snapshots: 3\nmax-wals: 5\ncors:\ninitial-advertise-peer-urls: 'https://192.168.1.72:2380'    # k8s-master02 IP\nadvertise-client-urls: 'https://192.168.1.72:2379'     # k8s-master02 IP\ndiscovery:\ndiscovery-fallback: 'proxy'\ndiscovery-proxy:\ndiscovery-srv:\ninitial-cluster: 'k8s-master01=https://192.168.1.71:2380,k8s-master02=https://192.168.1.72:2380,k8s-master03=https://192.168.1.73:2380'             # k8s-master01ã€k8s-master02ã€k8s-master03 IP \ninitial-cluster-token: 'etcd-k8s-cluster'\ninitial-cluster-state: 'new'\nstrict-reconfig-check: false\nenable-v2: true\nenable-pprof: true\nproxy: 'off'\nproxy-failure-wait: 5000\nproxy-refresh-interval: 30000\nproxy-dial-timeout: 1000\nproxy-write-timeout: 5000\nproxy-read-timeout: 0\nclient-transport-security:\n  cert-file: '/etc/kubernetes/pki/etcd/etcd.pem'\n  key-file: '/etc/kubernetes/pki/etcd/etcd-key.pem'\n  client-cert-auth: true\n  trusted-ca-file: '/etc/kubernetes/pki/etcd/etcd-ca.pem'\n  auto-tls: true\npeer-transport-security:\n  cert-file: '/etc/kubernetes/pki/etcd/etcd.pem'\n  key-file: '/etc/kubernetes/pki/etcd/etcd-key.pem'\n  peer-client-cert-auth: true\n  trusted-ca-file: '/etc/kubernetes/pki/etcd/etcd-ca.pem'\n  auto-tls: true\ndebug: false\nlog-package-levels:\nlog-outputs: [default]\nforce-new-cluster: false\n</code></pre>\n<h6 id=\"613-master03\"><a class=\"anchor\" href=\"#613-master03\">#</a> 6.1.3 Master03</h6>\n<pre><code># vim /etc/etcd/etcd.config.yml\nname: 'k8s-master03'           # k8s-master03åç§°\ndata-dir: /var/lib/etcd\nwal-dir: /var/lib/etcd/wal\nsnapshot-count: 5000\nheartbeat-interval: 100\nelection-timeout: 1000\nquota-backend-bytes: 0\nlisten-peer-urls: 'https://192.168.1.73:2380'           # k8s-master03 IP\nlisten-client-urls: 'https://192.168.1.73:2379,http://127.0.0.1:2379'       # k8s-master03 IP\nmax-snapshots: 3\nmax-wals: 5\ncors:\ninitial-advertise-peer-urls: 'https://192.168.1.73:2380'      # k8s-master03 IP\nadvertise-client-urls: 'https://192.168.1.73:2379'            # k8s-master03 IP\ndiscovery:\ndiscovery-fallback: 'proxy'\ndiscovery-proxy:\ndiscovery-srv:\ninitial-cluster: 'k8s-master01=https://192.168.1.71:2380,k8s-master02=https://192.168.1.72:2380,k8s-master03=https://192.168.1.73:2380'                # k8s-master01ã€k8s-master02ã€k8s-master03 IP\ninitial-cluster-token: 'etcd-k8s-cluster'\ninitial-cluster-state: 'new'\nstrict-reconfig-check: false\nenable-v2: true\nenable-pprof: true\nproxy: 'off'\nproxy-failure-wait: 5000\nproxy-refresh-interval: 30000\nproxy-dial-timeout: 1000\nproxy-write-timeout: 5000\nproxy-read-timeout: 0\nclient-transport-security:\n  cert-file: '/etc/kubernetes/pki/etcd/etcd.pem'\n  key-file: '/etc/kubernetes/pki/etcd/etcd-key.pem'\n  client-cert-auth: true\n  trusted-ca-file: '/etc/kubernetes/pki/etcd/etcd-ca.pem'\n  auto-tls: true\npeer-transport-security:\n  cert-file: '/etc/kubernetes/pki/etcd/etcd.pem'\n  key-file: '/etc/kubernetes/pki/etcd/etcd-key.pem'\n  peer-client-cert-auth: true\n  trusted-ca-file: '/etc/kubernetes/pki/etcd/etcd-ca.pem'\n  auto-tls: true\ndebug: false\nlog-package-levels:\nlog-outputs: [default]\nforce-new-cluster: false\n</code></pre>\n<h6 id=\"614-å¯åŠ¨etcd\"><a class=\"anchor\" href=\"#614-å¯åŠ¨etcd\">#</a> 6.1.4 å¯åŠ¨ Etcd</h6>\n<p><mark>æ‰€æœ‰ Master èŠ‚ç‚¹</mark>åˆ›å»º etcd service å¹¶å¯åŠ¨</p>\n<pre><code># vim /usr/lib/systemd/system/etcd.service\n[Unit]\nDescription=Etcd Service\nDocumentation=https://coreos.com/etcd/docs/latest/\nAfter=network.target\n\n[Service]\nType=notify\nExecStart=/usr/local/bin/etcd --config-file=/etc/etcd/etcd.config.yml\nRestart=on-failure\nRestartSec=10\nLimitNOFILE=65536\n\n[Install]\nWantedBy=multi-user.target\nAlias=etcd3.service\n</code></pre>\n<p><mark>æ‰€æœ‰ Master èŠ‚ç‚¹</mark>åˆ›å»º etcd çš„è¯ä¹¦ç›®å½•ï¼š</p>\n<pre><code>mkdir /etc/kubernetes/pki/etcd\nln -s /etc/etcd/ssl/* /etc/kubernetes/pki/etcd/\nsystemctl daemon-reload\nsystemctl enable --now etcd\n</code></pre>\n<p>æŸ¥çœ‹ etcd çŠ¶æ€ï¼š</p>\n<pre><code>export ETCDCTL_API=3\netcdctl --endpoints=&quot;192.168.1.73:2379,192.168.1.72:2379,192.168.1.71:2379&quot; --cacert=/etc/kubernetes/pki/etcd/etcd-ca.pem --cert=/etc/kubernetes/pki/etcd/etcd.pem --key=/etc/kubernetes/pki/etcd/etcd-key.pem  endpoint status --write-out=table\n</code></pre>\n<h5 id=\"62-apiserveré…ç½®\"><a class=\"anchor\" href=\"#62-apiserveré…ç½®\">#</a> 6.2 APIServer é…ç½®</h5>\n<h6 id=\"621-master01\"><a class=\"anchor\" href=\"#621-master01\">#</a> 6.2.1 Master01</h6>\n<p>æ³¨æ„ï¼šæœ¬æ–‡æ¡£ä½¿ç”¨çš„ k8s service ç½‘æ®µä¸º 10.96.0.0/16ï¼Œè¯¥ç½‘æ®µä¸èƒ½å’Œå®¿ä¸»æœºçš„ç½‘æ®µã€Pod ç½‘æ®µçš„é‡å¤ï¼Œè¯·æŒ‰éœ€ä¿®æ”¹ï¼š</p>\n<pre><code>[root@k8s-master01 pki]# vim /usr/lib/systemd/system/kube-apiserver.service \n\n[Unit]\nDescription=Kubernetes API Server\nDocumentation=https://github.com/kubernetes/kubernetes\nAfter=network.target\n\n[Service]\nExecStart=/usr/local/bin/kube-apiserver \\\n      --v=2  \\\n      --allow-privileged=true  \\\n      --bind-address=0.0.0.0  \\\n      --secure-port=6443  \\\n      --advertise-address=192.168.1.71 \\\n      --service-cluster-ip-range=10.96.0.0/16  \\\n      --service-node-port-range=30000-32767  \\\n      --etcd-servers=https://192.168.1.71:2379,https://192.168.1.72:2379,https://192.168.1.73:2379 \\\n      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \\\n      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \\\n      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \\\n      --client-ca-file=/etc/kubernetes/pki/ca.pem  \\\n      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \\\n      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \\\n      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \\\n      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \\\n      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \\\n      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \\\n      --service-account-issuer=https://kubernetes.default.svc.cluster.local \\\n      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \\\n      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \\\n      --authorization-mode=Node,RBAC  \\\n      --enable-bootstrap-token-auth=true  \\\n      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \\\n      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \\\n      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \\\n      --requestheader-allowed-names=aggregator  \\\n      --requestheader-group-headers=X-Remote-Group  \\\n      --requestheader-extra-headers-prefix=X-Remote-Extra-  \\\n      --requestheader-username-headers=X-Remote-User\n      # --token-auth-file=/etc/kubernetes/token.csv\n\nRestart=on-failure\nRestartSec=10s\nLimitNOFILE=65535\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>\n<h6 id=\"622-master02\"><a class=\"anchor\" href=\"#622-master02\">#</a> 6.2.2 Master02</h6>\n<p>æ³¨æ„ï¼šæœ¬æ–‡æ¡£ä½¿ç”¨çš„ k8s service ç½‘æ®µä¸º 10.96.0.0/16ï¼Œè¯¥ç½‘æ®µä¸èƒ½å’Œå®¿ä¸»æœºçš„ç½‘æ®µã€Pod ç½‘æ®µçš„é‡å¤ï¼Œè¯·æŒ‰éœ€ä¿®æ”¹ï¼š</p>\n<pre><code>[root@k8s-master01 pki]# vim  /usr/lib/systemd/system/kube-apiserver.service \n\n[Unit]\nDescription=Kubernetes API Server\nDocumentation=https://github.com/kubernetes/kubernetes\nAfter=network.target\n\n[Service]\nExecStart=/usr/local/bin/kube-apiserver \\\n      --v=2  \\\n      --allow-privileged=true  \\\n      --bind-address=0.0.0.0  \\\n      --secure-port=6443  \\\n      --advertise-address=192.168.1.72 \\\n      --service-cluster-ip-range=10.96.0.0/16  \\\n      --service-node-port-range=30000-32767  \\\n      --etcd-servers=https://192.168.1.71:2379,https://192.168.1.72:2379,https://192.168.1.73:2379 \\\n      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \\\n      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \\\n      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \\\n      --client-ca-file=/etc/kubernetes/pki/ca.pem  \\\n      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \\\n      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \\\n      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \\\n      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \\\n      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \\\n      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \\\n      --service-account-issuer=https://kubernetes.default.svc.cluster.local \\\n      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \\\n      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \\\n      --authorization-mode=Node,RBAC  \\\n      --enable-bootstrap-token-auth=true  \\\n      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \\\n      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \\\n      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \\\n      --requestheader-allowed-names=aggregator  \\\n      --requestheader-group-headers=X-Remote-Group  \\\n      --requestheader-extra-headers-prefix=X-Remote-Extra-  \\\n      --requestheader-username-headers=X-Remote-User\n\nRestart=on-failure\nRestartSec=10s\nLimitNOFILE=65535\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>\n<h6 id=\"623-master03\"><a class=\"anchor\" href=\"#623-master03\">#</a> 6.2.3 Master03</h6>\n<p>æ³¨æ„ï¼šæœ¬æ–‡æ¡£ä½¿ç”¨çš„ k8s service ç½‘æ®µä¸º 10.96.0.0/16ï¼Œè¯¥ç½‘æ®µä¸èƒ½å’Œå®¿ä¸»æœºçš„ç½‘æ®µã€Pod ç½‘æ®µçš„é‡å¤ï¼Œè¯·æŒ‰éœ€ä¿®æ”¹ï¼š</p>\n<pre><code>[root@k8s-master01 pki]# vim  /usr/lib/systemd/system/kube-apiserver.service \n\n[Unit]\nDescription=Kubernetes API Server\nDocumentation=https://github.com/kubernetes/kubernetes\nAfter=network.target\n\n[Service]\nExecStart=/usr/local/bin/kube-apiserver \\\n      --v=2  \\\n      --allow-privileged=true  \\\n      --bind-address=0.0.0.0  \\\n      --secure-port=6443  \\\n      --advertise-address=192.168.1.73 \\\n      --service-cluster-ip-range=10.96.0.0/16  \\\n      --service-node-port-range=30000-32767  \\\n      --etcd-servers=https://192.168.1.71:2379,https://192.168.1.72:2379,https://192.168.1.73:2379 \\\n      --etcd-cafile=/etc/etcd/ssl/etcd-ca.pem  \\\n      --etcd-certfile=/etc/etcd/ssl/etcd.pem  \\\n      --etcd-keyfile=/etc/etcd/ssl/etcd-key.pem  \\\n      --client-ca-file=/etc/kubernetes/pki/ca.pem  \\\n      --tls-cert-file=/etc/kubernetes/pki/apiserver.pem  \\\n      --tls-private-key-file=/etc/kubernetes/pki/apiserver-key.pem  \\\n      --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.pem  \\\n      --kubelet-client-key=/etc/kubernetes/pki/apiserver-key.pem  \\\n      --service-account-key-file=/etc/kubernetes/pki/sa.pub  \\\n      --service-account-signing-key-file=/etc/kubernetes/pki/sa.key  \\\n      --service-account-issuer=https://kubernetes.default.svc.cluster.local \\\n      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \\\n      --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,ResourceQuota  \\\n      --authorization-mode=Node,RBAC  \\\n      --enable-bootstrap-token-auth=true  \\\n      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \\\n      --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \\\n      --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \\\n      --requestheader-allowed-names=aggregator  \\\n      --requestheader-group-headers=X-Remote-Group  \\\n      --requestheader-extra-headers-prefix=X-Remote-Extra-  \\\n      --requestheader-username-headers=X-Remote-User\n      # --token-auth-file=/etc/kubernetes/token.csv\n\nRestart=on-failure\nRestartSec=10s\nLimitNOFILE=65535\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>\n<h6 id=\"624-å¯åŠ¨apiserver\"><a class=\"anchor\" href=\"#624-å¯åŠ¨apiserver\">#</a> 6.2.4 å¯åŠ¨ apiserver</h6>\n<p><mark>æ‰€æœ‰ Master èŠ‚ç‚¹</mark>å¼€å¯ kube-apiserverï¼š</p>\n<pre><code>systemctl daemon-reload &amp;&amp; systemctl enable --now kube-apiserver\n</code></pre>\n<p>æ£€æµ‹ kube-server çŠ¶æ€ï¼š</p>\n<pre><code># systemctl status kube-apiserver\n\nâ— kube-apiserver.service â€“ Kubernetes API Server\n   Loaded: loaded (/usr/lib/systemd/system/kube-apiserver.service; enabled; vendor preset: disabled)\n   Active: active (running) since Sat 2020-08-22 21:26:49 CST; 26s agoÂ \n</code></pre>\n<p>å¦‚æœç³»ç»Ÿæ—¥å¿—æœ‰è¿™äº›æç¤ºå¯ä»¥å¿½ç•¥:</p>\n<pre><code>Dec 11 20:51:15 k8s-master01 kube-apiserver: I1211 20:51:15.004739    7450 clientconn.go:948] ClientConn switching balancer to â€œpick_firstâ€\nDec 11 20:51:15 k8s-master01 kube-apiserver: I1211 20:51:15.004843    7450 balancer_conn_wrappers.go:78] pickfirstBalancer: HandleSubConnStateChange: 0xc011bd4c80, &#123;CONNECTING &lt;nil&gt;&#125;\nDec 11 20:51:15 k8s-master01 kube-apiserver: I1211 20:51:15.010725    7450 balancer_conn_wrappers.go:78] pickfirstBalancer: HandleSubConnStateChange: 0xc011bd4c80, &#123;READY &lt;nil&gt;&#125;\nDec 11 20:51:15 k8s-master01 kube-apiserver: I1211 20:51:15.011370    7450 controlbuf.go:508] transport: loopyWriter.run returning. Connection error: desc = â€œtransport is closingâ€\n</code></pre>\n<h5 id=\"63-controllermanage\"><a class=\"anchor\" href=\"#63-controllermanage\">#</a> 6.3 ControllerManage</h5>\n<p><mark>æ‰€æœ‰ Master èŠ‚ç‚¹</mark>é…ç½® kube-controller-manager serviceï¼ˆæ‰€æœ‰ master èŠ‚ç‚¹é…ç½®ä¸€æ ·ï¼‰</p>\n<p>æ³¨æ„ï¼šæœ¬æ–‡æ¡£ä½¿ç”¨çš„ k8s Pod ç½‘æ®µä¸º 172.16.0.0/16ï¼Œè¯¥ç½‘æ®µä¸èƒ½å’Œå®¿ä¸»æœºçš„ç½‘æ®µã€k8s Service ç½‘æ®µçš„é‡å¤ï¼Œè¯·æŒ‰éœ€ä¿®æ”¹ï¼š</p>\n<pre><code>[root@k8s-master01 pki]# vim /usr/lib/systemd/system/kube-controller-manager.service\n[Unit]\nDescription=Kubernetes Controller Manager\nDocumentation=https://github.com/kubernetes/kubernetes\nAfter=network.target\n\n[Service]\nExecStart=/usr/local/bin/kube-controller-manager \\\n      --v=2 \\\n      --root-ca-file=/etc/kubernetes/pki/ca.pem \\\n      --cluster-signing-cert-file=/etc/kubernetes/pki/ca.pem \\\n      --cluster-signing-key-file=/etc/kubernetes/pki/ca-key.pem \\\n      --service-account-private-key-file=/etc/kubernetes/pki/sa.key \\\n      --kubeconfig=/etc/kubernetes/controller-manager.kubeconfig \\\n      --authentication-kubeconfig=/etc/kubernetes/controller-manager.kubeconfig \\\n      --authorization-kubeconfig=/etc/kubernetes/controller-manager.kubeconfig \\\n      --leader-elect=true \\\n      --use-service-account-credentials=true \\\n      --node-monitor-grace-period=40s \\\n      --node-monitor-period=5s \\\n      --controllers=*,bootstrapsigner,tokencleaner \\\n      --allocate-node-cidrs=true \\\n      --cluster-cidr=172.16.0.0/16 \\\n      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem \\\n      --node-cidr-mask-size=24\n      \nRestart=always\nRestartSec=10s\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>\n<p><mark>æ‰€æœ‰ Master èŠ‚ç‚¹</mark>å¯åŠ¨ kube-controller-manager</p>\n<pre><code>[root@k8s-master01 pki]# systemctl daemon-reload\n\n[root@k8s-master01 pki]# systemctl enable --now kube-controller-manager\nCreated symlink /etc/systemd/system/multi-user.target.wants/kube-controller-manager.service â†’ /usr/lib/systemd/system/kube-controller-manager.service.\n</code></pre>\n<p>æŸ¥çœ‹å¯åŠ¨çŠ¶æ€</p>\n<pre><code>[root@k8s-master01 pki]# systemctl  status kube-controller-manager\nâ— kube-controller-manager.service â€“ Kubernetes Controller Manager\n   Loaded: loaded (/usr/lib/ ubern/system/kube-controller-manager.service; enabled; vendor preset: disabled)\n Active: active (running) since Fri 2020-12-11 20:53:05 CST; 8s ago\n     Docs: https://github.com/  ubernetes/  ubernetes\n Main PID: 7518 (kube-controller)\n</code></pre>\n<h5 id=\"64-scheduler\"><a class=\"anchor\" href=\"#64-scheduler\">#</a> 6.4 Scheduler</h5>\n<p>æ‰€æœ‰ Master èŠ‚ç‚¹é…ç½® kube-scheduler serviceï¼ˆæ‰€æœ‰ master èŠ‚ç‚¹é…ç½®ä¸€æ ·ï¼‰</p>\n<pre><code>[root@k8s-master01 pki]# vim /usr/lib/systemd/system/kube-scheduler.service \n[Unit]\nDescription=Kubernetes Scheduler\nDocumentation=https://github.com/kubernetes/kubernetes\nAfter=network.target\n\n[Service]\nExecStart=/usr/local/bin/kube-scheduler \\\n      --v=2 \\\n      --leader-elect=true \\\n      --authentication-kubeconfig=/etc/kubernetes/scheduler.kubeconfig \\\n      --authorization-kubeconfig=/etc/kubernetes/scheduler.kubeconfig \\\n      --kubeconfig=/etc/kubernetes/scheduler.kubeconfig\n\nRestart=always\nRestartSec=10s\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>\n<p>å¯åŠ¨ schedulerï¼š</p>\n<pre><code>[root@k8s-master01 pki]# systemctl daemon-reload\n\n[root@k8s-master01 pki]# systemctl enable --now kube-scheduler\nCreated symlink /etc/systemd/system/multi-user.target.wants/kube-scheduler.service â†’ /usr/lib/systemd/system/kube-scheduler.service.\n[root@k8s-master01 pki]# systemctl status kube-scheduler\nâ— kube-scheduler.service - Kubernetes Scheduler\n   Loaded: loaded (/usr/lib/systemd/system/kube-scheduler.service; enabled; vendor preset: disabled)\n   Active: active (running) since Wed 2022-05-04 17:31:13 CST; 6s ago\n     Docs: https://github.com/kubernetes/kubernetes\n Main PID: 5815 (kube-scheduler)\n    Tasks: 9\n   Memory: 19.8M\n</code></pre>\n<h4 id=\"7-tls-bootstrappingé…ç½®\"><a class=\"anchor\" href=\"#7-tls-bootstrappingé…ç½®\">#</a> 7. TLS Bootstrapping é…ç½®</h4>\n<p>åªéœ€è¦åœ¨<mark> Master01</mark> åˆ›å»º bootstrap</p>\n<p>æ³¨æ„ï¼š ä¿®æ”¹é»„è‰²éƒ¨åˆ†çš„ IP åœ°å€</p>\n<pre><code>cd /root/k8s-ha-install/bootstrap\nkubectl config set-cluster kubernetes     --certificate-authority=/etc/kubernetes/pki/ca.pem     --embed-certs=true     --server=https://192.168.1.70:8443     --kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig\nkubectl config set-credentials tls-bootstrap-token-user     --token=c8ad9c.2e4d610cf3e7426e --kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig\nkubectl config set-context tls-bootstrap-token-user@kubernetes     --cluster=kubernetes     --user=tls-bootstrap-token-user     --kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig\nkubectl config use-context tls-bootstrap-token-user@kubernetes     --kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig\n\n[root@k8s-master01 bootstrap]# mkdir -p /root/.kube ; cp /etc/kubernetes/admin.kubeconfig /root/.kube/config\n</code></pre>\n<p>å¯ä»¥æ­£å¸¸æŸ¥è¯¢é›†ç¾¤çŠ¶æ€ï¼Œæ‰å¯ä»¥ç»§ç»­å¾€ä¸‹ï¼Œå¦åˆ™ä¸è¡Œï¼Œéœ€è¦æ’æŸ¥ k8s ç»„ä»¶æ˜¯å¦æœ‰æ•…éšœï¼ˆåªè¦æœ‰ç»“æœå³å¯ï¼Œå¦‚æœè¿”å›ä¸ä¸€æ ·ä¸å½±å“ï¼‰</p>\n<pre><code># kubectl get cs\nWarning: v1 ComponentStatus is deprecated in v1.19+\nNAME                 STATUS    MESSAGE   ERROR\ncontroller-manager   Healthy   ok        \nscheduler            Healthy   ok        \netcd-0               Healthy   ok\n</code></pre>\n<p>åˆ›å»º bootstrap ç›¸å…³èµ„æºï¼š</p>\n<pre><code>[root@k8s-master01 bootstrap]# kubectl create -f bootstrap.secret.yaml \nsecret/bootstrap-token-c8ad9c created\nclusterrolebinding.rbac.authorization.k8s.io/kubelet-bootstrap created\nclusterrolebinding.rbac.authorization.k8s.io/node-autoapprove-bootstrap created\nclusterrolebinding.rbac.authorization.k8s.io/node-autoapprove-certificate-rotation created\nclusterrole.rbac.authorization.k8s.io/system:kube-apiserver-to-kubelet created\nclusterrolebinding.rbac.authorization.k8s.io/system:kube-apiserver created\n</code></pre>\n<h4 id=\"8-nodeèŠ‚ç‚¹é…ç½®\"><a class=\"anchor\" href=\"#8-nodeèŠ‚ç‚¹é…ç½®\">#</a> 8. Node èŠ‚ç‚¹é…ç½®</h4>\n<h5 id=\"81-å¤åˆ¶è¯ä¹¦\"><a class=\"anchor\" href=\"#81-å¤åˆ¶è¯ä¹¦\">#</a> 8.1 å¤åˆ¶è¯ä¹¦</h5>\n<p><mark>Master01 èŠ‚ç‚¹</mark>å¤åˆ¶è¯ä¹¦è‡³å…¶ä»–èŠ‚ç‚¹ï¼š</p>\n<pre><code>cd /etc/kubernetes/\n\nfor NODE in k8s-master02 k8s-master03 k8s-node01 k8s-node02; do\n     ssh $NODE mkdir -p /etc/kubernetes/pki\n     for FILE in pki/ca.pem pki/ca-key.pem pki/front-proxy-ca.pem bootstrap-kubelet.kubeconfig; do\n       scp /etc/kubernetes/$FILE $NODE:/etc/kubernetes/$&#123;FILE&#125;\n done\n done\n</code></pre>\n<p>æ‰§è¡Œç»“æœï¼š</p>\n<pre><code>ca.pem                                                                                                                                                                         100% 1407   459.5KB/s   00:00    \nâ€¦\nbootstrap-kubelet.kubeconfig                                                                                                                                                   100% 2291   685.4KB/s   00:00\n</code></pre>\n<h5 id=\"82-kubeleté…ç½®\"><a class=\"anchor\" href=\"#82-kubeleté…ç½®\">#</a> 8.2 Kubelet é…ç½®</h5>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>åˆ›å»º Kubelet é…ç½®ç›®å½•</p>\n<pre><code>mkdir -p /var/lib/kubelet /var/log/kubernetes /etc/systemd/system/kubelet.service.d /etc/kubernetes/manifests/\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>é…ç½® kubelet service</p>\n<pre><code>[root@k8s-master01 bootstrap]# vim  /usr/lib/systemd/system/kubelet.service\n\n[Unit]\nDescription=Kubernetes Kubelet\nDocumentation=https://github.com/kubernetes/kubernetes\n\n[Service]\nExecStart=/usr/local/bin/kubelet\n\nRestart=always\nStartLimitInterval=0\nRestartSec=10\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>é…ç½® kubelet service çš„é…ç½®æ–‡ä»¶ï¼ˆä¹Ÿå¯ä»¥å†™åˆ° kubelet.serviceï¼‰ï¼š</p>\n<pre><code># Runtimeä¸ºContainerd\n# vim /etc/systemd/system/kubelet.service.d/10-kubelet.conf\n\n[Service]\nEnvironment=&quot;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.kubeconfig --kubeconfig=/etc/kubernetes/kubelet.kubeconfig&quot;\nEnvironment=&quot;KUBELET_SYSTEM_ARGS=--container-runtime-endpoint=unix:///run/containerd/containerd.sock&quot;\nEnvironment=&quot;KUBELET_CONFIG_ARGS=--config=/etc/kubernetes/kubelet-conf.yml&quot;\nEnvironment=&quot;KUBELET_EXTRA_ARGS=--node-labels=node.kubernetes.io/node='' &quot;\nExecStart=\nExecStart=/usr/local/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_SYSTEM_ARGS $KUBELET_EXTRA_ARGS\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>åˆ›å»º kubelet çš„é…ç½®æ–‡ä»¶</p>\n<p><em>æ³¨æ„ï¼šå¦‚æœæ›´æ”¹äº† k8s çš„ service ç½‘æ®µï¼Œéœ€è¦æ›´æ”¹ kubelet-conf.yml çš„ clusterDNS: é…ç½®ï¼Œæ”¹æˆ k8s Service ç½‘æ®µçš„ç¬¬åä¸ªåœ°å€ï¼Œæ¯”å¦‚ 10.96.0.10</em></p>\n<pre><code>[root@k8s-master01 bootstrap]# vim /etc/kubernetes/kubelet-conf.yml\n\napiVersion: kubelet.config.k8s.io/v1beta1\nkind: KubeletConfiguration\naddress: 0.0.0.0\nport: 10250\nreadOnlyPort: 10255\nauthentication:\n  anonymous:\n    enabled: false\n  webhook:\n    cacheTTL: 2m0s\n    enabled: true\n  x509:\n    clientCAFile: /etc/kubernetes/pki/ca.pem\nauthorization:\n  mode: Webhook\n  webhook:\n    cacheAuthorizedTTL: 5m0s\n    cacheUnauthorizedTTL: 30s\ncgroupDriver: systemd\ncgroupsPerQOS: true\nclusterDNS:\n- 10.96.0.10\nclusterDomain: cluster.local\ncontainerLogMaxFiles: 5\ncontainerLogMaxSize: 10Mi\ncontentType: application/vnd.kubernetes.protobuf\ncpuCFSQuota: true\ncpuManagerPolicy: none\ncpuManagerReconcilePeriod: 10s\nenableControllerAttachDetach: true\nenableDebuggingHandlers: true\nenforceNodeAllocatable:\n- pods\neventBurst: 10\neventRecordQPS: 5\nevictionHard:\n  imagefs.available: 15%\n  memory.available: 100Mi\n  nodefs.available: 10%\n  nodefs.inodesFree: 5%\nevictionPressureTransitionPeriod: 5m0s\nfailSwapOn: true\nfileCheckFrequency: 20s\nhairpinMode: promiscuous-bridge\nhealthzBindAddress: 127.0.0.1\nhealthzPort: 10248\nhttpCheckFrequency: 20s\nimageGCHighThresholdPercent: 85\nimageGCLowThresholdPercent: 80\nimageMinimumGCAge: 2m0s\niptablesDropBit: 15\niptablesMasqueradeBit: 14\nkubeAPIBurst: 10\nkubeAPIQPS: 5\nmakeIPTablesUtilChains: true\nmaxOpenFiles: 1000000\nmaxPods: 110\nnodeStatusUpdateFrequency: 10s\noomScoreAdj: -999\npodPidsLimit: -1\nregistryBurst: 10\nregistryPullQPS: 5\nresolvConf: /etc/resolv.conf\nrotateCertificates: true\nruntimeRequestTimeout: 2m0s\nserializeImagePulls: true\nstaticPodPath: /etc/kubernetes/manifests\nstreamingConnectionIdleTimeout: 4h0m0s\nsyncFrequency: 1m0s\nvolumeStatsAggPeriod: 1m0s\n</code></pre>\n<p>å¯åŠ¨<mark>æ‰€æœ‰èŠ‚ç‚¹</mark> kubelet</p>\n<pre><code>systemctl daemon-reload\nsystemctl enable --now kubelet\n</code></pre>\n<p>æ­¤æ—¶ç³»ç»Ÿæ—¥å¿— /var/log/messages**** æ˜¾ç¤ºåªæœ‰å¦‚ä¸‹ä¸¤ç§ä¿¡æ¯ä¸ºæ­£å¸¸ ****ï¼Œå®‰è£… calico åå³å¯æ¢å¤</p>\n<pre><code>Unable to update cni config: no networks found in /etc/cni/net.d\n</code></pre>\n<p><a href=\"https://imgse.com/i/pE2ZkVK\"><img loading=\"lazy\" data-src=\"https://s21.ax1x.com/2025/04/10/pE2ZkVK.png\" alt=\"pE2ZkVK.png\" /></a></p>\n<p><em>å¦‚æœæœ‰å¾ˆå¤šæŠ¥é”™æ—¥å¿—ï¼Œæˆ–è€…æœ‰å¤§é‡çœ‹ä¸æ‡‚çš„æŠ¥é”™ï¼Œè¯´æ˜ kubelet çš„é…ç½®æœ‰è¯¯ï¼Œéœ€è¦æ£€æŸ¥ kubelet é…ç½®</em></p>\n<p>Master01 æŸ¥çœ‹é›†ç¾¤çŠ¶æ€ (Ready æˆ– NotReady éƒ½æ­£å¸¸)</p>\n<pre><code>[root@k8s-master01 bootstrap]# kubectl get node\n</code></pre>\n<h5 id=\"83-kube-proxyé…ç½®\"><a class=\"anchor\" href=\"#83-kube-proxyé…ç½®\">#</a> 8.3 kube-proxy é…ç½®</h5>\n<p><em>æ³¨æ„ï¼Œå¦‚æœä¸æ˜¯é«˜å¯ç”¨é›†ç¾¤ï¼Œ192.168.1.70:8443 æ”¹ä¸º master01 çš„åœ°å€ï¼Œ8443 æ”¹ä¸º apiserver çš„ç«¯å£ï¼Œé»˜è®¤æ˜¯ 6443</em></p>\n<p>ç”Ÿæˆ kube-proxy çš„è¯ä¹¦ï¼Œä»¥ä¸‹æ“ä½œåªåœ¨<mark> Master01</mark> æ‰§è¡Œ</p>\n<pre><code>cd /root/k8s-ha-install/pki\ncfssl gencert \\\n   -ca=/etc/kubernetes/pki/ca.pem \\\n   -ca-key=/etc/kubernetes/pki/ca-key.pem \\\n   -config=ca-config.json \\\n   -profile=kubernetes \\\n   kube-proxy-csr.json | cfssljson -bare /etc/kubernetes/pki/kube-proxy\n\nkubectl config set-cluster kubernetes \\\n     --certificate-authority=/etc/kubernetes/pki/ca.pem \\\n     --embed-certs=true \\\n     --server=https://192.168.1.70:8443 \\\n     --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig\n\n\nkubectl config set-credentials system:kube-proxy \\\n     --client-certificate=/etc/kubernetes/pki/kube-proxy.pem \\\n     --client-key=/etc/kubernetes/pki/kube-proxy-key.pem \\\n     --embed-certs=true \\\n     --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig\n\nkubectl config set-context system:kube-proxy@kubernetes \\\n     --cluster=kubernetes \\\n     --user=system:kube-proxy \\\n     --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig\n\n\nkubectl config use-context system:kube-proxy@kubernetes \\\n     --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig\n</code></pre>\n<p>å°† kubeconfig å‘é€è‡³å…¶ä»–èŠ‚ç‚¹</p>\n<pre><code>for NODE in k8s-master02 k8s-master03; do\n     scp /etc/kubernetes/kube-proxy.kubeconfig  $NODE:/etc/kubernetes/kube-proxy.kubeconfig\n done\n\nfor NODE in k8s-node01 k8s-node02; do\n     scp /etc/kubernetes/kube-proxy.kubeconfig $NODE:/etc/kubernetes/kube-proxy.kubeconfig\n done\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>æ·»åŠ  kube-proxy çš„é…ç½®å’Œ service æ–‡ä»¶ï¼š</p>\n<pre><code>vim /usr/lib/systemd/system/kube-proxy.service\n\n[Unit]\nDescription=Kubernetes Kube Proxy\nDocumentation=https://github.com/kubernetes/kubernetes\nAfter=network.target\n\n[Service]\nExecStart=/usr/local/bin/kube-proxy \\\n  --config=/etc/kubernetes/kube-proxy.yaml \\\n  --v=2\n\nRestart=always\nRestartSec=10s\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>\n<p>å¦‚æœæ›´æ”¹äº†é›†ç¾¤ Pod çš„ç½‘æ®µï¼Œéœ€è¦æ›´æ”¹ kube-proxy.yaml çš„ clusterCIDR ä¸ºè‡ªå·±çš„ Pod ç½‘æ®µï¼š</p>\n<pre><code>vim /etc/kubernetes/kube-proxy.yaml\n\napiVersion: kubeproxy.config.k8s.io/v1alpha1\nbindAddress: 0.0.0.0\nclientConnection:\n  acceptContentTypes: &quot;&quot;\n  burst: 10\n  contentType: application/vnd.kubernetes.protobuf\n  kubeconfig: /etc/kubernetes/kube-proxy.kubeconfig\n  qps: 5\nclusterCIDR: 172.16.0.0/16 \nconfigSyncPeriod: 15m0s\nconntrack:\n  max: null\n  maxPerCore: 32768\n  min: 131072\n  tcpCloseWaitTimeout: 1h0m0s\n  tcpEstablishedTimeout: 24h0m0s\nenableProfiling: false\nhealthzBindAddress: 0.0.0.0:10256\nhostnameOverride: &quot;&quot;\niptables:\n  masqueradeAll: false\n  masqueradeBit: 14\n  minSyncPeriod: 0s\n  syncPeriod: 30s\nipvs:\n  masqueradeAll: true\n  minSyncPeriod: 5s\n  scheduler: &quot;rr&quot;\n  syncPeriod: 30s\nkind: KubeProxyConfiguration\nmetricsBindAddress: 127.0.0.1:10249\nmode: &quot;ipvs&quot;\nnodePortAddresses: null\noomScoreAdj: -999\nportRange: &quot;&quot;\nudpIdleTimeout: 250ms\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>å¯åŠ¨ kube-proxy</p>\n<pre><code>[root@k8s-master01 k8s-ha-install]# systemctl daemon-reload\n[root@k8s-master01 k8s-ha-install]# systemctl enable --now kube-proxy\nCreated symlink /etc/systemd/system/multi-user.target.wants/kube-proxy.service â†’ /usr/lib/systemd/system/kube-proxy.service.\n</code></pre>\n<p>æ­¤æ—¶ç³»ç»Ÿæ—¥å¿— /var/log/messages**** æ˜¾ç¤ºåªæœ‰å¦‚ä¸‹ä¸¤ç§ä¿¡æ¯ä¸ºæ­£å¸¸ ****ï¼Œå®‰è£… calico åå³å¯æ¢å¤</p>\n<pre><code>Unable to update cni config: no networks found in /etc/cni/net.d\n</code></pre>\n<p><a href=\"https://imgse.com/i/pE2ZkVK\"><img loading=\"lazy\" data-src=\"https://s21.ax1x.com/2025/04/10/pE2ZkVK.png\" alt=\"pE2ZkVK.png\" /></a></p>\n<h4 id=\"9-calicoç»„ä»¶çš„å®‰è£…\"><a class=\"anchor\" href=\"#9-calicoç»„ä»¶çš„å®‰è£…\">#</a> 9. Calico ç»„ä»¶çš„å®‰è£…</h4>\n<p>ä»¥ä¸‹æ­¥éª¤åªåœ¨ master01 æ‰§è¡Œï¼š</p>\n<pre><code>cd /root/k8s-ha-install/calico/\n</code></pre>\n<p>æ›´æ”¹ calico çš„ç½‘æ®µï¼Œä¸»è¦éœ€è¦å°†çº¢è‰²éƒ¨åˆ†çš„ç½‘æ®µï¼Œæ”¹ä¸ºè‡ªå·±çš„ Pod ç½‘æ®µ</p>\n<pre><code>sed -i &quot;s#POD_CIDR#172.16.0.0/16#g&quot; calico.yaml\n</code></pre>\n<p><em>æ£€æŸ¥ç½‘æ®µæ˜¯è‡ªå·±çš„ Pod ç½‘æ®µï¼Œ grep &quot;IPV4POOL_CIDR&quot; calico.yaml  -A 1</em></p>\n<p>æŸ¥çœ‹å®¹å™¨å’ŒèŠ‚ç‚¹çŠ¶æ€ï¼š</p>\n<pre><code>[root@k8s-master01 calico]# kubectl get po -n kube-system\nNAME                                       READY   STATUS    RESTARTS      AGE\ncalico-kube-controllers-66686fdb54-mk2g6   1/1     Running   1 (20s ago)   85s\ncalico-node-8fxqp                          1/1     Running   0             85s\ncalico-node-8nkfl                          1/1     Running   0             86s\ncalico-node-pmpf4                          1/1     Running   0             86s\ncalico-node-vnlk7                          1/1     Running   0             86s\ncalico-node-xpchb                          1/1     Running   0             85s\ncalico-typha-67c6dc57d6-259t8              1/1     Running   0             86s\n</code></pre>\n<p><em>å¦‚æœå®¹å™¨çŠ¶æ€å¼‚å¸¸å¯ä»¥ä½¿ç”¨ kubectl describe æˆ–è€… kubectl logs æŸ¥çœ‹å®¹å™¨çš„æ—¥å¿—</em></p>\n<ol>\n<li>Kubectl logs -f POD_NAME -n kube-system</li>\n<li>Kubectl logs -f POD_NAME -c upgrade-ipam -n kube-system</li>\n</ol>\n<h4 id=\"10-å®‰è£…coredns\"><a class=\"anchor\" href=\"#10-å®‰è£…coredns\">#</a> 10. å®‰è£… CoreDNS</h4>\n<pre><code>cd /root/k8s-ha-install/\n</code></pre>\n<p>å¦‚æœæ›´æ”¹äº† k8s service çš„ç½‘æ®µéœ€è¦å°† coredns çš„ serviceIP æ”¹æˆ k8s service ç½‘æ®µçš„ç¬¬åä¸ª IP</p>\n<pre><code>COREDNS_SERVICE_IP=`kubectl get svc | grep kubernetes | awk '&#123;print $3&#125;'`0\nsed -i &quot;s#KUBEDNS_SERVICE_IP#$&#123;COREDNS_SERVICE_IP&#125;#g&quot; CoreDNS/coredns.yaml\n</code></pre>\n<p>å®‰è£… coredns</p>\n<pre><code>[root@k8s-master01 k8s-ha-install]# kubectl  create -f CoreDNS/coredns.yaml \nserviceaccount/coredns created\nclusterrole.rbac.authorization.k8s.io/system:coredns created\nclusterrolebinding.rbac.authorization.k8s.io/system:coredns created\nconfigmap/coredns created\ndeployment.apps/coredns created\nservice/kube-dns created\n</code></pre>\n<h4 id=\"11-metricséƒ¨ç½²\"><a class=\"anchor\" href=\"#11-metricséƒ¨ç½²\">#</a> 11. Metrics éƒ¨ç½²</h4>\n<p>åœ¨æ–°ç‰ˆçš„ Kubernetes ä¸­ç³»ç»Ÿèµ„æºçš„é‡‡é›†å‡ä½¿ç”¨ Metrics-serverï¼Œå¯ä»¥é€šè¿‡ Metrics é‡‡é›†èŠ‚ç‚¹å’Œ Pod çš„å†…å­˜ã€ç£ç›˜ã€CPU å’Œç½‘ç»œçš„ä½¿ç”¨ç‡ã€‚</p>\n<p>ä»¥ä¸‹æ“ä½œå‡åœ¨<mark> master01 èŠ‚ç‚¹</mark>æ‰§è¡Œï¼Œå®‰è£… metrics server:</p>\n<pre><code>cd /root/k8s-ha-install/metrics-server\nkubectl  create -f . \n\nserviceaccount/metrics-server created\nclusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created\nclusterrole.rbac.authorization.k8s.io/system:metrics-server created\nrolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created\nclusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created\nclusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created\nservice/metrics-server created\ndeployment.apps/metrics-server created\napiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created\n</code></pre>\n<p>ç­‰å¾… metrics server å¯åŠ¨ç„¶åæŸ¥çœ‹çŠ¶æ€ï¼š</p>\n<pre><code># kubectl  top node\nNAME           CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   \nk8s-master01   231m         5%     1620Mi          42%       \nk8s-master02   274m         6%     1203Mi          31%       \nk8s-master03   202m         5%     1251Mi          32%       \nk8s-node01     69m          1%     667Mi           17%       \nk8s-node02     73m          1%     650Mi           16%\n</code></pre>\n<p>å¦‚æœæœ‰å¦‚ä¸‹æŠ¥é”™ï¼Œå¯ä»¥ç­‰å¾… 10 åˆ†é’Ÿåï¼Œå†æ¬¡æŸ¥çœ‹ï¼š</p>\n<pre><code>Error from server (ServiceUnavailable): the server is currently unable to handle the request (get nodes.metrics.k8s.io)\n</code></pre>\n<h4 id=\"12-dashboardéƒ¨ç½²\"><a class=\"anchor\" href=\"#12-dashboardéƒ¨ç½²\">#</a> 12. Dashboard éƒ¨ç½²</h4>\n<h5 id=\"121-å®‰è£…dashboard\"><a class=\"anchor\" href=\"#121-å®‰è£…dashboard\">#</a> 12.1 å®‰è£… Dashboard</h5>\n<p>Dashboard ç”¨äºå±•ç¤ºé›†ç¾¤ä¸­çš„å„ç±»èµ„æºï¼ŒåŒæ—¶ä¹Ÿå¯ä»¥é€šè¿‡ Dashboard å®æ—¶æŸ¥çœ‹ Pod çš„æ—¥å¿—å’Œåœ¨å®¹å™¨ä¸­æ‰§è¡Œä¸€äº›å‘½ä»¤ç­‰ã€‚</p>\n<pre><code>cd /root/k8s-ha-install/dashboard/\n\n[root@k8s-master01 dashboard]# kubectl  create -f .\nserviceaccount/admin-user created\nclusterrolebinding.rbac.authorization.k8s.io/admin-user created\nnamespace/kubernetes-dashboard created\nserviceaccount/kubernetes-dashboard created\nservice/kubernetes-dashboard created\nsecret/kubernetes-dashboard-certs created\nsecret/kubernetes-dashboard-csrf created\nsecret/kubernetes-dashboard-key-holder created\nconfigmap/kubernetes-dashboard-settings created\nrole.rbac.authorization.k8s.io/kubernetes-dashboard created\nclusterrole.rbac.authorization.k8s.io/kubernetes-dashboard created\nrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created\nclusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created\ndeployment.apps/kubernetes-dashboard created\nservice/dashboard-metrics-scraper created\ndeployment.apps/dashboard-metrics-scraper created\n</code></pre>\n<h5 id=\"122-ç™»å½•dashboard\"><a class=\"anchor\" href=\"#122-ç™»å½•dashboard\">#</a> 12.2 ç™»å½• dashboard</h5>\n<p>åœ¨è°·æ­Œæµè§ˆå™¨ï¼ˆChromeï¼‰å¯åŠ¨æ–‡ä»¶ä¸­åŠ å…¥å¯åŠ¨å‚æ•°ï¼Œç”¨äºè§£å†³æ— æ³•è®¿é—® Dashboard çš„é—®é¢˜ï¼Œå‚è€ƒä¸‹å›¾ï¼š</p>\n<pre><code>--test-type --ignore-certificate-errors\n</code></pre>\n<p><a href=\"https://imgse.com/i/pEgWfHJ\"><img loading=\"lazy\" data-src=\"https://s21.ax1x.com/2025/04/09/pEgWfHJ.png\" alt=\"pEgWfHJ.png\" /></a></p>\n<p>æ›´æ”¹ dashboard çš„ svc ä¸º NodePort:</p>\n<pre><code>kubectl edit svc kubernetes-dashboard -n kubernetes-dashboard\n</code></pre>\n<p><a href=\"https://imgse.com/i/pEgW5NR\"><img loading=\"lazy\" data-src=\"https://s21.ax1x.com/2025/04/09/pEgW5NR.png\" alt=\"pEgW5NR.png\" /></a></p>\n<p><em>å°† ClusterIP æ›´æ”¹ä¸º NodePortï¼ˆå¦‚æœå·²ç»ä¸º NodePort å¿½ç•¥æ­¤æ­¥éª¤ï¼‰</em></p>\n<p>æŸ¥çœ‹ç«¯å£å·ï¼š</p>\n<pre><code>[root@k8s-master01 ~]# kubectl get svc kubernetes-dashboard -n kubernetes-dashboard\nNAME                   TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)         AGE\nkubernetes-dashboard   NodePort   10.96.139.11   &lt;none&gt;        443:32409/TCP   24h\n</code></pre>\n<p>æ ¹æ®è‡ªå·±çš„å®ä¾‹ç«¯å£å·ï¼Œé€šè¿‡ä»»æ„å®‰è£…äº† kube-proxy çš„å®¿ä¸»æœºçš„ IP + ç«¯å£å³å¯è®¿é—®åˆ° dashboardï¼š</p>\n<p>è®¿é—® Dashboardï¼š<a href=\"https://192.168.181.129:31106\">https://192.168.1.71:32409</a> ï¼ˆæŠŠ IP åœ°å€å’Œç«¯å£æ”¹æˆä½ è‡ªå·±çš„ï¼‰é€‰æ‹©ç™»å½•æ–¹å¼ä¸ºä»¤ç‰Œï¼ˆå³ token æ–¹å¼ï¼‰ï¼Œå‚è€ƒä¸‹å›¾ï¼š</p>\n<p><a href=\"https://imgse.com/i/pEgW736\"><img loading=\"lazy\" data-src=\"https://s21.ax1x.com/2025/04/09/pEgW736.png\" alt=\"pEgW736.png\" /></a></p>\n<p>åˆ›å»ºç™»å½• Tokenï¼š</p>\n<pre><code>kubectl create token admin-user -n kube-system\n</code></pre>\n<p>å°† token å€¼è¾“å…¥åˆ°ä»¤ç‰Œåï¼Œå•å‡»ç™»å½•å³å¯è®¿é—® Dashboardï¼Œå‚è€ƒä¸‹å›¾ï¼š</p>\n<p><a href=\"https://imgse.com/i/pEgfPv8\"><img loading=\"lazy\" data-src=\"https://s21.ax1x.com/2025/04/09/pEgfPv8.png\" alt=\"pEgfPv8.png\" /></a></p>\n<h4 id=\"14-containerdé…ç½®é•œåƒåŠ é€Ÿ\"><a class=\"anchor\" href=\"#14-containerdé…ç½®é•œåƒåŠ é€Ÿ\">#</a> 14. Containerd é…ç½®é•œåƒåŠ é€Ÿ</h4>\n<pre><code># vim /etc/containerd/config.toml\n#æ·»åŠ ä»¥ä¸‹é…ç½®é•œåƒåŠ é€ŸæœåŠ¡\n       [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.mirrors.&quot;docker.io&quot;]\n        endpoint=[&quot;https://dockerproxy.com&quot;, &quot;https://mirror.baidubce.com&quot;,&quot;https://ccr.ccs.tencentyun.com&quot;,&quot;https://docker.m.daocloud.io&quot;,&quot;https://docker.nju.edu.cn&quot;,&quot;https://docker.mirrors.ustc.edu.cn&quot;,&quot;https://registry-1.docker.io&quot;, &quot;https://hbv0b596.mirror.aliyuncs.com&quot;]\n       [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.mirrors.&quot;registry.k8s.io&quot;]\n        endpoint=[&quot;https://dockerproxy.com&quot;, &quot;https://mirror.baidubce.com&quot;,&quot;https://ccr.ccs.tencentyun.com&quot;,&quot;https://docker.m.daocloud.io&quot;,&quot;https://docker.nju.edu.cn&quot;,&quot;https://docker.mirrors.ustc.edu.cn&quot;,&quot;https://hbv0b596.mirror.aliyuncs.com&quot;, &quot;https://k8s.m.daocloud.io&quot;, &quot;https://docker.mirrors.ustc.edu.cn&quot;,&quot;https://hub-mirror.c.163.com&quot;]\n</code></pre>\n<p>æ‰€æœ‰èŠ‚ç‚¹é‡æ–°å¯åŠ¨ Containerdï¼š</p>\n<pre><code># systemctl daemon-reload\n# systemctl restart containerd\n</code></pre>\n<h4 id=\"15-dockeré…ç½®é•œåƒåŠ é€Ÿ\"><a class=\"anchor\" href=\"#15-dockeré…ç½®é•œåƒåŠ é€Ÿ\">#</a> 15. Docker é…ç½®é•œåƒåŠ é€Ÿ</h4>\n<pre><code># sudo mkdir -p /etc/docker\n# sudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'\n&#123;\n  &quot;registry-mirrors&quot;: [\n\t  &quot;https://docker.credclouds.com&quot;,\n\t  &quot;https://k8s.credclouds.com&quot;,\n\t  &quot;https://quay.credclouds.com&quot;,\n\t  &quot;https://gcr.credclouds.com&quot;,\n\t  &quot;https://k8s-gcr.credclouds.com&quot;,\n\t  &quot;https://ghcr.credclouds.com&quot;,\n\t  &quot;https://do.nark.eu.org&quot;,\n\t  &quot;https://docker.m.daocloud.io&quot;,\n\t  &quot;https://docker.nju.edu.cn&quot;,\n\t  &quot;https://docker.mirrors.sjtug.sjtu.edu.cn&quot;,\n\t  &quot;https://docker.1panel.live&quot;,\n\t  &quot;https://docker.rainbond.cc&quot;\n  ], \n  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;] \n&#125;\nEOF\n</code></pre>\n<p>æ‰€æœ‰èŠ‚ç‚¹é‡æ–°å¯åŠ¨ Dockerï¼š</p>\n<pre><code># systemctl daemon-reload\n# systemctl enable --now docker\n</code></pre>\n<p><em>æœ¬æ–‡å‡ºè‡ªäºï¼š<a href=\"https://edu.51cto.com/course/23845.html\">https://edu.51cto.com/course/23845.html</a></em></p>\n",
            "tags": [
                "Kubernetes"
            ]
        },
        {
            "id": "http://ixuyong.cn/posts/2628187572.html",
            "url": "http://ixuyong.cn/posts/2628187572.html",
            "title": "MySQLè¿ç»´DBAåº”ç”¨ä¸å®è·µ",
            "date_published": "2025-04-09T14:02:40.000Z",
            "content_html": "<h3 id=\"mysqlè¿ç»´dbaåº”ç”¨ä¸å®è·µ\"><a class=\"anchor\" href=\"#mysqlè¿ç»´dbaåº”ç”¨ä¸å®è·µ\">#</a> MySQL è¿ç»´ DBA åº”ç”¨ä¸å®è·µ</h3>\n<h4 id=\"1æ—¥å¿—\"><a class=\"anchor\" href=\"#1æ—¥å¿—\">#</a> 1. æ—¥å¿—</h4>\n<p>åœ¨ä»»ä½•ä¸€ç§æ•°æ®åº“ä¸­ï¼Œéƒ½ä¼šæœ‰å„ç§å„æ ·çš„æ—¥å¿—ï¼Œè¿™äº›æ—¥å¿—è®°å½•äº†æ•°æ®åº“è¿è¡Œçš„å„ä¸ªæ–¹é¢ã€‚å¯ä»¥å¸®åŠ©æ•°æ®åº“ç®¡ç†å‘˜è¿½è¸ªæ•°æ®åº“æ›¾ç»å‘ç”Ÿçš„ä¸€äº›äº‹æƒ…ã€‚</p>\n<p>å¯¹äº MySQL æ•°æ®åº“ï¼Œæä¾›äº†å››ç§ä¸åŒçš„æ—¥å¿—å¸®åŠ©æˆ‘ä»¬è¿½è¸ªã€‚</p>\n<ul>\n<li>\n<p>é”™è¯¯æ—¥å¿—</p>\n</li>\n<li>\n<p>äºŒè¿›åˆ¶æ—¥å¿—</p>\n</li>\n<li>\n<p>æŸ¥è¯¢æ—¥å¿—</p>\n</li>\n<li>\n<p>æ…¢æŸ¥è¯¢æ—¥å¿—</p>\n</li>\n</ul>\n<h5 id=\"11-é”™è¯¯æ—¥å¿—\"><a class=\"anchor\" href=\"#11-é”™è¯¯æ—¥å¿—\">#</a> 1.1 é”™è¯¯æ—¥å¿—</h5>\n<p>é”™è¯¯æ—¥å¿—æ˜¯ MySQL ä¸­æœ€é‡è¦çš„æ—¥å¿—ä¹‹ä¸€ï¼Œå®ƒè®°å½•äº†å½“ mysqld (MySQL æœåŠ¡) å¯åŠ¨å’Œåœæ­¢æ—¶ï¼Œä»¥åŠæœåŠ¡å™¨åœ¨è¿è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿä»»ä½•ä¸¥é‡é”™è¯¯æ—¶çš„ç›¸å…³ä¿¡æ¯ã€‚å½“æ•°æ®åº“å‡ºç°ä»»ä½•æ•…éšœå¯¼è‡´æ— æ³•æ­£å¸¸ä½¿ç”¨æ—¶ï¼Œå»ºè®®é¦–å…ˆæŸ¥çœ‹æ­¤æ—¥å¿—ã€‚</p>\n<p>è¯¥æ—¥å¿—æ˜¯é»˜è®¤å¼€å¯çš„ï¼Œé»˜è®¤å­˜æ”¾ç›®å½• /var/log/ï¼Œé»˜è®¤çš„æ—¥å¿—æ–‡ä»¶åä¸º mysqld.logã€‚æŸ¥çœ‹æ—¥å¿—ä½ç½®ï¼›</p>\n<pre><code>mysql&gt; show variables like '%log_error%';\n+---------------------+---------------------+\n| Variable_name       | Value               |\n+---------------------+---------------------+\n| binlog_error_action | ABORT_SERVER        |\n| log_error           | /var/log/mysqld.log |\n| log_error_verbosity | 3                   |\n+---------------------+---------------------+\n</code></pre>\n<h5 id=\"12-äºŒè¿›åˆ¶æ—¥å¿—\"><a class=\"anchor\" href=\"#12-äºŒè¿›åˆ¶æ—¥å¿—\">#</a> 1.2 äºŒè¿›åˆ¶æ—¥å¿—</h5>\n<p>äºŒè¿›åˆ¶æ—¥å¿— (BINLOG) è®°å½•äº†æ‰€æœ‰çš„ DDL (æ•°æ®å®šä¹‰è¯­è¨€) è¯­å¥å’Œ DML (æ•°æ®æ“çºµè¯­è¨€) è¯­å¥ï¼Œä½†ä¸åŒ…æ‹¬æ•°æ®æŸ¥è¯¢ï¼ˆSELECTã€ SHOWï¼‰è¯­å¥ã€‚</p>\n<p>ä½œç”¨:</p>\n<p>â‘ . ç¾éš¾æ—¶çš„æ•°æ®æ¢å¤ï¼›</p>\n<p>â‘¡. MySQL çš„ä¸»ä»å¤åˆ¶ã€‚</p>\n<p>åœ¨ MySQL5.7 ç‰ˆæœ¬ä¸­ï¼Œé»˜è®¤äºŒè¿›åˆ¶æ—¥å¿—æ˜¯å…³é—­ç€çš„ï¼Œæ¶‰åŠåˆ°çš„å‚æ•°å¦‚ä¸‹:</p>\n<h6 id=\"121-å¼€å¯-bin-logè®°å½•\"><a class=\"anchor\" href=\"#121-å¼€å¯-bin-logè®°å½•\">#</a> 1.2.1 å¼€å¯ bin-log è®°å½•</h6>\n<pre><code>1.1æ”¹ä¿®é…ç½®æ–‡ä»¶\n[root@db01 ~]# vim /etc/my.cnf\nserver-id=1\nlog-bin=mysql-bin\nmax_binlog_size=500M\nexpire_logs_days=15\n\n1.2æŸ¥çœ‹æ˜¯å¦å¼€å¯binlog.\nmysql&gt; show variables like 'log_%';\n+----------------------------------------+--------------------------------+\n| Variable_name                          | Value                          |\n+----------------------------------------+--------------------------------+\n| log_bin                                | ON                             |\n| log_bin_basename                       | /var/lib/mysql/mysql-bin       |\n| log_bin_index                          | /var/lib/mysql/mysql-bin.index |\n| log_bin_trust_function_creators        | OFF                            |\n| log_bin_use_v1_row_events              | OFF                            |\n| log_builtin_as_identified_by_password  | OFF                            |\n| log_error                              | /var/log/mysqld.log            |\n| log_error_verbosity                    | 3                              |\n| log_output                             | FILE                           |\n| log_queries_not_using_indexes          | OFF                            |\n| log_slave_updates                      | OFF                            |\n| log_slow_admin_statements              | OFF                            |\n| log_slow_slave_statements              | OFF                            |\n| log_statements_unsafe_for_binlog       | ON                             |\n| log_syslog                             | OFF                            |\n| log_syslog_facility                    | daemon                         |\n| log_syslog_include_pid                 | ON                             |\n| log_syslog_tag                         |                                |\n| log_throttle_queries_not_using_indexes | 0                              |\n| log_timestamps                         | UTC                            |\n| log_warnings                           | 2                              |\n+----------------------------------------+--------------------------------+\n\n1.3æŸ¥çœ‹binlog\nmysql&gt; show binary logs;\n+------------------+-----------+\n| Log_name         | File_size |\n+------------------+-----------+\n| mysql-bin.000001 |     36825 |\n| mysql-bin.000002 |    200464 |\n| mysql-bin.000003 |    419809 |\n+------------------+-----------+\n\n1.4æŸ¥çœ‹binlogæ—¥å¿—ä¿å­˜å¤©æ•° \n# 0è¡¨ç¤ºæ°¸ä¹…ä¿ç•™ï¼Œexpire_logs_daysï¼šä¿ç•™æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„binlogå†å²æ—¥å¿—ï¼Œä¸Šç¤ºä¾‹è®¾ç½®çš„15å¤©å†…\nmysql&gt; show variables like 'expire_logs_days';\n+------------------+-------+\n| Variable_name    | Value |\n+------------------+-------+\n| expire_logs_days | 15    |\n+------------------+-------+\n1 row in set (0.00 sec)\n\n1.5æŸ¥çœ‹binlogæ—¥å¿—ä¿å­˜å¤§å°\n#max_binlog_sizeï¼šbin logæ—¥å¿—æ¯è¾¾åˆ°è®¾å®šå¤§å°åï¼Œä¼šä½¿ç”¨æ–°çš„bin logæ—¥å¿—ã€‚å¦‚mysql-bin.000002è¾¾åˆ°500Måï¼Œåˆ›å»ºå¹¶ä½¿ç”¨mysql-bin.000003æ–‡ä»¶ä½œä¸ºæ—¥å¿—è®°å½•ã€‚\nmysql&gt; show variables like 'max_binlog_size';\n+-----------------+-----------+\n| Variable_name   | Value     |\n+-----------------+-----------+\n| max_binlog_size | 524288000 |\n+-----------------+-----------+\n\n1.6æ‰‹åŠ¨æ‰§è¡Œflush logs\n#å°†ä¼šnewä¸€ä¸ªæ–°æ–‡ä»¶ç”¨äºè®°å½•binlog\nmysql&gt; flush logs;\n\n1.7æ‰‹åŠ¨æ¸…ç†binlog\n#å°†mysql-bin.000010ä¹‹å‰çš„æ—¥å¿—æ¸…ç†æ‰\nmysql&gt; purge binary logs to 'mysql-bin.000010';\nQuery OK, 0 rows affected (0.01 sec)\n\n#åˆ é™¤2022-04-21 18:08:00ä¹‹å‰çš„binlogæ—¥å¿—\nmysql&gt; purge binary logs before '2022-04-21 18:08:00';\n\n#æ¸…é™¤å…¨éƒ¨binlog\nmysql&gt; reset master;\n</code></pre>\n<h6 id=\"122-æ—¥å¿—æ ¼å¼\"><a class=\"anchor\" href=\"#122-æ—¥å¿—æ ¼å¼\">#</a> <strong>1.2.2 æ—¥å¿—æ ¼å¼</strong></h6>\n<p>MySQL æœåŠ¡å™¨ä¸­æä¾›äº†å¤šç§æ ¼å¼æ¥è®°å½•äºŒè¿›åˆ¶æ—¥å¿—ï¼Œå…·ä½“æ ¼å¼åŠç‰¹ç‚¹å¦‚ä¸‹ï¼š</p>\n<table>\n<thead>\n<tr>\n<th><strong>æ—¥å¿—æ ¼å¼</strong></th>\n<th><strong>å«ä¹‰</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>STATEMENT</td>\n<td>åŸºäº SQL è¯­å¥çš„æ—¥å¿—è®°å½•ï¼Œè®°å½•çš„æ˜¯ SQL è¯­å¥ï¼Œå¯¹æ•°æ®è¿›è¡Œä¿®æ”¹çš„ SQL éƒ½ä¼šè®°å½•åœ¨æ—¥å¿—æ–‡ä»¶ä¸­ã€‚</td>\n</tr>\n<tr>\n<td>ROW</td>\n<td>åŸºäºè¡Œçš„æ—¥å¿—è®°å½•ï¼Œè®°å½•çš„æ˜¯æ¯ä¸€è¡Œçš„æ•°æ®å˜æ›´ã€‚(é»˜è®¤)</td>\n</tr>\n<tr>\n<td>MIXED</td>\n<td>æ··åˆäº† STATEMENT å’Œ ROW ä¸¤ç§æ ¼å¼ï¼Œé»˜è®¤é‡‡ç”¨ STATEMENT, åœ¨æŸäº›ç‰¹æ®Šæƒ…å†µä¸‹ä¼šè‡ªåŠ¨åˆ‡æ¢ä¸º ROW è¿›è¡Œè®°å½•ã€‚</td>\n</tr>\n</tbody>\n</table>\n<pre><code>mysql&gt; show variables like 'binlog_format';\n+---------------+-------+\n| Variable_name | Value |\n+---------------+-------+\n| binlog_format | ROW   |\n+---------------+-------+\n</code></pre>\n<p>ç”±äºæ—¥å¿—æ˜¯ä»¥äºŒè¿›åˆ¶æ–¹å¼å­˜å‚¨çš„ï¼Œä¸èƒ½ç›´æ¥è¯»å–ï¼Œéœ€è¦é€šè¿‡äºŒè¿›åˆ¶æ—¥å¿—æŸ¥è¯¢å·¥å…· <code>mysqlbinlog</code>  æ¥æŸ¥çœ‹ï¼Œå…·ä½“è¯­æ³•:</p>\n<pre><code>mysqlbinlog [ å‚æ•°é€‰é¡¹] logfilename\nå‚æ•°é€‰é¡¹:\n\t-d\t\t\tæŒ‡å®šæ•°æ®åº“åç§°ï¼Œåªåˆ—å‡ºæŒ‡å®šçš„æ•°æ®åº“ç›¸å…³æ“ä½œã€‚\n\t-o\t\t\tå¿½ç•¥æ‰æ—¥å¿—ä¸­çš„å‰nè¡Œå‘½ä»¤ã€‚\n\t-v\t\t\tå°†è¡Œäº‹ä»¶(æ•°æ®å˜æ›´)é‡æ„ä¸ºSQLè¯­å¥\n\t-vv\t\t\tå°†è¡Œäº‹ä»¶(æ•°æ®å˜æ›´)é‡æ„ä¸ºSQLè¯­å¥ï¼Œå¹¶è¾“å‡ºæ³¨é‡Šä¿¡æ¯\n</code></pre>\n<pre><code>mysql&gt; use zh;\nDatabase changed\nmysql&gt; show tables;\n+----------------+\n| Tables_in_zh   |\n+----------------+\n| account        |\n| course         |\n| dept           |\n| emp            |\n| score          |\n| student        |\n| student_course |\n| tb_user        |\n| tb_user_edu    |\n| user           |\n| user1          |\n+----------------+\n11 rows in set (0.00 sec)\n\nmysql&gt;  update tb_user_edu set university = &quot;åŒ—äº¬å¤§å­¦&quot;;\nQuery OK, 4 rows affected (0.00 sec)\nRows matched: 4  Changed: 4  Warnings: 0\n\n#äºŒè¿›åˆ¶æ—¥å¿—æŸ¥çœ‹\n[root@db01 ~]# mysqlbinlog -v /var/lib/mysql/mysql-bin.000001 \n</code></pre>\n<h6 id=\"123-ä¿®æ”¹binlogæ ¼å¼\"><a class=\"anchor\" href=\"#123-ä¿®æ”¹binlogæ ¼å¼\">#</a> 1.2.3 ä¿®æ”¹ binlog æ ¼å¼</h6>\n<pre><code>[root@db01 ~]# vim /etc/my.cnf\n...\nbinlog_format=STATEMENT\n...\n[root@db01 ~]# systemctl restart mysqld\n\nmysql&gt;  update tb_user_edu set university = 'æ¸…åå¤§å­¦';\n[root@db01 ~]# mysqlbinlog -v /var/lib/mysql/mysql-bin.000002 \n...\nSET TIMESTAMP=1701440373/*!*/;\nupdate tb_user_edu set university = 'æ¸…åå¤§å­¦'\n...\n</code></pre>\n<h5 id=\"13-æŸ¥è¯¢æ—¥å¿—\"><a class=\"anchor\" href=\"#13-æŸ¥è¯¢æ—¥å¿—\">#</a> 1.3 æŸ¥è¯¢æ—¥å¿—</h5>\n<p>æŸ¥è¯¢æ—¥å¿—ä¸­è®°å½•äº†å®¢æˆ·ç«¯çš„æ‰€æœ‰æ“ä½œè¯­å¥ï¼Œè€ŒäºŒè¿›åˆ¶æ—¥å¿—ä¸åŒ…å«æŸ¥è¯¢æ•°æ®çš„ SQL è¯­å¥ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œ<strong>æŸ¥è¯¢æ—¥å¿—æ˜¯æœªå¼€å¯çš„</strong>ã€‚å¦‚æœéœ€è¦å¼€å¯æŸ¥è¯¢æ—¥å¿—ï¼Œå¯ä»¥è®¾ç½®ä»¥ä¸‹é…ç½®ï¸°</p>\n<pre><code>mysql&gt; show variables like '%general%';\n+------------------+-------------------------+\n| Variable_name    | Value                   |\n+------------------+-------------------------+\n| general_log      | OFF                     |\n| general_log_file | /var/lib/mysql/db01.log |\n+------------------+-------------------------+\n2 rows in set (0.00 sec)\n\n#å¼€å¯æŸ¥è¯¢æ—¥å¿—åŠŸèƒ½\n[root@db01 ~]# cat /etc/my.cnf\ngeneral_log=1\ngeneral_log_file=/var/lib/mysql/mysql_query.log \n[root@db01 ~]# systemctl restart mysqld\n\n[root@db01 ~]# tail -f /var/lib/mysql/mysql_query.log \n2023-12-01T14:31:28.554384Z\t    2 Field List\tstudent \n2023-12-01T14:31:28.554743Z\t    2 Field List\tstudent_course \n2023-12-01T14:31:35.737041Z\t    2 Query\tshow variables like '%general%'\n2023-12-01T14:31:37.345179Z\t    2 Query\tshow variables like '%general%'\n2023-12-01T14:32:17.593471Z\t    2 Query\tSELECT DATABASE()\n2023-12-01T14:32:17.593651Z\t    2 Init DB\tzh\n2023-12-01T14:32:25.249258Z\t    2 Query\tselect * from emp\n</code></pre>\n<h5 id=\"14-æ…¢æŸ¥è¯¢æ—¥å¿—\"><a class=\"anchor\" href=\"#14-æ…¢æŸ¥è¯¢æ—¥å¿—\">#</a> 1.4 æ…¢æŸ¥è¯¢æ—¥å¿—</h5>\n<p>æ…¢æŸ¥è¯¢<a href=\"https://so.csdn.net/so/search?q=%E6%97%A5%E5%BF%97%E8%AE%B0%E5%BD%95&amp;spm=1001.2101.3001.7020\">æ—¥å¿—è®°å½•</a>äº†æ‰€æœ‰æ‰§è¡Œæ—¶é—´è¶…è¿‡å‚æ•° <code>long_ query_time</code>  è®¾ç½®å€¼å¹¶ä¸”æ‰«æè®°å½•æ•°ä¸å°äº <code>min_examined_row_limit</code>  çš„æ‰€æœ‰çš„ SQL è¯­å¥çš„æ—¥å¿—ï¼Œé»˜è®¤æœªå¼€å¯ã€‚<strong> <code>long_query_time</code>  é»˜è®¤ä¸º 10 ç§’ï¼Œæœ€å°ä¸º 0ï¼Œç²¾åº¦å¯ä»¥åˆ°å¾®ç§’ã€‚</strong></p>\n<pre><code>[root@db01 ~]# vim /etc/my.cnf\n#æ…¢æŸ¥è¯¢æ—¥å¿—\nslow_query_log=on\n##æ‰§è¡Œæ—¶é—´å‚æ•°\nlong_query_time=2\n# è‹¥æ²¡æœ‰æŒ‡å®šï¼Œé»˜è®¤åå­—ä¸ºhostname_slow.log\nslow_query_log_file = /var/lib/mysql/slow-query.log\n[root@db01 ~]# systemctl restart mysqld\n\n#åˆ¶é€ æ…¢æŸ¥è¯¢å¹¶æ‰§è¡Œ\nmysql&gt; select sleep(3);\n[root@db01 ~]# tail -f /var/lib/mysql/slow-query.log \n/usr/sbin/mysqld, Version: 5.7.43-log (MySQL Community Server (GPL)). started with:\nTcp port: 0  Unix socket: /var/lib/mysql/mysql.sock\nTime                 Id Command    Argument\n# Time: 2023-12-01T14:47:57.763735Z\n# User@Host: root[root] @ localhost []  Id:     2\n# Query_time: 3.001229  Lock_time: 0.000000 Rows_sent: 1  Rows_examined: 0\nuse zh;\nSET timestamp=1701442077;\nselect sleep(3);\n</code></pre>\n<p>é»˜è®¤æƒ…å†µä¸‹ï¼Œä¸ä¼šè®°å½•ç®¡ç†è¯­å¥ï¼Œä¹Ÿä¸ä¼šè®°å½•ä¸ä½¿ç”¨ç´¢å¼•è¿›è¡ŒæŸ¥æ‰¾çš„æŸ¥è¯¢ã€‚å¯ä»¥ä½¿ç”¨ <code>log_slow_admin_statements</code>  å’Œæ›´æ”¹æ­¤è¡Œä¸º <code>log_queries_not_using_indexes</code> , å¦‚ä¸‹æ‰€è¿°ã€‚</p>\n<pre><code>#è®°å½•æ‰§è¡Œè¾ƒæ…¢çš„ç®¡ç†è¯­å¥\nlog_slow_admin_statements = 1\n#è®°å½•æ‰§è¡Œè¾ƒæ…¢çš„æœªä½¿ç”¨ç´¢å¼•çš„è¯­å¥\nlog_queries_not_using_indexes = 1\n</code></pre>\n<h4 id=\"2-ä¸»ä»å¤åˆ¶\"><a class=\"anchor\" href=\"#2-ä¸»ä»å¤åˆ¶\">#</a> 2. ä¸»ä»å¤åˆ¶</h4>\n<h5 id=\"21-ä¸»ä»å¤åˆ¶çš„æ¦‚è¿°\"><a class=\"anchor\" href=\"#21-ä¸»ä»å¤åˆ¶çš„æ¦‚è¿°\">#</a> 2.1 ä¸»ä»å¤åˆ¶çš„æ¦‚è¿°</h5>\n<p>ä¸»ä»å¤åˆ¶æ˜¯æŒ‡å°†<strong>ä¸»æ•°æ®åº“çš„ DDL å’Œ DML æ“ä½œ</strong>é€šè¿‡<strong>äºŒè¿›åˆ¶æ—¥å¿—</strong>ä¼ åˆ°<strong>ä»åº“æœåŠ¡å™¨</strong>ä¸­ï¼Œç„¶ååœ¨ä»åº“ä¸Šå¯¹è¿™äº›æ—¥å¿—é‡æ–°æ‰§è¡Œ (ä¹Ÿå«é‡åš) ï¼Œä»è€Œä½¿å¾—ä»åº“å’Œä¸»åº“çš„æ•°æ®ä¿æŒåŒæ­¥ã€‚</p>\n<p><a href=\"https://imgse.com/i/pEgO0Mj\"><img loading=\"lazy\" data-src=\"https://s21.ax1x.com/2025/04/09/pEgO0Mj.png\" alt=\"pEgO0Mj.png\" /></a></p>\n<p>MySQL æ”¯æŒä¸€å°ä¸»åº“åŒæ—¶å‘å¤šå°ä»åº“è¿›è¡Œå¤åˆ¶ï¼Œä»åº“åŒæ—¶ä¹Ÿå¯ä»¥ä½œä¸ºå…¶ä»–ä»æœåŠ¡å™¨çš„ä¸»åº“ï¼Œ å®ç°é“¾çŠ¶å¤åˆ¶ã€‚</p>\n<p>MySQL å¤åˆ¶çš„æœ‰ç‚¹ä¸»è¦åŒ…å«ä»¥ä¸‹ä¸‰ä¸ªæ–¹é¢ï¼š</p>\n<ol>\n<li>ä¸»åº“å‡ºç°é—®é¢˜ï¼Œå¯ä»¥å¿«é€Ÿåˆ‡æ¢åˆ°ä»åº“æä¾›æœåŠ¡ï¼›</li>\n<li>å®ç°è¯»å†™åˆ†ç¦»ï¼Œé™ä½ä¸»åº“çš„è®¿é—®å‹åŠ›ï¼›ï¼ˆå¦‚æœå¢åˆ æ”¹å¯¹ä¸»åº“ æŸ¥è¯¢å¯¹ä»åº“ï¼‰</li>\n<li>å¯ä»¥åœ¨ä»åº“ä¸­æ‰§è¡Œå¤‡ä»½ï¼Œä»¥é¿å…å¤‡ä»½æœŸé—´å½±å“ä¸»åº“æœåŠ¡ã€‚</li>\n</ol>\n<h5 id=\"22-ä¸»ä»å¤åˆ¶çš„åŸç†\"><a class=\"anchor\" href=\"#22-ä¸»ä»å¤åˆ¶çš„åŸç†\">#</a> 2.2 ä¸»ä»å¤åˆ¶çš„åŸç†</h5>\n<p><a href=\"https://imgse.com/i/pEgOdzQ\"><img loading=\"lazy\" data-src=\"https://s21.ax1x.com/2025/04/09/pEgOdzQ.png\" alt=\"pEgOdzQ.png\" /></a></p>\n<p>ä»ä¸Šå›¾æ¥çœ‹ï¼Œå¤åˆ¶åˆ†æˆä¸‰æ­¥ï¼š</p>\n<ol>\n<li>Master ä¸»åº“åœ¨äº‹åŠ¡æäº¤æ—¶ï¼Œä¼šæŠŠæ•°æ®å˜æ›´è®°å½•åœ¨äºŒè¿›åˆ¶æ—¥å¿—æ–‡ä»¶ Binlog ä¸­ã€‚</li>\n<li>ä»åº“ IO çº¿ç¨‹è¯»å–ä¸»åº“çš„äºŒè¿›åˆ¶æ—¥å¿—æ–‡ä»¶ Binlogï¼Œå†™å…¥åˆ°ä»åº“çš„ä¸­ç»§æ—¥å¿— Relay Logã€‚</li>\n<li>slave é‡åšä¸­ç»§æ—¥å¿—ä¸­çš„äº‹ä»¶ï¼ŒSQL çº¿ç¨‹å°†æ”¹å˜åæ˜ å®ƒè‡ªå·±çš„æ•°æ®ã€‚</li>\n</ol>\n<h5 id=\"23-ä¸»ä»å¤åˆ¶çš„æ­å»º\"><a class=\"anchor\" href=\"#23-ä¸»ä»å¤åˆ¶çš„æ­å»º\">#</a> 2.3 ä¸»ä»å¤åˆ¶çš„æ­å»º</h5>\n<p><strong>ä¸»ä»å¤åˆ¶çš„æ­å»ºæ­¥éª¤</strong>ï¼š</p>\n<ol>\n<li>å‡†å¤‡ä¸»ä»å¤åˆ¶æœåŠ¡å™¨ç¯å¢ƒ</li>\n<li>å®Œæˆä¸»åº“é…ç½®</li>\n<li>å®Œæˆä»åº“é…ç½®</li>\n</ol>\n<h6 id=\"231-æœåŠ¡å™¨å‡†å¤‡\"><a class=\"anchor\" href=\"#231-æœåŠ¡å™¨å‡†å¤‡\">#</a> 2.3.1 æœåŠ¡å™¨å‡†å¤‡</h6>\n<p><a href=\"https://imgse.com/i/pEgODLn\"><img loading=\"lazy\" data-src=\"https://s21.ax1x.com/2025/04/09/pEgODLn.png\" alt=\"pEgODLn.png\" /></a></p>\n<h6 id=\"232-ä¸»åº“é…ç½®\"><a class=\"anchor\" href=\"#232-ä¸»åº“é…ç½®\">#</a> 2.3.2 ä¸»åº“é…ç½®</h6>\n<p><strong>#1. å®‰è£… MySQL</strong></p>\n<pre><code>#1ã€å…³é—­é˜²ç«å¢™ã€selinuxã€ç¯å¢ƒé…ç½®\n[root@db01 ~]# hostnamectl set-hostname db01\n[root@db01 ~]# systemctl stop firewalld\n[root@db01 ~]# systemctl disable firewalld\n[root@db01 ~]# sed -i 's/^SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux\n[root@db01 ~]# sed -i 's/^SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config\n[root@db01 ~]# yum install net-tools vim tree lrzsz wget unzip dos2unix bash-completion  lsof ntp ntpdate git -y\n[root@db01 ~]# yum update -y --exclude=kernel* &amp;&amp; reboot\n[root@db01 ~]# echo 'Asia/Shanghai' &gt;/etc/timezone\n[root@db01 ~]# ntpdate time2.aliyun.com\n[root@db01 ~]# crontab -e\n*/5 * * * * /usr/sbin/ntpdate time2.aliyun.com &amp;&gt; /dev/nul\n[root@db01 ~]# mkdir /soft /data /scripts /backup\n\n#2ã€å®‰è£…Mysql5.7\n[root@db01 ~]# yum install -y mysql-community-server\n[root@db01 ~]# systemctl start mysqld &amp;&amp; systemctl enable mysqld\n\n[root@db01 ~]# mysql -uroot -p$(awk '/temporary password/&#123;print $NF&#125;' /var/log/mysqld.log)\nmysql&gt; ALTER USER 'root'@'localhost' IDENTIFIED BY 'passwd';\nmysql&gt; grant all on *.* to 'root'@'192.168.1.%' identified by 'passwd';\n\n#3ã€å…è®¸rootç”¨æˆ·åœ¨ä»»ä½•åœ°æ–¹è¿›è¡Œè¿œç¨‹ç™»å½•ï¼Œå¹¶å…·æœ‰æ‰€æœ‰åº“ä»»ä½•æ“ä½œæƒé™ï¼Œå…·ä½“æ“ä½œå¦‚ä¸‹ï¼š\nmysql -u root -p&quot;youpass&quot;\nmysql&gt;GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'passwd' WITH GRANT OPTION;\nFLUSH PRIVILEGES;\n\n#4.é…ç½®ä¸»åº“\n[root@db01 ~]# vim /etc/my.cnf\nserver-id=1                #mysqlæœåŠ¡IDï¼Œä¿è¯æ•´ä¸ªé›†ç¾¤ç¯å¢ƒä¸­å”¯ä¸€ï¼Œ å–å€¼èŒƒå›´: 1 - 2^&#123;32&#125;-1\nlog-bin=mysql-bin          #å¯åŠ¨äºŒè¿›åˆ¶æ—¥å¿—\nread-only=0                #æ˜¯å¦åªè¯»,1ä»£è¡¨åªè¯», 0ä»£è¡¨è¯»å†™\n#binlog-ignore-db=mysql    #å¿½ç•¥çš„æ•°æ®ï¼ŒæŒ‡ä¸éœ€è¦åŒæ­¥çš„æ•°æ®åº“\n#binlog-do-db=db01         #æŒ‡å®šåŒæ­¥çš„æ•°æ®åº“\n[root@db01 ~]# systemctl restart mysqld\n\n#5.åˆ›å»ºreplç”¨æˆ·ï¼Œå¹¶è®¾ç½®å¯†ç ï¼Œè¯¥ç”¨æˆ·å¯åœ¨ä»»æ„ä¸»æœºè¿æ¥è¯¥MySQLæœåŠ¡\nmysql&gt; grant replication slave on *.* to 'repl'@'%' identified by 'passwd';\n\n#6.æŸ¥çœ‹masterä½ç½®ç‚¹\nmysql&gt; show master status;        \n+------------------+----------+--------------+------------------+-------------------+\n| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |\n+------------------+----------+--------------+------------------+-------------------+\n| mysql-bin.000006 |      889 |              |                  |                   |\n+------------------+----------+--------------+------------------+-------------------+\n1 row in set (0.00 sec)\n</code></pre>\n<h6 id=\"233-ä»åº“é…ç½®\"><a class=\"anchor\" href=\"#233-ä»åº“é…ç½®\">#</a> 2.3.3 ä»åº“é…ç½®</h6>\n<table>\n<thead>\n<tr>\n<th>å‚æ•°å</th>\n<th>å«ä¹‰</th>\n<th><strong>8.0.23 ä¹‹å‰</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>SOURCE_HOST</td>\n<td>ä¸»åº“ IP åœ°å€</td>\n<td>MASTER_HOST</td>\n</tr>\n<tr>\n<td>SOURCE_USER</td>\n<td>è¿æ¥ä¸»åº“çš„ç”¨æˆ·å</td>\n<td>MASTER_USER</td>\n</tr>\n<tr>\n<td>SOURCE_PASSWORD</td>\n<td>è¿æ¥ä¸»åº“çš„å¯†ç </td>\n<td>MASTER_PASSWORD</td>\n</tr>\n<tr>\n<td>SOURCE_LOG FILE</td>\n<td>binlog æ—¥å¿—æ–‡ä»¶å</td>\n<td>MASTER LOG_FILE</td>\n</tr>\n<tr>\n<td>SOURCE_LOG POS</td>\n<td>binlog æ—¥å¿—æ–‡ä»¶ä½ç½®</td>\n<td>MASTER_LOG_POS</td>\n</tr>\n</tbody>\n</table>\n<pre><code>#1.é…ç½®ä»åº“\n[root@db02 ~]# vim /etc/my.cnf\nserver-id=2           #mysqlæœåŠ¡ID\nread-only=1           #æ˜¯å¦åªè¯»,1ä»£è¡¨åªè¯», 0ä»£è¡¨è¯»å†™\n[root@db02 ~]# systemctl restart mysqld\n\n#2..é…ç½®ä»æœåŠ¡å™¨ï¼Œè¿æ¥ä¸»æœåŠ¡å™¨\nmysql&gt; change master to master_host='192.168.40.150',master_user='repl',master_password='passwd',master_log_file='mysql-bin.000006',master_log_pos=889;\n\n#3.å¼€å¯ä»åº“\nmysql&gt; start slave;\nQuery OK, 0 rows affected (0.00 sec)\n\n#4.æ£€æŸ¥ä¸»ä»å¤åˆ¶çŠ¶æ€\nmysql&gt; show slave status\\G\n*************************** 1. row ***************************\n               Slave_IO_State: Waiting for master to send event\n                  Master_Host: 192.168.40.150\n                  Master_User: repl\n                  Master_Port: 3306\n                Connect_Retry: 60\n              Master_Log_File: mysql-bin.000006\n          Read_Master_Log_Pos: 889\n               Relay_Log_File: db02-relay-bin.000002\n                Relay_Log_Pos: 320\n        Relay_Master_Log_File: mysql-bin.000006\n             Slave_IO_Running: Yes\n            Slave_SQL_Running: Yes\n              Replicate_Do_DB: \n          Replicate_Ignore_DB: \n           Replicate_Do_Table: \n       Replicate_Ignore_Table: \n      Replicate_Wild_Do_Table: \n  Replicate_Wild_Ignore_Table: \n                   Last_Errno: 0\n                   Last_Error: \n                 Skip_Counter: 0\n          Exec_Master_Log_Pos: 889\n              Relay_Log_Space: 526\n              Until_Condition: None\n               Until_Log_File: \n                Until_Log_Pos: 0\n           Master_SSL_Allowed: No\n           Master_SSL_CA_File: \n           Master_SSL_CA_Path: \n              Master_SSL_Cert: \n            Master_SSL_Cipher: \n               Master_SSL_Key: \n        Seconds_Behind_Master: 0\nMaster_SSL_Verify_Server_Cert: No\n                Last_IO_Errno: 0\n                Last_IO_Error: \n               Last_SQL_Errno: 0\n               Last_SQL_Error: \n  Replicate_Ignore_Server_Ids: \n             Master_Server_Id: 1\n                  Master_UUID: 9b911bea-43e6-11ee-b239-000c29074f5d\n             Master_Info_File: /var/lib/mysql/master.info\n                    SQL_Delay: 0\n          SQL_Remaining_Delay: NULL\n      Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates\n           Master_Retry_Count: 86400\n                  Master_Bind: \n      Last_IO_Error_Timestamp: \n     Last_SQL_Error_Timestamp: \n               Master_SSL_Crl: \n           Master_SSL_Crlpath: \n           Retrieved_Gtid_Set: \n            Executed_Gtid_Set: \n                Auto_Position: 0\n         Replicate_Rewrite_DB: \n                 Channel_Name: \n           Master_TLS_Version: \n1 row in set (0.00 sec)\n</code></pre>\n<h4 id=\"3-åˆ†åº“åˆ†è¡¨\"><a class=\"anchor\" href=\"#3-åˆ†åº“åˆ†è¡¨\">#</a> 3. <a href=\"https://so.csdn.net/so/search?q=%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8&amp;spm=1001.2101.3001.7020\">åˆ†åº“åˆ†è¡¨</a></h4>\n<h5 id=\"31-åˆ†åº“åˆ†è¡¨ä»‹ç»\"><a class=\"anchor\" href=\"#31-åˆ†åº“åˆ†è¡¨ä»‹ç»\">#</a> 3.1 åˆ†åº“åˆ†è¡¨ä»‹ç»</h5>\n<h6 id=\"311-ç°åœ¨çš„é—®é¢˜\"><a class=\"anchor\" href=\"#311-ç°åœ¨çš„é—®é¢˜\">#</a> 3.1.1 ç°åœ¨çš„é—®é¢˜</h6>\n<p><strong>å•æ•°æ®åº“</strong></p>\n<p>æ‰€æœ‰æ•°æ®éƒ½æ˜¯å­˜æ”¾åœ¨ä¸€ä¸ª<a href=\"https://so.csdn.net/so/search?q=%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6&amp;spm=1001.2101.3001.7020\">æ•°æ®åº“æ–‡ä»¶</a>é‡Œçš„ï¼Œç»è¿‡å¸¸å¹´ç´¯æœˆï¼Œå†…å­˜ä¸è¶³äº†æ€ä¹ˆåŠï¼Ÿ</p>\n<p><a href=\"https://imgse.com/i/pEgOyd0\"><img loading=\"lazy\" data-src=\"https://s21.ax1x.com/2025/04/09/pEgOyd0.png\" alt=\"pEgOyd0.png\" /></a></p>\n<p>éšç€äº’è”ç½‘åŠç§»åŠ¨äº’è”ç½‘çš„å‘å±•ï¼Œåº”ç”¨ç³»ç»Ÿçš„æ•°æ®é‡ä¹Ÿæ˜¯æˆæŒ‡æ•°å¼å¢é•¿ï¼Œè‹¥é‡‡ç”¨å•æ•°æ®åº“è¿›è¡Œæ•°æ®å­˜å‚¨ï¼Œå­˜åœ¨ä»¥ä¸‹æ€§èƒ½ç“¶é¢ˆï¼š</p>\n<p>IO ç“¶é¢ˆï¼šçƒ­ç‚¹æ•°æ®å¤ªå¤šï¼Œæ•°æ®åº“ç¼“å­˜ä¸è¶³ï¼Œäº§ç”Ÿå¤§é‡ç£ç›˜ IOï¼Œæ•ˆç‡è¾ƒä½ã€‚è¯·æ±‚æ•°æ®å¤ªå¤šï¼Œå¸¦å®½ä¸å¤Ÿï¼Œç½‘ç»œ IO ç“¶é¢ˆã€‚<br />\nCPU ç“¶é¢ˆï¼š æ’åºã€åˆ†ç»„ã€è¿æ¥æŸ¥è¯¢ã€èšåˆç»Ÿè®¡ç­‰ SQL ä¼šè€—è´¹å¤§é‡çš„ CPU èµ„æºï¼Œè¯·æ±‚æ•°å¤ªå¤šï¼ŒCPU å‡ºç°ç“¶é¢ˆã€‚</p>\n<p><a href=\"https://imgse.com/i/pEgO6oV\"><img loading=\"lazy\" data-src=\"https://s21.ax1x.com/2025/04/09/pEgO6oV.png\" alt=\"pEgO6oV.png\" /></a></p>\n<p><strong>åˆ†åº“åˆ†è¡¨çš„ä¸­å¿ƒæ€æƒ³ï¼š<br />\nå°†æ•°æ®åˆ†æ•£å­˜å‚¨ï¼Œä½¿å¾—å•ä¸€æ•°æ®åº“ / è¡¨çš„æ•°æ®é‡å˜å°æ¥ç¼“è§£å•ä¸€æ•°æ®åº“çš„æ€§èƒ½é—®é¢˜ï¼Œä»è€Œè¾¾åˆ°æå‡æ•°æ®åº“æ€§èƒ½çš„ç›®çš„ã€‚</strong></p>\n<h6 id=\"312-æ‹†åˆ†ç­–ç•¥\"><a class=\"anchor\" href=\"#312-æ‹†åˆ†ç­–ç•¥\">#</a> 3.1.2 æ‹†åˆ†ç­–ç•¥</h6>\n<p><a href=\"https://imgse.com/i/pE2dAXt\"><img loading=\"lazy\" data-src=\"https://s21.ax1x.com/2025/04/10/pE2dAXt.png\" alt=\"pE2dAXt.png\" /></a></p>\n<h6 id=\"313-å‚ç›´æ‹†åˆ†ç­–ç•¥\"><a class=\"anchor\" href=\"#313-å‚ç›´æ‹†åˆ†ç­–ç•¥\">#</a> 3.1.3 å‚ç›´æ‹†åˆ†ç­–ç•¥</h6>\n<p><a href=\"https://imgse.com/i/pE2dnAS\"><img loading=\"lazy\" data-src=\"https://s21.ax1x.com/2025/04/10/pE2dnAS.png\" alt=\"pE2dnAS.png\" /></a></p>\n<p>ç‰¹ç‚¹:</p>\n<ol>\n<li>æ¯ä¸ªåº“çš„è¡¨ç»“æ„éƒ½ä¸ä¸€æ ·ã€‚</li>\n<li>æ¯ä¸ªåº“çš„æ•°æ®ä¹Ÿä¸ä¸€æ · ã€‚</li>\n<li>æ‰€æœ‰ï¼Œåº“çš„å¹¶é›†æ˜¯å…¨é‡æ•°æ®ã€‚</li>\n</ol>\n<p><a href=\"https://imgse.com/i/pE2dQpj\"><img loading=\"lazy\" data-src=\"https://s21.ax1x.com/2025/04/10/pE2dQpj.png\" alt=\"pE2dQpj.png\" /></a></p>\n<p>ç‰¹ç‚¹:</p>\n<ol>\n<li>æ¯ä¸ªè¡¨çš„ç»“æ„éƒ½ä¸ä¸€æ ·ã€‚</li>\n<li>æ¯ä¸ªè¡¨çš„æ•°æ®ä¹Ÿæœ¯ä¸€æ ·ï¼Œä¸€èˆ¬é€šè¿‡ä¸€åˆ— (ä¸»é”® / å¤–é”®) å…³è”ã€‚</li>\n<li>æ‰€æœ‰è¡¨çš„å¹¶é›†æ˜¯å…¨é‡æ•°æ®ã€‚</li>\n</ol>\n<h6 id=\"314-æ°´å¹³æ‹†åˆ†ç­–ç•¥\"><a class=\"anchor\" href=\"#314-æ°´å¹³æ‹†åˆ†ç­–ç•¥\">#</a> 3.1.4 æ°´å¹³æ‹†åˆ†ç­–ç•¥</h6>\n<p><a href=\"https://imgse.com/i/pE2d3Xq\"><img loading=\"lazy\" data-src=\"https://s21.ax1x.com/2025/04/10/pE2d3Xq.png\" alt=\"pE2d3Xq.png\" /></a></p>\n<p>æ°´å¹³åˆ†åº“ï¼šä»¥ â€œå­—æ®µâ€ ä¸ºä¾æ®ï¼Œæ”¹ä¸ºä»¥ â€œè¡Œï¼ˆè®°å½•ï¼‰â€ ä¸ºä¾æ®ã€‚è®²ä¸€ä¸ªåº“çš„æ•°æ®æ‹†åˆ†åˆ°å¤šä¸ªåº“</p>\n<p>ç‰¹ç‚¹ï¼š</p>\n<ol>\n<li>æ¯ä¸ªåº“çš„è¡¨ç»“æ„éƒ½ä¸€æ ·ã€‚</li>\n<li>æ¯ä¸ªåº“çš„æ•°æ®éƒ½ä¸ä¸€æ ·ã€‚</li>\n<li>æ‰€æœ‰åº“çš„å¹¶é›†æ˜¯å…¨é‡æ•°æ®ã€‚</li>\n</ol>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/8Vp5L6j.png\" alt=\"1.png\" /></p>\n<p>ç‰¹ç‚¹ï¼š</p>\n<ol>\n<li>æ¯ä¸ªè¡¨çš„è¡¨ç»“æ„éƒ½ä¸€æ · ã€‚</li>\n<li>æ¯ä¸ªè¡¨çš„æ•°æ®éƒ½ä¸ä¸€æ · ã€‚</li>\n<li>æ‰€æœ‰è¡¨çš„å¹¶é›†æ˜¯å…¨é‡æ•°æ®ã€‚</li>\n</ol>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/2ctPFwi.png\" alt=\"2.png\" /></p>\n<ul>\n<li>shardingJDBCï¼šåŸºäº AOP åŸç†ï¼Œåœ¨åº”ç”¨ç¨‹åºä¸­å¯¹æœ¬åœ°æ‰§è¡Œçš„ SQL è¿›è¡Œæ‹¦æˆªï¼Œè§£æã€æ”¹å†™ã€è·¯ç”±å¤„ç†ã€‚éœ€è¦è‡ªè¡Œç¼–ç é…ç½®å®ç°ï¼Œåªæ”¯æŒ java è¯­è¨€ï¼Œæ€§èƒ½è¾ƒé«˜ã€‚</li>\n<li>MyCatï¼šæ•°æ®åº“åˆ†åº“åˆ†è¡¨ä¸­é—´ä»¶ï¼Œä¸ç”¨è°ƒæ•´ä»£ç å³å¯å®ç°åˆ†åº“åˆ†è¡¨ï¼Œæ”¯æŒå¤šç§è¯­è¨€ï¼Œæ€§èƒ½ä¸åŠå‰è€…ã€‚</li>\n</ul>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/lgs1r8g.png\" alt=\"3.png\" /></p>\n<h5 id=\"32-mycatæ¦‚è¿°\"><a class=\"anchor\" href=\"#32-mycatæ¦‚è¿°\">#</a> 3.2 Mycat æ¦‚è¿°</h5>\n<p>Mycat æ˜¯å¼€æºçš„ã€æ´»è·ƒçš„ã€åŸºäº Java è¯­è¨€ç¼–å†™çš„<strong> MySQL æ•°æ®åº“ä¸­é—´ä»¶</strong>ã€‚å¯ä»¥åƒä½¿ç”¨ mysql ä¸€æ ·æ¥ä½¿ç”¨ mycatï¼Œå¯¹äºå¼€å‘äººå‘˜æ¥è¯´æ ¹æœ¬æ„Ÿè§‰ä¸åˆ° mycat çš„å­˜åœ¨ã€‚</p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/KFB4gQ8.png\" alt=\"5.png\" /></p>\n<p>ä¼˜åŠ¿ï¼š</p>\n<ul>\n<li>æ€§èƒ½å¯é ç¨³å®š</li>\n<li>å¼ºå¤§çš„æŠ€æœ¯å›¢é˜Ÿ</li>\n<li>ä½“ç³»å®Œå–„</li>\n<li>ç¤¾åŒºæ´»è·ƒ</li>\n</ul>\n<p>Mycat æ˜¯é‡‡ç”¨ java è¯­è¨€å¼€å‘çš„å¼€æºçš„æ•°æ®åº“ä¸­é—´ä»¶ï¼Œæ”¯æŒ Windows å’Œ Linux è¿è¡Œç¯å¢ƒï¼Œä¸‹é¢ä»‹ç» MyCat çš„ Linux ä¸­çš„ç¯å¢ƒæ­å»ºã€‚ æˆ‘ä»¬éœ€è¦åœ¨å‡†å¤‡å¥½çš„æœåŠ¡å™¨ä¸­å®‰è£…å¦‚ä¸‹è½¯ä»¶ã€‚</p>\n<table>\n<thead>\n<tr>\n<th>æœåŠ¡å™¨</th>\n<th>å®‰è£…è½¯ä»¶</th>\n<th>è¯´æ˜</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>192.168.40.213</td>\n<td>JDKã€Mycat</td>\n<td>MyCat ä¸­é—´ä»¶æœåŠ¡å™¨</td>\n</tr>\n<tr>\n<td>192.168.40.210</td>\n<td>MySQL</td>\n<td>åˆ†ç‰‡æœåŠ¡å™¨</td>\n</tr>\n<tr>\n<td>192.168.40.211</td>\n<td>MySQL</td>\n<td>åˆ†ç‰‡æœåŠ¡å™¨</td>\n</tr>\n<tr>\n<td>192.168.40.212</td>\n<td>MySQL</td>\n<td>åˆ†ç‰‡æœåŠ¡å™¨</td>\n</tr>\n</tbody>\n</table>\n<p>JDK å®‰è£…</p>\n<pre><code>#è§£å‹jdk\n[root@mycat ~]# tar xf jdk-8u371-linux-x64.tar.gz -C /usr/local\n[root@mycat ~]# ln -s /usr/local/jdk1.8.0_371/ /usr/local/jdk\n\n# æ·»åŠ ç¯å¢ƒå˜é‡\n[root@mycat ~]# vim /etc/profile.d/jdk.sh \nexport JAVA_HOME=/usr/local/jdk\nexport PATH=$PATH:$JAVA_HOME/bin\nexport JRE_HOME=$JAVA_HOME/jre \nexport CLASSPATH=$JAVA_HOME/lib/:$JRE_HOME/lib/\n\n[root@mycat ~]# source /etc/profile\n[root@mycat ~]# java -version\n</code></pre>\n<p>Mycat å®‰è£…</p>\n<pre><code>[root@mycat ~]# tar xf Mycat-server-1.6-RELEASE-20161028204710-linux.tar.gz -C /usr/local/\n[root@mycat ~]# ll /usr/local/mycat/\ntotal 12\ndrwxr-xr-x 2 root root  190 Dec  2 22:15 bin\ndrwxrwxrwx 2 root root    6 Mar  1  2016 catlet\ndrwxrwxrwx 4 root root 4096 Dec  2 22:15 conf\ndrwxr-xr-x 2 root root 4096 Dec  2 22:15 lib\ndrwxrwxrwx 2 root root    6 Oct 28  2016 logs\n-rwxrwxrwx 1 root root  217 Oct 28  2016 version.txt\n\n#ä¸Šä¼ jaråŒ…\n[root@mycat ~]# rz /usr/local/mycat/lib/mysql-connector-java-8.0.25.jar\n[root@mycat lib]# chmod 777 mysql-connector-java-8.0.25.jar \n</code></pre>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/n86yXtx.png\" alt=\"4.png\" /></p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/U26clQE.png\" alt=\"6.png\" /></p>\n<h6 id=\"321-mycatå…¥é—¨\"><a class=\"anchor\" href=\"#321-mycatå…¥é—¨\">#</a> 3.2.1 Mycat å…¥é—¨</h6>\n<p>ç”±äº tb_gorder è¡¨ä¸­æ•°æ®é‡å¾ˆå¤§ï¼Œç£ç›˜ IO åŠå®¹é‡éƒ½åˆ°è¾¾äº†ç“¶é¢ˆï¼Œç°åœ¨éœ€è¦å¯¹ tb_order è¡¨è¿›è¡Œæ•°æ®åˆ†ç‰‡ï¼Œåˆ†ä¸ºä¸‰ä¸ªæ•°æ®èŠ‚ç‚¹ï¼Œæ¯ä¸€ä¸ªèŠ‚ç‚¹ä¸»æœºä½äºä¸åŒçš„æœåŠ¡å™¨ä¸Šï¼Œå…·ä½“çš„ç»“æ„ï¼Œå‚è€ƒä¸‹å›¾ï¼š</p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/YjmWPQf.png\" alt=\"5.png\" /></p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/PQqJdjJ.png\" alt=\"8.png\" /></p>\n<h6 id=\"322-mycaté…ç½®\"><a class=\"anchor\" href=\"#322-mycaté…ç½®\">#</a> 3.2.2 Mycat é…ç½®</h6>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/iXUxPhi.png\" alt=\"9.png\" /></p>\n<pre><code>[root@mycat ~]# cat /usr/local/mycat/conf/schema.xml \n&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;!DOCTYPE mycat:schema SYSTEM &quot;schema.dtd&quot;&gt;\n&lt;mycat:schema xmlns:mycat=&quot;http://io.mycat/&quot;&gt;\n\t&lt;schema name=&quot;DB01&quot; checkSQLschema=&quot;true&quot; sqlMaxLimit=&quot;100&quot;&gt;\n\t\t&lt;table name=&quot;TB_ORDER&quot; dataNode=&quot;dn1,dn2,dn3&quot; rule=&quot;auto-sharding-long&quot; /&gt;\n\t&lt;/schema&gt;\n\t\n\t&lt;dataNode name=&quot;dn1&quot; dataHost=&quot;dhost1&quot; database=&quot;db01&quot; /&gt;\n\t&lt;dataNode name=&quot;dn2&quot; dataHost=&quot;dhost2&quot; database=&quot;db01&quot; /&gt;\n\t&lt;dataNode name=&quot;dn3&quot; dataHost=&quot;dhost3&quot; database=&quot;db01&quot; /&gt;\n\t\n\t&lt;dataHost name=&quot;dhost1&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot;\n\t\t\t  writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;jdbc&quot; switchType=&quot;1&quot;  slaveThreshold=&quot;100&quot;&gt;\n\t\t&lt;heartbeat&gt;select user()&lt;/heartbeat&gt;\n\t\t\n\t\t&lt;writeHost host=&quot;master&quot; url=&quot;jdbc:mysql://192.168.40.210:3306?useSSL=false&amp;amp;serverTimezone=Asia/Shanghai&amp;amp;characterEncoding=utf8&quot; user=&quot;root&quot; password=&quot;Superman*2023&quot; /&gt;\n\t&lt;/dataHost&gt;\n\t\n\t&lt;dataHost name=&quot;dhost2&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot;\n\t\t\t  writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;jdbc&quot; switchType=&quot;1&quot;  slaveThreshold=&quot;100&quot;&gt;\n\t\t&lt;heartbeat&gt;select user()&lt;/heartbeat&gt;\n\t\t\n\t\t&lt;writeHost host=&quot;master&quot; url=&quot;jdbc:mysql://192.168.40.211:3306?useSSL=false&amp;amp;serverTimezone=Asia/Shanghai&amp;amp;characterEncoding=utf8&quot; user=&quot;root&quot; password=&quot;Superman*2023&quot; /&gt;\n\t&lt;/dataHost&gt;\n\t\n\t&lt;dataHost name=&quot;dhost3&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot;\n\t\t\t  writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;jdbc&quot; switchType=&quot;1&quot;  slaveThreshold=&quot;100&quot;&gt;\n\t\t&lt;heartbeat&gt;select user()&lt;/heartbeat&gt;\n\t\t\n\t\t&lt;writeHost host=&quot;master&quot; url=&quot;jdbc:mysql://192.168.40.212:3306?useSSL=false&amp;amp;serverTimezone=Asia/Shanghai&amp;amp;characterEncoding=utf8&quot; user=&quot;root&quot; password=&quot;Superman*2023&quot; /&gt;\n\t&lt;/dataHost&gt;\n&lt;/mycat:schema&gt;\n</code></pre>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/KkUttwJ.png\" alt=\"10.png\" /></p>\n<pre><code>[root@mycat mycat]# cat /usr/local/mycat/conf/server.xml \n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;!-- - - Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); \n\t- you may not use this file except in compliance with the License. - You \n\tmay obtain a copy of the License at - - http://www.apache.org/licenses/LICENSE-2.0 \n\t- - Unless required by applicable law or agreed to in writing, software - \n\tdistributed under the License is distributed on an &quot;AS IS&quot; BASIS, - WITHOUT \n\tWARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. - See the \n\tLicense for the specific language governing permissions and - limitations \n\tunder the License. --&gt;\n&lt;!DOCTYPE mycat:server SYSTEM &quot;server.dtd&quot;&gt;\n&lt;mycat:server xmlns:mycat=&quot;http://io.mycat/&quot;&gt;\n\t&lt;system&gt;\n\t&lt;property name=&quot;useSqlStat&quot;&gt;0&lt;/property&gt;  &lt;!-- 1ä¸ºå¼€å¯å®æ—¶ç»Ÿè®¡ã€0ä¸ºå…³é—­ --&gt;\n\t&lt;property name=&quot;useGlobleTableCheck&quot;&gt;0&lt;/property&gt;  &lt;!-- 1ä¸ºå¼€å¯å…¨åŠ ç­ä¸€è‡´æ€§æ£€æµ‹ã€0ä¸ºå…³é—­ --&gt;\n\n\t\t&lt;property name=&quot;sequnceHandlerType&quot;&gt;2&lt;/property&gt;\n      &lt;!--  &lt;property name=&quot;useCompression&quot;&gt;1&lt;/property&gt;--&gt; &lt;!--1ä¸ºå¼€å¯mysqlå‹ç¼©åè®®--&gt;\n        &lt;!--  &lt;property name=&quot;fakeMySQLVersion&quot;&gt;5.6.20&lt;/property&gt;--&gt; &lt;!--è®¾ç½®æ¨¡æ‹Ÿçš„MySQLç‰ˆæœ¬å·--&gt;\n\t&lt;!-- &lt;property name=&quot;processorBufferChunk&quot;&gt;40960&lt;/property&gt; --&gt;\n\t&lt;!-- \n\t&lt;property name=&quot;processors&quot;&gt;1&lt;/property&gt; \n\t&lt;property name=&quot;processorExecutor&quot;&gt;32&lt;/property&gt; \n\t --&gt;\n\t\t&lt;!--é»˜è®¤ä¸ºtype 0: DirectByteBufferPool | type 1 ByteBufferArena--&gt;\n\t\t&lt;property name=&quot;processorBufferPoolType&quot;&gt;0&lt;/property&gt;\n\t\t&lt;!--é»˜è®¤æ˜¯65535 64K ç”¨äºsqlè§£ææ—¶æœ€å¤§æ–‡æœ¬é•¿åº¦ --&gt;\n\t\t&lt;!--&lt;property name=&quot;maxStringLiteralLength&quot;&gt;65535&lt;/property&gt;--&gt;\n\t\t&lt;!--&lt;property name=&quot;sequnceHandlerType&quot;&gt;0&lt;/property&gt;--&gt;\n\t\t&lt;!--&lt;property name=&quot;backSocketNoDelay&quot;&gt;1&lt;/property&gt;--&gt;\n\t\t&lt;!--&lt;property name=&quot;frontSocketNoDelay&quot;&gt;1&lt;/property&gt;--&gt;\n\t\t&lt;!--&lt;property name=&quot;processorExecutor&quot;&gt;16&lt;/property&gt;--&gt;\n\t\t&lt;!--\n\t\t\t&lt;property name=&quot;serverPort&quot;&gt;8066&lt;/property&gt; &lt;property name=&quot;managerPort&quot;&gt;9066&lt;/property&gt; \n\t\t\t&lt;property name=&quot;idleTimeout&quot;&gt;300000&lt;/property&gt; &lt;property name=&quot;bindIp&quot;&gt;0.0.0.0&lt;/property&gt; \n\t\t\t&lt;property name=&quot;frontWriteQueueSize&quot;&gt;4096&lt;/property&gt; &lt;property name=&quot;processors&quot;&gt;32&lt;/property&gt; --&gt;\n\t\t&lt;!--åˆ†å¸ƒå¼äº‹åŠ¡å¼€å…³ï¼Œ0ä¸ºä¸è¿‡æ»¤åˆ†å¸ƒå¼äº‹åŠ¡ï¼Œ1ä¸ºè¿‡æ»¤åˆ†å¸ƒå¼äº‹åŠ¡ï¼ˆå¦‚æœåˆ†å¸ƒå¼äº‹åŠ¡å†…åªæ¶‰åŠå…¨å±€è¡¨ï¼Œåˆ™ä¸è¿‡æ»¤ï¼‰ï¼Œ2ä¸ºä¸è¿‡æ»¤åˆ†å¸ƒå¼äº‹åŠ¡,ä½†æ˜¯è®°å½•åˆ†å¸ƒå¼äº‹åŠ¡æ—¥å¿—--&gt;\n\t\t&lt;property name=&quot;handleDistributedTransactions&quot;&gt;0&lt;/property&gt;\n\t\t\n\t\t\t&lt;!--\n\t\t\toff heap for merge/order/group/limit      1å¼€å¯   0å…³é—­\n\t\t--&gt;\n\t\t&lt;property name=&quot;useOffHeapForMerge&quot;&gt;1&lt;/property&gt;\n\n\t\t&lt;!--\n\t\t\tå•ä½ä¸ºm\n\t\t--&gt;\n\t\t&lt;property name=&quot;memoryPageSize&quot;&gt;1m&lt;/property&gt;\n\n\t\t&lt;!--\n\t\t\tå•ä½ä¸ºk\n\t\t--&gt;\n\t\t&lt;property name=&quot;spillsFileBufferSize&quot;&gt;1k&lt;/property&gt;\n\n\t\t&lt;property name=&quot;useStreamOutput&quot;&gt;0&lt;/property&gt;\n\n\t\t&lt;!--\n\t\t\tå•ä½ä¸ºm\n\t\t--&gt;\n\t\t&lt;property name=&quot;systemReserveMemorySize&quot;&gt;384m&lt;/property&gt;\n\n\n\t\t&lt;!--æ˜¯å¦é‡‡ç”¨zookeeperåè°ƒåˆ‡æ¢  --&gt;\n\t\t&lt;property name=&quot;useZKSwitch&quot;&gt;true&lt;/property&gt;\n\n\n\t&lt;/system&gt;\n\t\n\t&lt;!-- å…¨å±€SQLé˜²ç«å¢™è®¾ç½® --&gt;\n\t&lt;!-- \n\t&lt;firewall&gt; \n\t   &lt;whitehost&gt;\n\t      &lt;host host=&quot;127.0.0.1&quot; user=&quot;mycat&quot;/&gt;\n\t      &lt;host host=&quot;127.0.0.2&quot; user=&quot;mycat&quot;/&gt;\n\t   &lt;/whitehost&gt;\n       &lt;blacklist check=&quot;false&quot;&gt;\n       &lt;/blacklist&gt;\n\t&lt;/firewall&gt;\n\t--&gt;\n\t\n\t&lt;user name=&quot;root&quot;&gt;\n\t\t&lt;property name=&quot;password&quot;&gt;Superman*2023&lt;/property&gt;\n\t\t&lt;property name=&quot;schemas&quot;&gt;DB01&lt;/property&gt;\n\t\t\n\t\t&lt;!-- è¡¨çº§ DML æƒé™è®¾ç½® --&gt;\n\t\t&lt;!-- \t\t\n\t\t&lt;privileges check=&quot;false&quot;&gt;\n\t\t\t&lt;schema name=&quot;TESTDB&quot; dml=&quot;0110&quot; &gt;\n\t\t\t\t&lt;table name=&quot;tb01&quot; dml=&quot;0000&quot;&gt;&lt;/table&gt;\n\t\t\t\t&lt;table name=&quot;tb02&quot; dml=&quot;1111&quot;&gt;&lt;/table&gt;\n\t\t\t&lt;/schema&gt;\n\t\t&lt;/privileges&gt;\t\t\n\t\t --&gt;\n\t&lt;/user&gt;\n\n\t&lt;user name=&quot;user&quot;&gt;\n\t\t&lt;property name=&quot;password&quot;&gt;Superman*2023&lt;/property&gt;\n\t\t&lt;property name=&quot;schemas&quot;&gt;DB01&lt;/property&gt;\n\t\t&lt;property name=&quot;readOnly&quot;&gt;true&lt;/property&gt;\n\t&lt;/user&gt;\n\n&lt;/mycat:server&gt;\n</code></pre>\n<h6 id=\"323-mycatå¯åŠ¨\"><a class=\"anchor\" href=\"#323-mycatå¯åŠ¨\">#</a> 3.2.3 Mycat å¯åŠ¨</h6>\n<pre><code>#1.å¯åŠ¨mycat\n[root@mycat mycat]# ./bin/mycat restart\n\n#2.wrapper.logæ—¥å¿—ä¸­å¸¸è§é”™è¯¯\nERROR | wrapper | 2021/1/10 13:31:05 | Startup failed: Timed out waiting for signal from JVM.\nERROR | wrapper | 2021/1/10 13:31:05 | JVM did not exit on request, terminated\n\n#3.å¯åŠ¨Mycatè¶…æ—¶,å‰å¾€wrapper.confé…ç½®è¶…æ—¶ç­–ç•¥\n[root@mycat mycat]# vim /usr/local/mycat/conf/wrapper.conf\n...\nwrapper.startup.timeout=300     //æ·»åŠ æ­¤è¡Œï¼Œè¶…æ—¶æ—¶é—´300ç§’\nwrapper.ping.timeout=120\n\n#4.æŸ¥çœ‹mycatæ˜¯å¦å¯åŠ¨\n[root@mycat mycat]# tail -f logs/wrapper.log\n...\nINFO   | jvm 1    | 2023/12/02 22:53:44 | MyCAT Server startup successfully. see logs in logs/mycat.log\n[root@mycat mycat]# netstat -lntp|grep 8066\ntcp6       0      0 :::8066                 :::*                    LISTEN      18028/java\n</code></pre>\n<h6 id=\"324-åˆ†ç‰‡æµ‹è¯•\"><a class=\"anchor\" href=\"#324-åˆ†ç‰‡æµ‹è¯•\">#</a> 3.2.4 åˆ†ç‰‡æµ‹è¯•</h6>\n<pre><code>[root@db3 ~]#  mysql -h 192.168.40.213 -P 8066 -uroot -p'Superman*2023'\nmysql: [Warning] Using a password on the command line interface can be insecure.\nWelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 3\nServer version: 5.6.29-mycat-1.6-RELEASE-20161028204710 MyCat Server (OpenCloundDB)\n\nCopyright (c) 2000, 2023, Oracle and/or its affiliates.\n\nOracle is a registered trademark of Oracle Corporation and/or its\naffiliates. Other names may be trademarks of their respective\nowners.\n\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\nmysql&gt; show databases;\n+----------+\n| DATABASE |\n+----------+\n| DB01     |\n+----------+\n1 row in set (0.00 sec)\n\nmysql&gt; use DB01;\nReading table information for completion of table and column names\nYou can turn off this feature to get a quicker startup with -A\n\nDatabase changed\nmysql&gt; show tables;\n+----------------+\n| Tables in DB01 |\n+----------------+\n| tb_order       |\n+----------------+\n1 row in set (0.00 sec)\nmysql&gt; CREATE TABLE TB_ORDER(\n    -&gt; id BIGINT(20) NOT NULL,\n    -&gt; title VARCHAR(100) NOT NULL,\n    -&gt; PRIMARY KEY (id)\n    -&gt; )ENGINE=INNODB DEFAULT CHARSET=utf8;\nQuery OK, 0 rows affected (0.04 sec)\n OK!\nmysql&gt;INSERT INTO TB_ORDER(id,title) VALUES(1,'guods1');\nmysql&gt;INSERT INTO TB_ORDER(id,title) VALUES(2,'guods2');\nmysql&gt;INSERT INTO TB_ORDER(id,title) VALUES(3,'guods3');\nmysql&gt;INSERT INTO TB_ORDER(id,title) VALUES(4,'guods4');\nmysql&gt; select * from TB_ORDER;\n+------+--------+\n| id   | title  |\n+------+--------+\n|    1 | guods1 |\n|    2 | guods2 |\n|    3 | guods3 |\n|    4 | guods4 |\n+------+--------+\n4 rows in set (0.03 sec)\n</code></pre>\n<p><strong>æ•°æ®å†™å…¥åˆ° db1 ä¸­ï¼Œå› ä¸º mycat åˆ†ç‰‡è§„åˆ™ä¸º 0-50000000 å­˜å…¥èŠ‚ç‚¹ 1,5000001-10000000 å­˜å…¥èŠ‚ç‚¹ 2,10000001-15000000 å­˜å…¥èŠ‚ç‚¹ 3ï¼Œ15000001 ä»¥ä¸Šæ— æ³•æ’å…¥æ•°æ®ï¼Œéœ€è¦å¢åŠ æ•°æ®èŠ‚ç‚¹ã€‚</strong></p>\n<pre><code>[root@mycat mycat]# vim conf/rule.xml\n...\n        &lt;tableRule name=&quot;auto-sharding-long&quot;&gt;\n                &lt;rule&gt;\n                        &lt;columns&gt;id&lt;/columns&gt;\n                        &lt;algorithm&gt;rang-long&lt;/algorithm&gt;\n                &lt;/rule&gt;\n        &lt;/tableRule&gt;\n\n....\n       &lt;function name=&quot;rang-long&quot;\n                class=&quot;io.mycat.route.function.AutoPartitionByLong&quot;&gt;\n                &lt;property name=&quot;mapFile&quot;&gt;autopartition-long.txt&lt;/property&gt;\n        &lt;/function&gt;\n\n...\n\n[root@mycat mycat]# cat conf/autopartition-long.txt\n# range start-end ,data node index\n# K=1000,M=10000.\n0-500M=0\n500M-1000M=1\n\n#5000001-10000000å­˜å…¥èŠ‚ç‚¹2 \nmysql&gt; INSERT INTO TB_ORDER(id,title) VALUES(5000001,'guods5000001');\nQuery OK, 1 row affected (0.01 sec)\n OK!\n \n#10000001-15000000å­˜å…¥èŠ‚ç‚¹3 \nmysql&gt; INSERT INTO TB_ORDER(id,title) VALUES(10000001,'guods10000001');\nQuery OK, 1 row affected (0.00 sec)\n OK!\n\n#15000001ä»¥ä¸Šæ— æ³•æ’å…¥æ•°æ®ï¼Œéœ€è¦å¢åŠ æ•°æ®èŠ‚ç‚¹\nmysql&gt; INSERT INTO TB_ORDER(id,title) VALUES(15000001,'guods15000001');\nERROR 1064 (HY000): can't find any valid datanode :TB_ORDER -&gt; ID -&gt; 15000001\n</code></pre>\n<h5 id=\"33-mycaté…ç½®\"><a class=\"anchor\" href=\"#33-mycaté…ç½®\">#</a> 3.3 Mycat é…ç½®</h5>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/I9QLBBR.png\" alt=\"11.png\" /></p>\n<h6 id=\"331-schemaæ ‡ç­¾\"><a class=\"anchor\" href=\"#331-schemaæ ‡ç­¾\">#</a> 3.3.1 Schema æ ‡ç­¾</h6>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/TmYK7fP.png\" alt=\"13.png\" /></p>\n<p>schema æ ‡ç­¾ç”¨äºå®šä¹‰ MyCat å®ä¾‹ä¸­çš„é€»è¾‘åº“ï¼Œä¸€ä¸ª MyCat å®ä¾‹ä¸­ï¼Œå¯ä»¥æœ‰å¤šä¸ªé€»è¾‘åº“ï¼Œå¯ä»¥é€šè¿‡ schema æ ‡ç­¾æ¥åˆ’åˆ†ä¸åŒçš„é€»è¾‘åº“ã€‚MyCat ä¸­çš„é€»è¾‘åº“çš„æ¦‚å¿µï¼Œç­‰åŒäº MySQL ä¸­çš„ database æ¦‚å¿µï¼Œéœ€è¦æ“ä½œæŸä¸ªé€»è¾‘åº“ä¸‹çš„è¡¨æ—¶ä¹Ÿéœ€è¦åˆ‡æ¢é€»è¾‘åº“ (use xxx)ã€‚</p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/SGo0DCv.png\" alt=\"14.png\" /></p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/XtDxXWj.png\" alt=\"15.png\" /></p>\n<h6 id=\"332-datanodeæ ‡ç­¾\"><a class=\"anchor\" href=\"#332-datanodeæ ‡ç­¾\">#</a> 3.3.2 Datanode æ ‡ç­¾</h6>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/phHZ48F.png\" alt=\"16.png\" /></p>\n<h6 id=\"333-datahostæ ‡ç­¾\"><a class=\"anchor\" href=\"#333-datahostæ ‡ç­¾\">#</a> 3.3.3 Datahost æ ‡ç­¾</h6>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/fXBnwcS.png\" alt=\"17.png\" /></p>\n<h6 id=\"334-rulexml\"><a class=\"anchor\" href=\"#334-rulexml\">#</a> 3.3.4 rule.xml</h6>\n<p>rule.xml ä¸­å®šä¹‰æ‰€æœ‰æ‹†åˆ†è¡¨çš„è§„åˆ™ï¼Œåœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­å¯ä»¥çµæ´»çš„ä½¿ç”¨åˆ†ç‰‡ç®—æ³•ï¼Œæˆ–è€…å¯¹åŒä¸€ä¸ªåˆ†ç‰‡ç®—æ³•ä½¿ç”¨ä¸åŒçš„å‚æ•°ï¼Œå®ƒè®©åˆ†ç‰‡è¿‡ç¨‹å¯é…ç½®åŒ–ã€‚ä¸»è¦åŒ…å«ä¸¤ç±»æ ‡ç­¾ï¼š <code>tableRule</code> ã€ <code>Function</code> ã€‚</p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/Ecm1Nvr.png\" alt=\"18.png\" /></p>\n<h6 id=\"335-serverxml\"><a class=\"anchor\" href=\"#335-serverxml\">#</a> 3.3.5 server.xml</h6>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/xIDxYpu.png\" alt=\"19.png\" /></p>\n<h5 id=\"34-mycatåˆ†ç‰‡\"><a class=\"anchor\" href=\"#34-mycatåˆ†ç‰‡\">#</a> 3.4 Mycat åˆ†ç‰‡</h5>\n<h6 id=\"341-åˆ†åº“åˆ†è¡¨-mycatåˆ†ç‰‡-å‚ç›´åˆ†åº“\"><a class=\"anchor\" href=\"#341-åˆ†åº“åˆ†è¡¨-mycatåˆ†ç‰‡-å‚ç›´åˆ†åº“\">#</a> 3.4.1 åˆ†åº“åˆ†è¡¨ - MyCat åˆ†ç‰‡ - å‚ç›´åˆ†åº“</h6>\n<p>åœºæ™¯ï¼šåœ¨ä¸šåŠ¡ç³»ç»Ÿä¸­ï¼Œæ¶‰åŠä»¥ä¸‹è¡¨ç»“æ„ï¼Œä½†æ˜¯ç”±äºç”¨æˆ·ä¸è®¢å•æ¯å¤©éƒ½ä¼šäº§ç”Ÿå¤§é‡çš„æ•°æ®ï¼Œå•å°æœåŠ¡å™¨çš„æ•°æ®å­˜å‚¨åŠå¤„ç†èƒ½åŠ›æ˜¯æœ‰é™çš„ï¼Œå¯ä»¥å¯¹æ•°æ®åº“è¡¨è¿›è¡Œæ‹†åˆ†ï¼ŒåŸæœ‰çš„æ•°æ®åº“è¡¨å¦‚ä¸‹ã€‚</p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/plSdAyY.png\" alt=\"20.png\" /></p>\n<p><strong>ps: åˆ†åº“ä¸éœ€è¦æŒ‡å®š ruleï¼Œæ¶‰åŠåˆ†è¡¨éœ€è¦ä½¿ç”¨ ruleï¼›</strong></p>\n<p><strong>ç¯å¢ƒå‡†å¤‡</strong></p>\n<p>â‘ å¦‚å›¾æ‰€ç¤ºå‡†å¤‡ä¸‰å° Linux æœåŠ¡å™¨ï¼ˆip ä¸ºï¼š192.168.40.210ã€192.168.40.211ã€192.168.40.212ï¼‰å¯ä»¥æ ¹æ®è‡ªå·±çš„å®é™…æƒ…å†µè¿›è¡Œå‡†å¤‡ã€‚<br />\nâ‘¡ä¸‰å°æœåŠ¡å™¨ä¸Šéƒ½å®‰è£… MySQLï¼Œåœ¨ 192.168.40.213 æœåŠ¡å™¨ä¸Šå®‰è£… MyCatã€‚<br />\nâ‘¢ä¸‰å°æœåŠ¡å™¨å…³é—­é˜²ç«å¢™æˆ–è€…å¼€æ”¾å¯¹åº”çš„ç«¯å£ã€‚<br />\nâ‘£åˆ†åˆ«åœ¨ä¸‰å° MySQL ä¸­åˆ›å»ºæ•°æ®åº“ shoppingã€‚<br />\n<img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/uMZB18q.png\" alt=\"21.png\" /></p>\n<p><strong>schema.xml æ–‡ä»¶é…ç½®å¦‚ä¸‹ï¼š</strong></p>\n<pre><code>[root@mycat ~]# cat /usr/local/mycat/conf/schema.xml \n&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;!DOCTYPE mycat:schema SYSTEM &quot;schema.dtd&quot;&gt;\n&lt;mycat:schema xmlns:mycat=&quot;http://io.mycat/&quot;&gt;\n\t&lt;schema name=&quot;SHOPPING&quot; checkSQLschema=&quot;true&quot; sqlMaxLimit=&quot;100&quot;&gt;\n\t\t&lt;table name=&quot;tb_goods_base&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_goods_brand&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_goods_cat&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_goods_desc&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_goods_item&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;goods_id&quot; /&gt;\n\t\t\n\t\t&lt;table name=&quot;tb_order_item&quot; dataNode=&quot;dn2&quot; primaryKey=&quot;id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_order_master&quot; dataNode=&quot;dn2&quot; primaryKey=&quot;order_id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_order_pay_log&quot; dataNode=&quot;dn2&quot; primaryKey=&quot;out_trade_no&quot; /&gt;\n\t\t\n\t\t&lt;table name=&quot;tb_user&quot; dataNode=&quot;dn3&quot; primaryKey=&quot;id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_user_address&quot; dataNode=&quot;dn3&quot; primaryKey=&quot;id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_areas_provinces&quot; dataNode=&quot;dn3&quot; primaryKey=&quot;id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_areas_city&quot; dataNode=&quot;dn3&quot; primaryKey=&quot;id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_areas_region&quot; dataNode=&quot;dn3&quot; primaryKey=&quot;id&quot; /&gt;\n\t&lt;/schema&gt;\n\t\n\t&lt;dataNode name=&quot;dn1&quot; dataHost=&quot;dhost1&quot; database=&quot;shopping&quot; /&gt;\n\t&lt;dataNode name=&quot;dn2&quot; dataHost=&quot;dhost2&quot; database=&quot;shopping&quot; /&gt;\n\t&lt;dataNode name=&quot;dn3&quot; dataHost=&quot;dhost3&quot; database=&quot;shopping&quot; /&gt;\n\t\n\t&lt;dataHost name=&quot;dhost1&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot;\n\t\t\t  writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;jdbc&quot; switchType=&quot;1&quot;  slaveThreshold=&quot;100&quot;&gt;\n\t\t&lt;heartbeat&gt;select user()&lt;/heartbeat&gt;\n\t\t\n\t\t&lt;writeHost host=&quot;master&quot; url=&quot;jdbc:mysql://192.168.40.210:3306?useSSL=false&amp;amp;serverTimezone=Asia/Shanghai&amp;amp;characterEncoding=utf8&quot; user=&quot;root&quot; password=&quot;Superman*2023&quot; /&gt;\n\t&lt;/dataHost&gt;\n\t\n\t&lt;dataHost name=&quot;dhost2&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot;\n\t\t\t  writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;jdbc&quot; switchType=&quot;1&quot;  slaveThreshold=&quot;100&quot;&gt;\n\t\t&lt;heartbeat&gt;select user()&lt;/heartbeat&gt;\n\t\t\n\t\t&lt;writeHost host=&quot;master&quot; url=&quot;jdbc:mysql://192.168.40.211:3306?useSSL=false&amp;amp;serverTimezone=Asia/Shanghai&amp;amp;characterEncoding=utf8&quot; user=&quot;root&quot; password=&quot;Superman*2023&quot; /&gt;\n\t&lt;/dataHost&gt;\n\t\n\t&lt;dataHost name=&quot;dhost3&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot;\n\t\t\t  writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;jdbc&quot; switchType=&quot;1&quot;  slaveThreshold=&quot;100&quot;&gt;\n\t\t&lt;heartbeat&gt;select user()&lt;/heartbeat&gt;\n\t\t\n\t\t&lt;writeHost host=&quot;master&quot; url=&quot;jdbc:mysql://192.168.40.212:3306?useSSL=false&amp;amp;serverTimezone=Asia/Shanghai&amp;amp;characterEncoding=utf8&quot; user=&quot;root&quot; password=&quot;Superman*2023&quot; /&gt;\n\t&lt;/dataHost&gt;\n&lt;/mycat:schema&gt;\n</code></pre>\n<p><strong>server.xml æ–‡ä»¶é…ç½®å¦‚ä¸‹ï¼š</strong></p>\n<pre><code>[root@mycat ~]# cat /usr/local/mycat/conf/server.xml \n...\n\t&lt;user name=&quot;root&quot;&gt;\n\t\t&lt;property name=&quot;password&quot;&gt;Superman*2023&lt;/property&gt;\n\t\t&lt;property name=&quot;schemas&quot;&gt;SHOPPING&lt;/property&gt;\n\t\t\n\t\t&lt;!-- è¡¨çº§ DML æƒé™è®¾ç½® --&gt;\n\t\t&lt;!-- \t\t\n\t\t&lt;privileges check=&quot;false&quot;&gt;\n\t\t\t&lt;schema name=&quot;TESTDB&quot; dml=&quot;0110&quot; &gt;\n\t\t\t\t&lt;table name=&quot;tb01&quot; dml=&quot;0000&quot;&gt;&lt;/table&gt;\n\t\t\t\t&lt;table name=&quot;tb02&quot; dml=&quot;1111&quot;&gt;&lt;/table&gt;\n\t\t\t&lt;/schema&gt;\n\t\t&lt;/privileges&gt;\t\t\n\t\t --&gt;\n\t&lt;/user&gt;\n\n\t&lt;user name=&quot;user&quot;&gt;\n\t\t&lt;property name=&quot;password&quot;&gt;Superman*2023&lt;/property&gt;\n\t\t&lt;property name=&quot;schemas&quot;&gt;SHOPPING&lt;/property&gt;\n\t\t&lt;property name=&quot;readOnly&quot;&gt;true&lt;/property&gt;\n\t&lt;/user&gt;\n\n&lt;/mycat:server&gt;\n</code></pre>\n<p><strong>åˆ†åº“åˆ†è¡¨ - MyCat åˆ†ç‰‡ - å‚ç›´åˆ†åº“ - æµ‹è¯•</strong></p>\n<p><strong>å‚ç›´åˆ†åº“ - æµ‹è¯•</strong></p>\n<pre><code>#1.é‡å¯mycat\n[root@mycat ~]# /usr/local/mycat/bin/mycat restart\nStopping Mycat-server...\nStopped Mycat-server.\nStarting Mycat-server...\n[root@mycat ~]# tail -f  /usr/local/mycat/logs/wrapper.log \n...\nINFO   | jvm 1    | 2023/12/03 15:29:02 | MyCAT Server startup successfully. see logs in logs/mycat.log\ncreate database shopping default charset utf8mb4;\n\n#2.åœ¨3å°èŠ‚ç‚¹åˆ›å»ºshoppingæ•°æ®åº“\nmysql&gt; create database shopping default charset utf8mb4;\nmysql&gt; create database shopping default charset utf8mb4;\nmysql&gt; create database shopping default charset utf8mb4;\n\n#3.ç™»å…¥mycat\n[root@db3 ~]# mysql -h 192.168.40.213 -P 8066 -uroot -p'Superman*2023'\nmysql&gt; show databases;\n+----------+\n| DATABASE |\n+----------+\n| SHOPPING |\n+----------+\n1 row in set (0.01 sec)\n\n#4.æŸ¥çœ‹é€»è¾‘åº“\nmysql&gt; show databases;\n+----------+\n| DATABASE |\n+----------+\n| SHOPPING |\n+----------+\n1 row in set (0.01 sec)\n\n#5.åˆ‡æ¢åˆ°SHOPPINGæ•°æ®åº“\nmysql&gt; use SHOPPING;\nReading table information for completion of table and column names\nYou can turn off this feature to get a quicker startup with -A\n\nDatabase changed\n\n#6.æŸ¥çœ‹é€»è¾‘è¡¨\nmysql&gt; show tables;\n+--------------------+\n| Tables in SHOPPING |\n+--------------------+\n| tb_areas_city      |\n| tb_areas_provinces |\n| tb_areas_region    |\n| tb_goods_base      |\n| tb_goods_brand     |\n| tb_goods_cat       |\n| tb_goods_desc      |\n| tb_goods_item      |\n| tb_order_item      |\n| tb_order_master    |\n| tb_order_pay_log   |\n| tb_user            |\n| tb_user_address    |\n+--------------------+\n13 rows in set (0.00 sec)\n\n#7.ä¸Šä¼ shopping-table.sqlè¡¨ç»“æ„æ–‡ä»¶ä¸shopping-insert.sqlæ•°æ®æ–‡ä»¶\n\n#8.æ‰§è¡Œshopping-table.sqlæ–‡ä»¶\nmysql&gt; source /root/shopping-table.sql\n\n#9.æ‰§è¡Œshopping-insert.sqlæ–‡ä»¶\nmysql&gt; source /root/shopping-insert.sql\n\n#10.æŸ¥çœ‹ä¸‰ä¸ªæ•°æ®åº“å¯ä»¥å‘ç°ï¼ˆæ ¹æ®schema.xmlé…ç½®æ–‡ä»¶çš„é…ç½®è¿›è¡Œäº†å®ç°ï¼‰\nâ‘ 192.168.40.210çš„æ•°æ®åº“ä¸­å­˜æ”¾äº† tb_goods_baseã€tb_goods_brandã€tb_goods_catã€tb_goods_descã€tb_goods_itemè¿™äº”å¼ è¡¨\nâ‘¡192.168.40.211çš„æ•°æ®åº“ä¸­å­˜æ”¾äº† tb_order_itemã€tb_order_masterã€tb_order_pay_logè¿™ä¸‰å¼ è¡¨ï¼›\nâ‘¢192.168.40.212çš„æ•°æ®åº“ä¸­å­˜æ”¾äº† tb_userã€tb_user_addressã€tb_areas_provincesã€tb_areas_cityã€tb_areas_regionè¿™äº”å¼ è¡¨\n</code></pre>\n<p><strong>exam1: æŸ¥è¯¢ç”¨æˆ·çš„æ”¶ä»¶äººåŠæ”¶ä»¶äººåœ°å€ä¿¡æ¯ (åŒ…å«çœã€å¸‚ã€åŒº)ã€‚</strong></p>\n<pre><code>mysql&gt; select ua.user_id,ua.contact,p.province,c.city,r.area,ua.address from tb_user_address ua,tb_areas_city c,tb_areas_provinces p,tb_areas_region r where ua.province_id = p.provinceid and ua.city_id = c.cityid and ua.town_id = r.areaid;\n+-----------+-----------+-----------+-----------+-----------+--------------------+\n| user_id   | contact   | province  | city      | area      | address            |\n+-----------+-----------+-----------+-----------+-----------+--------------------+\n| deng      | å¶é—®      | åŒ—äº¬å¸‚    | å¸‚è¾–åŒº    | è¥¿åŸåŒº    | å’æ˜¥æ­¦é¦†æ€»éƒ¨       |\n| java00001 | æä½³çº¢    | åŒ—äº¬å¸‚    | å¸‚è¾–åŒº    | å´‡æ–‡åŒº    | ä¿®æ­£å¤§å¦           |\n| deng      | æå°é¾™    | åŒ—äº¬å¸‚    | å¸‚è¾–åŒº    | å´‡æ–‡åŒº    | æ°¸æ˜¥æ­¦é¦†           |\n| zhaoliu   | èµµä¸‰      | åŒ—äº¬å¸‚    | å¸‚è¾–åŒº    | å®£æ­¦åŒº    | è¥¿ç›´é—¨             |\n| java00001 | æå˜‰è¯š    | åŒ—äº¬å¸‚    | å¸‚è¾–åŒº    | æœé˜³åŒº    | é‡‘ç‡•é¾™åŠå…¬æ¥¼       |\n| java00001 | æä½³æ˜Ÿ    | åŒ—äº¬å¸‚    | å¸‚è¾–åŒº    | æœé˜³åŒº    | ä¸­è…¾å¤§å¦           |\n+-----------+-----------+-----------+-----------+-----------+--------------------+\n</code></pre>\n<p><em><strong>ps: æ­¤æŸ¥è¯¢è¯­å¥åªæ¶‰åŠäº†ä¸€ä¸ªåˆ†ç‰‡æ‰€ä»¥æŸ¥è¯¢æˆåŠŸ</strong></em></p>\n<p><strong>exam2: æŸ¥è¯¢æ¯ä¸€ç¬”è®¢å•åŠè®¢å•çš„æ”¶ä»¶åœ°å€ä¿¡æ¯ (åŒ…å«çœã€å¸‚ã€åŒº)ã€‚</strong></p>\n<pre><code>mysql&gt; SELECT order_id,payment,receiver,province,city,area FROM tb_order_master o,tb_areas_provinces p,tb_areas_city c,tb_areas_region r WHERE o.receiver_province = p.provinceid AND o.receiver_city = c.cityid AND o.receiver_region = r.areaid;\nERROR 1064 (HY000): invalid route in sql, multi tables found but datanode has no intersection  sql:SELECT order_id,payment,receiver,province,city,area FROM tb_order_master o,tb_areas_provinces p,tb_areas_city c,tb_areas_region r WHERE o.receiver_province = p.provinceid AND o.receiver_city = c.cityid AND o.receiver_region = r.areaid\n</code></pre>\n<p><em><strong>ps: æ­¤æŸ¥è¯¢è¯­å¥æ¶‰åŠå¤šä¸ªåˆ†ç‰‡æ‰€ä»¥æŸ¥è¯¢æŠ¥é”™ï¼Œä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜éœ€è¦è¿›è¡Œå…¨å±€è¡¨é…ç½®</strong></em></p>\n<p><strong>å…¨å±€è¡¨é…ç½®</strong></p>\n<p>å¯¹äºçœã€å¸‚ã€åŒº / å¿è¡¨ tb_areas_provincesï¼Œtb_areas_cityï¼Œtb_areas_regionï¼Œæ˜¯å±äºæ•°æ®å­—å…¸è¡¨ï¼Œåœ¨å¤šä¸ªä¸šåŠ¡æ¨¡å—ä¸­éƒ½å¯èƒ½ä¼šé‡åˆ°ï¼Œå¯ä»¥å°†å…¶è®¾ç½®ä¸ºå…¨å±€è¡¨ï¼Œåˆ©äºä¸šåŠ¡æ“ä½œã€‚</p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/EqJJ3Yv.png\" alt=\"22.png\" /></p>\n<p><strong>1. ä¿®æ”¹ MyCatâ€”schema.xml æ–‡ä»¶é…ç½®</strong></p>\n<p><strong>schema.xml æ–‡ä»¶é…ç½®å¦‚ä¸‹ï¼š</strong></p>\n<pre><code>[root@mycat ~]# cat /usr/local/mycat/conf/schema.xml \n&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;!DOCTYPE mycat:schema SYSTEM &quot;schema.dtd&quot;&gt;\n&lt;mycat:schema xmlns:mycat=&quot;http://io.mycat/&quot;&gt;\n\t&lt;schema name=&quot;SHOPPING&quot; checkSQLschema=&quot;true&quot; sqlMaxLimit=&quot;100&quot;&gt;\n\t\t&lt;table name=&quot;tb_goods_base&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_goods_brand&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_goods_cat&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_goods_desc&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_goods_item&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;goods_id&quot; /&gt;\n\t\t\n\t\t&lt;table name=&quot;tb_order_item&quot; dataNode=&quot;dn2&quot; primaryKey=&quot;id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_order_master&quot; dataNode=&quot;dn2&quot; primaryKey=&quot;order_id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_order_pay_log&quot; dataNode=&quot;dn2&quot; primaryKey=&quot;out_trade_no&quot; /&gt;\n\t\t\n\t\t&lt;table name=&quot;tb_user&quot; dataNode=&quot;dn3&quot; primaryKey=&quot;id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_user_address&quot; dataNode=&quot;dn3&quot; primaryKey=&quot;id&quot; /&gt;\n\n\t\t&lt;table name=&quot;tb_areas_provinces&quot; dataNode=&quot;dn1,dn2,dn3&quot; primaryKey=&quot;id&quot; type=&quot;global&quot;/&gt;\n\t\t&lt;table name=&quot;tb_areas_city&quot; dataNode=&quot;dn1,dn2,dn3&quot; primaryKey=&quot;id&quot; type=&quot;global&quot;/&gt;\n\t\t&lt;table name=&quot;tb_areas_region&quot; dataNode=&quot;dn1,dn2,dn3&quot; primaryKey=&quot;id&quot; type=&quot;global&quot; /&gt;\n\t&lt;/schema&gt;\n\t\n\t&lt;dataNode name=&quot;dn1&quot; dataHost=&quot;dhost1&quot; database=&quot;shopping&quot; /&gt;\n\t&lt;dataNode name=&quot;dn2&quot; dataHost=&quot;dhost2&quot; database=&quot;shopping&quot; /&gt;\n\t&lt;dataNode name=&quot;dn3&quot; dataHost=&quot;dhost3&quot; database=&quot;shopping&quot; /&gt;\n\t\n\t&lt;dataHost name=&quot;dhost1&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot;\n\t\t\t  writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;jdbc&quot; switchType=&quot;1&quot;  slaveThreshold=&quot;100&quot;&gt;\n\t\t&lt;heartbeat&gt;select user()&lt;/heartbeat&gt;\n\t\t\n\t\t&lt;writeHost host=&quot;master&quot; url=&quot;jdbc:mysql://192.168.40.210:3306?useSSL=false&amp;amp;serverTimezone=Asia/Shanghai&amp;amp;characterEncoding=utf8&quot; user=&quot;root&quot; password=&quot;Superman*2023&quot; /&gt;\n\t&lt;/dataHost&gt;\n\t\n\t&lt;dataHost name=&quot;dhost2&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot;\n\t\t\t  writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;jdbc&quot; switchType=&quot;1&quot;  slaveThreshold=&quot;100&quot;&gt;\n\t\t&lt;heartbeat&gt;select user()&lt;/heartbeat&gt;\n\t\t\n\t\t&lt;writeHost host=&quot;master&quot; url=&quot;jdbc:mysql://192.168.40.211:3306?useSSL=false&amp;amp;serverTimezone=Asia/Shanghai&amp;amp;characterEncoding=utf8&quot; user=&quot;root&quot; password=&quot;Superman*2023&quot; /&gt;\n\t&lt;/dataHost&gt;\n\t\n\t&lt;dataHost name=&quot;dhost3&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot;\n\t\t\t  writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;jdbc&quot; switchType=&quot;1&quot;  slaveThreshold=&quot;100&quot;&gt;\n\t\t&lt;heartbeat&gt;select user()&lt;/heartbeat&gt;\n\t\t\n\t\t&lt;writeHost host=&quot;master&quot; url=&quot;jdbc:mysql://192.168.40.212:3306?useSSL=false&amp;amp;serverTimezone=Asia/Shanghai&amp;amp;characterEncoding=utf8&quot; user=&quot;root&quot; password=&quot;Superman*2023&quot; /&gt;\n\t&lt;/dataHost&gt;\n&lt;/mycat:schema&gt;\n</code></pre>\n<p><strong>2. å…¨å±€è¡¨æµ‹è¯•</strong></p>\n<pre><code>#1.åˆ é™¤3ä¸ªèŠ‚ç‚¹ä¸ŠåŸæœ‰è¡¨\n\n#2.é‡å¯mycat\n[root@mycat ~]# /usr/local/mycat/bin/mycat restart\nStopping Mycat-server...\nStopped Mycat-server.\nStarting Mycat-server...\n[root@mycat ~]# tail -f  /usr/local/mycat/logs/wrapper.log \n...\nINFO   | jvm 1    | 2023/12/03 15:29:02 | MyCAT Server startup successfully. see logs in logs/mycat.log\ncreate database shopping default charset utf8mb4;\n\n#3.æ‰§è¡Œshopping-table.sqlæ–‡ä»¶\n[root@db3 ~]# mysql -h 192.168.40.213 -P 8066 -uroot -p'Superman*2023'\nmysql&gt; source /root/shopping-table.sql\n\n#4.æ‰§è¡Œshopping-insert.sqlæ–‡ä»¶\nmysql&gt; source /root/shopping-insert.sql\n\n#5 exam1:æŸ¥è¯¢ç”¨æˆ·çš„æ”¶ä»¶äººåŠæ”¶ä»¶äººåœ°å€ä¿¡æ¯(åŒ…å«çœã€å¸‚ã€åŒº)ã€‚\nmysql&gt; select ua.user_id,ua.contact,p.province,c.city,r.area,ua.address from tb_user_address ua,tb_areas_city c,tb_areas_provinces p,tb_areas_region r where ua.province_id = p.provinceid and ua.city_id = c.cityid and ua.town_id = r.areaid;\n\n#6 exam2:æŸ¥è¯¢æ¯ä¸€ç¬”è®¢å•åŠè®¢å•çš„æ”¶ä»¶åœ°å€ä¿¡æ¯(åŒ…å«çœã€å¸‚ã€åŒº)\nmysql&gt; SELECT order_id,payment,receiver,province,city,area FROM tb_order_master o,tb_areas_provinces p,tb_areas_city c,tb_areas_region r WHERE o.receiver_province = p.provinceid AND o.receiver_city = c.cityid AND o.receiver_region = r.areaid;\n</code></pre>\n<h6 id=\"342-åˆ†åº“åˆ†è¡¨-mycatåˆ†ç‰‡-æ°´å¹³åˆ†è¡¨\"><a class=\"anchor\" href=\"#342-åˆ†åº“åˆ†è¡¨-mycatåˆ†ç‰‡-æ°´å¹³åˆ†è¡¨\">#</a> 3.4.2 åˆ†åº“åˆ†è¡¨ - MyCat åˆ†ç‰‡ - æ°´å¹³åˆ†è¡¨</h6>\n<ul>\n<li><strong>æ°´å¹³åˆ†è¡¨</strong></li>\n</ul>\n<p><strong>åœºæ™¯</strong>ï¼šåœ¨ä¸šåŠ¡ç³»ç»Ÿä¸­ï¼Œæœ‰ä¸€å¼ è¡¨ï¼ˆæ—¥å¿—è¡¨ï¼‰ï¼Œä¸šåŠ¡ç³»ç»Ÿæ¯å¤©éƒ½ä¼šäº§ç”Ÿå¤§é‡çš„æ—¥å¿—æ•°æ®ï¼Œå•å°æœåŠ¡å™¨çš„æ•°æ®å­˜å‚¨åŠå¤„ç†èƒ½åŠ›æ˜¯æœ‰é™çš„ï¼Œå¯ä»¥å¯¹æ•°æ®åº“è¡¨è¿›è¡Œæ‹†åˆ†ã€‚</p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/0kMP4Ru.png\" alt=\"23.png\" /></p>\n<p><strong>å‡†å¤‡ç¯å¢ƒï¼š</strong></p>\n<p>â‘ å¦‚å›¾æ‰€ç¤ºå‡†å¤‡ä¸‰å° Linux æœåŠ¡å™¨ï¼ˆip ä¸ºï¼š192.168.40.210ã€192.168.40.211ã€192.168.40.212ï¼‰å¯ä»¥æ ¹æ®è‡ªå·±çš„å®é™…æƒ…å†µè¿›è¡Œå‡†å¤‡ã€‚<br />\nâ‘¡ä¸‰å°æœåŠ¡å™¨ä¸Šéƒ½å®‰è£… MySQLï¼Œåœ¨ 192.168.40.213 æœåŠ¡å™¨ä¸Šå®‰è£… MyCatã€‚<br />\nâ‘¢ä¸‰å°æœåŠ¡å™¨å…³é—­é˜²ç«å¢™æˆ–è€…å¼€æ”¾å¯¹åº”çš„ç«¯å£ã€‚<br />\nâ‘£åˆ†åˆ«åœ¨ä¸‰å° MySQL ä¸­åˆ›å»ºæ•°æ®åº“ itcastã€‚<br />\n<img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/zTm8XwU.png\" alt=\"24.png\" /></p>\n<p><strong>1. ä¸‰å° MySQL ä¸­åˆ›å»ºæ•°æ®åº“ itcast</strong></p>\n<pre><code>mysql&gt; create database itcast default charset utf8mb4;\nmysql&gt; create database itcast default charset utf8mb4;\nmysql&gt; create database itcast default charset utf8mb4;\n</code></pre>\n<p><strong>2.MyCatâ€”server.xml æ–‡ä»¶é…ç½®</strong></p>\n<p><strong>server.xml æ–‡ä»¶é…ç½®å¦‚ä¸‹ï¼š</strong></p>\n<pre><code>[root@mycat ~]# cat /usr/local/mycat/conf/schema.xml \n&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;!DOCTYPE mycat:schema SYSTEM &quot;schema.dtd&quot;&gt;\n&lt;mycat:schema xmlns:mycat=&quot;http://io.mycat/&quot;&gt;\n\t&lt;schema name=&quot;SHOPPING&quot; checkSQLschema=&quot;true&quot; sqlMaxLimit=&quot;100&quot;&gt;\n\t\t&lt;table name=&quot;tb_goods_base&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_goods_brand&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_goods_cat&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_goods_desc&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_goods_item&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;goods_id&quot; /&gt;\n\t\t\n\t\t&lt;table name=&quot;tb_order_item&quot; dataNode=&quot;dn2&quot; primaryKey=&quot;id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_order_master&quot; dataNode=&quot;dn2&quot; primaryKey=&quot;order_id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_order_pay_log&quot; dataNode=&quot;dn2&quot; primaryKey=&quot;out_trade_no&quot; /&gt;\n\t\t\n\t\t&lt;table name=&quot;tb_user&quot; dataNode=&quot;dn3&quot; primaryKey=&quot;id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_user_address&quot; dataNode=&quot;dn3&quot; primaryKey=&quot;id&quot; /&gt;\n\n                &lt;table name=&quot;tb_areas_provinces&quot; dataNode=&quot;dn1,dn2,dn3&quot; primaryKey=&quot;id&quot; type=&quot;global&quot; /&gt;\n\t\t&lt;table name=&quot;tb_areas_city&quot; dataNode=&quot;dn1,dn2,dn3&quot; primaryKey=&quot;id&quot; type=&quot;global&quot; /&gt;\n\t\t&lt;table name=&quot;tb_areas_region&quot; dataNode=&quot;dn1,dn2,dn3&quot; primaryKey=&quot;id&quot; type=&quot;global&quot; /&gt;\n\t&lt;/schema&gt;\n\n        &lt;schema name=&quot;ITCAST&quot; checkSQLschema=&quot;true&quot; sqlMaxLimit=&quot;100&quot;&gt;\n        \t&lt;table name=&quot;tb_log&quot; dataNode=&quot;dn4,dn5,dn6&quot; primaryKey=&quot;id&quot; rule=&quot;mod-long&quot; /&gt;\n        &lt;/schema&gt;\n\t\n\t&lt;dataNode name=&quot;dn1&quot; dataHost=&quot;dhost1&quot; database=&quot;shopping&quot; /&gt;\n\t&lt;dataNode name=&quot;dn2&quot; dataHost=&quot;dhost2&quot; database=&quot;shopping&quot; /&gt;\n\t&lt;dataNode name=&quot;dn3&quot; dataHost=&quot;dhost3&quot; database=&quot;shopping&quot; /&gt;\n\n\t&lt;dataNode name=&quot;dn4&quot; dataHost=&quot;dhost1&quot; database=&quot;itcast&quot; /&gt;\n\t&lt;dataNode name=&quot;dn5&quot; dataHost=&quot;dhost2&quot; database=&quot;itcast&quot; /&gt;\n\t&lt;dataNode name=&quot;dn6&quot; dataHost=&quot;dhost3&quot; database=&quot;itcast&quot; /&gt;\n\t\n\t&lt;dataHost name=&quot;dhost1&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot;\n\t\t\t  writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;jdbc&quot; switchType=&quot;1&quot;  slaveThreshold=&quot;100&quot;&gt;\n\t\t&lt;heartbeat&gt;select user()&lt;/heartbeat&gt;\n\t\t\n\t\t&lt;writeHost host=&quot;master&quot; url=&quot;jdbc:mysql://192.168.40.210:3306?useSSL=false&amp;amp;serverTimezone=Asia/Shanghai&amp;amp;characterEncoding=utf8&quot; user=&quot;root&quot; password=&quot;Superman*2023&quot; /&gt;\n\t&lt;/dataHost&gt;\n\t\n\t&lt;dataHost name=&quot;dhost2&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot;\n\t\t\t  writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;jdbc&quot; switchType=&quot;1&quot;  slaveThreshold=&quot;100&quot;&gt;\n\t\t&lt;heartbeat&gt;select user()&lt;/heartbeat&gt;\n\t\t\n\t\t&lt;writeHost host=&quot;master&quot; url=&quot;jdbc:mysql://192.168.40.211:3306?useSSL=false&amp;amp;serverTimezone=Asia/Shanghai&amp;amp;characterEncoding=utf8&quot; user=&quot;root&quot; password=&quot;Superman*2023&quot; /&gt;\n\t&lt;/dataHost&gt;\n\t\n\t&lt;dataHost name=&quot;dhost3&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot;\n\t\t\t  writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;jdbc&quot; switchType=&quot;1&quot;  slaveThreshold=&quot;100&quot;&gt;\n\t\t&lt;heartbeat&gt;select user()&lt;/heartbeat&gt;\n\t\t\n\t\t&lt;writeHost host=&quot;master&quot; url=&quot;jdbc:mysql://192.168.40.212:3306?useSSL=false&amp;amp;serverTimezone=Asia/Shanghai&amp;amp;characterEncoding=utf8&quot; user=&quot;root&quot; password=&quot;Superman*2023&quot; /&gt;\n\t&lt;/dataHost&gt;\n&lt;/mycat:schema&gt;\n</code></pre>\n<p><strong>3.MyCatâ€”server.xml æ–‡ä»¶é…ç½®</strong></p>\n<p><strong>server.xml æ–‡ä»¶é…ç½®å¦‚ä¸‹ï¼š</strong></p>\n<pre><code>[root@mycat ~]# cat /usr/local/mycat/conf/server.xml \n...\n\t&lt;user name=&quot;root&quot;&gt;\n\t\t&lt;property name=&quot;password&quot;&gt;Superman*2023&lt;/property&gt;\n\t\t&lt;property name=&quot;schemas&quot;&gt;SHOPPING,ITCAST&lt;/property&gt;\n\t\t\n\t\t&lt;!-- è¡¨çº§ DML æƒé™è®¾ç½® --&gt;\n\t\t&lt;!-- \t\t\n\t\t&lt;privileges check=&quot;false&quot;&gt;\n\t\t\t&lt;schema name=&quot;TESTDB&quot; dml=&quot;0110&quot; &gt;\n\t\t\t\t&lt;table name=&quot;tb01&quot; dml=&quot;0000&quot;&gt;&lt;/table&gt;\n\t\t\t\t&lt;table name=&quot;tb02&quot; dml=&quot;1111&quot;&gt;&lt;/table&gt;\n\t\t\t&lt;/schema&gt;\n\t\t&lt;/privileges&gt;\t\t\n\t\t --&gt;\n\t&lt;/user&gt;\n\n\t&lt;user name=&quot;user&quot;&gt;\n\t\t&lt;property name=&quot;password&quot;&gt;Superman*2023&lt;/property&gt;\n\t\t&lt;property name=&quot;schemas&quot;&gt;SHOPPING,ITCAST&lt;/property&gt;\n\t\t&lt;property name=&quot;readOnly&quot;&gt;true&lt;/property&gt;\n\t&lt;/user&gt;\n\n&lt;/mycat:server&gt;\n</code></pre>\n<p><strong>4.MyCat å¯åŠ¨</strong></p>\n<pre><code>#1.é‡å¯mycat\n[root@mycat ~]# /usr/local/mycat/bin/mycat restart\nStopping Mycat-server...\nStopped Mycat-server.\nStarting Mycat-server...\n[root@mycat ~]# tail -f  /usr/local/mycat/logs/wrapper.log \n...\nINFO   | jvm 1    | 2023/12/03 15:29:02 | MyCAT Server startup successfully. see logs in logs/mycat.log\ncreate database shopping default charset utf8mb4;\n\n#2.ç™»å…¥mycat\n[root@db3 ~]# mysql -h 192.168.40.213 -P 8066 -uroot -p'Superman*2023'\nmysql&gt; show databases;\n+----------+\n| DATABASE |\n+----------+\n| ITCAST   |\n| SHOPPING |\n+----------+\n2 rows in set (0.00 sec)\n\nmysql&gt; use ITCAST;\nmysql&gt; show tables;\n+------------------+\n| Tables in ITCAST |\n+------------------+\n| tb_log           |\n+------------------+\n\n#3.åˆ›å»ºè¡¨ç»“æ„åŠæ•°æ®å¯¼å…¥\nmysql&gt; CREATE TABLE tb_log (\n    -&gt;   id bigint(20) NOT NULL COMMENT 'ID',\n    -&gt;   model_name varchar(200) DEFAULT NULL COMMENT 'æ¨¡å—å',\n    -&gt;   model_value varchar(200) DEFAULT NULL COMMENT 'æ¨¡å—å€¼',\n    -&gt;   return_value varchar(200) DEFAULT NULL COMMENT 'è¿”å›å€¼',\n    -&gt;   return_class varchar(200) DEFAULT NULL COMMENT 'è¿”å›å€¼ç±»å‹',\n    -&gt;   operate_user varchar(20) DEFAULT NULL COMMENT 'æ“ä½œç”¨æˆ·',\n    -&gt;   operate_time varchar(20) DEFAULT NULL COMMENT 'æ“ä½œæ—¶é—´',\n    -&gt;   param_and_value varchar(500) DEFAULT NULL COMMENT 'è¯·æ±‚å‚æ•°ååŠå‚æ•°å€¼',\n    -&gt;   operate_class varchar(200) DEFAULT NULL COMMENT 'æ“ä½œç±»',\n    -&gt;   operate_method varchar(200) DEFAULT NULL COMMENT 'æ“ä½œæ–¹æ³•',\n    -&gt;   cost_time bigint(20) DEFAULT NULL COMMENT 'æ‰§è¡Œæ–¹æ³•è€—æ—¶, å•ä½ ms',\n    -&gt;   source int(1) DEFAULT NULL COMMENT 'æ¥æº : 1 PC , 2 Android , 3 IOS',\n    -&gt;   PRIMARY KEY (id)\n    -&gt; ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\nQuery OK, 0 rows affected (0.09 sec)\n OK!\næŸ¥çœ‹ä¸‰ä¸ªæ•°æ®åº“å¯ä»¥å‘ç°è¡¨å’Œè¡¨ç»“æ„éƒ½æœ‰äº†\n\n#4.æ·»åŠ æ•°æ®\nINSERT INTO tb_log (id, model_name, model_value, return_value, return_class, operate_user, operate_time, param_and_value, operate_class, operate_method, cost_timeï¼Œsource) VALUES('1','user','insert','success','java.lang.String','10001','2022-01-06 18:12:28','&#123;\\&quot;age\\&quot;:\\&quot;20\\&quot;,\\&quot;name\\&quot;:\\&quot;Tom\\&quot;,\\&quot;gender\\&quot;:\\&quot;1\\&quot;&#125;','cn.itcast.controller.UserController','insert','10',1);\nINSERT INTO tb_log (id, model_name, model_value, return_value, return_class, operate_user, operate_time, param_and_value, operate_class, operate_method, cost_timeï¼Œsource) VALUES('2','user','insert','success','java.lang.String','10001','2022-01-06 18:12:27','&#123;\\&quot;age\\&quot;:\\&quot;20\\&quot;,\\&quot;name\\&quot;:\\&quot;Tom\\&quot;,\\&quot;gender\\&quot;:\\&quot;1\\&quot;&#125;','cn.itcast.controller.UserController','insert','23',1);\nINSERT INTO tb_log (id, model_name, model_value, return_value, return_class, operate_user, operate_time, param_and_value, operate_class, operate_method, cost_timeï¼Œsource) VALUES('3','user','update','success','java.lang.String','10001','2022-01-06 18:16:45','&#123;\\&quot;age\\&quot;:\\&quot;20\\&quot;,\\&quot;name\\&quot;:\\&quot;Tom\\&quot;,\\&quot;gender\\&quot;:\\&quot;1\\&quot;&#125;','cn.itcast.controller.UserController','update','34',1);\nINSERT INTO tb_log (id, model_name, model_value, return_value, return_class, operate_user, operate_time, param_and_value, operate_class, operate_method, cost_timeï¼Œsource) VALUES('4','user','update','success','java.lang.String','10001','2022-01-06 18:16:45','&#123;\\&quot;age\\&quot;:\\&quot;20\\&quot;,\\&quot;name\\&quot;:\\&quot;Tom\\&quot;,\\&quot;gender\\&quot;:\\&quot;1\\&quot;&#125;','cn.itcast.controller.UserController','update','13',2);\nINSERT INTO tb_log (id, model_name, model_value, return_value, return_class, operate_user, operate_time, param_and_value, operate_class, operate_method, cost_timeï¼Œsource) VALUES('5','user','insert','success','java.lang.String','10001','2022-01-06 18:30:31','&#123;\\&quot;age\\&quot;:\\&quot;200\\&quot;,\\&quot;name\\&quot;:\\&quot;TomCat\\&quot;,\\&quot;gender\\&quot;:\\&quot;0\\&quot;&#125;','cn.itcast.controller.UserController','insert','29',3);\nINSERT INTO tb_log (id, model_name, model_value, return_value, return_class, operate_user, operate_time, param_and_value, operate_class, operate_method, cost_timeï¼Œsource) VALUES('6','user','find','success','java.lang.String','10001','2022-01-06 18:30:31','&#123;\\&quot;age\\&quot;:\\&quot;200\\&quot;,\\&quot;name\\&quot;:\\&quot;TomCat\\&quot;,\\&quot;gender\\&quot;:\\&quot;0\\&quot;&#125;','cn.itcast.controller.UserController','find','29',2);\n\næŸ¥çœ‹ä¸‰ä¸ªæ•°æ®åº“å†…çš„tb_logè¡¨å‘ç°æœ‰æ•°æ®äº†ï¼Œæ•°æ®çš„åˆ†å¸ƒè§„åˆ™æ˜¯ idæ¨¡ä»¥3çš„ç»“æœä¸º0çš„æ•°æ®åˆ†å¸ƒåœ¨ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ï¼Œidæ¨¡ä»¥3çš„ç»“æœä¸º1çš„æ•°æ®åˆ†å¸ƒåœ¨ç¬¬äºŒä¸ªèŠ‚ç‚¹ï¼Œidæ¨¡ä»¥3çš„ç»“æœä¸º2çš„æ•°æ®åˆ†å¸ƒåœ¨ç¬¬ä¸‰ä¸ªèŠ‚ç‚¹\n</code></pre>\n<h5 id=\"33-åˆ†åº“åˆ†è¡¨-åˆ†ç‰‡è§„åˆ™\"><a class=\"anchor\" href=\"#33-åˆ†åº“åˆ†è¡¨-åˆ†ç‰‡è§„åˆ™\">#</a> 3.3 åˆ†åº“åˆ†è¡¨ - åˆ†ç‰‡è§„åˆ™</h5>\n<h6 id=\"331-åˆ†åº“åˆ†è¡¨-åˆ†ç‰‡è§„åˆ™-èŒƒå›´åˆ†ç‰‡\"><a class=\"anchor\" href=\"#331-åˆ†åº“åˆ†è¡¨-åˆ†ç‰‡è§„åˆ™-èŒƒå›´åˆ†ç‰‡\">#</a> 3.3.1 åˆ†åº“åˆ†è¡¨ - åˆ†ç‰‡è§„åˆ™ - èŒƒå›´åˆ†ç‰‡</h6>\n<p><strong>èŒƒå›´åˆ†ç‰‡</strong>ï¼šæ ¹æ®æŒ‡å®šçš„å­—æ®µåŠå…¶é…ç½®çš„èŒƒå›´ä¸æ•°æ®èŠ‚ç‚¹çš„å¯¹åº”æƒ…å†µï¼Œæ¥å†³å®šè¯¥æ•°æ®å±äºå“ªä¸€ä¸ªåˆ†ç‰‡ã€‚</p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/sdd8bvs.png\" alt=\"25.png\" /></p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/R3ecZ4k.png\" alt=\"26.png\" /></p>\n<pre><code>[root@mycat ~]# cat /usr/local/mycat/conf/autopartition-long.txt\n# range start-end ,data node index\n# K=1000,M=10000.\n0-500M=0\n500M-1000M=1\n1000M-1500M=2\n</code></pre>\n<h6 id=\"332-åˆ†åº“åˆ†è¡¨-åˆ†ç‰‡è§„åˆ™-å–æ¨¡åˆ†ç‰‡\"><a class=\"anchor\" href=\"#332-åˆ†åº“åˆ†è¡¨-åˆ†ç‰‡è§„åˆ™-å–æ¨¡åˆ†ç‰‡\">#</a> 3.3.2 åˆ†åº“åˆ†è¡¨ - åˆ†ç‰‡è§„åˆ™ - å–æ¨¡åˆ†ç‰‡</h6>\n<p><strong>å–æ¨¡åˆ†ç‰‡</strong>ï¼šæ ¹æ®æŒ‡å®šçš„å­—æ®µå€¼ä¸èŠ‚ç‚¹æ•°é‡è¿›è¡Œæ±‚æ¨¡è¿ç®—ï¼Œæ ¹æ®è¿ç®—ç»“æœï¼Œæ¥å†³å®šè¯¥æ•°æ®å±äºå“ªä¸€ä¸ªåˆ†ç‰‡ã€‚</p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/Xvn6sHi.png\" alt=\"1.png\" /></p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/aaey4H2.png\" alt=\"2.png\" /></p>\n<h6 id=\"333-åˆ†åº“åˆ†è¡¨-åˆ†ç‰‡è§„åˆ™-ä¸€è‡´æ€§hashç®—æ³•\"><a class=\"anchor\" href=\"#333-åˆ†åº“åˆ†è¡¨-åˆ†ç‰‡è§„åˆ™-ä¸€è‡´æ€§hashç®—æ³•\">#</a> 3.3.3 åˆ†åº“åˆ†è¡¨ - åˆ†ç‰‡è§„åˆ™ - ä¸€è‡´æ€§ hash ç®—æ³•</h6>\n<p><strong>ä¸€è‡´æ€§ hash ç®—æ³•</strong>ï¼šæ‰€è°“ä¸€è‡´æ€§å“ˆå¸Œï¼Œç›¸åŒçš„å“ˆå¸Œå› å­è®¡ç®—å€¼æ€»æ˜¯è¢«åˆ’åˆ†åˆ°ç›¸åŒçš„åˆ†åŒºè¡¨ä¸­ï¼Œä¸ä¼šå› ä¸ºåˆ†åŒºèŠ‚ç‚¹çš„å¢åŠ è€Œæ”¹å˜åŸæ¥æ•°æ®çš„åˆ†åŒºä½ç½®ã€‚</p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/6ANYtsD.png\" alt=\"3.png\" /></p>\n<p><img loading=\"lazy\" data-src=\"https://wp-cdn.4ce.cn/v2/8i8c5Le.png\" alt=\"4.png\" /></p>\n<p><strong>ä¸€è‡´æ€§ hash æµ‹è¯•</strong></p>\n<p>schema.xml é…ç½®</p>\n<pre><code>[root@mycat ~]# cat /usr/local/mycat/conf/schema.xml \n&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;!DOCTYPE mycat:schema SYSTEM &quot;schema.dtd&quot;&gt;\n&lt;mycat:schema xmlns:mycat=&quot;http://io.mycat/&quot;&gt;\n\t&lt;schema name=&quot;SHOPPING&quot; checkSQLschema=&quot;true&quot; sqlMaxLimit=&quot;100&quot;&gt;\n\t\t&lt;table name=&quot;tb_goods_base&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_goods_brand&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_goods_cat&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_goods_desc&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_goods_item&quot; dataNode=&quot;dn1&quot; primaryKey=&quot;goods_id&quot; /&gt;\n\t\t\n\t\t&lt;table name=&quot;tb_order_item&quot; dataNode=&quot;dn2&quot; primaryKey=&quot;id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_order_master&quot; dataNode=&quot;dn2&quot; primaryKey=&quot;order_id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_order_pay_log&quot; dataNode=&quot;dn2&quot; primaryKey=&quot;out_trade_no&quot; /&gt;\n\t\t\n\t\t&lt;table name=&quot;tb_user&quot; dataNode=&quot;dn3&quot; primaryKey=&quot;id&quot; /&gt;\n\t\t&lt;table name=&quot;tb_user_address&quot; dataNode=&quot;dn3&quot; primaryKey=&quot;id&quot; /&gt;\n\n                &lt;table name=&quot;tb_areas_provinces&quot; dataNode=&quot;dn1,dn2,dn3&quot; primaryKey=&quot;id&quot; type=&quot;global&quot; /&gt;\n\t\t&lt;table name=&quot;tb_areas_city&quot; dataNode=&quot;dn1,dn2,dn3&quot; primaryKey=&quot;id&quot; type=&quot;global&quot; /&gt;\n\t\t&lt;table name=&quot;tb_areas_region&quot; dataNode=&quot;dn1,dn2,dn3&quot; primaryKey=&quot;id&quot; type=&quot;global&quot; /&gt;\n\t&lt;/schema&gt;\n\n        &lt;schema name=&quot;ITCAST&quot; checkSQLschema=&quot;true&quot; sqlMaxLimit=&quot;100&quot;&gt;\n        \t&lt;table name=&quot;tb_log&quot; dataNode=&quot;dn4,dn5,dn6&quot; primaryKey=&quot;id&quot; rule=&quot;mod-long&quot; /&gt;\n        \t&lt;table name=&quot;tb_order&quot; dataNode=&quot;dn4,dn5,dn6&quot; primaryKey=&quot;id&quot; rule=&quot;sharding-by-murmur&quot; /&gt;\n        &lt;/schema&gt;\n\t\n\t&lt;dataNode name=&quot;dn1&quot; dataHost=&quot;dhost1&quot; database=&quot;shopping&quot; /&gt;\n\t&lt;dataNode name=&quot;dn2&quot; dataHost=&quot;dhost2&quot; database=&quot;shopping&quot; /&gt;\n\t&lt;dataNode name=&quot;dn3&quot; dataHost=&quot;dhost3&quot; database=&quot;shopping&quot; /&gt;\n\n\t&lt;dataNode name=&quot;dn4&quot; dataHost=&quot;dhost1&quot; database=&quot;itcast&quot; /&gt;\n\t&lt;dataNode name=&quot;dn5&quot; dataHost=&quot;dhost2&quot; database=&quot;itcast&quot; /&gt;\n\t&lt;dataNode name=&quot;dn6&quot; dataHost=&quot;dhost3&quot; database=&quot;itcast&quot; /&gt;\n\t\n\t&lt;dataHost name=&quot;dhost1&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot;\n\t\t\t  writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;jdbc&quot; switchType=&quot;1&quot;  slaveThreshold=&quot;100&quot;&gt;\n\t\t&lt;heartbeat&gt;select user()&lt;/heartbeat&gt;\n\t\t\n\t\t&lt;writeHost host=&quot;master&quot; url=&quot;jdbc:mysql://192.168.40.210:3306?useSSL=false&amp;amp;serverTimezone=Asia/Shanghai&amp;amp;characterEncoding=utf8&quot; user=&quot;root&quot; password=&quot;Superman*2023&quot; /&gt;\n\t&lt;/dataHost&gt;\n\t\n\t&lt;dataHost name=&quot;dhost2&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot;\n\t\t\t  writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;jdbc&quot; switchType=&quot;1&quot;  slaveThreshold=&quot;100&quot;&gt;\n\t\t&lt;heartbeat&gt;select user()&lt;/heartbeat&gt;\n\t\t\n\t\t&lt;writeHost host=&quot;master&quot; url=&quot;jdbc:mysql://192.168.40.211:3306?useSSL=false&amp;amp;serverTimezone=Asia/Shanghai&amp;amp;characterEncoding=utf8&quot; user=&quot;root&quot; password=&quot;Superman*2023&quot; /&gt;\n\t&lt;/dataHost&gt;\n\t\n\t&lt;dataHost name=&quot;dhost3&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot;\n\t\t\t  writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;jdbc&quot; switchType=&quot;1&quot;  slaveThreshold=&quot;100&quot;&gt;\n\t\t&lt;heartbeat&gt;select user()&lt;/heartbeat&gt;\n\t\t\n\t\t&lt;writeHost host=&quot;master&quot; url=&quot;jdbc:mysql://192.168.40.212:3306?useSSL=false&amp;amp;serverTimezone=Asia/Shanghai&amp;amp;characterEncoding=utf8&quot; user=&quot;root&quot; password=&quot;Superman*2023&quot; /&gt;\n\t&lt;/dataHost&gt;\n&lt;/mycat:schema&gt;\n</code></pre>\n<p><strong>rule.xml é…ç½®</strong></p>\n<pre><code>[root@mycat ~]# cat /usr/local/mycat/conf/rule.xml \n...\n\t&lt;function name=&quot;murmur&quot;\n\t\tclass=&quot;io.mycat.route.function.PartitionByMurmurHash&quot;&gt;\n\t\t&lt;property name=&quot;seed&quot;&gt;0&lt;/property&gt;&lt;!-- é»˜è®¤æ˜¯0 --&gt;\n\t\t&lt;property name=&quot;count&quot;&gt;3&lt;/property&gt;&lt;!-- è¦åˆ†ç‰‡çš„æ•°æ®åº“èŠ‚ç‚¹æ•°é‡ï¼Œå¿…é¡»æŒ‡å®šï¼Œå¦åˆ™æ²¡æ³•åˆ†ç‰‡ --&gt;\n\t\t&lt;property name=&quot;virtualBucketTimes&quot;&gt;160&lt;/property&gt;&lt;!-- ä¸€ä¸ªå®é™…çš„æ•°æ®åº“èŠ‚ç‚¹è¢«æ˜ å°„ä¸ºè¿™ä¹ˆå¤šè™šæ‹ŸèŠ‚ç‚¹ï¼Œé»˜è®¤æ˜¯160å€ï¼Œä¹Ÿå°±æ˜¯è™šæ‹ŸèŠ‚ç‚¹æ•°æ˜¯ç‰©ç†èŠ‚ç‚¹æ•°çš„160å€ --&gt;\n\t\t&lt;!-- &lt;property name=&quot;weightMapFile&quot;&gt;weightMapFile&lt;/property&gt; èŠ‚ç‚¹çš„æƒé‡ï¼Œæ²¡æœ‰æŒ‡å®šæƒé‡çš„èŠ‚ç‚¹é»˜è®¤æ˜¯1ã€‚ä»¥propertiesæ–‡ä»¶çš„æ ¼å¼å¡«å†™ï¼Œä»¥ä»0å¼€å§‹åˆ°count-1çš„æ•´æ•°å€¼ä¹Ÿå°±æ˜¯èŠ‚ç‚¹ç´¢å¼•ä¸ºkeyï¼Œä»¥èŠ‚ç‚¹æƒé‡å€¼ä¸ºå€¼ã€‚æ‰€æœ‰æƒé‡å€¼å¿…é¡»æ˜¯æ­£æ•´æ•°ï¼Œå¦åˆ™ä»¥1ä»£æ›¿ --&gt;\n\t\t&lt;!-- &lt;property name=&quot;bucketMapPath&quot;&gt;/etc/mycat/bucketMapPath&lt;/property&gt; \n\t\t\tç”¨äºæµ‹è¯•æ—¶è§‚å¯Ÿå„ç‰©ç†èŠ‚ç‚¹ä¸è™šæ‹ŸèŠ‚ç‚¹çš„åˆ†å¸ƒæƒ…å†µï¼Œå¦‚æœæŒ‡å®šäº†è¿™ä¸ªå±æ€§ï¼Œä¼šæŠŠè™šæ‹ŸèŠ‚ç‚¹çš„murmur hashå€¼ä¸ç‰©ç†èŠ‚ç‚¹çš„æ˜ å°„æŒ‰è¡Œè¾“å‡ºåˆ°è¿™ä¸ªæ–‡ä»¶ï¼Œæ²¡æœ‰é»˜è®¤å€¼ï¼Œå¦‚æœä¸æŒ‡å®šï¼Œå°±ä¸ä¼šè¾“å‡ºä»»ä½•ä¸œè¥¿ --&gt;\n\t&lt;/function&gt;\n...\n</code></pre>\n<p><strong>é‡å¯ mycat å¹¶æ’å…¥æ•°æ®æµ‹è¯•</strong></p>\n<pre><code>[root@mycat ~]# /usr/local/mycat/bin/mycat restart\nStopping Mycat-server...\nStopped Mycat-server.\nStarting Mycat-server...\n\n[root@mycat ~]# tail -f  /usr/local/mycat/logs/wrapper.log\n...\nINFO   | jvm 1    | 2023/12/03 22:17:47 | MyCAT Server startup successfully. see logs in logs/mycat.log\n\n[root@db3 ~]# mysql -h 192.168.40.213 -P 8066 -uroot -p'Superman*2023'\nServer version: 5.6.29-mycat-1.6-RELEASE-20161028204710 MyCat Server (OpenCloundDB)\n\nmysql&gt; show databases;\n+----------+\n| DATABASE |\n+----------+\n| ITCAST   |\n| SHOPPING |\n+----------+\n2 rows in set (0.00 sec)\n\nmysql&gt; use ITCAST;\nReading table information for completion of table and column names\nYou can turn off this feature to get a quicker startup with -A\n\nDatabase changed\nmysql&gt; show tables;\n+------------------+\n| Tables in ITCAST |\n+------------------+\n| tb_log           |\n| tb_order         |\n+------------------+\n2 rows in set (0.00 sec)\n\n#åˆ›å»ºè¡¨ç»“æ„\ncreate table tb_order(\n    id  varchar(100) not null primary key,\n    money   int null,\n    content varchar(200) null\n);\n\n#æ’å…¥æ•°æ®\nINSERT INTO tb_order (id, money, content) VALUES ('b92fdaaf-6fc4-11ec-b831-482ae33c4a2d', 10, 'b92fdaf8-6fc4-11ec-b831-482ae33c4a2d');\nINSERT INTO tb_order (id, money, content) VALUES ('b93482b6-6fc4-11ec-b831-482ae33c4a2d', 20, 'b93482d5-6fc4-11ec-b831-482ae33c4a2d');\nINSERT INTO tb_order (id, money, content) VALUES ('b937e246-6fc4-11ec-b831-482ae33c4a2d', 50, 'b937e25d-6fc4-11ec-b831-482ae33c4a2d');\nINSERT INTO tb_order (id, money, content) VALUES ('b93be2dd-6fc4-11ec-b831-482ae33c4a2d', 100, 'b93be2f9-6fc4-11ec-b831-482ae33c4a2d');\nINSERT INTO tb_order (id, money, content) VALUES ('b93f2d68-6fc4-11ec-b831-482ae33c4a2d', 130, 'b93f2d7d-6fc4-11ec-b831-482ae33c4a2d');\nINSERT INTO tb_order (id, money, content) VALUES ('b9451b98-6fc4-11ec-b831-482ae33c4a2d', 30, 'b9451bcc-6fc4-11ec-b831-482ae33c4a2d');\nINSERT INTO tb_order (id, money, content) VALUES ('b9488ec1-6fc4-11ec-b831-482ae33c4a2d', 560, 'b9488edb-6fc4-11ec-b831-482ae33c4a2d');\nINSERT INTO tb_order (id, money, content) VALUES ('b94be6e6-6fc4-11ec-b831-482ae33c4a2d', 10, 'b94be6ff-6fc4-11ec-b831-482ae33c4a2d');\nINSERT INTO tb_order (id, money, content) VALUES ('b94ee10d-6fc4-11ec-b831-482ae33c4a2d', 123, 'b94ee12c-6fc4-11ec-b831-482ae33c4a2d');\nINSERT INTO tb_order (id, money, content) VALUES ('b952492a-6fc4-11ec-b831-482ae33c4a2d', 145, 'b9524945-6fc4-11ec-b831-482ae33c4a2d');\nINSERT INTO tb_order (id, money, content) VALUES ('b95553ac-6fc4-11ec-b831-482ae33c4a2d', 543, 'b95553c8-6fc4-11ec-b831-482ae33c4a2d');\nINSERT INTO tb_order (id, money, content) VALUES ('b9581cdd-6fc4-11ec-b831-482ae33c4a2d', 17, 'b9581cfa-6fc4-11ec-b831-482ae33c4a2d');\nINSERT INTO tb_order (id, money, content) VALUES ('b95afc0f-6fc4-11ec-b831-482ae33c4a2d', 18, 'b95afc2a-6fc4-11ec-b831-482ae33c4a2d');\nINSERT INTO tb_order (id, money, content) VALUES ('b95daa99-6fc4-11ec-b831-482ae33c4a2d', 134, 'b95daab2-6fc4-11ec-b831-482ae33c4a2d');\nINSERT INTO tb_order (id, money, content) VALUES ('b9667e3c-6fc4-11ec-b831-482ae33c4a2d', 156, 'b9667e60-6fc4-11ec-b831-482ae33c4a2d');\nINSERT INTO tb_order (id, money, content) VALUES ('b96ab489-6fc4-11ec-b831-482ae33c4a2d', 175, 'b96ab4a5-6fc4-11ec-b831-482ae33c4a2d');\nINSERT INTO tb_order (id, money, content) VALUES ('b96e2942-6fc4-11ec-b831-482ae33c4a2d', 180, 'b96e295b-6fc4-11ec-b831-482ae33c4a2d');\nINSERT INTO tb_order (id, money, content) VALUES ('b97092ec-6fc4-11ec-b831-482ae33c4a2d', 123, 'b9709306-6fc4-11ec-b831-482ae33c4a2d');\nINSERT INTO tb_order (id, money, content) VALUES ('b973727a-6fc4-11ec-b831-482ae33c4a2d', 230, 'b9737293-6fc4-11ec-b831-482ae33c4a2d');\nINSERT INTO tb_order (id, money, content) VALUES ('b978840f-6fc4-11ec-b831-482ae33c4a2d', 560, 'b978843c-6fc4-11ec-b831-482ae33c4a2d');\n</code></pre>\n<p>PSï¼šæ•°æ®æŒ‰ä¸€è‡´æ€§ hash åˆ†å¸ƒåœ¨ä¸åŒèŠ‚ç‚¹</p>\n",
            "tags": [
                "MySQL"
            ]
        },
        {
            "id": "http://ixuyong.cn/posts/2771271649.html",
            "url": "http://ixuyong.cn/posts/2771271649.html",
            "title": "äº‘åŸç”ŸK8så®‰å…¨ä¸“å®¶CKSè®¤è¯è€ƒé¢˜è¯¦è§£",
            "date_published": "2025-04-09T13:38:39.000Z",
            "content_html": "<div class=\"hbe hbe-container\" id=\"hexo-blog-encrypt\" data-wpm=\"æŠ±æ­‰, è¿™ä¸ªå¯†ç çœ‹ç€ä¸å¤ªå¯¹, è¯·å†è¯•è¯•ã€‚\" data-whm=\"æŠ±æ­‰, è¿™ä¸ªæ–‡ç« ä¸èƒ½è¢«æ ¡éªŒ, ä¸è¿‡æ‚¨è¿˜æ˜¯èƒ½çœ‹çœ‹è§£å¯†åçš„å†…å®¹ã€‚\">\n  <script id=\"hbeData\" type=\"hbeData\" data-hmacdigest=\"51b7696c170db1f393208c9728cf1b39666792a92daee416449ae392a4ae125d\">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</script>\n  <div class=\"hbe hbe-content\">\n    <div class=\"hbe hbe-input hbe-input-xray\">\n      <input class=\"hbe hbe-input-field hbe-input-field-xray\" type=\"password\" id=\"hbePass\">\n      <label class=\"hbe hbe-input-label hbe-input-label-xray\" for=\"hbePass\">\n        <span class=\"hbe hbe-input-label-content hbe-input-label-content-xray\">æ‚¨å¥½, è¿™é‡Œéœ€è¦è¾“å…¥å¯†ç ã€‚</span>\n      </label>\n      <svg class=\"hbe hbe-graphic hbe-graphic-xray\" width=\"300%\" height=\"100%\" viewBox=\"0 0 1200 60\" preserveAspectRatio=\"none\">\n        <path d=\"M0,56.5c0,0,298.666,0,399.333,0C448.336,56.5,513.994,46,597,46c77.327,0,135,10.5,200.999,10.5c95.996,0,402.001,0,402.001,0\"></path>\n        <path d=\"M0,2.5c0,0,298.666,0,399.333,0C448.336,2.5,513.994,13,597,13c77.327,0,135-10.5,200.999-10.5c95.996,0,402.001,0,402.001,0\"></path>\n      </svg>\n    </div>\n  </div>\n</div>\n<script data-pjax src=\"/lib/hbe.js\"></script><link href=\"/css/hbe.style.css\" rel=\"stylesheet\" type=\"text/css\">",
            "tags": [
                "Kubernetes"
            ]
        },
        {
            "id": "http://ixuyong.cn/posts/1414180692.html",
            "url": "http://ixuyong.cn/posts/1414180692.html",
            "title": "Redisé›†ç¾¤ï¼ˆä¸»ä»+å“¨å…µï¼‰æ¨¡å¼",
            "date_published": "2025-04-09T11:50:06.000Z",
            "content_html": "<h3 id=\"redisé›†ç¾¤ä¸»ä»å“¨å…µæ¨¡å¼\"><a class=\"anchor\" href=\"#redisé›†ç¾¤ä¸»ä»å“¨å…µæ¨¡å¼\">#</a> Redis é›†ç¾¤ï¼ˆä¸»ä» + å“¨å…µï¼‰æ¨¡å¼</h3>\n<h3 id=\"ä¸€-ä»€ä¹ˆæ˜¯redisä¸»ä»å¤åˆ¶\"><a class=\"anchor\" href=\"#ä¸€-ä»€ä¹ˆæ˜¯redisä¸»ä»å¤åˆ¶\">#</a> ä¸€ã€ä»€ä¹ˆæ˜¯ redis ä¸»ä»å¤åˆ¶ï¼Ÿ</h3>\n<p>ä¸»ä»å¤åˆ¶ï¼Œæ˜¯æŒ‡å°†ä¸€å° Redis æœåŠ¡å™¨çš„æ•°æ®ï¼Œå¤åˆ¶åˆ°å…¶ä»–çš„ Redis æœåŠ¡å™¨ã€‚å‰è€…ç§°ä¸ºä¸»èŠ‚ç‚¹ (master)ï¼Œåè€…ç§°ä¸ºä»èŠ‚ç‚¹ (slave), æ•°æ®çš„å¤åˆ¶æ˜¯å•å‘çš„ï¼Œåªèƒ½ç”±ä¸»èŠ‚ç‚¹åˆ°ä»èŠ‚ç‚¹ã€‚master ä»¥å†™ä¸ºä¸»ï¼Œslave ä»¥è¯»ä¸ºä¸»ã€‚</p>\n<p><a href=\"https://imgse.com/i/pEgTlKx\"><img loading=\"lazy\" data-src=\"https://s21.ax1x.com/2025/04/09/pEgTlKx.png\" alt=\"pEgTlKx.png\" /></a></p>\n<h3 id=\"äºŒ-ä¸»ä»å¤åˆ¶çš„ä½œç”¨\"><a class=\"anchor\" href=\"#äºŒ-ä¸»ä»å¤åˆ¶çš„ä½œç”¨\">#</a> äºŒã€ä¸»ä»å¤åˆ¶çš„ä½œç”¨</h3>\n<p>æ•°æ®å†—ä½™ï¼šä¸»ä»å¤åˆ¶å®ç°äº†æ•°æ®çš„çƒ­å¤‡ä»½ï¼Œæ˜¯æŒä¹…åŒ–ä¹‹å¤–çš„ä¸€ç§æ•°æ®å†—ä½™æ–¹å¼ã€‚<br />\næ•…éšœæ¢å¤ï¼šå½“ä¸»èŠ‚ç‚¹å‡ºç°é—®é¢˜æ—¶ï¼Œå¯ä»¥ç”±ä»èŠ‚ç‚¹æä¾›æœåŠ¡ï¼Œå®ç°å¿«é€Ÿçš„æ•…éšœæ¢å¤ï¼›å®é™…ä¸Šæ˜¯ä¸€ç§æœåŠ¡çš„å†—ä½™ã€‚<br />\nè´Ÿè½½å‡è¡¡ï¼šåœ¨ä¸»ä»å¤åˆ¶çš„åŸºç¡€ä¸Šï¼Œé…åˆè¯»å†™åˆ†ç¦»ï¼Œå¯ä»¥ç”±ä¸»èŠ‚ç‚¹æä¾›å†™æœåŠ¡ï¼Œç”±ä»èŠ‚ç‚¹æä¾›è¯»æœåŠ¡ï¼ˆå³å†™ Redis æ•°æ®æ—¶åº”ç”¨è¿æ¥ä¸»èŠ‚ç‚¹ï¼Œè¯» Redis æ•°æ®æ—¶åº”ç”¨è¿æ¥ä»èŠ‚ç‚¹ï¼‰ï¼Œåˆ†æ‹…æœåŠ¡å™¨è´Ÿè½½ï¼›å°¤å…¶æ˜¯åœ¨å†™å°‘è¯»å¤šçš„åœºæ™¯ä¸‹ï¼Œé€šè¿‡å¤šä¸ªä»èŠ‚ç‚¹åˆ†æ‹…è¯»è´Ÿè½½ï¼Œå¯ä»¥å¤§å¤§æé«˜ Redis æœåŠ¡å™¨çš„å¹¶å‘é‡ã€‚<br />\nè¯»å†™åˆ†ç¦»ï¼šç”¨äºå®ç°è¯»å†™åˆ†ç¦»ï¼Œä¸»åº“å†™ã€ä»åº“è¯»ï¼Œè¯»å†™åˆ†ç¦»ä¸ä»…å¯ä»¥æé«˜æœåŠ¡å™¨çš„è´Ÿè½½èƒ½åŠ›ï¼ŒåŒæ—¶å¯æ ¹æ®éœ€æ±‚çš„å˜åŒ–ï¼Œæ”¹å˜ä»åº“çš„æ•°é‡ï¼›<br />\né«˜å¯ç”¨åŸºçŸ³ï¼šé™¤äº†ä¸Šè¿°ä½œç”¨ä»¥å¤–ï¼Œä¸»ä»å¤åˆ¶è¿˜æ˜¯å“¨å…µå’Œé›†ç¾¤èƒ½å¤Ÿå®æ–½çš„åŸºç¡€ï¼Œå› æ­¤è¯´ä¸»ä»å¤åˆ¶æ˜¯ Redis é«˜å¯ç”¨çš„åŸºç¡€ã€‚</p>\n<h3 id=\"ä¸‰-å®ç°ä¸»ä»å¤åˆ¶\"><a class=\"anchor\" href=\"#ä¸‰-å®ç°ä¸»ä»å¤åˆ¶\">#</a> ä¸‰ã€å®ç°ä¸»ä»å¤åˆ¶</h3>\n<table>\n<thead>\n<tr>\n<th>ä¸»æœºå</th>\n<th>IP</th>\n<th>è§’è‰²</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>redis01</td>\n<td>192.168.40.101</td>\n<td>master</td>\n</tr>\n<tr>\n<td>redis02</td>\n<td>192.168.40.102</td>\n<td>slave</td>\n</tr>\n<tr>\n<td>redis03</td>\n<td>192.168.40.103</td>\n<td>slave</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"31-å…³é—­é˜²ç«å¢™-selinux\"><a class=\"anchor\" href=\"#31-å…³é—­é˜²ç«å¢™-selinux\">#</a> 3.1 å…³é—­é˜²ç«å¢™ã€selinux</h4>\n<pre><code>[root@master01 ~]# hostnamectl set-hostname redis01\n[root@redis01 ~]# systemctl stop firewalld\n[root@redis01 ~]# systemctl disable firewalld\n[root@redis01 ~]# sed -i 's/^SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux\n[root@redis01 ~]# sed -i 's/^SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config\n[root@redis01 ~]# yum install net-tools vim tree lrzsz wget unzip dos2unix bash-completion  lsof ntp ntpdate git -y\n[root@redis01 ~]# yum update -y --exclude=kernel* &amp;&amp; reboot\n[root@redis01 ~]# echo 'Asia/Shanghai' &gt;/etc/timezone\n[root@redis01 ~]# ntpdate time2.aliyun.com\n[root@redis01 ~]# crontab -e\n*/5 * * * * /usr/sbin/ntpdate time2.aliyun.com &amp;&gt; /dev/null\n[root@redis01 ~]# mkdir /soft /data /scripts /backup\n</code></pre>\n<h4 id=\"32-å®‰è£…redis\"><a class=\"anchor\" href=\"#32-å®‰è£…redis\">#</a> 3.2 å®‰è£… redis</h4>\n<pre><code>[root@redis01 ~]# yum install gcc-c++ -y\n[root@redis01 soft]# wget https://download.redis.io/releases/redis-6.2.11.tar.gz\n[root@redis01 soft]# tar xf redis-6.2.11.tar.gz \n[root@redis01 soft]# ln -s /soft/redis-6.2.11 /soft/redis\n[root@redis01 soft]# cd /soft/redis\n[root@redis01 redis]# make            #æ‰§è¡Œmakeç¼–è¯‘\n[root@redis01 redis]# make install    #å°† srcä¸‹çš„è®¸å¤šå¯æ‰§è¡Œæ–‡ä»¶å¤åˆ¶åˆ°/usr/local/bin ç›®å½•ä¸‹\n[root@redis01 redis]# redis-server /soft/redis/redis.conf &amp;\n[root@redis01 redis]# netstat -lntp|grep redis\ntcp        0      0 127.0.0.1:6379          0.0.0.0:*               LISTEN      69686/redis-server  \ntcp6       0      0 ::1:6379                :::*                    LISTEN      69686/redis-server     \n[root@redis01 redis]# redis-cli shutdown      #å…³é—­RedisæœåŠ¡\n</code></pre>\n<h4 id=\"33-redisé…ç½®æ–‡ä»¶è¯´æ˜\"><a class=\"anchor\" href=\"#33-redisé…ç½®æ–‡ä»¶è¯´æ˜\">#</a> 3.3 redis é…ç½®æ–‡ä»¶è¯´æ˜</h4>\n<pre><code>[root@db01 redis]# vim redis.conf \nbind 127.0.0.1      \t\t# ç»‘å®šçš„ip\nprotected-mode yes  \t\t# ä¿æŠ¤æ¨¡å¼\nport 6379           \t\t# ç«¯å£è®¾ç½®\ndaemonize yes               # åå°å¯åŠ¨\nbind 127.0.0.1      \t\t# ç»‘å®šçš„ip\nprotected-mode yes  \t\t# ä¿æŠ¤æ¨¡å¼\nport 6379           \t\t# ç«¯å£è®¾ç½®\nloglevel notice     \t\t# è®°å½•æ—¥å¿—çº§åˆ«\nlogfile &quot;redis.log&quot;         # æ—¥å¿—çš„æ–‡ä»¶ä½ç½®å\ndir ./               \t\t# æ—¥å¿—å­˜å‚¨ç›®å½•\ndatabases 16        \t\t# æ•°æ®åº“çš„æ•°é‡ï¼Œé»˜è®¤æ˜¯ 16 ä¸ªæ•°æ®åº“\nalways-show-logo yes \t\t# æ˜¯å¦æ€»æ˜¯æ˜¾ç¤ºLOGO\n\n# å¦‚æœ900så†…ï¼Œå¦‚æœè‡³å°‘æœ‰ä¸€ä¸ª1 keyè¿›è¡Œäº†ä¿®æ”¹ï¼Œæˆ‘ä»¬åŠè¿›è¡ŒæŒä¹…åŒ–æ“ä½œ\nsave 900 1\n# å¦‚æœ300så†…ï¼Œå¦‚æœè‡³å°‘10 keyè¿›è¡Œäº†ä¿®æ”¹ï¼Œæˆ‘ä»¬åŠè¿›è¡ŒæŒä¹…åŒ–æ“ä½œ\nsave 300 10\n# å¦‚æœ60så†…ï¼Œå¦‚æœè‡³å°‘10000 keyè¿›è¡Œäº†ä¿®æ”¹ï¼Œæˆ‘ä»¬åŠè¿›è¡ŒæŒä¹…åŒ–æ“ä½œ\nsave 60 10000\n# æˆ‘ä»¬ä¹‹åå­¦ä¹ æŒä¹…åŒ–ï¼Œä¼šè‡ªå·±å®šä¹‰è¿™ä¸ªæµ‹è¯•ï¼\nstop-writes-on-bgsave-error yes   # æŒä¹…åŒ–å¦‚æœå‡ºé”™ï¼Œæ˜¯å¦è¿˜éœ€è¦ç»§ç»­å·¥ä½œï¼\nrdbcompression yes                # æ˜¯å¦å‹ç¼© rdb æ–‡ä»¶ï¼Œéœ€è¦æ¶ˆè€—ä¸€äº›cpuèµ„æºï¼\nrdbchecksum yes                   # ä¿å­˜rdbæ–‡ä»¶çš„æ—¶å€™ï¼Œè¿›è¡Œé”™è¯¯çš„æ£€æŸ¥æ ¡éªŒï¼\ndbfilename dump.rdb               # rdb æ–‡ä»¶ä¿å­˜çš„åç§°ï¼\ndir ./                            # rdb æ–‡ä»¶ä¿å­˜çš„ç›®å½•ï¼\n\nslaveof 192.168.1.154 6379        # é…ç½®ä¸»ä»å¤åˆ¶\nrequirepass foobared              # é…ç½®redisç™»å½•å¯†ç \n\nappendonly no    # é»˜è®¤æ˜¯ä¸å¼€å¯aofæ¨¡å¼çš„ï¼Œé»˜è®¤æ˜¯ä½¿ç”¨rdbæ–¹å¼æŒä¹…åŒ–çš„ï¼Œåœ¨å¤§éƒ¨åˆ†æ‰€æœ‰çš„æƒ…å†µä¸‹ï¼Œrdbå®Œå…¨å¤Ÿç”¨ï¼\nappendfilename &quot;appendonly.aof&quot;   # æŒä¹…åŒ–çš„æ–‡ä»¶çš„åå­—\n# appendfsync always        # æ¯æ¬¡ä¿®æ”¹éƒ½ä¼š syncã€‚æ¶ˆè€—æ€§èƒ½\nappendfsync everysec        # æ¯ç§’æ‰§è¡Œä¸€æ¬¡ syncï¼Œå¯èƒ½ä¼šä¸¢å¤±è¿™1sçš„æ•°æ®ï¼\n# appendfsync no            # ä¸æ‰§è¡Œ syncï¼Œè¿™ä¸ªæ—¶å€™æ“ä½œç³»ç»Ÿè‡ªå·±åŒæ­¥æ•°æ®ï¼Œé€Ÿåº¦æœ€å¿«ï¼\nno-appendfsync-on-rewrite   #é‡å†™æ—¶æ˜¯å¦å¯ä»¥è¿ç”¨appendsyncï¼Œé»˜è®¤noï¼Œå¯ä»¥ä¿è¯æ•°æ®çš„å®‰å…¨æ€§\n</code></pre>\n<h4 id=\"34-redisç¯å¢ƒé…ç½®\"><a class=\"anchor\" href=\"#34-redisç¯å¢ƒé…ç½®\">#</a> 3.4 redis ç¯å¢ƒé…ç½®</h4>\n<p>#ä¿®æ”¹ maser é…ç½®æ–‡ä»¶</p>\n<pre><code>vim redis.conf\nbind 192.168.40.101 #ç»‘å®šæœ¬æœºipåœ°å€\nport 6739          #ç»‘å®šç«¯å£å·\ndaemonize yes      #ç”¨æ¥æŒ‡å®šredisæ˜¯å¦è¦ç”¨å®ˆæŠ¤è¿›ç¨‹çš„æ–¹å¼å¯åŠ¨ï¼Œé»˜è®¤ä¸ºno\npidfile /var/run/redis_6379.pid\nlogfile &quot;redis.log&quot;   #redisæ—¥å¿—æ–‡ä»¶\nrequirepass Superman*2023  #æœ¬åœ°rediså¯†ç \nmasterauth Superman*2023   #ä¸»èŠ‚ç‚¹rediså¯†ç  æ³¨æ„:ä»èŠ‚ç‚¹ä¹Ÿè¦é…ç½®ï¼Œåè¾¹å“¨å…µå®¹ç¾åˆ‡æ¢ç”¨åˆ°\nprotected-mode yes    #ä¿æŠ¤æ¨¡å¼\n</code></pre>\n<p>#ä¿®æ”¹ slave01 é…ç½®æ–‡ä»¶</p>\n<pre><code>vim redis.conf\nbind 192.168.40.102 #ç»‘å®šæœ¬æœºipåœ°å€\nport 6739          #ç»‘å®šç«¯å£å·\ndaemonize yes      #ç”¨æ¥æŒ‡å®šredisæ˜¯å¦è¦ç”¨å®ˆæŠ¤è¿›ç¨‹çš„æ–¹å¼å¯åŠ¨ï¼Œé»˜è®¤ä¸ºno\npidfile /var/run/redis_6379.pid\nlogfile &quot;redis.log&quot;   #redisæ—¥å¿—æ–‡ä»¶\nreplicaof  192.168.40.101 6379 #é…ç½®æ–‡ä»¶ä¸­è®¾ç½®ä¸»èŠ‚ç‚¹ï¼Œredisä¸»ä»å¤åˆ¶è¿™ä¸ªåœ°æ–¹åªé…ç½®ä»åº“ï¼Œæ³¨æ„:ä¸»åº“ä¸éœ€è¦è¿™ä¸ªé…ç½®\nrequirepass Superman*2023  #æœ¬åœ°rediså¯†ç \nmasterauth Superman*2023   #ä¸»èŠ‚ç‚¹rediså¯†ç  æ³¨æ„:ä»èŠ‚ç‚¹ä¹Ÿè¦é…ç½®ï¼Œåè¾¹å“¨å…µå®¹ç¾åˆ‡æ¢ç”¨åˆ°\nprotected-mode yes    #ä¿æŠ¤æ¨¡å¼\n</code></pre>\n<p>#ä¿®æ”¹ slave02 é…ç½®æ–‡ä»¶</p>\n<pre><code>vim redis.conf\nbind 192.168.40.103 #ç»‘å®šæœ¬æœºipåœ°å€\nport 6739          #ç»‘å®šç«¯å£å·\ndaemonize yes      #ç”¨æ¥æŒ‡å®šredisæ˜¯å¦è¦ç”¨å®ˆæŠ¤è¿›ç¨‹çš„æ–¹å¼å¯åŠ¨ï¼Œé»˜è®¤ä¸ºno\npidfile /var/run/redis_6379.pid\nlogfile &quot;redis.log&quot;   #redisæ—¥å¿—æ–‡ä»¶\nreplicaof  192.168.40.101 6379 #é…ç½®æ–‡ä»¶ä¸­è®¾ç½®ä¸»èŠ‚ç‚¹ï¼Œredisä¸»ä»å¤åˆ¶è¿™ä¸ªåœ°æ–¹åªé…ç½®ä»åº“ï¼Œæ³¨æ„:ä¸»åº“ä¸éœ€è¦è¿™ä¸ªé…ç½®\nrequirepass Superman*2023  #æœ¬åœ°rediså¯†ç \nmasterauth Superman*2023   #ä¸»èŠ‚ç‚¹rediså¯†ç  æ³¨æ„:ä»èŠ‚ç‚¹ä¹Ÿè¦é…ç½®ï¼Œåè¾¹å“¨å…µå®¹ç¾åˆ‡æ¢ç”¨åˆ°\nprotected-mode yes    #ä¿æŠ¤æ¨¡å¼\n</code></pre>\n<h4 id=\"35-å¯åŠ¨3å°redisæœåŠ¡\"><a class=\"anchor\" href=\"#35-å¯åŠ¨3å°redisæœåŠ¡\">#</a> 3.5 å¯åŠ¨ 3 å° redis æœåŠ¡</h4>\n<pre><code>#å¯åŠ¨redis01\n[root@redis01 redis]# redis-server /soft/redis/redis.conf\n[root@redis0[root@redis01 redis]# redis-server /soft/redis/redis.conf redis]# netstat -lntp|grep redis\ntcp        0      0 192.168.40.101:6379     0.0.0.0:*               LISTEN      117358/redis-server \n\n#å¯åŠ¨redis02\n[root@redis02 redis]# redis-server /soft/redis/redis.conf\n[root@redis02 redis]# netstat -lntp|grep redis\ntcp        0      0 192.168.40.102:6379     0.0.0.0:*               LISTEN      18210/redis-server\n\nå¯åŠ¨redis03\n[root@redis03 redis]# redis-server /soft/redis/redis.conf\n[root@redis03 redis]# netstat -lntp|grep redis\ntcp        0      0 192.168.40.103:6379     0.0.0.0:*               LISTEN      19186/redis-server \n</code></pre>\n<h4 id=\"36-æŸ¥çœ‹ä¸»ä»çŠ¶æ€\"><a class=\"anchor\" href=\"#36-æŸ¥çœ‹ä¸»ä»çŠ¶æ€\">#</a> 3.6 æŸ¥çœ‹ä¸»ä»çŠ¶æ€</h4>\n<pre><code>#ä¸»èŠ‚ç‚¹\n[root@redis01 redis]# redis-cli -p 6379 -h 192.168.40.101 -a Superman*2023\n192.168.40.101:6379&gt; info replication\n# Replication\nrole:master\nconnected_slaves:2\nslave0:ip=192.168.40.102,port=6379,state=online,offset=616,lag=0\nslave1:ip=192.168.40.103,port=6379,state=online,offset=616,lag=0\nmaster_failover_state:no-failover\nmaster_replid:93df7cd5095dcccdbf8266787031b17cf638a2ad\nmaster_replid2:0000000000000000000000000000000000000000\nmaster_repl_offset:616\nsecond_repl_offset:-1\nrepl_backlog_active:1\nrepl_backlog_size:1048576\nrepl_backlog_first_byte_offset:1\nrepl_backlog_histlen:616\n\n#ä»èŠ‚ç‚¹\n[root@redis01 redis]# redis-cli -p 6379 -h 192.168.40.103 -a Superman*2023\nWarning: Using a password with '-a' or '-u' option on the command line interface may not be safe.\n192.168.40.103:6379&gt; info replication\n# Replication\nrole:slave\nmaster_host:192.168.40.101\nmaster_port:6379\nmaster_link_status:up\nmaster_last_io_seconds_ago:1\nmaster_sync_in_progress:0\nslave_read_repl_offset:812\nslave_repl_offset:812\nslave_priority:100\nslave_read_only:1\nreplica_announced:1\nconnected_slaves:0\nmaster_failover_state:no-failover\nmaster_replid:93df7cd5095dcccdbf8266787031b17cf638a2ad\nmaster_replid2:0000000000000000000000000000000000000000\nmaster_repl_offset:812\nsecond_repl_offset:-1\nrepl_backlog_active:1\nrepl_backlog_size:1048576\nrepl_backlog_first_byte_offset:295\nrepl_backlog_histlen:518\n</code></pre>\n<h4 id=\"37-æµ‹è¯•ä¸»ä»\"><a class=\"anchor\" href=\"#37-æµ‹è¯•ä¸»ä»\">#</a> 3.7 æµ‹è¯•ä¸»ä»</h4>\n<pre><code>[root@redis01 redis]# redis-cli -p 6379 -h 192.168.40.101 -a Superman*2023\nWarning: Using a password with '-a' or '-u' option on the command line interface may not be safe.\n192.168.40.101:6379&gt; set k1 v1\nOK\n192.168.40.101:6379&gt; set k2 v2\nOK\n\n[root@redis03 redis]# redis-cli -p 6379 -h 192.168.40.103 -a Superman*2023\nWarning: Using a password with '-a' or '-u' option on the command line interface may not be safe.\n192.168.40.103:6379&gt; get k1\n&quot;v1&quot;\n192.168.40.103:6379&gt; get k2\n&quot;v2&quot;\n</code></pre>\n<p><strong>æ³¨æ„:</strong><br />\n1ã€ä¸»æœºå¯ä»¥å†™ï¼Œä»æœºä¸èƒ½å†™ï¼Œåªèƒ½è¯»ã€‚ä¸»æœºä¸­çš„æ‰€æœ‰æ•°æ®éƒ½ä¼šä¿å­˜åˆ°ä»æœºä¸­å»ã€‚<br />\n2ã€ä¸»æœºæ–­å¼€è¿æ¥ï¼Œä»æœºä¾æ—§è¿æ¥åˆ°ä¸»æœºçš„ï¼Œä½†æ˜¯æ²¡æœ‰å†™æ“ä½œï¼Œè¿™ä¸ªæ—¶å€™ï¼Œä¸»æœºå¦‚æœå›æ¥äº†ï¼Œä»æœºä¾æ—§å¯ä»¥ç›´æ¥è·å–åˆ°ä¸»æœºå†™çš„ä¿¡æ¯ï¼<br />\n3ã€å¦‚æœæ˜¯ä½¿ç”¨å‘½ä»¤è¡Œï¼Œæ¥é…ç½®çš„ä¸»ä»ï¼Œè¿™ä¸ªæ—¶å€™å¦‚æœé‡å¯äº†ï¼Œå°±ä¼šå˜å›ä¸»æœºï¼åªè¦å˜ä¸ºä»æœºï¼Œç«‹é©¬å°±ä¼šä»ä¸»æœºä¸­è·å–å€¼ï¼<br />\n4ã€ä¸»ä»å¤åˆ¶åŸç†<br />\n Slave å¯åŠ¨æˆåŠŸè¿æ¥åˆ° master åä¼šå‘é€ä¸€ä¸ª sync åŒæ­¥å‘½ä»¤<br />\n Master æ¥åˆ°å‘½ä»¤ï¼Œå¯åŠ¨åå°çš„å­˜ç›˜è¿›ç¨‹ï¼ŒåŒæ—¶æ”¶é›†æ‰€æœ‰æ¥æ”¶åˆ°çš„ç”¨äºä¿®æ”¹æ•°æ®é›†å‘½ä»¤ï¼Œåœ¨åå°è¿›ç¨‹æ‰§è¡Œå®Œæ¯•ä¹‹åï¼Œmaster å°†ä¼ é€æ•´ä¸ªæ•°æ®æ–‡ä»¶åˆ° slaveï¼Œå¹¶å®Œæˆä¸€æ¬¡å®Œå…¨åŒæ­¥ã€‚<br />\nå…¨é‡å¤åˆ¶ï¼šslave æœåŠ¡åœ¨æ¥æ”¶åˆ°æ•°æ®åº“æ–‡ä»¶æ•°æ®åï¼Œå°†å…¶å­˜ç›˜å¹¶åŠ è½½åˆ°å†…å­˜ä¸­ã€‚<br />\nå¢é‡å¤åˆ¶ï¼šMaster ç»§ç»­å°†æ–°çš„æ‰€æœ‰æ”¶é›†åˆ°çš„ä¿®æ”¹å‘½ä»¤ä¾æ¬¡ä¼ ç»™ slaveï¼Œå®ŒæˆåŒæ­¥ï¼Œä½†æ˜¯åªè¦æ˜¯é‡æ–°è¿æ¥ masterï¼Œä¸€æ¬¡å®Œå…¨åŒæ­¥ï¼ˆå…¨é‡å¤åˆ¶ï¼‰å°†è¢«è‡ªåŠ¨æ‰§è¡Œï¼ ä¸»æœºçš„æ•°æ®ä¸€å®šå¯ä»¥åœ¨ä»æœºä¸­çœ‹åˆ°ã€‚</p>\n<h3 id=\"å››-å“¨å…µæ¨¡å¼æ­å»º\"><a class=\"anchor\" href=\"#å››-å“¨å…µæ¨¡å¼æ­å»º\">#</a> å››ã€å“¨å…µæ¨¡å¼æ­å»º</h3>\n<p>1ã€ä»€ä¹ˆæ˜¯ redis å“¨å…µï¼Ÿ<br />\nRedisSentinel æ˜¯ Redis çš„é«˜å¯ç”¨æ€§è§£å†³æ–¹æ¡ˆï¼Œç”±ä¸€ä¸ªæˆ–å¤šä¸ª Sentinelï¼ˆå“¨å…µï¼‰å®ä¾‹ç»„æˆã€‚å®ƒå¯ä»¥ç›‘è§†ä»»æ„å¤šä¸ªä¸»æœåŠ¡å™¨ï¼Œä»¥åŠè¿™äº›ä¸»æœåŠ¡å™¨å±ä¸‹çš„æ‰€æœ‰ä»æœåŠ¡å™¨ï¼Œå¹¶åœ¨è¢«ç›‘è§†çš„ä¸»æœåŠ¡å™¨è¿›å…¥ä¸‹çº¿çŠ¶æ€æ—¶ï¼Œè‡ªåŠ¨å°†ä¸‹çº¿ä¸»æœåŠ¡å™¨å±ä¸‹çš„æŸä¸ªä»æœåŠ¡å™¨å‡çº§ä¸ºæ–°çš„ä¸»æœåŠ¡å™¨ï¼Œå®ƒçš„ä¸»è¦åŠŸèƒ½å¦‚ä¸‹ï¼š<br />\nç›‘æ§ (Monitoring)ï¼šSentinel ä¼šä¸æ–­åœ°æ£€æŸ¥ä½ çš„ä¸»æœåŠ¡å™¨å’Œä»æœåŠ¡å™¨æ˜¯å¦è¿ä½œæ­£å¸¸ã€‚<br />\né€šçŸ¥ (Notification)ï¼šå½“è¢«ç›‘æ§çš„æŸä¸ª Redis æœåŠ¡å™¨å‡ºç°é—®é¢˜æ—¶ï¼ŒSentinel å¯ä»¥é€šè¿‡ API å‘ç®¡ç†å‘˜æˆ–è€…å…¶ä»–åº”ç”¨ç¨‹åºå‘é€é€šçŸ¥ã€‚<br />\næ•…éšœè¿ç§»ï¼šå½“ä¸»æœåŠ¡å™¨ä¸èƒ½æ­£å¸¸å·¥ä½œæ—¶ï¼ŒSentinel ä¼šè‡ªåŠ¨è¿›è¡Œæ•…éšœè¿ç§»ï¼Œä¹Ÿå°±æ˜¯ä¸»ä»åˆ‡æ¢ã€‚<br />\nç»Ÿä¸€çš„é…ç½®ï¼šç®¡ç†è¿æ¥è€…è¯¢é—® sentinel å–å¾—ä¸»ä»çš„åœ°å€ã€‚</p>\n<p>2ã€å“¨å…µåŸç†æ˜¯ä»€ä¹ˆï¼Ÿ<br />\nSentinel ä½¿ç”¨çš„ç®—æ³•æ ¸å¿ƒæ˜¯ Raft ç®—æ³•ï¼Œä¸»è¦ç”¨é€”å°±æ˜¯ç”¨äºåˆ†å¸ƒå¼ç³»ç»Ÿï¼Œç³»ç»Ÿå®¹é”™ï¼Œä»¥åŠ Leader é€‰ä¸¾ï¼Œæ¯ä¸ª Sentinel éƒ½éœ€è¦å®šæœŸçš„æ‰§è¡Œä»¥ä¸‹ä»»åŠ¡ï¼š<br />\næ¯ä¸ª Sentinel ä¼šè‡ªåŠ¨å‘ç°å…¶ä»– Sentinel å’Œä»æœåŠ¡å™¨ï¼Œå®ƒä»¥æ¯ç§’é’Ÿä¸€æ¬¡çš„é¢‘ç‡å‘å®ƒæ‰€çŸ¥çš„ä¸»æœåŠ¡å™¨ã€ä»æœåŠ¡å™¨ä»¥åŠå…¶ä»– Sentinel å®ä¾‹å‘é€ä¸€ä¸ª PING å‘½ä»¤ã€‚<br />\nå¦‚æœä¸€ä¸ªå®ä¾‹ï¼ˆinstanceï¼‰è·ç¦»æœ€åä¸€æ¬¡æœ‰æ•ˆå›å¤ PING å‘½ä»¤çš„æ—¶é—´è¶…è¿‡ down-after-milliseconds é€‰é¡¹æ‰€æŒ‡å®šçš„å€¼ï¼Œ é‚£ä¹ˆè¿™ä¸ªå®ä¾‹ä¼šè¢« Sentinel æ ‡è®°ä¸ºä¸»è§‚ä¸‹çº¿ã€‚ æœ‰æ•ˆå›å¤å¯ä»¥æ˜¯ï¼š +PONG ã€ -LOADING æˆ–è€… -MASTERDOWN ã€‚<br />\nå¦‚æœä¸€ä¸ªä¸»æœåŠ¡å™¨è¢«æ ‡è®°ä¸ºä¸»è§‚ä¸‹çº¿ï¼Œ é‚£ä¹ˆæ­£åœ¨ç›‘è§†è¿™ä¸ªä¸»æœåŠ¡å™¨çš„æ‰€æœ‰ Sentinel è¦ä»¥æ¯ç§’ä¸€æ¬¡çš„é¢‘ç‡ç¡®è®¤ä¸»æœåŠ¡å™¨çš„ç¡®è¿›å…¥äº†ä¸»è§‚ä¸‹çº¿çŠ¶æ€ã€‚<br />\nå¦‚æœä¸€ä¸ªä¸»æœåŠ¡å™¨è¢«æ ‡è®°ä¸ºä¸»è§‚ä¸‹çº¿ï¼Œ å¹¶ä¸”æœ‰è¶³å¤Ÿæ•°é‡çš„ Sentinelï¼ˆè‡³å°‘è¦è¾¾åˆ°é…ç½®æ–‡ä»¶æŒ‡å®šçš„æ•°é‡ï¼‰åœ¨æŒ‡å®šçš„æ—¶é—´èŒƒå›´å†…åŒæ„è¿™ä¸€åˆ¤æ–­ï¼Œé‚£ä¹ˆè¿™ä¸ªä¸»æœåŠ¡å™¨è¢«æ ‡è®°ä¸ºå®¢è§‚ä¸‹çº¿ã€‚<br />\nåœ¨ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œ æ¯ä¸ª Sentinel ä¼šä»¥æ¯ 10 ç§’ä¸€æ¬¡çš„é¢‘ç‡å‘å®ƒå·²çŸ¥çš„æ‰€æœ‰ä¸»æœåŠ¡å™¨å’Œä»æœåŠ¡å™¨å‘é€ INFO å‘½ä»¤ã€‚å½“ä¸€ä¸ªä¸»æœåŠ¡å™¨ Sentinel æ ‡è®°ä¸ºå®¢è§‚ä¸‹çº¿æ—¶ï¼ŒSentinel å‘ä¸‹çº¿ä¸»æœåŠ¡å™¨çš„æ‰€æœ‰ä»æœåŠ¡å™¨å‘é€ INFO å‘½ä»¤çš„é¢‘ç‡ä¼šä» 10 ç§’ä¸€æ¬¡æ”¹ä¸ºæ¯ç§’ä¸€æ¬¡ã€‚<br />\nå½“æ²¡æœ‰è¶³å¤Ÿæ•°é‡çš„ Sentinel åŒæ„ä¸»æœåŠ¡å™¨å·²ç»ä¸‹çº¿ï¼Œ ä¸»æœåŠ¡å™¨çš„å®¢è§‚ä¸‹çº¿çŠ¶æ€å°±ä¼šè¢«ç§»é™¤ã€‚ å½“ä¸»æœåŠ¡å™¨é‡æ–°å‘ Sentinel çš„ PING å‘½ä»¤è¿”å›æœ‰æ•ˆå›å¤æ—¶ï¼Œ ä¸»æœåŠ¡å™¨çš„ä¸»ç®¡ä¸‹çº¿çŠ¶æ€å°±ä¼šè¢«ç§»é™¤ã€‚</p>\n<p><a href=\"https://imgse.com/i/pEgT1r6\"><img loading=\"lazy\" data-src=\"https://s21.ax1x.com/2025/04/09/pEgT1r6.png\" alt=\"pEgT1r6.png\" /></a></p>\n<h4 id=\"41-æ­å»ºå“¨å…µ\"><a class=\"anchor\" href=\"#41-æ­å»ºå“¨å…µ\">#</a> 4.1 æ­å»ºå“¨å…µ</h4>\n<p><em>åœ¨æ¯å°æœåŠ¡å™¨ä¸Šéƒ¨ç½²ä¸€ä¸ªå“¨å…µï¼Œé…ç½®æ–¹å¼å¦‚ä¸‹:</em></p>\n<pre><code>[root@redis01 redis]# vim sentinel.conf\n#ç«¯å£é»˜è®¤ä¸º26379ã€‚\nport 26379\n#å…³é—­ä¿æŠ¤æ¨¡å¼ï¼Œå¯ä»¥å¤–éƒ¨è®¿é—®ã€‚\nprotected-mode no\n#è®¾ç½®ä¸ºåå°å¯åŠ¨ã€‚\ndaemonize yes\n#æ—¥å¿—æ–‡ä»¶ã€‚\nlogfile &quot;/soft/redis/sentinel.log&quot;\n#æŒ‡å®šæœåŠ¡å™¨IPåœ°å€å’Œç«¯å£ï¼Œå¹¶ä¸”æŒ‡å®šå½“æœ‰2å°å“¨å…µè®¤ä¸ºä¸»æœºæŒ‚äº†ï¼Œåˆ™å¯¹ä¸»æœºè¿›è¡Œå®¹ç¾åˆ‡æ¢ã€‚æ³¨æ„:ä¸‰å°å“¨å…µè¿™é‡Œçš„ipé…ç½®å‡ä¸ºä¸»èŠ‚ç‚¹ip å’Œç«¯å£\nsentinel monitor mymaster 192.168.40.101 6379 2\n#å½“åœ¨Rediså®ä¾‹ä¸­å¼€å¯äº†requirepassï¼Œè¿™é‡Œå°±éœ€è¦æä¾›å¯†ç ã€‚\nsentinel auth-pass mymaster psw66\n#è¿™é‡Œè®¾ç½®äº†ä¸»æœºå¤šå°‘ç§’æ— å“åº”ï¼Œåˆ™è®¤ä¸ºæŒ‚äº†ã€‚\nsentinel down-after-milliseconds mymaster 3000\n#ä¸»å¤‡åˆ‡æ¢æ—¶ï¼Œæœ€å¤šæœ‰å¤šå°‘ä¸ªslaveåŒæ—¶å¯¹æ–°çš„masterè¿›è¡ŒåŒæ­¥ï¼Œè¿™é‡Œè®¾ç½®ä¸ºé»˜è®¤çš„\nsnetinel parallel-syncs mymaster 1\n#æ•…éšœè½¬ç§»çš„è¶…æ—¶æ—¶é—´ï¼Œè¿™é‡Œè®¾ç½®ä¸ºä¸‰åˆ†é’Ÿã€‚\nsentinel failover-timeout mymaster 180000\n</code></pre>\n<h4 id=\"42-å¯åŠ¨ä¸‰å°æœåŠ¡å™¨ä¸Šçš„å“¨å…µ\"><a class=\"anchor\" href=\"#42-å¯åŠ¨ä¸‰å°æœåŠ¡å™¨ä¸Šçš„å“¨å…µ\">#</a> 4.2 å¯åŠ¨ä¸‰å°æœåŠ¡å™¨ä¸Šçš„å“¨å…µ</h4>\n<pre><code>#å¯åŠ¨redis01çš„sentine\n[root@redis01 redis]# redis-sentinel /soft/redis/sentinel.conf\n[root@redis01 redis]#  netstat -lntp|grep redis\ntcp        0      0 0.0.0.0:26379           0.0.0.0:*               LISTEN      33536/redis-sentine \ntcp        0      0 192.168.40.101:6379     0.0.0.0:*               LISTEN      117358/redis-server \ntcp6       0      0 :::26379                :::*                    LISTEN      33536/redis-sentine\n\n#å¯åŠ¨redis02çš„sentine\n[root@redis02 redis]# redis-sentinel /soft/redis/sentinel.conf\n[root@redis02 redis]#  netstat -lntp|grep redis\ntcp        0      0 0.0.0.0:26379           0.0.0.0:*               LISTEN      18757/redis-sentine \ntcp        0      0 192.168.40.102:6379     0.0.0.0:*               LISTEN      18210/redis-server  \ntcp6       0      0 :::26379                :::*                    LISTEN      18757/redis-sentine\n\n#å¯åŠ¨redis03çš„sentine\n[root@redis03 redis]# redis-sentinel /soft/redis/sentinel.conf                     \n[root@redis03 redis]# netstat -lntp|grep redis\ntcp        0      0 0.0.0.0:26379           0.0.0.0:*               LISTEN      19745/redis-sentine \ntcp        0      0 192.168.40.103:6379     0.0.0.0:*               LISTEN      19186/redis-server  \ntcp6       0      0 :::26379                :::*                    LISTEN      19745/redis-sentine\n</code></pre>\n<h4 id=\"43-è¿æ¥å®¢æˆ·ç«¯\"><a class=\"anchor\" href=\"#43-è¿æ¥å®¢æˆ·ç«¯\">#</a> 4.3 è¿æ¥å®¢æˆ·ç«¯</h4>\n<pre><code>[root@redis01 redis]# redis-cli -p 26379\n127.0.0.1:26379&gt;  info sentinel\n# Sentinel\nsentinel_masters:1\nsentinel_tilt:0\nsentinel_running_scripts:0\nsentinel_scripts_queue_length:0\nsentinel_simulate_failure_flags:0\nmaster0:name=mymaster,status=ok,address=192.168.40.101:6379,slaves=2,sentinels=3\n</code></pre>\n<h4 id=\"44-rediså®¹ç¾åˆ‡æ¢\"><a class=\"anchor\" href=\"#44-rediså®¹ç¾åˆ‡æ¢\">#</a> 4.4 redis å®¹ç¾åˆ‡æ¢</h4>\n<pre><code>#è¿æ¥rediså®¢æˆ·ç«¯\n[root@redis01 redis]# redis-cli -p 6379 -h 192.168.40.101 \n#éªŒè¯å¯†ç \n192.168.40.101:6379&gt; auth Superman*2023\nOK\n#å…³é—­redisæœåŠ¡\n192.168.40.101:6379&gt; shutdown\nnot connected&gt;\n#é€€å‡ºå®¢æˆ·ç«¯\nnot connected&gt; exit\n</code></pre>\n<p>å…³é—­ä¸»èŠ‚ç‚¹ä¹‹åï¼Œæˆ‘ä»¬å»æŸ¥çœ‹å“¨å…µæ—¥å¿—:</p>\n<pre><code>[root@redis01 ~]# tail -f /soft/redis/sentinel.log \n91936:X 14 Apr 2023 23:26:23.838 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n91936:X 14 Apr 2023 23:26:23.838 # Redis version=6.2.11, bits=64, commit=00000000, modified=0, pid=91936, just started\n91936:X 14 Apr 2023 23:26:23.838 # Configuration loaded\n91936:X 14 Apr 2023 23:26:23.838 * monotonic clock: POSIX clock_gettime\n91936:X 14 Apr 2023 23:26:23.839 * Running mode=sentinel, port=26379.\n91936:X 14 Apr 2023 23:26:23.839 # Sentinel ID is 835b4c8544fb250af5fd479f834ee369cc4f388e\n91936:X 14 Apr 2023 23:26:23.839 # +monitor master mymaster 192.168.40.101 6379 quorum 2\n\n\n\n91936:X 14 Apr 2023 23:31:25.329 # +sdown master mymaster 192.168.40.101 6379   #è¿™é‡Œåº”è¯¥æ˜¯å‘ç°ä¸»èŠ‚ç‚¹å®•æœº\n91936:X 14 Apr 2023 23:31:25.359 # +new-epoch 5\n91936:X 14 Apr 2023 23:31:25.360 # +vote-for-leader ab43979285cb47b1b459aeb0ab91b63fa9d1a989 5\n91936:X 14 Apr 2023 23:31:25.401 # +odown master mymaster 192.168.40.101 6379 #quorum 3/2 ä¸¤ä¸ªå“¨å…µéƒ½è§‰å¾—ä¸»èŠ‚ç‚¹å®•æœºäº†\n91936:X 14 Apr 2023 23:31:25.401 # Next failover delay: I will not start a failover before Fri Apr 14 23:37:25 2023\n91936:X 14 Apr 2023 23:31:26.468 # +config-update-from sentinel ab43979285cb47b1b459aeb0ab91b63fa9d1a989 192.168.40.102 26379 @ mymaster 192.168.40.101 6379\n91936:X 14 Apr 2023 23:31:26.468 # +switch-master mymaster 192.168.40.101 6379 192.168.40.103 6379 #é€šè¿‡æŠ•ç¥¨é€‰ä¸¾40.103ä¸ºæ–°çš„ä¸»èŠ‚ç‚¹\n91936:X 14 Apr 2023 23:31:26.468 * +slave slave 192.168.40.102:6379 192.168.40.102 6379 @ mymaster 192.168.40.103 6379\n91936:X 14 Apr 2023 23:31:26.469 * +slave slave 192.168.40.101:6379 192.168.40.101 6379 @ mymaster 192.168.40.103 6379\n</code></pre>\n<p>ä¸‹é¢æˆ‘ä»¬å» 40.103 ä¸‹æŸ¥çœ‹å“¨å…µä¸»ä»åˆ‡æ¢æ˜¯å¦æˆåŠŸ</p>\n<pre><code>[root@redis03 redis]# redis-cli -p 6379 -h 192.168.40.103\n192.168.40.103:6379&gt; auth Superman*2023\nOK\n192.168.40.103:6379&gt; info replication\n# Replication\nrole:master   # 40.103å˜æˆä¸»èŠ‚ç‚¹äº†\nconnected_slaves:1   # ä¸‹é¢çš„ä»æœºä¸ªæ•°ä¸º1\nslave0:ip=192.168.40.102,port=6379,state=online,offset=108708,lag=1\nmaster_failover_state:no-failover\nmaster_replid:cf36f762dcae0c07b54f7287dc19d7ecc0d50dd3\nmaster_replid2:a7de32d10b2d31f8886c84ca91dc7f055439c935\nmaster_repl_offset:108851\nsecond_repl_offset:59887\nrepl_backlog_active:1\nrepl_backlog_size:1048576\nrepl_backlog_first_byte_offset:1\nrepl_backlog_histlen:108851\n</code></pre>\n<p>é‡æ–°è¿æ¥æŒ‚æ‰çš„ä¸»èŠ‚ç‚¹</p>\n<pre><code>[root@redis01 redis]# redis-server redis.conf \n[root@redis01 redis]#  redis-cli -p 6379 -h 192.168.40.101\n192.168.40.101:6379&gt; auth Superman*2023\nOK\n192.168.40.101:6379&gt; info replication\n# Replication\nrole:slave          #ä¸»èŠ‚ç‚¹è¿æ¥å›æ¥ä¹‹åè‡ªåŠ¨å˜æˆäº†ä»èŠ‚ç‚¹ï¼Œå¹¶ä¸”æˆåŠŸè¿ä¸Šäº†ä¸»æœº\nmaster_host:192.168.40.103\nmaster_port:6379\nmaster_link_status:up\nmaster_last_io_seconds_ago:1\nmaster_sync_in_progress:0\nslave_read_repl_offset:130607\nslave_repl_offset:130607\nslave_priority:100\nslave_read_only:1\nreplica_announced:1\nconnected_slaves:0\nmaster_failover_state:no-failover\nmaster_replid:cf36f762dcae0c07b54f7287dc19d7ecc0d50dd3\nmaster_replid2:0000000000000000000000000000000000000000\nmaster_repl_offset:130607\nsecond_repl_offset:-1\nrepl_backlog_active:1\nrepl_backlog_size:1048576\nrepl_backlog_first_byte_offset:126982\nrepl_backlog_histlen:3626\n</code></pre>\n<p>å†å»ä¸»èŠ‚ç‚¹ç¡®è®¤ä¸€ä¸‹</p>\n<pre><code>192.168.40.103:6379&gt; info replication\n# Replication\nrole:master\nconnected_slaves:2   #ä¸¤ä¸ªä»èŠ‚ç‚¹\nslave0:ip=192.168.40.102,port=6379,state=online,offset=147879,lag=1\nslave1:ip=192.168.40.101,port=6379,state=online,offset=147879,lag=1\nmaster_failover_state:no-failover\nmaster_replid:cf36f762dcae0c07b54f7287dc19d7ecc0d50dd3\nmaster_replid2:a7de32d10b2d31f8886c84ca91dc7f055439c935\nmaster_repl_offset:148165\nsecond_repl_offset:59887\nrepl_backlog_active:1\nrepl_backlog_size:1048576\nrepl_backlog_first_byte_offset:1\nrepl_backlog_histlen:148165\n</code></pre>\n<p>äº”ã€å“¨å…µæ¨¡å¼çš„ä¼˜ç¼ºç‚¹<br />\n 1. ä¼˜ç‚¹</p>\n<p>å“¨å…µé›†ç¾¤ï¼ŒåŸºäºä¸»ä»å¤åˆ¶æ¨¡å¼ï¼Œæ‰€æœ‰çš„ä¸»ä»é…ç½®ä¼˜ç‚¹ï¼Œå®ƒå…¨æœ‰</p>\n<p>ä¸»ä»å¯ä»¥åˆ‡æ¢ï¼Œæ•…éšœå¯ä»¥è½¬ç§»ï¼Œç³»ç»Ÿçš„å¯ç”¨æ€§å°±ä¼šæ›´å¥½</p>\n<p>å“¨å…µæ¨¡å¼å°±æ˜¯ä¸»ä»æ¨¡å¼çš„å‡çº§ï¼Œæ‰‹åŠ¨åˆ°è‡ªåŠ¨ï¼Œæ›´åŠ å¥å£®ï¼</p>\n<p>2. ç¼ºç‚¹</p>\n<p>Redis ä¸å¥½åœ¨çº¿æ‰©å®¹ï¼Œé›†ç¾¤å®¹é‡ä¸€æ—¦åˆ°è¾¾ä¸Šé™ï¼Œåœ¨çº¿æ‰©å®¹å°±ååˆ†éº»çƒ¦</p>\n<p>å“¨å…µæ¨¡å¼çš„é…ç½®ç¹ç</p>\n<p>3. å“¨å…µæ¨¡å¼çš„é…ç½®æ–‡ä»¶è¯¦è§£</p>\n<pre><code># Example sentinel.conf\n# å“¨å…µsentinelå®ä¾‹è¿è¡Œçš„ç«¯å£ é»˜è®¤26379\nport 26379\n \n# å“¨å…µsentinelçš„å·¥ä½œç›®å½•\ndir /tmp\n \n# å“¨å…µsentinelç›‘æ§çš„redisä¸»èŠ‚ç‚¹çš„ ip port\n# master-name å¯ä»¥è‡ªå·±å‘½åçš„ä¸»èŠ‚ç‚¹åå­— åªèƒ½ç”±å­—æ¯A-zã€æ•°å­—0-9 ã€è¿™ä¸‰ä¸ªå­—ç¬¦&quot;.-_&quot;ç»„æˆã€‚\n# quorum é…ç½®å¤šå°‘ä¸ªsentinelå“¨å…µç»Ÿä¸€è®¤ä¸ºmasterä¸»èŠ‚ç‚¹å¤±è” é‚£ä¹ˆè¿™æ—¶å®¢è§‚ä¸Šè®¤ä¸ºä¸»èŠ‚ç‚¹å¤±è”äº†\n# sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt;\nsentinel monitor mymaster 127.0.0.1 6379 2\n  \n# å½“åœ¨Rediså®ä¾‹ä¸­å¼€å¯äº†requirepass foobared æˆæƒå¯†ç è¿™æ ·æ‰€æœ‰è¿æ¥Rediså®ä¾‹çš„å®¢æˆ·ç«¯éƒ½è¦æä¾› å¯†ç \n# è®¾ç½®å“¨å…µsentinel è¿æ¥ä¸»ä»çš„å¯†ç  æ³¨æ„å¿…é¡»ä¸ºä¸»ä»è®¾ç½®ä¸€æ ·çš„éªŒè¯å¯†ç \n# sentinel auth-pass &lt;master-name&gt; &lt;password&gt;\nsentinel auth-pass mymaster MySUPER--secret-0123passw0rd\n \n# æŒ‡å®šå¤šå°‘æ¯«ç§’ä¹‹å ä¸»èŠ‚ç‚¹æ²¡æœ‰åº”ç­”å“¨å…µsentinel æ­¤æ—¶å“¨å…µä¸»è§‚ä¸Šè®¤ä¸ºä¸»èŠ‚ç‚¹ä¸‹çº¿ é»˜è®¤30ç§’\n# sentinel down-after-milliseconds &lt;master-name&gt; &lt;milliseconds&gt;\nsentinel down-after-milliseconds mymaster 30000\n \n# è¿™ä¸ªé…ç½®é¡¹æŒ‡å®šäº†åœ¨å‘ç”Ÿfailoverä¸»å¤‡åˆ‡æ¢æ—¶æœ€å¤šå¯ä»¥æœ‰å¤šå°‘ä¸ªslaveåŒæ—¶å¯¹æ–°çš„masterè¿›è¡ŒåŒæ­¥ï¼Œè¿™ä¸ªæ•°å­—è¶Šå°ï¼Œå®Œæˆfailoveræ‰€éœ€çš„æ—¶é—´å°±è¶Šé•¿ï¼Œ ä½†æ˜¯å¦‚æœè¿™ä¸ªæ•°å­—è¶Šå¤§ï¼Œå°±æ„å‘³ç€è¶Š å¤šçš„slaveå› ä¸ºreplicationè€Œä¸å¯ç”¨ã€‚ å¯ä»¥é€šè¿‡å°†è¿™ä¸ªå€¼è®¾ä¸º 1 æ¥ä¿è¯æ¯æ¬¡åªæœ‰ä¸€ä¸ªslave å¤„äºä¸èƒ½å¤„ç†å‘½ä»¤è¯·æ±‚çš„çŠ¶æ€ã€‚\n# sentinel parallel-syncs &lt;master-name&gt; &lt;numslaves&gt;\nsentinel parallel-syncs mymaster 1\n \n# æ•…éšœè½¬ç§»çš„è¶…æ—¶æ—¶é—´ failover-timeout å¯ä»¥ç”¨åœ¨ä»¥ä¸‹è¿™äº›æ–¹é¢ï¼š\n#1. åŒä¸€ä¸ªsentinelå¯¹åŒä¸€ä¸ªmasterä¸¤æ¬¡failoverä¹‹é—´çš„é—´éš”æ—¶é—´ã€‚\n#2. å½“ä¸€ä¸ªslaveä»ä¸€ä¸ªé”™è¯¯çš„masteré‚£é‡ŒåŒæ­¥æ•°æ®å¼€å§‹è®¡ç®—æ—¶é—´ã€‚ç›´åˆ°slaveè¢«çº æ­£ä¸ºå‘æ­£ç¡®çš„masteré‚£ é‡ŒåŒæ­¥æ•°æ®æ—¶ã€‚\n#3.å½“æƒ³è¦å–æ¶ˆä¸€ä¸ªæ­£åœ¨è¿›è¡Œçš„failoveræ‰€éœ€è¦çš„æ—¶é—´ã€‚\n#4.å½“è¿›è¡Œfailoveræ—¶ï¼Œé…ç½®æ‰€æœ‰slavesæŒ‡å‘æ–°çš„masteræ‰€éœ€çš„æœ€å¤§æ—¶é—´ã€‚ä¸è¿‡ï¼Œå³ä½¿è¿‡äº†è¿™ä¸ªè¶…æ—¶ï¼Œ slavesä¾ç„¶ä¼šè¢«æ­£ç¡®é…ç½®ä¸ºæŒ‡å‘masterï¼Œä½†æ˜¯å°±ä¸æŒ‰parallel-syncsæ‰€é…ç½®çš„è§„åˆ™æ¥äº† # é»˜è®¤ä¸‰åˆ†é’Ÿ\n# sentinel failover-timeout &lt;master-name&gt; &lt;milliseconds&gt; bilibiliï¼š\nsentinel failover-timeout mymaster 180000\n \n# SCRIPTS EXECUTION\n#é…ç½®å½“æŸä¸€äº‹ä»¶å‘ç”Ÿæ—¶æ‰€éœ€è¦æ‰§è¡Œçš„è„šæœ¬ï¼Œå¯ä»¥é€šè¿‡è„šæœ¬æ¥é€šçŸ¥ç®¡ç†å‘˜ï¼Œä¾‹å¦‚å½“ç³»ç»Ÿè¿è¡Œä¸æ­£å¸¸æ—¶å‘é‚®ä»¶é€šçŸ¥ ç›¸å…³äººå‘˜ã€‚\n#å¯¹äºè„šæœ¬çš„è¿è¡Œç»“æœæœ‰ä»¥ä¸‹è§„åˆ™ï¼š\n#è‹¥è„šæœ¬æ‰§è¡Œåè¿”å›1ï¼Œé‚£ä¹ˆè¯¥è„šæœ¬ç¨åå°†ä¼šè¢«å†æ¬¡æ‰§è¡Œï¼Œé‡å¤æ¬¡æ•°ç›®å‰é»˜è®¤ä¸º10\n#è‹¥è„šæœ¬æ‰§è¡Œåè¿”å›2ï¼Œæˆ–è€…æ¯”2æ›´é«˜çš„ä¸€ä¸ªè¿”å›å€¼ï¼Œè„šæœ¬å°†ä¸ä¼šé‡å¤æ‰§è¡Œã€‚\n#å¦‚æœè„šæœ¬åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­ç”±äºæ”¶åˆ°ç³»ç»Ÿä¸­æ–­ä¿¡å·è¢«ç»ˆæ­¢äº†ï¼Œåˆ™åŒè¿”å›å€¼ä¸º1æ—¶çš„è¡Œä¸ºç›¸åŒã€‚\n#ä¸€ä¸ªè„šæœ¬çš„æœ€å¤§æ‰§è¡Œæ—¶é—´ä¸º60sï¼Œå¦‚æœè¶…è¿‡è¿™ä¸ªæ—¶é—´ï¼Œè„šæœ¬å°†ä¼šè¢«ä¸€ä¸ªSIGKILLä¿¡å·ç»ˆæ­¢ï¼Œä¹‹åé‡æ–°æ‰§è¡Œã€‚\n#é€šçŸ¥å‹è„šæœ¬:å½“sentinelæœ‰ä»»ä½•è­¦å‘Šçº§åˆ«çš„äº‹ä»¶å‘ç”Ÿæ—¶ï¼ˆæ¯”å¦‚è¯´rediså®ä¾‹çš„ä¸»è§‚å¤±æ•ˆå’Œå®¢è§‚å¤±æ•ˆç­‰ç­‰ï¼‰ï¼Œ å°†ä¼šå»è°ƒç”¨è¿™ä¸ªè„šæœ¬ï¼Œè¿™æ—¶è¿™ä¸ªè„šæœ¬åº”è¯¥é€šè¿‡é‚®ä»¶ï¼ŒSMSç­‰æ–¹å¼å»é€šçŸ¥ç³»ç»Ÿç®¡ç†å‘˜å…³äºç³»ç»Ÿä¸æ­£å¸¸è¿è¡Œçš„ä¿¡ æ¯ã€‚è°ƒç”¨è¯¥è„šæœ¬æ—¶ï¼Œå°†ä¼ ç»™è„šæœ¬ä¸¤ä¸ªå‚æ•°ï¼Œä¸€ä¸ªæ˜¯äº‹ä»¶çš„ç±»å‹ï¼Œä¸€ä¸ªæ˜¯äº‹ä»¶çš„æè¿°ã€‚å¦‚æœsentinel.confé… ç½®æ–‡ä»¶ä¸­é…ç½®äº†è¿™ä¸ªè„šæœ¬è·¯å¾„ï¼Œé‚£ä¹ˆå¿…é¡»ä¿è¯è¿™ä¸ªè„šæœ¬å­˜åœ¨äºè¿™ä¸ªè·¯å¾„ï¼Œå¹¶ä¸”æ˜¯å¯æ‰§è¡Œçš„ï¼Œå¦åˆ™sentinelæ—  æ³•æ­£å¸¸å¯åŠ¨æˆåŠŸã€‚\n#é€šçŸ¥è„šæœ¬\n# shellç¼–ç¨‹\n# sentinel notification-script &lt;master-name&gt; &lt;script-path&gt; sentinel\nnotification-script mymaster /var/redis/notify.sh\n \n# å®¢æˆ·ç«¯é‡æ–°é…ç½®ä¸»èŠ‚ç‚¹å‚æ•°è„šæœ¬\n# å½“ä¸€ä¸ªmasterç”±äºfailoverè€Œå‘ç”Ÿæ”¹å˜æ—¶ï¼Œè¿™ä¸ªè„šæœ¬å°†ä¼šè¢«è°ƒç”¨ï¼Œé€šçŸ¥ç›¸å…³çš„å®¢æˆ·ç«¯å…³äºmasteråœ°å€å·² ç»å‘ç”Ÿæ”¹å˜çš„ä¿¡æ¯ã€‚\n# ä»¥ä¸‹å‚æ•°å°†ä¼šåœ¨è°ƒç”¨è„šæœ¬æ—¶ä¼ ç»™è„šæœ¬:\n# &lt;master-name&gt; &lt;role&gt; &lt;state&gt; &lt;from-ip&gt; &lt;from-port&gt; &lt;to-ip&gt; &lt;to-port&gt; # ç›®å‰&lt;state&gt;æ€»æ˜¯â€œfailoverâ€,\n# &lt;role&gt;æ˜¯â€œleaderâ€æˆ–è€…â€œobserverâ€ä¸­çš„ä¸€ä¸ªã€‚\n# å‚æ•° from-ip, from-port, to-ip, to-portæ˜¯ç”¨æ¥å’Œæ—§çš„masterå’Œæ–°çš„master(å³æ—§çš„slave)é€š ä¿¡çš„# è¿™ä¸ªè„šæœ¬åº”è¯¥æ˜¯é€šç”¨çš„ï¼Œèƒ½è¢«å¤šæ¬¡è°ƒç”¨ï¼Œä¸æ˜¯é’ˆå¯¹æ€§çš„ã€‚\n# sentinel client-reconfig-script &lt;master-name&gt; &lt;script-path&gt; sentinel client-reconfig-\nscript mymaster /var/redis/reconfig.sh\n</code></pre>\n<p><em>å†å»çœ‹ä¸€ä¸‹ redis çš„é…ç½®æ–‡ä»¶å’Œå“¨å…µçš„é…ç½®æ–‡ä»¶ï¼Œä½ ä¼šæƒŠè®¶çš„å‘ç°ï¼Œé‡Œè¾¹çš„é…ç½®æ–‡ä»¶å·²ç»è¢«æ”¹è¿‡æ¥äº†ã€‚</em></p>\n<pre><code>cat redis.con\n...\nreplicaof 192.168.40.103 6379\n</code></pre>\n",
            "tags": [
                "Redis"
            ]
        },
        {
            "id": "http://ixuyong.cn/posts/3166738000.html",
            "url": "http://ixuyong.cn/posts/3166738000.html",
            "title": "Kubeadmé«˜å¯ç”¨å®‰è£…K8sé›†ç¾¤",
            "date_published": "2025-04-09T10:28:34.000Z",
            "content_html": "<h2 id=\"kubeadmé«˜å¯ç”¨å®‰è£…k8sé›†ç¾¤\"><a class=\"anchor\" href=\"#kubeadmé«˜å¯ç”¨å®‰è£…k8sé›†ç¾¤\">#</a> Kubeadm é«˜å¯ç”¨å®‰è£… K8s é›†ç¾¤</h2>\n<h4 id=\"1-åŸºæœ¬é…ç½®\"><a class=\"anchor\" href=\"#1-åŸºæœ¬é…ç½®\">#</a> 1. åŸºæœ¬é…ç½®</h4>\n<h5 id=\"11-åŸºæœ¬ç¯å¢ƒé…ç½®\"><a class=\"anchor\" href=\"#11-åŸºæœ¬ç¯å¢ƒé…ç½®\">#</a> 1.1 åŸºæœ¬ç¯å¢ƒé…ç½®</h5>\n<table>\n<thead>\n<tr>\n<th>ä¸»æœºå</th>\n<th>IP åœ°å€</th>\n<th>è¯´æ˜</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>k8s-master01 ~ 03</td>\n<td>192.168.1.71 ~ 73</td>\n<td>master èŠ‚ç‚¹ * 3</td>\n</tr>\n<tr>\n<td>/</td>\n<td>192.168.1.70</td>\n<td>keepalived è™šæ‹Ÿ IPï¼ˆä¸å ç”¨æœºå™¨ï¼‰</td>\n</tr>\n<tr>\n<td>k8s-node01 ~ 02</td>\n<td>192.168.1.74/75</td>\n<td>worker èŠ‚ç‚¹ * 2</td>\n</tr>\n</tbody>\n</table>\n<p><em>è¯·ç»Ÿä¸€æ›¿æ¢è¿™äº›ç½‘æ®µï¼ŒPod ç½‘æ®µå’Œ service å’Œå®¿ä¸»æœºç½‘æ®µä¸è¦é‡å¤ï¼ï¼ï¼</em></p>\n<table>\n<thead>\n<tr>\n<th><em><strong>* é…ç½®ä¿¡æ¯ *</strong></em></th>\n<th>å¤‡æ³¨</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ç³»ç»Ÿç‰ˆæœ¬</td>\n<td>Rocky Linux 8/9</td>\n</tr>\n<tr>\n<td>Containerd</td>\n<td>latest</td>\n</tr>\n<tr>\n<td>Pod ç½‘æ®µ</td>\n<td>172.16.0.0/16</td>\n</tr>\n<tr>\n<td>Service ç½‘æ®µ</td>\n<td>10.96.0.0/16</td>\n</tr>\n</tbody>\n</table>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>æ›´æ”¹ä¸»æœºåï¼ˆå…¶å®ƒèŠ‚ç‚¹æŒ‰éœ€ä¿®æ”¹ï¼‰ï¼š</p>\n<pre><code>hostnamectl set-hostname k8s-master01 \n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>é…ç½® hostsï¼Œä¿®æ”¹ /etc/hosts å¦‚ä¸‹ï¼š</p>\n<pre><code>[root@k8s-master01 ~]# cat /etc/hosts\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n192.168.1.71 k8s-master01\n192.168.1.72 k8s-master02\n192.168.1.73 k8s-master03\n192.168.1.74 k8s-node01\n192.168.1.75 k8s-node02\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>é…ç½® yum æºï¼š</p>\n<pre><code># é…ç½®åŸºç¡€æº\nsed -e 's|^mirrorlist=|#mirrorlist=|g' \\\n    -e 's|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g' \\\n    -i.bak \\\n    /etc/yum.repos.d/*.repo\n\nyum makecache\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>å¿…å¤‡å·¥å…·å®‰è£…ï¼š</p>\n<pre><code>yum install wget jq psmisc vim net-tools telnet yum-utils device-mapper-persistent-data lvm2 git rsyslog -y\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>å…³é—­é˜²ç«å¢™ã€selinuxã€dnsmasqã€swapã€å¼€å¯ rsyslogã€‚æœåŠ¡å™¨é…ç½®å¦‚ä¸‹ï¼š</p>\n<pre><code>systemctl disable --now firewalld \nsystemctl disable --now dnsmasq\nsetenforce 0\nsed -i 's#SELINUX=enforcing#SELINUX=disabled#g' /etc/sysconfig/selinux\nsed -i 's#SELINUX=enforcing#SELINUX=disabled#g' /etc/selinux/config\nsystemctl enable --now rsyslog\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>å…³é—­ swap åˆ†åŒºï¼š</p>\n<pre><code>swapoff -a &amp;&amp; sysctl -w vm.swappiness=0\nsed -ri '/^[^#]*swap/s@^@#@' /etc/fstab\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>å®‰è£… ntpdateï¼š</p>\n<pre><code>sudo dnf install epel-release -y\nsudo dnf config-manager --set-enabled epel\nsudo dnf install ntpsec\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>åŒæ­¥æ—¶é—´å¹¶é…ç½®ä¸Šæµ·æ—¶åŒºï¼š</p>\n<pre><code>ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime\necho 'Asia/Shanghai' &gt;/etc/timezone\nntpdate time2.aliyun.com\n# åŠ å…¥åˆ°crontab\ncrontab -e\n*/5 * * * * /usr/sbin/ntpdate time2.aliyun.com\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>é…ç½® limitï¼š</p>\n<pre><code>ulimit -SHn 65535\nvim /etc/security/limits.conf\n# æœ«å°¾æ·»åŠ å¦‚ä¸‹å†…å®¹\n* soft nofile 65536\n* hard nofile 131072\n* soft nproc 65535\n* hard nproc 655350\n* soft memlock unlimited\n* hard memlock unlimited\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>å‡çº§ç³»ç»Ÿï¼š</p>\n<pre><code>yum update -y\n</code></pre>\n<p><mark>Master01 èŠ‚ç‚¹</mark>å…å¯†é’¥ç™»å½•å…¶ä»–èŠ‚ç‚¹ï¼Œå®‰è£…è¿‡ç¨‹ä¸­ç”Ÿæˆé…ç½®æ–‡ä»¶å’Œè¯ä¹¦å‡åœ¨ Master01 ä¸Šæ“ä½œï¼Œé›†ç¾¤ç®¡ç†ä¹Ÿåœ¨ Master01 ä¸Šæ“ä½œï¼š</p>\n<pre><code>ssh-keygen -t rsa\nfor i in k8s-master01 k8s-master02 k8s-master03 k8s-node01 k8s-node02;do ssh-copy-id -i .ssh/id_rsa.pub $i;done\n</code></pre>\n<p><em>æ³¨æ„ï¼šå…¬æœ‰äº‘ç¯å¢ƒï¼Œå¯èƒ½éœ€è¦æŠŠ kubectl æ”¾åœ¨ä¸€ä¸ªé Master èŠ‚ç‚¹ä¸Š</em></p>\n<p><mark>Master01 èŠ‚ç‚¹</mark>ä¸‹è½½å®‰è£…æ‰€æœ‰çš„æºç æ–‡ä»¶ï¼š</p>\n<pre><code>cd /root/ ; git clone https://gitee.com/chinagei/k8s-ha-install\n</code></pre>\n<h5 id=\"12-å†…æ ¸é…ç½®\"><a class=\"anchor\" href=\"#12-å†…æ ¸é…ç½®\">#</a> 1.2 å†…æ ¸é…ç½®</h5>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>å®‰è£… ipvsadmï¼š</p>\n<pre><code>yum install ipvsadm ipset sysstat conntrack libseccomp -y\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>é…ç½® ipvs æ¨¡å—ï¼š</p>\n<pre><code>modprobe -- ip_vs\nmodprobe -- ip_vs_rr\nmodprobe -- ip_vs_wrr\nmodprobe -- ip_vs_sh\nmodprobe -- nf_conntrack\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>åˆ›å»º ipvs.confï¼Œå¹¶é…ç½®å¼€æœºè‡ªåŠ¨åŠ è½½ï¼š</p>\n<pre><code>vim /etc/modules-load.d/ipvs.conf \n# åŠ å…¥ä»¥ä¸‹å†…å®¹\nip_vs\nip_vs_lc\nip_vs_wlc\nip_vs_rr\nip_vs_wrr\nip_vs_lblc\nip_vs_lblcr\nip_vs_dh\nip_vs_sh\nip_vs_fo\nip_vs_nq\nip_vs_sed\nip_vs_ftp\nip_vs_sh\nnf_conntrack\nip_tables\nip_set\nxt_set\nipt_set\nipt_rpfilter\nipt_REJECT\nipip\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>ç„¶åæ‰§è¡Œ systemctl enable --now systemd-modules-load.service å³å¯ï¼ˆæŠ¥é”™ä¸ç”¨ç®¡ï¼‰</p>\n<pre><code>systemctl enable --now systemd-modules-load.service\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>å†…æ ¸ä¼˜åŒ–é…ç½®ï¼š</p>\n<pre><code>cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.conf\nnet.ipv4.ip_forward = 1\nnet.bridge.bridge-nf-call-iptables = 1\nnet.bridge.bridge-nf-call-ip6tables = 1\nfs.may_detach_mounts = 1\nnet.ipv4.conf.all.route_localnet = 1\nvm.overcommit_memory=1\nvm.panic_on_oom=0\nfs.inotify.max_user_watches=89100\nfs.file-max=52706963\nfs.nr_open=52706963\nnet.netfilter.nf_conntrack_max=2310720\n\nnet.ipv4.tcp_keepalive_time = 600\nnet.ipv4.tcp_keepalive_probes = 3\nnet.ipv4.tcp_keepalive_intvl =15\nnet.ipv4.tcp_max_tw_buckets = 36000\nnet.ipv4.tcp_tw_reuse = 1\nnet.ipv4.tcp_max_orphans = 327680\nnet.ipv4.tcp_orphan_retries = 3\nnet.ipv4.tcp_syncookies = 1\nnet.ipv4.tcp_max_syn_backlog = 16384\nnet.ipv4.ip_conntrack_max = 65536\nnet.ipv4.tcp_max_syn_backlog = 16384\nnet.ipv4.tcp_timestamps = 0\nnet.core.somaxconn = 16384\nEOF\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>åº”ç”¨é…ç½®ï¼š</p>\n<pre><code>sysctl --system\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>é…ç½®å®Œå†…æ ¸åï¼Œé‡å¯æœºå™¨ï¼Œä¹‹åæŸ¥çœ‹å†…æ ¸æ¨¡å—æ˜¯å¦å·²è‡ªåŠ¨åŠ è½½ï¼š</p>\n<pre><code>reboot\nlsmod | grep --color=auto -e ip_vs -e nf_conntrack\n</code></pre>\n<h4 id=\"2-é«˜å¯ç”¨ç»„ä»¶å®‰è£…\"><a class=\"anchor\" href=\"#2-é«˜å¯ç”¨ç»„ä»¶å®‰è£…\">#</a> 2. é«˜å¯ç”¨ç»„ä»¶å®‰è£…</h4>\n<p><em>æ³¨æ„ï¼šå¦‚æœå®‰è£…çš„ä¸æ˜¯é«˜å¯ç”¨é›†ç¾¤ï¼Œhaproxy å’Œ keepalived æ— éœ€å®‰è£…</em></p>\n<p><em>æ³¨æ„ï¼šå…¬æœ‰äº‘è¦ç”¨å…¬æœ‰äº‘è‡ªå¸¦çš„è´Ÿè½½å‡è¡¡ï¼Œæ¯”å¦‚é˜¿é‡Œäº‘çš„ SLBã€NLBï¼Œè…¾è®¯äº‘çš„ ELBï¼Œç”¨æ¥æ›¿ä»£ haproxy å’Œ keepalivedï¼Œå› ä¸ºå…¬æœ‰äº‘å¤§éƒ¨åˆ†éƒ½æ˜¯ä¸æ”¯æŒ keepalived çš„ã€‚</em></p>\n<p><mark>æ‰€æœ‰ Master èŠ‚ç‚¹</mark>é€šè¿‡ yum å®‰è£… HAProxy å’Œ KeepAlivedï¼š</p>\n<pre><code>yum install keepalived haproxy -y\n</code></pre>\n<p><mark>æ‰€æœ‰ Master èŠ‚ç‚¹</mark>é…ç½® HAProxyï¼Œéœ€è¦æ³¨æ„é»„è‰²éƒ¨åˆ†çš„ IPï¼š</p>\n<pre><code>[root@k8s-master01 etc]# mkdir /etc/haproxy\n[root@k8s-master01 etc]# vim /etc/haproxy/haproxy.cfg \nglobal\n  maxconn  2000\n  ulimit-n  16384\n  log  127.0.0.1 local0 err\n  stats timeout 30s\n\ndefaults\n  log global\n  mode  http\n  option  httplog\n  timeout connect 5000\n  timeout client  50000\n  timeout server  50000\n  timeout http-request 15s\n  timeout http-keep-alive 15s\n\nfrontend monitor-in\n  bind *:33305\n  mode http\n  option httplog\n  monitor-uri /monitor\n\nfrontend k8s-master\n  bind 0.0.0.0:16443       #HAProxyç›‘å¬ç«¯å£\n  bind 127.0.0.1:16443     #HAProxyç›‘å¬ç«¯å£\n  mode tcp\n  option tcplog\n  tcp-request inspect-delay 5s\n  default_backend k8s-master\n\nbackend k8s-master\n  mode tcp\n  option tcplog\n  option tcp-check\n  balance roundrobin\n  default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100\n  server k8s-master01\t192.168.1.71:6443  check       #API Server IPåœ°å€\n  server k8s-master02\t192.168.1.72:6443  check       #API Server IPåœ°å€\n  server k8s-master03\t192.168.1.73:6443  check       #API Server IPåœ°å€\n</code></pre>\n<p><mark>æ‰€æœ‰ Master èŠ‚ç‚¹</mark>é…ç½® KeepAlivedï¼Œéœ€è¦æ³¨æ„é»„è‰²éƒ¨åˆ†çš„é…ç½®ã€‚</p>\n<p><mark>Master01 èŠ‚ç‚¹</mark>çš„é…ç½®ï¼š</p>\n<pre><code>[root@k8s-master01 etc]# mkdir /etc/keepalived\n\n[root@k8s-master01 ~]# vim /etc/keepalived/keepalived.conf \n! Configuration File for keepalived\nglobal_defs &#123;\n    router_id LVS_DEVEL\nscript_user root\n    enable_script_security\n&#125;\nvrrp_script chk_apiserver &#123;\n    script &quot;/etc/keepalived/check_apiserver.sh&quot;\n    interval 5\n    weight -5\n    fall 2  \nrise 1\n&#125;\nvrrp_instance VI_1 &#123;\n    state MASTER\n    interface ens160               #ç½‘å¡åç§°\n    mcast_src_ip 192.168.1.71      #K8s-master01 IPåœ°å€\n    virtual_router_id 51\n    priority 101\n    advert_int 2\n    authentication &#123;\n        auth_type PASS\n        auth_pass K8SHA_KA_AUTH\n    &#125;\n    virtual_ipaddress &#123;\n        192.168.1.70        #VIPåœ°å€\n    &#125;\n    track_script &#123;\n       chk_apiserver\n    &#125;\n&#125;\t\n</code></pre>\n<p><mark>Master02 èŠ‚ç‚¹</mark>çš„é…ç½®ï¼š</p>\n<pre><code># vim /etc/keepalived/keepalived.conf \n\n! Configuration File for keepalived\nglobal_defs &#123;\n    router_id LVS_DEVEL\nscript_user root\n    enable_script_security\n&#125;\nvrrp_script chk_apiserver &#123;\n    script &quot;/etc/keepalived/check_apiserver.sh&quot;\n   interval 5\n    weight -5\n    fall 2  \nrise 1\n&#125;\nvrrp_instance VI_1 &#123;\n    state BACKUP\n    interface ens160                #ç½‘å¡åç§°\n    mcast_src_ip 192.168.1.72       #K8s-master02 IPåœ°å€\n    virtual_router_id 51\n    priority 100\n    advert_int 2\n    authentication &#123;\n        auth_type PASS\n        auth_pass K8SHA_KA_AUTH\n    &#125;\n    virtual_ipaddress &#123;\n        192.168.1.70              #VIPåœ°å€\n    &#125;\n    track_script &#123;\n       chk_apiserver\n    &#125;\n&#125;\n</code></pre>\n<p><mark>Master03 èŠ‚ç‚¹</mark>çš„é…ç½®ï¼š</p>\n<pre><code># vim /etc/keepalived/keepalived.conf \n\n! Configuration File for keepalived\nglobal_defs &#123;\n    router_id LVS_DEVEL\nscript_user root\n    enable_script_security\n&#125;\nvrrp_script chk_apiserver &#123;\n    script &quot;/etc/keepalived/check_apiserver.sh&quot;\n interval 5\n    weight -5\n    fall 2  \nrise 1\n&#125;\nvrrp_instance VI_1 &#123;\n    state BACKUP\n    interface ens160                 #ç½‘å¡åç§°\n    mcast_src_ip 192.168.1.73        #K8s-master03 IPåœ°å€\n    virtual_router_id 51\n    priority 100\n    advert_int 2\n    authentication &#123;\n        auth_type PASS\n        auth_pass K8SHA_KA_AUTH\n    &#125;\n    virtual_ipaddress &#123;\n        192.168.1.70          #VIPåœ°å€\n    &#125;\n    track_script &#123;\n       chk_apiserver\n    &#125;\n&#125;\n</code></pre>\n<p><mark>æ‰€æœ‰ master èŠ‚ç‚¹</mark>é…ç½® KeepAlived å¥åº·æ£€æŸ¥æ–‡ä»¶ï¼š</p>\n<pre><code>[root@k8s-master01 keepalived]# vim /etc/keepalived/check_apiserver.sh \n#!/bin/bash\n\nerr=0\nfor k in $(seq 1 3)\ndo\n    check_code=$(pgrep haproxy)\n    if [[ $check_code == &quot;&quot; ]]; then\n        err=$(expr $err + 1)\n        sleep 1\n        continue\n    else\n        err=0\n        break\n    fi\ndone\n\nif [[ $err != &quot;0&quot; ]]; then\n    echo &quot;systemctl stop keepalived&quot;\n    /usr/bin/systemctl stop keepalived\n    exit 1\nelse\n    exit 0\nfi\n</code></pre>\n<p><mark>æ‰€æœ‰ master èŠ‚ç‚¹</mark>é…ç½®å¥åº·æ£€æŸ¥æ–‡ä»¶æ·»åŠ æ‰§è¡Œæƒé™ï¼š</p>\n<pre><code>chmod +x /etc/keepalived/check_apiserver.sh\n</code></pre>\n<p><mark>æ‰€æœ‰ master èŠ‚ç‚¹</mark>å¯åŠ¨ haproxy å’Œ keepalivedï¼š</p>\n<pre><code>[root@k8s-master01 keepalived]# systemctl daemon-reload\n[root@k8s-master01 keepalived]# systemctl enable --now haproxy\n[root@k8s-master01 keepalived]# systemctl enable --now keepalived\n</code></pre>\n<p>é‡è¦ï¼šå¦‚æœå®‰è£…äº† keepalived å’Œ haproxyï¼Œéœ€è¦æµ‹è¯• keepalived æ˜¯å¦æ˜¯æ­£å¸¸çš„</p>\n<pre><code>æ‰€æœ‰èŠ‚ç‚¹æµ‹è¯•VIP\n[root@k8s-master01 ~]# ping 192.168.1.70 -c 4\nPING 192.168.1.70 (192.168.1.70) 56(84) bytes of data.\n64 bytes from 192.168.1.70: icmp_seq=1 ttl=64 time=0.464 ms\n64 bytes from 192.168.1.70: icmp_seq=2 ttl=64 time=0.063 ms\n64 bytes from 192.168.1.70: icmp_seq=3 ttl=64 time=0.062 ms\n64 bytes from 192.168.1.70: icmp_seq=4 ttl=64 time=0.063 ms\n\n[root@k8s-master01 ~]# telnet 192.168.1.70 16443\nTrying 192.168.1.70...\nConnected to 192.168.1.70.\nEscape character is '^]'.\nConnection closed by foreign host.\n</code></pre>\n<p>å¦‚æœ ping ä¸é€šä¸” telnet æ²¡æœ‰å‡ºç° ] ï¼Œåˆ™è®¤ä¸º VIP ä¸å¯ä»¥ï¼Œä¸å¯åœ¨ç»§ç»­å¾€ä¸‹æ‰§è¡Œï¼Œéœ€è¦æ’æŸ¥ keepalived çš„é—®é¢˜ï¼Œæ¯”å¦‚é˜²ç«å¢™å’Œ selinuxï¼Œhaproxy å’Œ keepalived çš„çŠ¶æ€ï¼Œç›‘å¬ç«¯å£ç­‰</p>\n<ul>\n<li>æ‰€æœ‰èŠ‚ç‚¹æŸ¥çœ‹é˜²ç«å¢™çŠ¶æ€å¿…é¡»ä¸º disable å’Œ inactiveï¼šsystemctl status firewalld</li>\n<li>æ‰€æœ‰èŠ‚ç‚¹æŸ¥çœ‹ selinux çŠ¶æ€ï¼Œå¿…é¡»ä¸º disableï¼šgetenforce</li>\n<li>master èŠ‚ç‚¹æŸ¥çœ‹ haproxy å’Œ keepalived çŠ¶æ€ï¼šsystemctl status keepalived haproxy</li>\n<li>master èŠ‚ç‚¹æŸ¥çœ‹ç›‘å¬ç«¯å£ï¼šnetstat -lntp</li>\n</ul>\n<p>å¦‚æœä»¥ä¸Šéƒ½æ²¡æœ‰é—®é¢˜ï¼Œéœ€è¦ç¡®è®¤ï¼š</p>\n<ol>\n<li>\n<p>æ˜¯å¦æ˜¯å…¬æœ‰äº‘æœºå™¨</p>\n</li>\n<li>\n<p>æ˜¯å¦æ˜¯ç§æœ‰äº‘æœºå™¨ï¼ˆç±»ä¼¼ OpenStackï¼‰</p>\n</li>\n</ol>\n<p>ä¸Šè¿°å…¬æœ‰äº‘ä¸€èˆ¬éƒ½æ˜¯ä¸æ”¯æŒ keepalivedï¼Œç§æœ‰äº‘å¯èƒ½ä¹Ÿæœ‰é™åˆ¶ï¼Œéœ€è¦å’Œè‡ªå·±çš„ç§æœ‰äº‘ç®¡ç†å‘˜å’¨è¯¢</p>\n<h4 id=\"3-runtimeå®‰è£…\"><a class=\"anchor\" href=\"#3-runtimeå®‰è£…\">#</a> 3. Runtime å®‰è£…</h4>\n<p>å¦‚æœå®‰è£…çš„ç‰ˆæœ¬ä½äº 1.24ï¼Œé€‰æ‹© Docker å’Œ Containerd å‡å¯ï¼Œé«˜äº 1.24 å»ºè®®é€‰æ‹© Containerd ä½œä¸º Runtimeï¼Œä¸å†æ¨èä½¿ç”¨ Docker ä½œä¸º Runtimeã€‚</p>\n<h5 id=\"31-å®‰è£…containerd\"><a class=\"anchor\" href=\"#31-å®‰è£…containerd\">#</a> 3.1 å®‰è£… Containerd</h5>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>é…ç½®å®‰è£…æºï¼š</p>\n<pre><code>yum install wget jq psmisc vim net-tools telnet yum-utils device-mapper-persistent-data lvm2 git -y\nyum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>å®‰è£… docker-ceï¼ˆå¦‚æœåœ¨ä»¥å‰å·²ç»å®‰è£…è¿‡ï¼Œéœ€è¦é‡æ–°å®‰è£…æ›´æ–°ä¸€ä¸‹ï¼‰ï¼š</p>\n<pre><code># yum install docker-ce containerd -y\n</code></pre>\n<p><em>å¯ä»¥æ— éœ€å¯åŠ¨ Dockerï¼Œåªéœ€è¦é…ç½®å’Œå¯åŠ¨ Containerd å³å¯ã€‚</em></p>\n<p>é¦–å…ˆé…ç½® Containerd æ‰€éœ€çš„æ¨¡å—ï¼ˆ<mark>æ‰€æœ‰èŠ‚ç‚¹</mark>ï¼‰ï¼š</p>\n<pre><code># cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf\noverlay\nbr_netfilter\nEOF\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>åŠ è½½æ¨¡å—ï¼š</p>\n<pre><code># modprobe -- overlay\n# modprobe -- br_netfilter\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>ï¼Œé…ç½® Containerd æ‰€éœ€çš„å†…æ ¸ï¼š</p>\n<pre><code># cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf\nnet.bridge.bridge-nf-call-iptables  = 1\nnet.ipv4.ip_forward                 = 1\nnet.bridge.bridge-nf-call-ip6tables = 1\nEOF\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>åŠ è½½å†…æ ¸ï¼š</p>\n<pre><code># sysctl --system\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>ç”Ÿæˆ Containerd çš„é…ç½®æ–‡ä»¶ï¼š</p>\n<pre><code># mkdir -p /etc/containerd\n# containerd config default | tee /etc/containerd/config.toml\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>æ›´æ”¹ Containerd çš„ Cgroup å’Œ Pause é•œåƒé…ç½®ï¼š</p>\n<pre><code>sed -i 's#SystemdCgroup = false#SystemdCgroup = true#g' /etc/containerd/config.toml\nsed -i 's#k8s.gcr.io/pause#registry.cn-hangzhou.aliyuncs.com/google_containers/pause#g'  /etc/containerd/config.toml\nsed -i 's#registry.gcr.io/pause#registry.cn-hangzhou.aliyuncs.com/google_containers/pause#g'  /etc/containerd/config.toml\nsed -i 's#registry.k8s.io/pause#registry.cn-hangzhou.aliyuncs.com/google_containers/pause#g'  /etc/containerd/config.toml\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>å¯åŠ¨ Containerdï¼Œå¹¶é…ç½®å¼€æœºè‡ªå¯åŠ¨ï¼š</p>\n<pre><code># systemctl daemon-reload\n# systemctl enable --now containerd\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>é…ç½® crictl å®¢æˆ·ç«¯è¿æ¥çš„è¿è¡Œæ—¶ä½ç½®ï¼ˆå¯é€‰ï¼‰ï¼š</p>\n<pre><code># cat &gt; /etc/crictl.yaml &lt;&lt;EOF\nruntime-endpoint: unix:///run/containerd/containerd.sock\nimage-endpoint: unix:///run/containerd/containerd.sock\ntimeout: 10\ndebug: false\nEOF\n</code></pre>\n<h4 id=\"4-å®‰è£…kubernetesç»„ä»¶\"><a class=\"anchor\" href=\"#4-å®‰è£…kubernetesç»„ä»¶\">#</a> 4 . å®‰è£… Kubernetes ç»„ä»¶</h4>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>é…ç½®æºï¼ˆæ³¨æ„æ›´æ”¹ç‰ˆæœ¬å·ï¼‰ï¼š</p>\n<pre><code>cat &lt;&lt;EOF | tee /etc/yum.repos.d/kubernetes.repo\n[kubernetes]\nname=Kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/rpm/\nenabled=1\ngpgcheck=1\ngpgkey=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/rpm/repodata/repomd.xml.key\nEOF\n</code></pre>\n<p>é¦–å…ˆåœ¨<mark> Master01 èŠ‚ç‚¹</mark>æŸ¥çœ‹æœ€æ–°çš„ Kubernetes ç‰ˆæœ¬æ˜¯å¤šå°‘ï¼š</p>\n<pre><code># yum list kubeadm.x86_64 --showduplicates | sort -r\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>å®‰è£… 1.32 æœ€æ–°ç‰ˆæœ¬ kubeadmã€kubelet å’Œ kubectlï¼š</p>\n<pre><code># yum install kubeadm-1.32* kubelet-1.32* kubectl-1.32* -y\n</code></pre>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>è®¾ç½® Kubelet å¼€æœºè‡ªå¯åŠ¨ï¼ˆç”±äºè¿˜æœªåˆå§‹åŒ–ï¼Œæ²¡æœ‰ kubelet çš„é…ç½®æ–‡ä»¶ï¼Œæ­¤æ—¶ kubelet æ— æ³•å¯åŠ¨ï¼Œæ— éœ€å…³å¿ƒï¼‰ï¼š</p>\n<pre><code># systemctl daemon-reload\n# systemctl enable --now kubelet\n</code></pre>\n<p><em>æ­¤æ—¶ kubelet æ˜¯èµ·ä¸æ¥çš„ï¼Œæ—¥å¿—ä¼šæœ‰æŠ¥é”™ä¸å½±å“ï¼</em></p>\n<h4 id=\"5-é›†ç¾¤åˆå§‹åŒ–\"><a class=\"anchor\" href=\"#5-é›†ç¾¤åˆå§‹åŒ–\">#</a> 5 . é›†ç¾¤åˆå§‹åŒ–</h4>\n<p>ä»¥ä¸‹æ“ä½œåœ¨<mark> master01</mark>ï¼ˆæ³¨æ„é»„è‰²éƒ¨åˆ†ï¼‰ï¼š</p>\n<pre><code>vim kubeadm-config.yaml\napiVersion: kubeadm.k8s.io/v1beta3\nbootstrapTokens:\n- groups:\n  - system:bootstrappers:kubeadm:default-node-token\n  token: 7t2weq.bjbawausm0jaxury\n  ttl: 24h0m0s\n  usages:\n  - signing\n  - authentication\nkind: InitConfiguration\nlocalAPIEndpoint:\n  advertiseAddress: 192.168.1.71\n  bindPort: 6443\nnodeRegistration:\n  criSocket: unix:///var/run/containerd/containerd.sock\n  name: k8s-master01\n  taints:\n  - effect: NoSchedule\n    key: node-role.kubernetes.io/control-plane\n---\napiServer:\n  certSANs:\n  - 192.168.1.70               # å¦‚æœæ­å»ºçš„ä¸æ˜¯é«˜å¯ç”¨é›†ç¾¤ï¼ŒæŠŠæ­¤å¤„æ”¹ä¸ºmasterçš„IP\n  timeoutForControlPlane: 4m0s\napiVersion: kubeadm.k8s.io/v1beta3\ncertificatesDir: /etc/kubernetes/pki\nclusterName: kubernetes\ncontrolPlaneEndpoint: 192.168.1.70:16443 # å¦‚æœæ­å»ºçš„ä¸æ˜¯é«˜å¯ç”¨é›†ç¾¤ï¼ŒæŠŠæ­¤å¤„IPæ”¹ä¸ºmasterçš„IPï¼Œç«¯å£æ”¹æˆ6443\ncontrollerManager: &#123;&#125;\netcd:\n  local:\n    dataDir: /var/lib/etcd\nimageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers\nkind: ClusterConfiguration\nkubernetesVersion: v1.32.3    # æ›´æ”¹æ­¤å¤„çš„ç‰ˆæœ¬å·å’Œkubeadm versionä¸€è‡´\nnetworking:\n  dnsDomain: cluster.local\n  podSubnet: 172.16.0.0/16    # æ³¨æ„æ­¤å¤„çš„ç½‘æ®µï¼Œä¸è¦ä¸serviceå’ŒèŠ‚ç‚¹ç½‘æ®µå†²çª\n  serviceSubnet: 10.96.0.0/16 # æ³¨æ„æ­¤å¤„çš„ç½‘æ®µï¼Œä¸è¦ä¸podå’ŒèŠ‚ç‚¹ç½‘æ®µå†²çª\nscheduler: &#123;&#125;\n</code></pre>\n<p><mark>master01 èŠ‚ç‚¹</mark>æ›´æ–° kubeadm æ–‡ä»¶ï¼š</p>\n<pre><code>kubeadm config migrate --old-config kubeadm-config.yaml --new-config new.yaml\n</code></pre>\n<p>å°† new.yaml æ–‡ä»¶å¤åˆ¶åˆ°<mark>å…¶ä»– master èŠ‚ç‚¹</mark>:</p>\n<pre><code>for i in k8s-master02 k8s-master03; do scp new.yaml $i:/root/; done\n</code></pre>\n<p>ä¹‹å<mark>æ‰€æœ‰ Master èŠ‚ç‚¹</mark>æå‰ä¸‹è½½é•œåƒï¼Œå¯ä»¥èŠ‚çœåˆå§‹åŒ–æ—¶é—´ï¼ˆå…¶ä»–èŠ‚ç‚¹ä¸éœ€è¦æ›´æ”¹ä»»ä½•é…ç½®ï¼ŒåŒ…æ‹¬ IP åœ°å€ä¹Ÿä¸éœ€è¦æ›´æ”¹ï¼‰ï¼š</p>\n<pre><code>kubeadm config images pull --config /root/new.yaml \n</code></pre>\n<p>æ­£ç¡®çš„åé¦ˆä¿¡æ¯å¦‚ä¸‹ï¼ˆ<em><strong>* ç‰ˆæœ¬å¯èƒ½ä¸ä¸€æ · *</strong></em>ï¼‰ï¼š</p>\n<pre><code>[root@k8s-master02 ~]# kubeadm config images pull --config /root/new.yaml \n[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.32.0\n[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.32.0\n[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.32.0\n[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.32.0\n[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.11.3\n[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.10\n[config/images] Pulled registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.5.16-0\n</code></pre>\n<p><mark>Master01 èŠ‚ç‚¹</mark>åˆå§‹åŒ–ï¼Œåˆå§‹åŒ–ä»¥åä¼šåœ¨ /etc/kubernetes ç›®å½•ä¸‹ç”Ÿæˆå¯¹åº”çš„è¯ä¹¦å’Œé…ç½®æ–‡ä»¶ï¼Œä¹‹åå…¶ä»– Master èŠ‚ç‚¹åŠ å…¥ Master01 å³å¯ï¼š</p>\n<pre><code>kubeadm init --config /root/new.yaml  --upload-certs\n</code></pre>\n<p>åˆå§‹åŒ–æˆåŠŸä»¥åï¼Œä¼šäº§ç”Ÿ Token å€¼ï¼Œç”¨äºå…¶ä»–èŠ‚ç‚¹åŠ å…¥æ—¶ä½¿ç”¨ï¼Œå› æ­¤è¦è®°å½•ä¸‹åˆå§‹åŒ–æˆåŠŸç”Ÿæˆçš„ token å€¼ï¼ˆä»¤ç‰Œå€¼ï¼‰ï¼š</p>\n<pre><code>Your Kubernetes control-plane has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nAlternatively, if you are the root user, you can run:\n\n  export KUBECONFIG=/etc/kubernetes/admin.conf\n\nYou should now deploy a pod network to the cluster.\nRun &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nYou can now join any number of the control-plane node running the following command on each as root:\n\n# ä¸è¦å¤åˆ¶æ–‡æ¡£å½“ä¸­çš„ï¼Œè¦å»ä½¿ç”¨èŠ‚ç‚¹ç”Ÿæˆçš„\n  kubeadm join 192.168.1.70:16443 --token 7t2weq.bjbawausm0jaxury \\\n\t--discovery-token-ca-cert-hash sha256:df72788de04bbc2e8fca70becb8a9e8503a962b5d7cd9b1842a0c39930d08c94 \\\n\t--control-plane --certificate-key c595f7f4a7a3beb0d5bdb75d9e4eff0a60b977447e76c1d6885e82c3aa43c94c\n\nPlease note that the certificate-key gives access to cluster sensitive data, keep it secret!\nAs a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use\n&quot;kubeadm init phase upload-certs --upload-certs&quot; to reload certs afterward.\n\nThen you can join any number of worker nodes by running the following on each as root:\n\nkubeadm join 192.168.1.70:16443 --token 7t2weq.bjbawausm0jaxury \\\n\t--discovery-token-ca-cert-hash sha256:df72788de04bbc2e8fca70becb8a9e8503a962b5d7cd9b1842a0c39930d08c94\n</code></pre>\n<p><mark>Master01 èŠ‚ç‚¹</mark>é…ç½®ç¯å¢ƒå˜é‡ï¼Œç”¨äºè®¿é—® Kubernetes é›†ç¾¤ï¼š</p>\n<pre><code>cat &lt;&lt;EOF &gt;&gt; /root/.bashrc\nexport KUBECONFIG=/etc/kubernetes/admin.conf\nEOF\nsource /root/.bashrc\n</code></pre>\n<p><mark>Master01 èŠ‚ç‚¹</mark>æŸ¥çœ‹èŠ‚ç‚¹çŠ¶æ€ï¼šï¼ˆæ˜¾ç¤º NotReady ä¸å½±å“ï¼‰</p>\n<pre><code># kubectl get node\nNAME           STATUS     ROLES           AGE   VERSION\nk8s-master01   NotReady   control-plane   24s   v1.32.3\n</code></pre>\n<p>é‡‡ç”¨åˆå§‹åŒ–å®‰è£…æ–¹å¼ï¼Œæ‰€æœ‰çš„ç³»ç»Ÿç»„ä»¶å‡ä»¥å®¹å™¨çš„æ–¹å¼è¿è¡Œå¹¶ä¸”åœ¨ kube-system å‘½åç©ºé—´å†…ï¼Œæ­¤æ—¶å¯ä»¥æŸ¥çœ‹ Pod çŠ¶æ€ï¼ˆæ˜¾ç¤º pending ä¸å½±å“ï¼‰ï¼š</p>\n<pre><code class=\"language-\\\"># kubectl get pods -n kube-system\n</code></pre>\n<h5 id=\"51-åˆå§‹åŒ–å¤±è´¥æ’æŸ¥\"><a class=\"anchor\" href=\"#51-åˆå§‹åŒ–å¤±è´¥æ’æŸ¥\">#</a> 5.1 åˆå§‹åŒ–å¤±è´¥æ’æŸ¥</h5>\n<p>å¦‚æœåˆå§‹åŒ–å¤±è´¥ï¼Œé‡ç½®åå†æ¬¡åˆå§‹åŒ–ï¼Œå‘½ä»¤å¦‚ä¸‹ï¼ˆæ²¡æœ‰å¤±è´¥ä¸è¦æ‰§è¡Œï¼‰ï¼š</p>\n<pre><code>kubeadm reset -f ; ipvsadm --clear  ; rm -rf ~/.kube\n</code></pre>\n<p>å¦‚æœå¤šæ¬¡å°è¯•éƒ½æ˜¯åˆå§‹åŒ–å¤±è´¥ï¼Œéœ€è¦çœ‹ç³»ç»Ÿæ—¥å¿—ï¼ŒCentOS/RockyLinux æ—¥å¿—è·¯å¾„:/var/log/messagesï¼ŒUbuntu ç³»åˆ—æ—¥å¿—è·¯å¾„:/var/log/syslogï¼š</p>\n<pre><code>tail -f /var/log/messages | grep -v &quot;not found&quot;\n</code></pre>\n<p>ç»å¸¸å‡ºé”™çš„åŸå› ï¼š</p>\n<ol>\n<li>Containerd çš„é…ç½®æ–‡ä»¶ä¿®æ”¹çš„ä¸å¯¹ï¼Œè‡ªè¡Œå‚è€ƒã€Šå®‰è£… containerdã€‹å°èŠ‚æ ¸å¯¹</li>\n<li>new.yaml é…ç½®é—®é¢˜ï¼Œæ¯”å¦‚éé«˜å¯ç”¨é›†ç¾¤å¿˜è®°ä¿®æ”¹ 16443 ç«¯å£ä¸º 6443</li>\n<li>new.yaml é…ç½®é—®é¢˜ï¼Œä¸‰ä¸ªç½‘æ®µæœ‰äº¤å‰ï¼Œå‡ºç° IP åœ°å€å†²çª</li>\n<li>VIP ä¸é€šå¯¼è‡´æ— æ³•åˆå§‹åŒ–æˆåŠŸï¼Œæ­¤æ—¶ messages æ—¥å¿—ä¼šæœ‰ VIP è¶…æ—¶çš„æŠ¥é”™</li>\n</ol>\n<h5 id=\"52-é«˜å¯ç”¨master\"><a class=\"anchor\" href=\"#52-é«˜å¯ç”¨master\">#</a> 5.2 é«˜å¯ç”¨ Master</h5>\n<p><strong>å…¶ä»– master</strong> åŠ å…¥é›†ç¾¤ï¼Œmaster02 å’Œ master03 åˆ†åˆ«æ‰§è¡Œ (åƒä¸‡ä¸è¦åœ¨ master01 å†æ¬¡æ‰§è¡Œï¼Œä¸èƒ½ç›´æ¥å¤åˆ¶æ–‡æ¡£å½“ä¸­çš„å‘½ä»¤ï¼Œè€Œæ˜¯ä½ è‡ªå·±åˆšæ‰ master01 åˆå§‹åŒ–ä¹‹åäº§ç”Ÿçš„å‘½ä»¤)</p>\n<pre><code>kubeadm join 192.168.1.70:16443 --token 7t2weq.bjbawausm0jaxury \\\n\t--discovery-token-ca-cert-hash sha256:df72788de04bbc2e8fca70becb8a9e8503a962b5d7cd9b1842a0c39930d08c94 \\\n\t--control-plane --certificate-key c595f7f4a7a3beb0d5bdb75d9e4eff0a60b977447e76c1d6885e82c3aa43c94c\n</code></pre>\n<p>æŸ¥çœ‹å½“å‰çŠ¶æ€ï¼šï¼ˆå¦‚æœæ˜¾ç¤º NotReady ä¸å½±å“ï¼‰</p>\n<pre><code># kubectl get node\nNAME           STATUS     ROLES           AGE     VERSION\nk8s-master01   NotReady   control-plane   4m23s   v1.32.3\nk8s-master02   NotReady   control-plane   66s     v1.32.3\nk8s-master03   NotReady   control-plane   14s     v1.32.3\n</code></pre>\n<h5 id=\"53-tokenè¿‡æœŸå¤„ç†\"><a class=\"anchor\" href=\"#53-tokenè¿‡æœŸå¤„ç†\">#</a> 5.3 Token è¿‡æœŸå¤„ç†</h5>\n<p>æ³¨æ„ï¼šä»¥ä¸‹æ­¥éª¤æ˜¯ä¸Šè¿° init å‘½ä»¤äº§ç”Ÿçš„ Token è¿‡æœŸäº†æ‰éœ€è¦æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼Œå¦‚æœæ²¡æœ‰è¿‡æœŸä¸éœ€è¦æ‰§è¡Œï¼Œç›´æ¥ join å³å¯ã€‚</p>\n<p>Token è¿‡æœŸåç”Ÿæˆæ–°çš„ tokenï¼š</p>\n<pre><code>kubeadm token create --print-join-command\n</code></pre>\n<p>Master éœ€è¦ç”Ÿæˆ --certificate-keyï¼š</p>\n<pre><code>kubeadm init phase upload-certs  --upload-certs\n</code></pre>\n<h4 id=\"6-nodeèŠ‚ç‚¹çš„é…ç½®\"><a class=\"anchor\" href=\"#6-nodeèŠ‚ç‚¹çš„é…ç½®\">#</a> 6. Node èŠ‚ç‚¹çš„é…ç½®</h4>\n<p>Node èŠ‚ç‚¹ä¸Šä¸»è¦éƒ¨ç½²å…¬å¸çš„ä¸€äº›ä¸šåŠ¡åº”ç”¨ï¼Œç”Ÿäº§ç¯å¢ƒä¸­ä¸å»ºè®® Master èŠ‚ç‚¹éƒ¨ç½²ç³»ç»Ÿç»„ä»¶ä¹‹å¤–çš„å…¶ä»– Podï¼Œæµ‹è¯•ç¯å¢ƒå¯ä»¥å…è®¸ Master èŠ‚ç‚¹éƒ¨ç½² Pod ä»¥èŠ‚çœç³»ç»Ÿèµ„æºã€‚</p>\n<pre><code>kubeadm join 192.168.1.70:16443 --token 7t2weq.bjbawausm0jaxury \\\n\t--discovery-token-ca-cert-hash sha256:377702f508fe70b9d8ab68beccaa9af1b4609b754e4cc2fcc6185974e1d620b5\n</code></pre>\n<p>æ‰€æœ‰èŠ‚ç‚¹åˆå§‹åŒ–å®Œæˆåï¼ŒæŸ¥çœ‹é›†ç¾¤çŠ¶æ€ï¼ˆNotReady ä¸å½±å“ï¼‰</p>\n<pre><code># kubectl get node\nNAME           STATUS     ROLES           AGE     VERSION\nk8s-master01   NotReady   control-plane   4m23s   v1.32.3\nk8s-master02   NotReady   control-plane   66s     v1.32.3\nk8s-master03   NotReady   control-plane   14s     v1.32.3\nk8s-node01     NotReady   &lt;none&gt;          13s     v1.32.3\nk8s-node02     NotReady   &lt;none&gt;          10s     v1.32.3\n</code></pre>\n<h4 id=\"7-calicoç»„ä»¶çš„å®‰è£…\"><a class=\"anchor\" href=\"#7-calicoç»„ä»¶çš„å®‰è£…\">#</a> 7. Calico ç»„ä»¶çš„å®‰è£…</h4>\n<p><mark>æ‰€æœ‰èŠ‚ç‚¹</mark>ç¦æ­¢ NetworkManager ç®¡ç† Calico çš„ç½‘ç»œæ¥å£ï¼Œé˜²æ­¢æœ‰å†²çªæˆ–å¹²æ‰°ï¼š</p>\n<pre><code>cat &gt;&gt;/etc/NetworkManager/conf.d/calico.conf&lt;&lt;EOF\n[keyfile]\nunmanaged-devices=interface-name:cali*;interface-name:tunl*;interface-name:vxlan.calico;interface-name:vxlan-v6.calico;interface-name:wireguard.cali;interface-name:wg-v6.cali\nEOF\nsystemctl daemon-reload\nsystemctl restart NetworkManager\n</code></pre>\n<p>ä»¥ä¸‹æ­¥éª¤åªåœ¨<mark> master01</mark> æ‰§è¡Œï¼ˆ.x ä¸éœ€è¦æ›´æ”¹ï¼‰ï¼š</p>\n<pre><code>cd /root/k8s-ha-install &amp;&amp; git checkout manual-installation-v1.32.x &amp;&amp; cd calico/\n</code></pre>\n<p>ä¿®æ”¹ Pod ç½‘æ®µï¼š</p>\n<pre><code>POD_SUBNET=`cat /etc/kubernetes/manifests/kube-controller-manager.yaml | grep cluster-cidr= | awk -F= '&#123;print $NF&#125;'`\n\nsed -i &quot;s#POD_CIDR#$&#123;POD_SUBNET&#125;#g&quot; calico.yaml\nkubectl apply -f calico.yaml\n</code></pre>\n<p>æŸ¥çœ‹å®¹å™¨å’ŒèŠ‚ç‚¹çŠ¶æ€ï¼š</p>\n<pre><code>[root@k8s-master01 ~]# kubectl get pods -n kube-system\nNAME                                       READY   STATUS    RESTARTS   AGE\ncalico-kube-controllers-6f497d8478-v2q8c   1/1     Running   0          24h\ncalico-node-7mzmb                          1/1     Running   0          24h\ncalico-node-ljqnl                          1/1     Running   0          24h\ncalico-node-njqlb                          1/1     Running   0          24h\ncalico-node-ph4m4                          1/1     Running   0          24h\ncalico-node-rx8rl                          1/1     Running   0          24h\ncoredns-76fccbbb6b-76559                   1/1     Running   0          24h\ncoredns-76fccbbb6b-hkvn7                   1/1     Running   0          24h\netcd-k8s-master01                          1/1     Running   0          24h\netcd-k8s-master02                          1/1     Running   0          24h\netcd-k8s-master03                          1/1     Running   0          24h\nkube-apiserver-k8s-master01                1/1     Running   0          24h\nkube-apiserver-k8s-master02                1/1     Running   0          24h\nkube-apiserver-k8s-master03                1/1     Running   0          24h\nkube-controller-manager-k8s-master01       1/1     Running   0          24h\nkube-controller-manager-k8s-master02       1/1     Running   0          24h\nkube-controller-manager-k8s-master03       1/1     Running   0          24h\nkube-proxy-9dtz4                           1/1     Running   0          24h\nkube-proxy-jh7rl                           1/1     Running   0          24h\nkube-proxy-jvvwt                           1/1     Running   0          24h\nkube-proxy-sh89l                           1/1     Running   0          24h\nkube-proxy-t2j49                           1/1     Running   0          24h\nkube-scheduler-k8s-master01                1/1     Running   0          24h\nkube-scheduler-k8s-master02                1/1     Running   0          24h\nkube-scheduler-k8s-master03                1/1     Running   0          24h\nmetrics-server-7d9d8df576-jgnp2            1/1     Running   0          24h\n</code></pre>\n<p>æ­¤æ—¶èŠ‚ç‚¹å…¨éƒ¨å˜ä¸º Ready çŠ¶æ€ï¼š</p>\n<pre><code>[root@k8s-master01 ~]# kubectl get nodes\nNAME           STATUS   ROLES           AGE   VERSION\nk8s-master01   Ready    control-plane   24h   v1.32.3\nk8s-master02   Ready    control-plane   24h   v1.32.3\nk8s-master03   Ready    control-plane   24h   v1.32.3\nk8s-node01     Ready    &lt;none&gt;          24h   v1.32.3\nk8s-node02     Ready    &lt;none&gt;          24h   v1.32.3\n</code></pre>\n<h4 id=\"8-metricséƒ¨ç½²\"><a class=\"anchor\" href=\"#8-metricséƒ¨ç½²\">#</a> 8. Metrics éƒ¨ç½²</h4>\n<p>åœ¨æ–°ç‰ˆçš„ Kubernetes ä¸­ç³»ç»Ÿèµ„æºçš„é‡‡é›†å‡ä½¿ç”¨ Metrics-serverï¼Œå¯ä»¥é€šè¿‡ Metrics é‡‡é›†èŠ‚ç‚¹å’Œ Pod çš„å†…å­˜ã€ç£ç›˜ã€CPU å’Œç½‘ç»œçš„ä½¿ç”¨ç‡ã€‚</p>\n<p>å°†<mark> Master01 èŠ‚ç‚¹</mark>çš„ front-proxy-ca.crt å¤åˆ¶åˆ°æ‰€æœ‰ Node èŠ‚ç‚¹</p>\n<pre><code>scp /etc/kubernetes/pki/front-proxy-ca.crt k8s-node01:/etc/kubernetes/pki/front-proxy-ca.crt\n\nscp /etc/kubernetes/pki/front-proxy-ca.crt k8s-node(å…¶ä»–èŠ‚ç‚¹è‡ªè¡Œæ‹·è´):/etc/kubernetes/pki/front-proxy-ca.crt\n</code></pre>\n<p>ä»¥ä¸‹æ“ä½œå‡åœ¨<mark> master01 èŠ‚ç‚¹</mark>æ‰§è¡Œ:</p>\n<p>å®‰è£… metrics server</p>\n<pre><code>cd /root/k8s-ha-install/kubeadm-metrics-server\n\n# kubectl  create -f comp.yaml \nserviceaccount/metrics-server created\nclusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created\nclusterrole.rbac.authorization.k8s.io/system:metrics-server created\nrolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created\nclusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created\nclusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created\nservice/metrics-server created\ndeployment.apps/metrics-server created\napiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created\n</code></pre>\n<p>æŸ¥çœ‹çŠ¶æ€ï¼š</p>\n<pre><code>[root@k8s-master01 ~]# kubectl get po -n kube-system -l k8s-app=metrics-server\nNAME                              READY   STATUS    RESTARTS   AGE\nmetrics-server-7d9d8df576-jgnp2   1/1     Running   0          24h\n</code></pre>\n<p>ç­‰ Pod å˜æˆ 1/1   Running åï¼ŒæŸ¥çœ‹èŠ‚ç‚¹å’Œ Pod èµ„æºä½¿ç”¨ç‡ï¼š</p>\n<pre><code>[root@k8s-master01 ~]#  kubectl top node\nNAME           CPU(cores)   CPU(%)   MEMORY(bytes)   MEMORY(%)   \nk8s-master01   132m         3%       932Mi           5%          \nk8s-master02   131m         3%       845Mi           5%          \nk8s-master03   148m         3%       912Mi           5%          \nk8s-node01     54m          1%       600Mi           3%          \nk8s-node02     49m          1%       602Mi           3%          \n[root@k8s-master01 ~]#  kubectl top po -A\nNAMESPACE              NAME                                         CPU(cores)   MEMORY(bytes)   \ningress-nginx          ingress-nginx-controller-5v9gl               2m           98Mi            \ningress-nginx          ingress-nginx-controller-r978m               1m           104Mi           \nkrm                    krm-backend-d7ff675d8-vmt9z                  1m           21Mi            \nkrm                    krm-frontend-588ffd677b-c2pgj                1m           4Mi             \nkrm                    nginx-574cf48959-vcfjs                       0m           2Mi             \nkube-system            calico-kube-controllers-6f497d8478-v2q8c     6m           17Mi            \nkube-system            calico-node-7mzmb                            16m          176Mi           \nkube-system            calico-node-ljqnl                            15m          182Mi           \nkube-system            calico-node-njqlb                            19m          180Mi           \nkube-system            calico-node-ph4m4                            15m          178Mi           \nkube-system            calico-node-rx8rl                            17m          180Mi           \nkube-system            coredns-76fccbbb6b-76559                     2m           16Mi            \nkube-system            coredns-76fccbbb6b-hkvn7                     2m           16Mi            \nkube-system            etcd-k8s-master01                            22m          86Mi            \nkube-system            etcd-k8s-master02                            27m          84Mi            \nkube-system            etcd-k8s-master03                            22m          84Mi            \nkube-system            kube-apiserver-k8s-master01                  22m          267Mi           \nkube-system            kube-apiserver-k8s-master02                  20m          242Mi           \nkube-system            kube-apiserver-k8s-master03                  18m          241Mi           \nkube-system            kube-controller-manager-k8s-master01         6m           69Mi            \nkube-system            kube-controller-manager-k8s-master02         2m           21Mi            \nkube-system            kube-controller-manager-k8s-master03         1m           19Mi            \nkube-system            kube-proxy-9dtz4                             11m          30Mi            \nkube-system            kube-proxy-jh7rl                             1m           27Mi            \nkube-system            kube-proxy-jvvwt                             17m          29Mi            \nkube-system            kube-proxy-sh89l                             1m           29Mi            \nkube-system            kube-proxy-t2j49                             16m          29Mi            \nkube-system            kube-scheduler-k8s-master01                  6m           25Mi            \nkube-system            kube-scheduler-k8s-master02                  6m           25Mi            \nkube-system            kube-scheduler-k8s-master03                  6m           25Mi            \nkube-system            metrics-server-7d9d8df576-jgnp2              2m           26Mi            \nkubernetes-dashboard   dashboard-metrics-scraper-69b4796d9b-klnwr   1m           19Mi            \nkubernetes-dashboard   kubernetes-dashboard-778584b9dd-pd5ln        1m           31Mi  \n</code></pre>\n<h4 id=\"9-dashboardéƒ¨ç½²\"><a class=\"anchor\" href=\"#9-dashboardéƒ¨ç½²\">#</a> 9. Dashboard éƒ¨ç½²</h4>\n<h5 id=\"91-å®‰è£…dashboard\"><a class=\"anchor\" href=\"#91-å®‰è£…dashboard\">#</a> 9.1 å®‰è£… Dashboard</h5>\n<p>Dashboard ç”¨äºå±•ç¤ºé›†ç¾¤ä¸­çš„å„ç±»èµ„æºï¼ŒåŒæ—¶ä¹Ÿå¯ä»¥é€šè¿‡ Dashboard å®æ—¶æŸ¥çœ‹ Pod çš„æ—¥å¿—å’Œåœ¨å®¹å™¨ä¸­æ‰§è¡Œä¸€äº›å‘½ä»¤ç­‰ã€‚</p>\n<pre><code>cd /root/k8s-ha-install/dashboard/\n\n[root@k8s-master01 dashboard]# kubectl  create -f .\nserviceaccount/admin-user created\nclusterrolebinding.rbac.authorization.k8s.io/admin-user created\nnamespace/kubernetes-dashboard created\nserviceaccount/kubernetes-dashboard created\nservice/kubernetes-dashboard created\nsecret/kubernetes-dashboard-certs created\nsecret/kubernetes-dashboard-csrf created\nsecret/kubernetes-dashboard-key-holder created\nconfigmap/kubernetes-dashboard-settings created\nrole.rbac.authorization.k8s.io/kubernetes-dashboard created\nclusterrole.rbac.authorization.k8s.io/kubernetes-dashboard created\nrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created\nclusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created\ndeployment.apps/kubernetes-dashboard created\nservice/dashboard-metrics-scraper created\ndeployment.apps/dashboard-metrics-scraper created\n</code></pre>\n<h5 id=\"92-ç™»å½•dashboard\"><a class=\"anchor\" href=\"#92-ç™»å½•dashboard\">#</a> 9.2 ç™»å½• dashboard</h5>\n<p>åœ¨è°·æ­Œæµè§ˆå™¨ï¼ˆChromeï¼‰å¯åŠ¨æ–‡ä»¶ä¸­åŠ å…¥å¯åŠ¨å‚æ•°ï¼Œç”¨äºè§£å†³æ— æ³•è®¿é—® Dashboard çš„é—®é¢˜ï¼Œå‚è€ƒä¸‹å›¾ï¼š</p>\n<pre><code>--test-type --ignore-certificate-errors\n</code></pre>\n<p><a href=\"https://imgse.com/i/pEgWfHJ\"><img loading=\"lazy\" data-src=\"https://s21.ax1x.com/2025/04/09/pEgWfHJ.png\" alt=\"pEgWfHJ.png\" /></a></p>\n<p>æ›´æ”¹ dashboard çš„ svc ä¸º NodePort:</p>\n<pre><code>kubectl edit svc kubernetes-dashboard -n kubernetes-dashboard\n</code></pre>\n<p><a href=\"https://imgse.com/i/pEgW5NR\"><img loading=\"lazy\" data-src=\"https://s21.ax1x.com/2025/04/09/pEgW5NR.png\" alt=\"pEgW5NR.png\" /></a></p>\n<p><em>å°† ClusterIP æ›´æ”¹ä¸º NodePortï¼ˆå¦‚æœå·²ç»ä¸º NodePort å¿½ç•¥æ­¤æ­¥éª¤ï¼‰</em></p>\n<p>æŸ¥çœ‹ç«¯å£å·ï¼š</p>\n<pre><code>[root@k8s-master01 ~]# kubectl get svc kubernetes-dashboard -n kubernetes-dashboard\nNAME                   TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)         AGE\nkubernetes-dashboard   NodePort   10.96.139.11   &lt;none&gt;        443:32409/TCP   24h\n</code></pre>\n<p>æ ¹æ®è‡ªå·±çš„å®ä¾‹ç«¯å£å·ï¼Œé€šè¿‡ä»»æ„å®‰è£…äº† kube-proxy çš„å®¿ä¸»æœºçš„ IP + ç«¯å£å³å¯è®¿é—®åˆ° dashboardï¼š</p>\n<p>è®¿é—® Dashboardï¼š<a href=\"https://192.168.181.129:31106\">https://192.168.1.71:32409</a> ï¼ˆæŠŠ IP åœ°å€å’Œç«¯å£æ”¹æˆä½ è‡ªå·±çš„ï¼‰é€‰æ‹©ç™»å½•æ–¹å¼ä¸ºä»¤ç‰Œï¼ˆå³ token æ–¹å¼ï¼‰ï¼Œå‚è€ƒä¸‹å›¾ï¼š</p>\n<p><a href=\"https://imgse.com/i/pEgW736\"><img loading=\"lazy\" data-src=\"https://s21.ax1x.com/2025/04/09/pEgW736.png\" alt=\"pEgW736.png\" /></a></p>\n<p>åˆ›å»ºç™»å½• Tokenï¼š</p>\n<pre><code>kubectl create token admin-user -n kube-system\n</code></pre>\n<p>å°† token å€¼è¾“å…¥åˆ°ä»¤ç‰Œåï¼Œå•å‡»ç™»å½•å³å¯è®¿é—® Dashboardï¼Œå‚è€ƒä¸‹å›¾ï¼š</p>\n<p><a href=\"https://imgse.com/i/pEgfPv8\"><img loading=\"lazy\" data-src=\"https://s21.ax1x.com/2025/04/09/pEgfPv8.png\" alt=\"pEgfPv8.png\" /></a></p>\n<h4 id=\"10å¿…çœ‹ä¸€äº›å¿…é¡»çš„é…ç½®æ›´æ”¹\"><a class=\"anchor\" href=\"#10å¿…çœ‹ä¸€äº›å¿…é¡»çš„é…ç½®æ›´æ”¹\">#</a> 10.ã€å¿…çœ‹ã€‘ä¸€äº›å¿…é¡»çš„é…ç½®æ›´æ”¹</h4>\n<p>å°† Kube-proxy æ”¹ä¸º ipvs æ¨¡å¼ï¼Œå› ä¸ºåœ¨åˆå§‹åŒ–é›†ç¾¤çš„æ—¶å€™æ³¨é‡Šäº† ipvs é…ç½®ï¼Œæ‰€ä»¥éœ€è¦è‡ªè¡Œä¿®æ”¹ä¸€ä¸‹ï¼š</p>\n<p>åœ¨ master01 èŠ‚ç‚¹æ‰§è¡Œï¼š</p>\n<pre><code>kubectl edit cm kube-proxy -n kube-system\nmode: ipvs\n</code></pre>\n<p>æ›´æ–° Kube-Proxy çš„ Podï¼š</p>\n<pre><code>kubectl patch daemonset kube-proxy -p &quot;&#123;\\&quot;spec\\&quot;:&#123;\\&quot;template\\&quot;:&#123;\\&quot;metadata\\&quot;:&#123;\\&quot;annotations\\&quot;:&#123;\\&quot;date\\&quot;:\\&quot;`date +'%s'`\\&quot;&#125;&#125;&#125;&#125;&#125;&quot; -n kube-system\n</code></pre>\n<p>éªŒè¯ Kube-Proxy æ¨¡å¼:</p>\n<pre><code>[root@k8s-master01]# curl 127.0.0.1:10249/proxyMode\nipvs\n</code></pre>\n<h4 id=\"11å¿…çœ‹æ³¨æ„äº‹é¡¹\"><a class=\"anchor\" href=\"#11å¿…çœ‹æ³¨æ„äº‹é¡¹\">#</a> 11.ã€å¿…çœ‹ã€‘æ³¨æ„äº‹é¡¹</h4>\n<p>æ³¨æ„ï¼škubeadm å®‰è£…çš„é›†ç¾¤ï¼Œè¯ä¹¦æœ‰æ•ˆæœŸé»˜è®¤æ˜¯ä¸€å¹´ã€‚master èŠ‚ç‚¹çš„ kube-apiserverã€kube-schedulerã€kube-controller-managerã€etcd éƒ½æ˜¯ä»¥å®¹å™¨è¿è¡Œçš„ã€‚å¯ä»¥é€šè¿‡ kubectl get po -n kube-system æŸ¥çœ‹ã€‚</p>\n<p>å¯åŠ¨å’ŒäºŒè¿›åˆ¶ä¸åŒçš„æ˜¯ï¼Œkubelet çš„é…ç½®æ–‡ä»¶åœ¨ /etc/sysconfig/kubelet å’Œ /var/lib/kubelet/config.yamlï¼Œä¿®æ”¹åéœ€è¦é‡å¯ kubelet è¿›ç¨‹ã€‚</p>\n<p>å…¶ä»–ç»„ä»¶çš„é…ç½®æ–‡ä»¶åœ¨ /etc/kubernetes/manifests ç›®å½•ä¸‹ï¼Œæ¯”å¦‚ kube-apiserver.yamlï¼Œè¯¥ yaml æ–‡ä»¶æ›´æ”¹åï¼Œkubelet ä¼šè‡ªåŠ¨åˆ·æ–°é…ç½®ï¼Œä¹Ÿå°±æ˜¯ä¼šé‡å¯ podã€‚ä¸èƒ½å†æ¬¡åˆ›å»ºè¯¥æ–‡ä»¶ã€‚</p>\n<p>kube-proxy çš„é…ç½®åœ¨ kube-system å‘½åç©ºé—´ä¸‹çš„ configmap ä¸­ï¼Œå¯ä»¥é€šè¿‡</p>\n<pre><code>kubectl edit cm kube-proxy -n kube-system\n</code></pre>\n<p>è¿›è¡Œæ›´æ”¹ï¼Œæ›´æ”¹å®Œæˆåï¼Œå¯ä»¥é€šè¿‡ patch é‡å¯ kube-proxy</p>\n<pre><code>kubectl patch daemonset kube-proxy -p &quot;&#123;\\&quot;spec\\&quot;:&#123;\\&quot;template\\&quot;:&#123;\\&quot;metadata\\&quot;:&#123;\\&quot;annotations\\&quot;:&#123;\\&quot;date\\&quot;:\\&quot;`date +'%s'`\\&quot;&#125;&#125;&#125;&#125;&#125;&quot; -n kube-system\n</code></pre>\n<p>Kubeadm å®‰è£…åï¼Œmaster èŠ‚ç‚¹é»˜è®¤ä¸å…è®¸éƒ¨ç½² podï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼åˆ é™¤ Taintï¼Œå³å¯éƒ¨ç½² Podï¼š</p>\n<pre><code>[root@k8s-master01 ~]# kubectl  taint node  -l node-role.kubernetes.io/control-plane node-role.kubernetes.io/control-plane:NoSchedule-\n</code></pre>\n<h4 id=\"12-containerdé…ç½®é•œåƒåŠ é€Ÿ\"><a class=\"anchor\" href=\"#12-containerdé…ç½®é•œåƒåŠ é€Ÿ\">#</a> 12. Containerd é…ç½®é•œåƒåŠ é€Ÿ</h4>\n<pre><code># vim /etc/containerd/config.toml\n#æ·»åŠ ä»¥ä¸‹é…ç½®é•œåƒåŠ é€ŸæœåŠ¡\n       [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.mirrors.&quot;docker.io&quot;]\n        endpoint=[&quot;https://dockerproxy.com&quot;, &quot;https://mirror.baidubce.com&quot;,&quot;https://ccr.ccs.tencentyun.com&quot;,&quot;https://docker.m.daocloud.io&quot;,&quot;https://docker.nju.edu.cn&quot;,&quot;https://docker.mirrors.ustc.edu.cn&quot;,&quot;https://registry-1.docker.io&quot;, &quot;https://hbv0b596.mirror.aliyuncs.com&quot;]\n       [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.mirrors.&quot;registry.k8s.io&quot;]\n        endpoint=[&quot;https://dockerproxy.com&quot;, &quot;https://mirror.baidubce.com&quot;,&quot;https://ccr.ccs.tencentyun.com&quot;,&quot;https://docker.m.daocloud.io&quot;,&quot;https://docker.nju.edu.cn&quot;,&quot;https://docker.mirrors.ustc.edu.cn&quot;,&quot;https://hbv0b596.mirror.aliyuncs.com&quot;, &quot;https://k8s.m.daocloud.io&quot;, &quot;https://docker.mirrors.ustc.edu.cn&quot;,&quot;https://hub-mirror.c.163.com&quot;]\n</code></pre>\n<p>æ‰€æœ‰èŠ‚ç‚¹é‡æ–°å¯åŠ¨ Containerdï¼š</p>\n<pre><code># systemctl daemon-reload\n# systemctl restart containerd\n</code></pre>\n<h4 id=\"13-dockeré…ç½®é•œåƒåŠ é€Ÿ\"><a class=\"anchor\" href=\"#13-dockeré…ç½®é•œåƒåŠ é€Ÿ\">#</a> 13. Docker é…ç½®é•œåƒåŠ é€Ÿ</h4>\n<pre><code># sudo mkdir -p /etc/docker\n# sudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'\n&#123;\n  &quot;registry-mirrors&quot;: [\n\t  &quot;https://docker.credclouds.com&quot;,\n\t  &quot;https://k8s.credclouds.com&quot;,\n\t  &quot;https://quay.credclouds.com&quot;,\n\t  &quot;https://gcr.credclouds.com&quot;,\n\t  &quot;https://k8s-gcr.credclouds.com&quot;,\n\t  &quot;https://ghcr.credclouds.com&quot;,\n\t  &quot;https://do.nark.eu.org&quot;,\n\t  &quot;https://docker.m.daocloud.io&quot;,\n\t  &quot;https://docker.nju.edu.cn&quot;,\n\t  &quot;https://docker.mirrors.sjtug.sjtu.edu.cn&quot;,\n\t  &quot;https://docker.1panel.live&quot;,\n\t  &quot;https://docker.rainbond.cc&quot;\n  ], \n  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;] \n&#125;\nEOF\n</code></pre>\n<p>æ‰€æœ‰èŠ‚ç‚¹é‡æ–°å¯åŠ¨ Dockerï¼š</p>\n<pre><code># systemctl daemon-reload\n# systemctl enable --now docker\n</code></pre>\n<p><em>æœ¬æ–‡å‡ºè‡ªäºï¼š<a href=\"https://edu.51cto.com/course/23845.html\">https://edu.51cto.com/course/23845.html</a></em></p>\n",
            "tags": [
                "Kubernetes"
            ]
        },
        {
            "id": "http://ixuyong.cn/posts/1922841233.html",
            "url": "http://ixuyong.cn/posts/1922841233.html",
            "title": "RsyncæœåŠ¡å®è·µ",
            "date_published": "2025-03-30T12:45:48.000Z",
            "content_html": "<h3 id=\"ursyncæœåŠ¡å®è·µu\"><a class=\"anchor\" href=\"#ursyncæœåŠ¡å®è·µu\">#</a> <u>Rsync æœåŠ¡å®è·µ</u></h3>\n<p><strong>ç¯å¢ƒå‡†å¤‡</strong></p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">ä¸»æœºå</th>\n<th style=\"text-align:center\"><strong>IP</strong></th>\n<th><strong>è§’è‰²</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">server</td>\n<td style=\"text-align:center\">192.168.40.101</td>\n<td>rsync æœåŠ¡ç«¯</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">client</td>\n<td style=\"text-align:center\">192.168.40.102</td>\n<td>rsync å®¢æˆ·</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"1rsyncæœåŠ¡ç«¯\"><a class=\"anchor\" href=\"#1rsyncæœåŠ¡ç«¯\">#</a> 1.rsync æœåŠ¡ç«¯</h4>\n<h5 id=\"11-å…³é—­é˜²ç«å¢™-selinux\"><a class=\"anchor\" href=\"#11-å…³é—­é˜²ç«å¢™-selinux\">#</a> 1.1 å…³é—­é˜²ç«å¢™ã€selinux</h5>\n<pre><code>[root@localhost ~]# hostnamectl set-hostname backup\n[root@localhost ~]# bash\n[root@backup ~]# hostnamectl set-hostname aizj_lb01\n[root@backup ~]# systemctl stop firewalld\n[root@backup ~]# systemctl disable firewalld\n[root@backup ~]# sed -i 's/^SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux\n[root@backup ~]# sed -i 's/^SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config\n[root@backup ~]# yum install net-tools vim tree lrzsz wget unzip dos2unix bash-completion  lsof ntp ntpdate git -y\n[root@backup ~]# yum update -y --exclude=kernel* &amp;&amp; reboot\n[root@backup ~]# echo 'Asia/Shanghai' &gt;/etc/timezone\n[root@backup ~]# ntpdate time2.aliyun.com\n[root@backup ~]# crontab -e\n*/5 * * * * /usr/sbin/ntpdate time2.aliyun.com &amp;&gt; /dev/nul\n[root@backup ~]# mkdir /soft /data /scripts /backup\n</code></pre>\n<h5 id=\"12-å®‰è£…rsync\"><a class=\"anchor\" href=\"#12-å®‰è£…rsync\">#</a> 1.2 å®‰è£… rsync</h5>\n<pre><code>[root@backup ~]# yum install -y rsync\n[root@server ~]# systemctl start rsyncd\n[root@server ~]# systemctl enable rsyncd\n[root@backup ~]# useradd -M -s /sbin/nologin rsync\n[root@backup ~]# mkdir -p /backup/mysql  /backup/file\n[root@backup ~]# chown -R rsync.rsync /backup/mysql /backup/file \n</code></pre>\n<h5 id=\"13-ä¿®æ”¹é…ç½®æ–‡ä»¶\"><a class=\"anchor\" href=\"#13-ä¿®æ”¹é…ç½®æ–‡ä»¶\">#</a> 1.3 ä¿®æ”¹é…ç½®æ–‡ä»¶</h5>\n<p><em><mark>#ç”Ÿäº§ç¯å¢ƒä¸­å–æ¶ˆæ³¨é‡Šï¼Œå¯¼è‡´å¤‡ä»½æ•°æ®æŠ¥é”™</mark></em></p>\n<pre><code>#å¸¦æ³¨é‡Šé…ç½®æ–‡ä»¶\n[root@backup ~]# vim /etc/rsyncd.conf\nuid = rsync             #è¿è¡ŒæœåŠ¡çš„ç”¨æˆ·\ngid = rsync             #è¿è¡ŒæœåŠ¡çš„ç»„\nport = 873              #æœåŠ¡ç›‘å¬ç«¯å£\nfake super = yes        #æœåŠ¡æ— éœ€ä½¿ç”¨rootç”¨æˆ·èº«ä»½ï¼Œå³å¯æ¥æ”¶æ–‡ä»¶çš„å®Œæ•´å±æ€§\nuse chroot = no         #ç¦é”¢ç›®å½•,ä¸å…è®¸è·å–rootæƒé™\nmax connections = 200   #æœ€å¤§è¿æ¥æ•°,æœ€å¤šèƒ½æœ‰å¤šå°‘ä¸ªå®¢æˆ·ç«¯è·ŸæœåŠ¡ç«¯çš„873ç«¯å£å»ºç«‹è¿æ¥\ntimeout = 600           #è¶…æ—¶æ—¶é—´\nignore errors          #å¿½ç•¥é”™è¯¯\nread only = false      #å®¢æˆ·æ˜¯å¦åªè¯»\nlist = false           #ä¸å…è®¸æŸ¥çœ‹æ¨¡å—ä¿¡æ¯\nauth users = rsync_backup         #å®šä¹‰è™šæ‹Ÿç”¨æˆ·ï¼Œç”¨æˆ·æ•°æ®ä¼ è¾“\nsecrets file = /etc/rsync.passwd  #å®šä¹‰è™šæ‹Ÿç”¨æˆ·å¯†ç è®¤è¯æ–‡ä»¶\nlog file = /var/log/rsyncd.log    #æ—¥å¿—æ–‡ä»¶å­˜æ”¾çš„ä½ç½®\n[backup_mysql]         #æ¨¡å—å\ncomment = welcome to rsync_backup\npath = /backup/mysql   #æ•°æ®å­˜æ”¾ç›®å½•\n[backup_file]          #æ¨¡å—å\ncomment = welcome to rsync_backup\npath = /backup/file    #æ•°æ®å­˜æ”¾ç›®å½• \n\n#ä¸å¸¦æ³¨é‡Šé…ç½®æ–‡ä»¶\n[root@backup ~]# cat /etc/rsyncd.conf\nuid = rsync        \ngid = rsync         \nport = 873     \nfake super = yes     \nuse chroot = no        \nmax connections = 200  \ntimeout = 600         \nignore errors       \nread only = false    \nlist = false          \nauth users = rsync_backup        \nsecrets file = /etc/rsync.passwd\nlog file = /var/log/rsyncd.log    \n[backup_mysql]       \ncomment = welcome to rsync_backup\npath = /backup/mysql  \n[backup_file]         \ncomment = welcome to rsync_backup\npath = /backup/file \n</code></pre>\n<h5 id=\"4-åˆ›å»ºè™šæ‹Ÿç”¨æˆ·å¯†ç æ–‡ä»¶å¹¶è®¾ç½®æƒé™\"><a class=\"anchor\" href=\"#4-åˆ›å»ºè™šæ‹Ÿç”¨æˆ·å¯†ç æ–‡ä»¶å¹¶è®¾ç½®æƒé™\">#</a> 4. åˆ›å»ºè™šæ‹Ÿç”¨æˆ·å¯†ç æ–‡ä»¶å¹¶è®¾ç½®æƒé™</h5>\n<pre><code>[root@backup ~]# cat /etc/rsync.passwd\nrsync_backup:your passwd\n[root@backup ~]# chmod 600 /etc/rsync.passwd\n[root@backup ~]# systemctl restart rsyncd &amp;&amp; systemctl status rsyncd\n</code></pre>\n<h5 id=\"5-æ£€æŸ¥æœåŠ¡ç«¯å£æ˜¯å¦å¼€å¯\"><a class=\"anchor\" href=\"#5-æ£€æŸ¥æœåŠ¡ç«¯å£æ˜¯å¦å¼€å¯\">#</a> 5. æ£€æŸ¥æœåŠ¡ç«¯å£æ˜¯å¦å¼€å¯</h5>\n<pre><code>[root@backup ~]# netstat -lntp | grep &quot;rsync&quot;\ntcp        0      0 0.0.0.0:873             0.0.0.0:*               LISTEN      20357/rsync         \ntcp6       0      0 :::873                  :::*                    LISTEN      20357/rsync \n</code></pre>\n<h4 id=\"2-rsyncå®¢æˆ·ç«¯\"><a class=\"anchor\" href=\"#2-rsyncå®¢æˆ·ç«¯\">#</a> 2. rsync å®¢æˆ·ç«¯</h4>\n<h5 id=\"21-å®‰è£…rsync\"><a class=\"anchor\" href=\"#21-å®‰è£…rsync\">#</a> 2.1 å®‰è£… rsync</h5>\n<pre><code>[root@db01 ~]# yum install nfs-utils -y\n</code></pre>\n<h5 id=\"22-é…ç½®ä¼ è¾“å¯†ç \"><a class=\"anchor\" href=\"#22-é…ç½®ä¼ è¾“å¯†ç \">#</a> 2.2 é…ç½®ä¼ è¾“å¯†ç </h5>\n<p>æ–¹æ³• 1ï¼šå°†å¯†ç å†™å…¥æ–‡ä»¶</p>\n<pre><code>[root@db01 ~]#  echo 'your passwd' &gt; /etc/rsync.pass\n[root@db01 ~]# cat /etc/rsync.pass \nyour passwd\n[root@db01 ~]# chmod 600 /etc/rsync.pass\n--æµ‹è¯•æ”¶å‘æ•°æ®ï¼š\n[root@db01 ~]# rsync -avz --password-file=/etc/rsync.pass /root/test rsync_backup@192.168.40.101::backup_file\nsending incremental file list\n\nsent 47 bytes  received 20 bytes  134.00 bytes/sec\ntotal size is 0  speedup is 0.00\n</code></pre>\n<p>æ–¹æ³• 2ï¼šä½¿ç”¨å¯†ç ç¯å¢ƒå˜é‡ RSYNC_PASSWORD</p>\n<pre><code>[root@db01 ~]# export RSYNC_PASSWORD='your passwd'\n--æµ‹è¯•æ”¶å‘æ•°æ®ï¼š\n[root@db01 ~]# rsync -avz /root/test rsync_backup@192.168.40.101::backup_file\nsending incremental file list\n\nsent 47 bytes  received 20 bytes  134.00 bytes/sec\ntotal size is 0  speedup is 0.00\n</code></pre>\n<h3 id=\"ursyncä¼ä¸šçº§å¤‡ä»½æ¡ˆä¾‹u\"><a class=\"anchor\" href=\"#ursyncä¼ä¸šçº§å¤‡ä»½æ¡ˆä¾‹u\">#</a> <u>Rsync ä¼ä¸šçº§å¤‡ä»½æ¡ˆä¾‹</u></h3>\n<p><strong>ç¯å¢ƒå‡†å¤‡</strong></p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">ä¸»æœºå</th>\n<th style=\"text-align:center\"><strong>IP</strong></th>\n<th><strong>è§’è‰²</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">server</td>\n<td style=\"text-align:center\">192.168.40.101</td>\n<td>rsync æœåŠ¡ç«¯</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">client</td>\n<td style=\"text-align:center\">192.168.40.102</td>\n<td>rsync å®¢æˆ·</td>\n</tr>\n</tbody>\n</table>\n<p><strong>å®¢æˆ·ç«¯éœ€æ±‚</strong></p>\n<ul>\n<li>å®¢æˆ·ç«¯æ¯å¤©å‡Œæ™¨ 3 ç‚¹å¤‡ä»½ MySQL è‡³ /backup ä¸‹ä»¥ &quot;ä¸»æœºå_IP åœ°å€_å½“å‰æ—¶é—´å‘½å&quot; çš„ç›®å½•ä¸­</li>\n<li>å®¢æˆ·ç«¯æ¨é€ /backup ç›®å½•ä¸‹æ•°æ®å¤‡ä»½ç›®å½•è‡³ Rsync å¤‡ä»½æœåŠ¡å™¨</li>\n<li>å®¢æˆ·ç«¯åªä¿ç•™æœ€è¿‘ä¸ƒå¤©çš„å¤‡ä»½æ•°æ®ï¼Œé¿å…æµªè´¹ç£ç›˜ç©ºé—´</li>\n</ul>\n<p><strong>æœåŠ¡ç«¯éœ€æ±‚</strong></p>\n<ul>\n<li>æœåŠ¡ç«¯éƒ¨ç½² rsync æœåŠ¡ï¼Œç”¨äºæ¥æ”¶ç”¨æˆ·çš„å¤‡ä»½æ•°æ®</li>\n<li>æœåŠ¡ç«¯æ¯å¤©æ ¡éªŒå®¢æˆ·ç«¯æ¨é€è¿‡æ¥çš„æ•°æ®æ˜¯å¦å®Œæ•´ï¼Œå¹¶å°†ç»“æœä»¥é‚®ä»¶çš„æ–¹å¼å‘é€ç»™ç®¡ç†å‘˜</li>\n<li>æœåŠ¡ç«¯ä»…ä¿ç•™ 6 ä¸ªæœˆçš„å¤‡ä»½æ•°æ®</li>\n</ul>\n<p><strong>æ³¨æ„</strong>ï¼šæ‰€æœ‰æœåŠ¡å™¨çš„å¤‡ä»½ç›®å½•å‡ä¸º /backupï¼Œæ‰€æœ‰è„šæœ¬å­˜æ”¾ç›®å½•å‡ä¸º /scriptsã€‚</p>\n<h4 id=\"1-æœåŠ¡ç«¯éƒ¨ç½²rsyncæœåŠ¡\"><a class=\"anchor\" href=\"#1-æœåŠ¡ç«¯éƒ¨ç½²rsyncæœåŠ¡\">#</a> <strong>1. æœåŠ¡ç«¯éƒ¨ç½² rsync æœåŠ¡</strong></h4>\n<h5 id=\"11-å…³é—­é˜²ç«å¢™-selinux-2\"><a class=\"anchor\" href=\"#11-å…³é—­é˜²ç«å¢™-selinux-2\">#</a> 1.1 å…³é—­é˜²ç«å¢™ã€selinux</h5>\n<pre><code>[root@localhost ~]# hostnamectl set-hostname backup\n[root@localhost ~]# bash\n[root@backup ~]# hostnamectl set-hostname aizj_lb01\n[root@backup ~]# systemctl stop firewalld\n[root@backup ~]# systemctl disable firewalld\n[root@backup ~]# sed -i 's/^SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux\n[root@backup ~]# sed -i 's/^SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config\n[root@backup ~]# yum install net-tools vim tree lrzsz wget unzip dos2unix bash-completion  lsof ntp ntpdate git -y\n[root@backup ~]# yum update -y --exclude=kernel* &amp;&amp; reboot\n[root@backup ~]# echo 'Asia/Shanghai' &gt;/etc/timezone\n[root@backup ~]# ntpdate time2.aliyun.com\n[root@backup ~]# crontab -e\n*/5 * * * * /usr/sbin/ntpdate time2.aliyun.com &amp;&gt; /dev/nul\n[root@backup ~]# mkdir /soft /data /scripts /backup\n</code></pre>\n<h5 id=\"12-å®‰è£…rsync-2\"><a class=\"anchor\" href=\"#12-å®‰è£…rsync-2\">#</a> 1.2 å®‰è£… rsync</h5>\n<pre><code>[root@backup ~]# yum install -y rsync\n[root@server ~]# systemctl start rsyncd\n[root@server ~]# systemctl enable rsyncd\n[root@backup ~]# useradd -M -s /sbin/nologin rsync\n[root@backup ~]# mkdir -p /backup/mysql  /backup/file\n[root@backup ~]# chown -R rsync.rsync /backup/mysql /backup/file \n</code></pre>\n<h5 id=\"13-ä¿®æ”¹é…ç½®æ–‡ä»¶-2\"><a class=\"anchor\" href=\"#13-ä¿®æ”¹é…ç½®æ–‡ä»¶-2\">#</a> 1.3 ä¿®æ”¹é…ç½®æ–‡ä»¶</h5>\n<p><em><mark>#ç”Ÿäº§ç¯å¢ƒä¸­å–æ¶ˆæ³¨é‡Šï¼Œå¯¼è‡´å¤‡ä»½æ•°æ®æŠ¥é”™</mark></em></p>\n<pre><code>#å¸¦æ³¨é‡Šé…ç½®æ–‡ä»¶\n[root@backup ~]# vim /etc/rsyncd.conf\nuid = rsync             #è¿è¡ŒæœåŠ¡çš„ç”¨æˆ·\ngid = rsync             #è¿è¡ŒæœåŠ¡çš„ç»„\nport = 873              #æœåŠ¡ç›‘å¬ç«¯å£\nfake super = yes        #æœåŠ¡æ— éœ€ä½¿ç”¨rootç”¨æˆ·èº«ä»½ï¼Œå³å¯æ¥æ”¶æ–‡ä»¶çš„å®Œæ•´å±æ€§\nuse chroot = no         #ç¦é”¢ç›®å½•,ä¸å…è®¸è·å–rootæƒé™\nmax connections = 200   #æœ€å¤§è¿æ¥æ•°,æœ€å¤šèƒ½æœ‰å¤šå°‘ä¸ªå®¢æˆ·ç«¯è·ŸæœåŠ¡ç«¯çš„873ç«¯å£å»ºç«‹è¿æ¥\ntimeout = 600           #è¶…æ—¶æ—¶é—´\nignore errors          #å¿½ç•¥é”™è¯¯\nread only = false      #å®¢æˆ·æ˜¯å¦åªè¯»\nlist = false           #ä¸å…è®¸æŸ¥çœ‹æ¨¡å—ä¿¡æ¯\nauth users = rsync_backup         #å®šä¹‰è™šæ‹Ÿç”¨æˆ·ï¼Œç”¨æˆ·æ•°æ®ä¼ è¾“\nsecrets file = /etc/rsync.passwd  #å®šä¹‰è™šæ‹Ÿç”¨æˆ·å¯†ç è®¤è¯æ–‡ä»¶\nlog file = /var/log/rsyncd.log    #æ—¥å¿—æ–‡ä»¶å­˜æ”¾çš„ä½ç½®\n[backup_mysql]         #æ¨¡å—å\ncomment = welcome to rsync_backup\npath = /backup/mysql   #æ•°æ®å­˜æ”¾ç›®å½•\n[backup_file]          #æ¨¡å—å\ncomment = welcome to rsync_backup\npath = /backup/file    #æ•°æ®å­˜æ”¾ç›®å½• \n\n#ä¸å¸¦æ³¨é‡Šé…ç½®æ–‡ä»¶\n[root@backup ~]# cat /etc/rsyncd.conf\nuid = rsync        \ngid = rsync         \nport = 873     \nfake super = yes     \nuse chroot = no        \nmax connections = 200  \ntimeout = 600         \nignore errors       \nread only = false    \nlist = false          \nauth users = rsync_backup        \nsecrets file = /etc/rsync.passwd\nlog file = /var/log/rsyncd.log    \n[backup_mysql]       \ncomment = welcome to rsync_backup\npath = /backup/mysql  \n[backup_file]         \ncomment = welcome to rsync_backup\npath = /backup/file \n</code></pre>\n<h5 id=\"4-åˆ›å»ºè™šæ‹Ÿç”¨æˆ·å¯†ç æ–‡ä»¶å¹¶è®¾ç½®æƒé™-2\"><a class=\"anchor\" href=\"#4-åˆ›å»ºè™šæ‹Ÿç”¨æˆ·å¯†ç æ–‡ä»¶å¹¶è®¾ç½®æƒé™-2\">#</a> 4. åˆ›å»ºè™šæ‹Ÿç”¨æˆ·å¯†ç æ–‡ä»¶å¹¶è®¾ç½®æƒé™</h5>\n<pre><code>[root@backup ~]# cat /etc/rsync.passwd\nrsync_backup:your passwd\n[root@backup ~]# chmod 600 /etc/rsync.passwd\n[root@backup ~]# systemctl restart rsyncd &amp;&amp; systemctl status rsyncd\n</code></pre>\n<h5 id=\"5-æ£€æŸ¥æœåŠ¡ç«¯å£æ˜¯å¦å¼€å¯-2\"><a class=\"anchor\" href=\"#5-æ£€æŸ¥æœåŠ¡ç«¯å£æ˜¯å¦å¼€å¯-2\">#</a> 5. æ£€æŸ¥æœåŠ¡ç«¯å£æ˜¯å¦å¼€å¯</h5>\n<pre><code>[root@backup ~]# netstat -lntp | grep &quot;rsync&quot;\ntcp        0      0 0.0.0.0:873             0.0.0.0:*               LISTEN      20357/rsync         \ntcp6       0      0 :::873                  :::*                    LISTEN      20357/rsync \n</code></pre>\n<h4 id=\"2-rsyncå®¢æˆ·ç«¯-2\"><a class=\"anchor\" href=\"#2-rsyncå®¢æˆ·ç«¯-2\">#</a> 2. rsync å®¢æˆ·ç«¯</h4>\n<h5 id=\"21-å®‰è£…rsync-2\"><a class=\"anchor\" href=\"#21-å®‰è£…rsync-2\">#</a> 2.1 å®‰è£… rsync</h5>\n<pre><code>[root@db01 ~]# yum install nfs-utils -y\n</code></pre>\n<h5 id=\"22-æµ‹è¯•å®¢æˆ·ç«¯å¤‡ä»½æ•°æ®å¹¶æ¨é€è‡³rsyncæœåŠ¡å™¨\"><a class=\"anchor\" href=\"#22-æµ‹è¯•å®¢æˆ·ç«¯å¤‡ä»½æ•°æ®å¹¶æ¨é€è‡³rsyncæœåŠ¡å™¨\">#</a> 2.2 æµ‹è¯•å®¢æˆ·ç«¯å¤‡ä»½æ•°æ®å¹¶æ¨é€è‡³ rsync æœåŠ¡å™¨</h5>\n<pre><code>[root@db01 ~]# export RSYNC_PASSWORD='your passwd'\n[root@db01 ~]# rsync -avz /root/test rsync_backup@192.168.40.101::backup_file\n</code></pre>\n<h5 id=\"23-å®¢æˆ·ç«¯å¤‡ä»½æ•°æ®å¹¶æ¨é€è‡³rsyncæœåŠ¡å™¨\"><a class=\"anchor\" href=\"#23-å®¢æˆ·ç«¯å¤‡ä»½æ•°æ®å¹¶æ¨é€è‡³rsyncæœåŠ¡å™¨\">#</a> <strong>2.3 å®¢æˆ·ç«¯å¤‡ä»½æ•°æ®å¹¶æ¨é€è‡³ rsync æœåŠ¡å™¨</strong></h5>\n<pre><code>[root@db01 ~]# mkdir /scripts\n[root@db01 ~]# cat /scripts/mysql_backup.sh \n#!/bin/bash\nexport PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin\n\n#1ã€å®šä¹‰å˜é‡\nHost=$(hostname)\nIp=$(ifconfig ens192 | awk 'NR==2&#123;print $2&#125;')\nDate=$(date +%F)\nBackupDir=/backup/mysql\nDest=$&#123;BackupDir&#125;/$&#123;Host&#125;_$&#123;Ip&#125;_$&#123;Date&#125;\nFILE_NAME=mysql_backup_`date '+%Y%m%d%H%M%S'`;\nOLDBINLOG=/var/lib/mysql/oldbinlog\n\n#2ã€åˆ›å»ºå¤‡ä»½ç›®å½•\nif [ ! -d $Dest ];then\n  mkdir -p $Dest\nfi\n\n#3ã€å¤‡ä»½ç›®å½•\n/usr/bin/mysqldump -u'root' -p'your passwd' nf_flms &gt; $Dest/nf-flms_$&#123;FILE_NAME&#125;.sql\ntar -czvf $Dest/$&#123;FILE_NAME&#125;.tar.gz $Dest/nf-flms_$&#123;FILE_NAME&#125;.sql\nrm -rf $Dest/*$&#123;FILE_NAME&#125;.sql\necho &quot;Your database backup successfully&quot;\n\n#4ã€æ ¡éªŒ\nmd5sum $Dest/* &gt;$Dest/backup_check_$Date\n\n#5ã€å°†å¤‡ä»½ç›®å½•æ¨åŠ¨åˆ°rsyncæœåŠ¡ç«¯\nRsync_Ip=192.168.1.145\nRsync_user=rsync_backup\nRsync_Module=backup_mysql\nexport RSYNC_PASSWORD=your passwd\nrsync -avz $Dest $Rsync_user@$Rsync_Ip::$Rsync_Module\n\n#6ã€åˆ é™¤15å¤©å¤‡ä»½ç›®å½•\nfind $Dest -type d -mtime +15 | xargs rm -rf\necho &quot;remove file  successfully&quot;\n\n[root@db01 ~]# chmod +x /scripts/etc_backup.sh\n[root@db01 ~]# crontab -e\n00 03 * * * /bin/bash /scripts/mysql_backup.sh &amp;&gt; /dev/null\n</code></pre>\n<h5 id=\"24-æœåŠ¡ç«¯æ ¡éªŒæ•°æ®å¹¶å°†ç»“æœä»¥é‚®ä»¶å‘é€ç»™ç®¡ç†å‘˜\"><a class=\"anchor\" href=\"#24-æœåŠ¡ç«¯æ ¡éªŒæ•°æ®å¹¶å°†ç»“æœä»¥é‚®ä»¶å‘é€ç»™ç®¡ç†å‘˜\">#</a> <strong>2.4 æœåŠ¡ç«¯æ ¡éªŒæ•°æ®å¹¶å°†ç»“æœä»¥é‚®ä»¶å‘é€ç»™ç®¡ç†å‘˜</strong></h5>\n<h6 id=\"241-é…ç½®é‚®ä»¶æœåŠ¡\"><a class=\"anchor\" href=\"#241-é…ç½®é‚®ä»¶æœåŠ¡\">#</a> 2.4.1 é…ç½®é‚®ä»¶æœåŠ¡</h6>\n<pre><code>[root@backup ~]# yum -y install mailx\n[root@backup ~]# cat /etc/mail.rc      #æœ€åä¸€è¡Œæ’å…¥\nset from=373370405@qq.com\nset smtp=smtps://smtp.qq.com:465\nset smtp-auth-user=373370405@qq.com\nset smtp-auth-password=**********   # å‘ä»¶é‚®ç®±çš„æˆæƒç \nset smtp-auth=login\nset ssl-verify=ignore\nset nss-config-dir=/etc/pki/nssdb\n</code></pre>\n<h6 id=\"242-å‘é€é‚®ä»¶æµ‹è¯•\"><a class=\"anchor\" href=\"#242-å‘é€é‚®ä»¶æµ‹è¯•\">#</a> 2.4.2 å‘é€é‚®ä»¶æµ‹è¯•</h6>\n<pre><code>[root@backup ~]#  echo Hello World | mail -s test 373370405@qq.com &amp;&gt; /dev/null\n</code></pre>\n<h6 id=\"243-é…ç½®è„šæœ¬æ ¡éªŒæ•°æ®å¹¶å°†ç»“æœå‘é€ç»™ç®¡ç†å‘˜\"><a class=\"anchor\" href=\"#243-é…ç½®è„šæœ¬æ ¡éªŒæ•°æ®å¹¶å°†ç»“æœå‘é€ç»™ç®¡ç†å‘˜\">#</a> 2.4.3 é…ç½®è„šæœ¬æ ¡éªŒæ•°æ®å¹¶å°†ç»“æœå‘é€ç»™ç®¡ç†å‘˜</h6>\n<pre><code>[root@backup mysql]# cat /scripts/check_backup.sh \n#!/bin/bash\nexport PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin\n\n#1ã€å®šä¹‰å˜é‡\nPath=/backup/mysql\nDate=$(date +%F)\n\n#2ã€æŸ¥çœ‹flagæ–‡ä»¶ï¼Œå¹¶å¯¹å¯¹æ–‡ä»¶è¿›è¡Œæ ¡éªŒ,ç„¶åå°†æ ¡éªŒçš„ç»“æœä¿å­˜è‡³result_æ—¶é—´\nfind $Path -type f -name &quot;backup_check_$&#123;Date&#125;*&quot;|xargs md5sum -c &gt;$Path/result_$&#123;Date&#125;\n\n#3ã€å°†æ ¡éªŒç»“æœå‘é€é‚®ä»¶ç»™ç®¡ç†å‘˜\nmail -s &quot;Mysql Backup&quot; 373370405@qq.com &lt;$Path/result_$&#123;Date&#125; &amp;&gt; /dev/null\n\n#4ã€åˆ é™¤è¶…è¿‡7å¤©çš„æ ¡éªŒç»“æœæ–‡ä»¶ï¼Œåˆ é™¤è¶…è¿‡180å¤©çš„å¤‡ä»½æ•°æ®æ–‡ä»¶\nfind $Path -type f -name &quot;result*&quot; -mtime +7 | xargs rm -rf\nfind $Path -type f -mtime +180 | xargs rm -rf\n</code></pre>\n<h6 id=\"244-å†™è®¡åˆ’ä»»åŠ¡\"><a class=\"anchor\" href=\"#244-å†™è®¡åˆ’ä»»åŠ¡\">#</a> <strong>2.4.4 å†™è®¡åˆ’ä»»åŠ¡</strong></h6>\n<pre><code>[root@backup ~]# chmod +x /scripts/check_backup.sh \n[root@db01 ~]# crontab -e\n00 06 * * * /bin/bash /scripts/mysql_backup.sh &amp;&gt; /dev/null\n</code></pre>\n<h3 id=\"rsyncsersyncå®ç°æ•°æ®å®æ—¶åŒæ­¥\"><a class=\"anchor\" href=\"#rsyncsersyncå®ç°æ•°æ®å®æ—¶åŒæ­¥\">#</a> Rsync+sersync å®ç°æ•°æ®å®æ—¶åŒæ­¥</h3>\n<p><strong>ç¯å¢ƒå‡†å¤‡</strong></p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">ä¸»æœºå</th>\n<th style=\"text-align:center\"><strong>IP</strong></th>\n<th><strong>è§’è‰²</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">server</td>\n<td style=\"text-align:center\">192.168.40.101</td>\n<td>rsync æœåŠ¡ç«¯</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">client</td>\n<td style=\"text-align:center\">192.168.40.102</td>\n<td>rsync å®¢æˆ·</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"1rsyncæœåŠ¡ç«¯-2\"><a class=\"anchor\" href=\"#1rsyncæœåŠ¡ç«¯-2\">#</a> 1.rsync æœåŠ¡ç«¯</h4>\n<h5 id=\"11-å…³é—­é˜²ç«å¢™-selinux-3\"><a class=\"anchor\" href=\"#11-å…³é—­é˜²ç«å¢™-selinux-3\">#</a> 1.1 å…³é—­é˜²ç«å¢™ã€selinux</h5>\n<pre><code>[root@localhost ~]# hostnamectl set-hostname backup\n[root@localhost ~]# bash\n[root@backup ~]# hostnamectl set-hostname aizj_lb01\n[root@backup ~]# systemctl stop firewalld\n[root@backup ~]# systemctl disable firewalld\n[root@backup ~]# sed -i 's/^SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux\n[root@backup ~]# sed -i 's/^SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config\n[root@backup ~]# yum install net-tools vim tree lrzsz wget unzip dos2unix bash-completion  lsof ntp ntpdate git -y\n[root@backup ~]# yum update -y --exclude=kernel* &amp;&amp; reboot\n[root@backup ~]# echo 'Asia/Shanghai' &gt;/etc/timezone\n[root@backup ~]# ntpdate time2.aliyun.com\n[root@backup ~]# crontab -e\n*/5 * * * * /usr/sbin/ntpdate time2.aliyun.com &amp;&gt; /dev/nul\n[root@backup ~]# mkdir /soft /data /scripts /backup\n</code></pre>\n<h5 id=\"12-å®‰è£…rsync-3\"><a class=\"anchor\" href=\"#12-å®‰è£…rsync-3\">#</a> 1.2 å®‰è£… rsync</h5>\n<pre><code>[root@backup ~]# yum install -y rsync\n[root@server ~]# systemctl start rsyncd\n[root@server ~]# systemctl enable rsyncd\n[root@backup ~]# useradd -M -s /sbin/nologin rsync\n[root@backup ~]# mkdir -p /backup/mysql  /backup/file\n[root@backup ~]# chown -R rsync.rsync /backup/mysql /backup/file \n</code></pre>\n<h5 id=\"13-ä¿®æ”¹é…ç½®æ–‡ä»¶-3\"><a class=\"anchor\" href=\"#13-ä¿®æ”¹é…ç½®æ–‡ä»¶-3\">#</a> 1.3 ä¿®æ”¹é…ç½®æ–‡ä»¶</h5>\n<p><em><mark>#ç”Ÿäº§ç¯å¢ƒä¸­å–æ¶ˆæ³¨é‡Šï¼Œå¯¼è‡´å¤‡ä»½æ•°æ®æŠ¥é”™</mark></em></p>\n<pre><code>#å¸¦æ³¨é‡Šé…ç½®æ–‡ä»¶\n[root@backup ~]# vim /etc/rsyncd.conf\nuid = rsync             #è¿è¡ŒæœåŠ¡çš„ç”¨æˆ·\ngid = rsync             #è¿è¡ŒæœåŠ¡çš„ç»„\nport = 873              #æœåŠ¡ç›‘å¬ç«¯å£\nfake super = yes        #æœåŠ¡æ— éœ€ä½¿ç”¨rootç”¨æˆ·èº«ä»½ï¼Œå³å¯æ¥æ”¶æ–‡ä»¶çš„å®Œæ•´å±æ€§\nuse chroot = no         #ç¦é”¢ç›®å½•,ä¸å…è®¸è·å–rootæƒé™\nmax connections = 200   #æœ€å¤§è¿æ¥æ•°,æœ€å¤šèƒ½æœ‰å¤šå°‘ä¸ªå®¢æˆ·ç«¯è·ŸæœåŠ¡ç«¯çš„873ç«¯å£å»ºç«‹è¿æ¥\ntimeout = 600           #è¶…æ—¶æ—¶é—´\nignore errors          #å¿½ç•¥é”™è¯¯\nread only = false      #å®¢æˆ·æ˜¯å¦åªè¯»\nlist = false           #ä¸å…è®¸æŸ¥çœ‹æ¨¡å—ä¿¡æ¯\nauth users = rsync_backup         #å®šä¹‰è™šæ‹Ÿç”¨æˆ·ï¼Œç”¨æˆ·æ•°æ®ä¼ è¾“\nsecrets file = /etc/rsync.passwd  #å®šä¹‰è™šæ‹Ÿç”¨æˆ·å¯†ç è®¤è¯æ–‡ä»¶\nlog file = /var/log/rsyncd.log    #æ—¥å¿—æ–‡ä»¶å­˜æ”¾çš„ä½ç½®\n[backup_mysql]         #æ¨¡å—å\ncomment = welcome to rsync_backup\npath = /backup/mysql   #æ•°æ®å­˜æ”¾ç›®å½•\n[backup_file]          #æ¨¡å—å\ncomment = welcome to rsync_backup\npath = /backup/file    #æ•°æ®å­˜æ”¾ç›®å½• \n\n#ä¸å¸¦æ³¨é‡Šé…ç½®æ–‡ä»¶\n[root@backup ~]# cat /etc/rsyncd.conf\nuid = rsync        \ngid = rsync         \nport = 873     \nfake super = yes     \nuse chroot = no        \nmax connections = 200  \ntimeout = 600         \nignore errors       \nread only = false    \nlist = false          \nauth users = rsync_backup        \nsecrets file = /etc/rsync.passwd\nlog file = /var/log/rsyncd.log    \n[backup_mysql]       \ncomment = welcome to rsync_backup\npath = /backup/mysql  \n[backup_file]         \ncomment = welcome to rsync_backup\npath = /backup/file \n</code></pre>\n<h5 id=\"4-åˆ›å»ºè™šæ‹Ÿç”¨æˆ·å¯†ç æ–‡ä»¶å¹¶è®¾ç½®æƒé™-3\"><a class=\"anchor\" href=\"#4-åˆ›å»ºè™šæ‹Ÿç”¨æˆ·å¯†ç æ–‡ä»¶å¹¶è®¾ç½®æƒé™-3\">#</a> 4. åˆ›å»ºè™šæ‹Ÿç”¨æˆ·å¯†ç æ–‡ä»¶å¹¶è®¾ç½®æƒé™</h5>\n<pre><code>[root@backup ~]# cat /etc/rsync.passwd\nrsync_backup:your passwd\n[root@backup ~]# chmod 600 /etc/rsync.passwd\n[root@backup ~]# systemctl restart rsyncd &amp;&amp; systemctl status rsyncd\n</code></pre>\n<h5 id=\"5-æ£€æŸ¥æœåŠ¡ç«¯å£æ˜¯å¦å¼€å¯-3\"><a class=\"anchor\" href=\"#5-æ£€æŸ¥æœåŠ¡ç«¯å£æ˜¯å¦å¼€å¯-3\">#</a> 5. æ£€æŸ¥æœåŠ¡ç«¯å£æ˜¯å¦å¼€å¯</h5>\n<pre><code>[root@backup ~]# netstat -lntp | grep &quot;rsync&quot;\ntcp        0      0 0.0.0.0:873             0.0.0.0:*               LISTEN      20357/rsync         \ntcp6       0      0 :::873                  :::*                    LISTEN      20357/rsync \n</code></pre>\n<h4 id=\"2-å®¢æˆ·ç«¯å®‰è£…sersync\"><a class=\"anchor\" href=\"#2-å®¢æˆ·ç«¯å®‰è£…sersync\">#</a> 2. å®¢æˆ·ç«¯å®‰è£… sersync</h4>\n<p><strong>2.1 å®‰è£… sercync ä¾èµ–</strong></p>\n<pre><code>[root@nfs ~]# yum install -y inotify-tools rsync\n</code></pre>\n<p><strong>2.2 å®‰è£… sercync</strong></p>\n<pre><code>[root@nfs ~]# mkdir -p /soft\n[root@nfs ~]# cd /soft/\n[root@nfs ~]# wget https://down.whsir.com/downloads/sersync2.5.4_64bit_binary_stable_final.tar.gz\n[root@nfs soft]# tar -xf sersync2.5.4_64bit_binary_stable_final.tar.gz\n[root@nfs soft]# mv GNU-Linux-x86 /usr/local/sersync\n</code></pre>\n<h5 id=\"23-ä¿®æ”¹é…ç½®æ–‡ä»¶\"><a class=\"anchor\" href=\"#23-ä¿®æ”¹é…ç½®æ–‡ä»¶\">#</a> 2.3 <strong>ä¿®æ”¹é…ç½®æ–‡ä»¶</strong></h5>\n<pre><code>[root@nfs soft]# cd /usr/local/sersync/\n[root@nfs sersync]# cp confxml.xml confxml.xml.bak\n[root@nfs sersync]# vim confxml.xml\n...\n5    &lt;fileSystem xfs=&quot;true&quot;/&gt;    #ç¬¬5è¡Œ falseæ”¹ä¸ºtrue\n13          &lt;delete start=&quot;true&quot;/&gt; #ç¬¬13-20è¡Œ falseæ”¹ä¸ºtrue,#è¯´æ˜ï¼šç›‘æ§ä»¥ä¸Šå˜åŒ–æ¨é€\n14        &lt;createFolder start=&quot;true&quot;/&gt;\n15        &lt;createFile start=&quot;false&quot;/&gt;\n16        &lt;closeWrite start=&quot;true&quot;/&gt;\n17        &lt;moveFrom start=&quot;true&quot;/&gt;\n18        &lt;moveTo start=&quot;true&quot;/&gt;\n19        &lt;attrib start=&quot;true&quot;/&gt;\n20        &lt;modify start=&quot;true&quot;/&gt;\n24        &lt;localpath watch=&quot;/data&quot;&gt;      #ç›‘æ§çš„æœ¬åœ°ç›®å½•\n25             &lt;remote ip=&quot;192.168.1.145&quot; name=&quot;backup_file&quot;/&gt;  #rsyncæœåŠ¡ç«¯IPå’Œæ¨¡å—åbackup_file\n30      &lt;commonParams params=&quot;-avz&quot;/&gt;  #rsyncå‘½ä»¤é€‰é¡¹\n31      &lt;auth start=&quot;true&quot; users=&quot;rsync_backup&quot; passwordfile=&quot;/etc/rsync.passwd&quot;/&gt; #rsyncè®¤è¯ä¿¡æ¯\n...\n</code></pre>\n<h5 id=\"24-ç”Ÿæˆå¯†ç æ–‡ä»¶\"><a class=\"anchor\" href=\"#24-ç”Ÿæˆå¯†ç æ–‡ä»¶\">#</a> 2.4 ç”Ÿæˆå¯†ç æ–‡ä»¶</h5>\n<pre><code>[root@nfs sersync]# echo 'your passwd' &gt; /etc/rsync.passwd\n[root@nfs sersync]# chmod 600 /etc/rsync.passwd\n</code></pre>\n<h5 id=\"25-å¯åŠ¨sersync\"><a class=\"anchor\" href=\"#25-å¯åŠ¨sersync\">#</a> 2.5 å¯åŠ¨ sersync</h5>\n<pre><code>[root@nfs sersync]# ln -s /usr/local/sersync/sersync2 /usr/bin/\n[root@nfs sersync]# sersync2 -dro /usr/local/sersync/confxml.xml     #é’ˆå¯¹é…ç½®æ–‡ä»¶confxml.xmlå¯åŠ¨sersync\n</code></pre>\n<p><strong>2.5 è®¾ç½® sersync å¼€æœºè‡ªå¯</strong></p>\n<pre><code>[root@qzj_nfs sersync]# vim /etc/rc.d/rc.local   \n/usr/local/sersync/sersync2 -d -r -o  /usr/local/sersync/confxml.xml  #åœ¨æœ€åæ·»åŠ ä¸€è¡Œ\n[root@qzj_nfs sersync]# chmod +x /etc/rc.d/rc.local\n</code></pre>\n<p><strong>2.6 æµ‹è¯•</strong></p>\n<p><em>åœ¨å®¢æˆ·ç«¯ /data ç›®å½•å¢åˆ æ”¹ç›®å½•æ–‡ä»¶ï¼Œrsync æœåŠ¡ç«¯æ•°æ®å­˜æ”¾ç›®å½•å˜åŒ–</em></p>\n<pre><code>[root@backup backup]# watch ls\n</code></pre>\n<p><strong>2.7 æ·»åŠ è„šæœ¬ç›‘æ§ sersync æ˜¯å¦æ­£å¸¸è¿è¡Œ</strong></p>\n<pre><code>[root@nfs sersync]# cat /scripts/check_sersync.sh \n#!/bin/sh\nsersync=&quot;/usr/local/sersync/sersync2&quot;\nconfxml=&quot;/usr/local/sersync/confxml.xml&quot;\nstatus=$(ps aux |grep 'sersync2'|grep -v 'grep'|wc -l)\nif [ $status -eq 0 ];\nthen\n$sersync -d -r -o $confxml &amp;\nelse\nexit 0;\nfi\n\n[root@nfs sersync]# chmod +x /scripts/check_sersync.sh\n[root@nfs sersync]# crontab -l\n*/5 * * * * /usr/bin/sh /scripts/check_sersync.sh &amp;&gt; /dev/null\n</code></pre>\n<p><em><strong>è¡¥å……ï¼š å¤šå®ä¾‹æƒ…å†µ</strong></em><br />\n 1ã€é…ç½®å¤šä¸ª confxml.xml æ–‡ä»¶ï¼ˆæ¯”å¦‚ï¼šwwwã€bbsã€blog.... ç­‰ç­‰ï¼‰<br />\n2ã€ä¿®æ”¹ç«¯å£ã€åŒæ­¥è·¯å¾„ã€æ¨¡å—åç§°<br />\n 3ã€æ ¹æ®ä¸åŒçš„éœ€æ±‚åŒæ­¥å¯¹åº”çš„å®ä¾‹æ–‡ä»¶<br />\n /usr/local/sersync/sersync2 -dro /usr/local/sersync/www_confxml.xml<br />\n/usr/local/sersync/sersync2 -dro /usr/local/sersync/bbs_confxml.xml</p>\n",
            "tags": [
                "rsync"
            ]
        },
        {
            "id": "http://ixuyong.cn/posts/3071070978.html",
            "url": "http://ixuyong.cn/posts/3071070978.html",
            "title": "ä¼ä¸šçº§ç§æœ‰ä»“åº“Harboræ­å»º",
            "date_published": "2025-03-30T08:17:00.000Z",
            "content_html": "<h3 id=\"ä¼ä¸šçº§ç§æœ‰ä»“åº“harbor\"><a class=\"anchor\" href=\"#ä¼ä¸šçº§ç§æœ‰ä»“åº“harbor\">#</a> ä¼ä¸šçº§ç§æœ‰ä»“åº“ Harbor</h3>\n<p>ä¼ä¸šéƒ¨ç½² Kuberetes é›†ç¾¤ç¯å¢ƒä¹‹åï¼Œæˆ‘ä»¬å°±å¯ä»¥å°†åŸæ¥åœ¨ä¼ ç»Ÿè™šæ‹Ÿæœºä¸Šè¿è¡Œçš„ä¸šåŠ¡ï¼Œè¿ç§»åˆ° kubernetes ä¸Šï¼Œè®© Kubernetes é€šè¿‡å®¹å™¨çš„æ–¹å¼æ¥ç®¡ç†ã€‚è€Œä¸€æ—¦æˆ‘ä»¬éœ€è¦å°†ä¼ ç»Ÿä¸šåŠ¡ä½¿ç”¨å®¹å™¨çš„æ–¹å¼è¿è¡Œèµ·æ¥ï¼Œå°±éœ€è¦æ„å»ºå¾ˆå¤šé•œåƒï¼Œé‚£ä¹ˆè¿™äº›é•œåƒå°±éœ€è¦æœ‰ä¸€ä¸ªä¸“é—¨çš„ä½ç½®å­˜å‚¨èµ·æ¥ï¼Œä¸ºæˆ‘ä»¬æä¾›é•œåƒä¸Šä¼ å’Œé•œåƒä¸‹è½½ç­‰åŠŸèƒ½ã€‚ä½†æˆ‘ä»¬ä¸èƒ½ä½¿ç”¨é˜¿é‡Œäº‘æˆ–è€… Dockerhub ç­‰ä»“åº“ï¼Œé¦–å…ˆæ‹‰å–é€Ÿåº¦æ¯”è¾ƒæ…¢ï¼Œå…¶æ¬¡é•œåƒçš„å®‰å…¨æ€§æ— æ³•ä¿è¯ï¼Œæ‰€ä»¥å°±éœ€è¦éƒ¨ç½²ä¸€ä¸ªç§æœ‰çš„é•œåƒä»“åº“æ¥ç®¡ç†è¿™äº›å®¹å™¨é•œåƒã€‚åŒæ—¶è¯¥ä»“åº“è¿˜éœ€è¦æä¾›é«˜å¯ç”¨åŠŸèƒ½ï¼Œç¡®ä¿éšæ—¶éƒ½èƒ½ä¸Šä¼ å’Œä¸‹è½½å¯ç”¨çš„å®¹å™¨é•œåƒã€‚</p>\n<h4 id=\"1-å…³é—­é˜²ç«å¢™-selinux-ç¯å¢ƒé…ç½®\"><a class=\"anchor\" href=\"#1-å…³é—­é˜²ç«å¢™-selinux-ç¯å¢ƒé…ç½®\">#</a> 1ã€å…³é—­é˜²ç«å¢™ã€Selinuxã€ç¯å¢ƒé…ç½®</h4>\n<pre><code>[root@harbor ~]# sudo mkdir -p /etc/docker\n[root@harbor ~]# hostnamectl set-hostname harbor\n[root@harbor ~]# systemctl stop firewalld\n[root@harbor ~]# systemctl disable firewalld\n[root@harbor ~]# sed -i 's/^SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux\n[root@harbor ~]# yum install net-tools vim tree lrzsz wget unzip dos2unix bash-completion  lsof ntp ntpdate -y\n[root@harbor ~]# yum update -y\n[root@harbor ~]# mkdir /soft /data /scripts /backup\n</code></pre>\n<h4 id=\"2-dockerå®‰è£…\"><a class=\"anchor\" href=\"#2-dockerå®‰è£…\">#</a> 2ã€Docker å®‰è£…</h4>\n<pre><code>[root@harbor ~]# yum install -y yum-utils device-mapper-persistent-data lvm2\n[root@harbor ~]# curl -o /etc/yum.repos.d/docker-ce.repo  https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n[root@harbor ~]# yum list docker-ce --showduplicates |sort -r \n[root@harbor ~]# yum install docker-ce docker-compose -y\n</code></pre>\n<h4 id=\"3-é…ç½®dockeråŠ é€Ÿ\"><a class=\"anchor\" href=\"#3-é…ç½®dockeråŠ é€Ÿ\">#</a> 3ã€é…ç½® Docker åŠ é€Ÿ</h4>\n<pre><code>[root@harbor ~]# sudo mkdir -p /etc/docker\n[root@harbor ~]# sudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'\n&#123;\n  &quot;registry-mirrors&quot;: [\n\t  &quot;https://docker.credclouds.com&quot;,\n\t  &quot;https://k8s.credclouds.com&quot;,\n\t  &quot;https://quay.credclouds.com&quot;,\n\t  &quot;https://gcr.credclouds.com&quot;,\n\t  &quot;https://k8s-gcr.credclouds.com&quot;,\n\t  &quot;https://ghcr.credclouds.com&quot;,\n\t  &quot;https://do.nark.eu.org&quot;,\n\t  &quot;https://docker.m.daocloud.io&quot;,\n\t  &quot;https://docker.nju.edu.cn&quot;,\n\t  &quot;https://docker.mirrors.sjtug.sjtu.edu.cn&quot;,\n\t  &quot;https://docker.1panel.live&quot;,\n\t  &quot;https://docker.rainbond.cc&quot;\n  ], \n  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;] \n&#125;\nEOF\n[root@harbor ~]# systemctl enable docker --now\n</code></pre>\n<h4 id=\"4-å®‰è£…harbor\"><a class=\"anchor\" href=\"#4-å®‰è£…harbor\">#</a> 4ã€å®‰è£… Harbor</h4>\n<pre><code>[root@harbor ~]# cd /soft/\n[root@harbor ~]# wget https://github.com/goharbor/harbor/releases/download/v2.6.1/harbor-offline-installer-v2.6.1.tgz\n[root@harbor soft]# tar xf harbor-offline-installer-v2.6.1.tgz\n[root@harbor soft]# cd harbor\n[root@harbor harbor]# vim harbor.yml\nhostname: 192.168.1.134\n...\n#https:\n#  # https port for harbor, default is 443\n#  port: 443\n#  # The path of cert and key files for nginx\n#  certificate: /your/certificate/path\n#  private_key: /your/private/key/path\n...\nharbor_admin_password: Harbor12345\n[root@harbor harbor]#  ./install.sh\n</code></pre>\n<h4 id=\"5-é…ç½®nginxè´Ÿè½½å‡è¡¡è°ƒåº¦\"><a class=\"anchor\" href=\"#5-é…ç½®nginxè´Ÿè½½å‡è¡¡è°ƒåº¦\">#</a> 5ã€é…ç½® Nginx è´Ÿè½½å‡è¡¡è°ƒåº¦</h4>\n<pre><code>[root@lb ~]# vim s.hmallleasing.com.conf\nserver &#123;\n    listen 443 ssl;\n    server_name harbor.hmallleasing.com;\n    client_max_body_size 1G; \n    ssl_prefer_server_ciphers on;\n    ssl_certificate  /etc/nginx/sslkey/_.hmallleasing.com_chain.crt;\n    ssl_certificate_key  /etc/nginx/sslkey/_.hmallleasing.com_key.key;\n    location / &#123;\n        proxy_pass http://192.168.1.134;\n#      include proxy_params;\n#        proxy_set_header Host $http_host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        \n        proxy_connect_timeout 30;\n        proxy_send_timeout 60;\n        proxy_read_timeout 60;\n        \n        proxy_buffering on;\n        proxy_buffer_size 32k;\n        proxy_buffers 4 128k;\n        proxy_temp_file_write_size 10240k;\t\t\n        proxy_max_temp_file_size 10240k;\n    &#125;\n&#125;\n\nserver &#123;\n    listen 80;\n    server_name s.hmallleasing.com;\n    return 302 https://$server_name$request_uri;\n&#125;\n</code></pre>\n<h4 id=\"6-æ¨é€é•œåƒè‡³harbor\"><a class=\"anchor\" href=\"#6-æ¨é€é•œåƒè‡³harbor\">#</a> 6ã€æ¨é€é•œåƒè‡³ Harbor</h4>\n<pre><code>[root@harbor harbor]# docker tag beae173ccac6 harbor.hmallleasing.com/ops/busybox.v1\n[root@harbor harbor]# docker push harbor.hmallleasing.com/ops/busybox.v1\n[root@harbor harbor]# docker login harbor.hmallleasing.com\n[root@harbor harbor]# docker push harbor.hmallleasing.com/ops/busybox.v1\n</code></pre>\n<h4 id=\"7-harboråœæ­¢ä¸å¯åŠ¨\"><a class=\"anchor\" href=\"#7-harboråœæ­¢ä¸å¯åŠ¨\">#</a> 7ã€Harbor åœæ­¢ä¸å¯åŠ¨</h4>\n<pre><code>#åœç”¨Harbor\n[root@harbor harbor]# pwd\n/soft/harbor\n[root@harbor harbor]# docker-compose stop\n #å¯åŠ¨Harbor\n[root@harbor harbor]# docker-compose up -d\n[root@harbor harbor]# docker-compose start\n</code></pre>\n",
            "tags": [
                "Harbor"
            ]
        }
    ]
}